{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n"
     ]
    }
   ],
   "source": [
    "%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n",
    "\n",
    "import torch\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine.defaults import DefaultPredictor\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import get_detection_dataset_dicts\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data import DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from pycocotools import mask\n",
    "\n",
    "import json\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from detectron2.utils.visualizer import Visualizer, VisImage\n",
    "\n",
    "from detectron2.config import configurable\n",
    "from detectron2.modeling.roi_heads.box_head import build_box_head\n",
    "from detectron2.modeling.roi_heads.roi_heads import StandardROIHeads\n",
    "\n",
    "from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputLayers, fast_rcnn_inference\n",
    "from detectron2.structures import Boxes, ImageList, Instances, pairwise_iou\n",
    "from detectron2.layers import ShapeSpec, batched_nms\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from detectron2.modeling.poolers import ROIPooler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from detectron2.layers import ShapeSpec, batched_nms, cat, cross_entropy, nonzero_tuple\n",
    "from detectron2.utils.events import get_event_storage\n",
    "from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
    "\n",
    "from detectron2.engine.defaults import DefaultTrainer\n",
    "import logging\n",
    "from detectron2.modeling import build_model\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.layers import ShapeSpec\n",
    "import torch\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class NonCocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name):\n",
    "        return COCOEvaluator(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset\n",
      "Starting...\n",
      "guitar_player\n",
      "\u001b[32m[03/04 11:14:09 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 11:14:09 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 11:14:09 d2.data.datasets.coco]: \u001b[0mLoaded 127 images in COCO format from /host/mic21-framework/server/uploads/guitar_player_gt.json\n",
      "\u001b[32m[03/04 11:14:09 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 127 images left.\n",
      "\u001b[32m[03/04 11:14:09 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
      "| guitar player | 124          |  microphone   | 54           |   guitar   | 80           |\n",
      "| digital gui.. | 65           | microphone .. | 52           |            |              |\n",
      "|     total     | 375          |               |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 11:14:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 11:14:09 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 11:14:09 d2.data.common]: \u001b[0mSerializing 127 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 11:14:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.53 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 11:14:10 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 11:14:30 d2.utils.events]: \u001b[0m eta: 0:24:23  iter: 19  total_loss: 2.537  loss_cls: 0.8689  loss_box_reg: 0.9748  loss_mask: 0.632  loss_rpn_cls: 0.02105  loss_rpn_loc: 0.03166  time: 0.9992  data_time: 0.3707  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:14:49 d2.utils.events]: \u001b[0m eta: 0:23:55  iter: 39  total_loss: 2.004  loss_cls: 0.6061  loss_box_reg: 0.8448  loss_mask: 0.4672  loss_rpn_cls: 0.0232  loss_rpn_loc: 0.05194  time: 0.9839  data_time: 0.3039  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:15:09 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 59  total_loss: 1.701  loss_cls: 0.488  loss_box_reg: 0.7788  loss_mask: 0.3165  loss_rpn_cls: 0.01721  loss_rpn_loc: 0.03793  time: 0.9792  data_time: 0.3048  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:15:28 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 79  total_loss: 1.412  loss_cls: 0.4054  loss_box_reg: 0.6302  loss_mask: 0.2636  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.04101  time: 0.9721  data_time: 0.3069  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:15:47 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 99  total_loss: 1.245  loss_cls: 0.3342  loss_box_reg: 0.6099  loss_mask: 0.2466  loss_rpn_cls: 0.008236  loss_rpn_loc: 0.03257  time: 0.9677  data_time: 0.3073  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:16:06 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 119  total_loss: 1.091  loss_cls: 0.3306  loss_box_reg: 0.5026  loss_mask: 0.2287  loss_rpn_cls: 0.006443  loss_rpn_loc: 0.02537  time: 0.9646  data_time: 0.3147  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:16:25 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 139  total_loss: 1.121  loss_cls: 0.3219  loss_box_reg: 0.5307  loss_mask: 0.2292  loss_rpn_cls: 0.007766  loss_rpn_loc: 0.03876  time: 0.9658  data_time: 0.3334  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:16:44 d2.utils.events]: \u001b[0m eta: 0:21:38  iter: 159  total_loss: 1.048  loss_cls: 0.2732  loss_box_reg: 0.5109  loss_mask: 0.219  loss_rpn_cls: 0.007928  loss_rpn_loc: 0.03786  time: 0.9622  data_time: 0.2921  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:17:03 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 179  total_loss: 0.9787  loss_cls: 0.2677  loss_box_reg: 0.4711  loss_mask: 0.2075  loss_rpn_cls: 0.007307  loss_rpn_loc: 0.02266  time: 0.9627  data_time: 0.3284  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:17:22 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 199  total_loss: 0.9934  loss_cls: 0.2568  loss_box_reg: 0.4492  loss_mask: 0.1995  loss_rpn_cls: 0.01073  loss_rpn_loc: 0.03122  time: 0.9594  data_time: 0.2870  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:17:42 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 219  total_loss: 0.8977  loss_cls: 0.24  loss_box_reg: 0.4349  loss_mask: 0.192  loss_rpn_cls: 0.008693  loss_rpn_loc: 0.03623  time: 0.9605  data_time: 0.3288  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:18:01 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 239  total_loss: 0.9562  loss_cls: 0.2382  loss_box_reg: 0.4813  loss_mask: 0.2065  loss_rpn_cls: 0.007872  loss_rpn_loc: 0.03344  time: 0.9597  data_time: 0.3264  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:18:20 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 259  total_loss: 0.9368  loss_cls: 0.2452  loss_box_reg: 0.4631  loss_mask: 0.1995  loss_rpn_cls: 0.00555  loss_rpn_loc: 0.03414  time: 0.9591  data_time: 0.3078  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:18:39 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 279  total_loss: 0.8842  loss_cls: 0.2314  loss_box_reg: 0.413  loss_mask: 0.1847  loss_rpn_cls: 0.006906  loss_rpn_loc: 0.03729  time: 0.9607  data_time: 0.3305  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:18:59 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 299  total_loss: 0.8812  loss_cls: 0.2043  loss_box_reg: 0.4455  loss_mask: 0.1686  loss_rpn_cls: 0.006269  loss_rpn_loc: 0.02659  time: 0.9611  data_time: 0.3128  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:19:17 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 319  total_loss: 0.8549  loss_cls: 0.2229  loss_box_reg: 0.389  loss_mask: 0.1739  loss_rpn_cls: 0.007585  loss_rpn_loc: 0.02805  time: 0.9598  data_time: 0.2963  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:19:36 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 339  total_loss: 0.7788  loss_cls: 0.1598  loss_box_reg: 0.4063  loss_mask: 0.1851  loss_rpn_cls: 0.00573  loss_rpn_loc: 0.02406  time: 0.9583  data_time: 0.2932  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:19:57 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 359  total_loss: 0.8905  loss_cls: 0.2192  loss_box_reg: 0.4043  loss_mask: 0.1801  loss_rpn_cls: 0.005018  loss_rpn_loc: 0.03145  time: 0.9623  data_time: 0.3479  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:20:16 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 379  total_loss: 0.7713  loss_cls: 0.1869  loss_box_reg: 0.3719  loss_mask: 0.1799  loss_rpn_cls: 0.006282  loss_rpn_loc: 0.03638  time: 0.9619  data_time: 0.2930  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:20:35 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 399  total_loss: 0.8361  loss_cls: 0.2009  loss_box_reg: 0.401  loss_mask: 0.1676  loss_rpn_cls: 0.006285  loss_rpn_loc: 0.03048  time: 0.9622  data_time: 0.3165  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:20:55 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 419  total_loss: 0.7864  loss_cls: 0.1749  loss_box_reg: 0.3914  loss_mask: 0.179  loss_rpn_cls: 0.006209  loss_rpn_loc: 0.02989  time: 0.9630  data_time: 0.3135  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:21:15 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 439  total_loss: 0.7373  loss_cls: 0.1414  loss_box_reg: 0.3721  loss_mask: 0.1522  loss_rpn_cls: 0.005361  loss_rpn_loc: 0.02809  time: 0.9642  data_time: 0.3227  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:21:34 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 459  total_loss: 0.7549  loss_cls: 0.1695  loss_box_reg: 0.381  loss_mask: 0.1515  loss_rpn_cls: 0.005114  loss_rpn_loc: 0.02995  time: 0.9633  data_time: 0.2977  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:21:54 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 479  total_loss: 0.7622  loss_cls: 0.1584  loss_box_reg: 0.3623  loss_mask: 0.1533  loss_rpn_cls: 0.005176  loss_rpn_loc: 0.03338  time: 0.9651  data_time: 0.3379  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:22:13 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 499  total_loss: 0.6713  loss_cls: 0.1688  loss_box_reg: 0.3234  loss_mask: 0.1451  loss_rpn_cls: 0.005016  loss_rpn_loc: 0.02234  time: 0.9643  data_time: 0.3080  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:22:32 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 519  total_loss: 0.7578  loss_cls: 0.1754  loss_box_reg: 0.3846  loss_mask: 0.172  loss_rpn_cls: 0.004384  loss_rpn_loc: 0.02629  time: 0.9655  data_time: 0.3316  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:22:53 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 539  total_loss: 0.6754  loss_cls: 0.1571  loss_box_reg: 0.3064  loss_mask: 0.1582  loss_rpn_cls: 0.003378  loss_rpn_loc: 0.02992  time: 0.9668  data_time: 0.3397  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:23:11 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 559  total_loss: 0.6518  loss_cls: 0.1415  loss_box_reg: 0.3463  loss_mask: 0.1566  loss_rpn_cls: 0.004857  loss_rpn_loc: 0.02713  time: 0.9657  data_time: 0.3048  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:23:30 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 579  total_loss: 0.6541  loss_cls: 0.1413  loss_box_reg: 0.3143  loss_mask: 0.1428  loss_rpn_cls: 0.003284  loss_rpn_loc: 0.02165  time: 0.9648  data_time: 0.3082  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:23:49 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 599  total_loss: 0.7181  loss_cls: 0.1704  loss_box_reg: 0.3615  loss_mask: 0.156  loss_rpn_cls: 0.004273  loss_rpn_loc: 0.03653  time: 0.9640  data_time: 0.3072  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:24:07 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 619  total_loss: 0.6635  loss_cls: 0.1384  loss_box_reg: 0.3595  loss_mask: 0.1548  loss_rpn_cls: 0.004142  loss_rpn_loc: 0.01911  time: 0.9628  data_time: 0.2953  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:24:27 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 639  total_loss: 0.6777  loss_cls: 0.1479  loss_box_reg: 0.3367  loss_mask: 0.137  loss_rpn_cls: 0.006033  loss_rpn_loc: 0.02643  time: 0.9627  data_time: 0.3308  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:24:46 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 659  total_loss: 0.6883  loss_cls: 0.1578  loss_box_reg: 0.346  loss_mask: 0.1433  loss_rpn_cls: 0.004168  loss_rpn_loc: 0.03072  time: 0.9630  data_time: 0.3135  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 11:25:05 d2.utils.events]: \u001b[0m eta: 0:13:11  iter: 679  total_loss: 0.6554  loss_cls: 0.1406  loss_box_reg: 0.3052  loss_mask: 0.1448  loss_rpn_cls: 0.004585  loss_rpn_loc: 0.02481  time: 0.9626  data_time: 0.3145  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:25:24 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 699  total_loss: 0.6736  loss_cls: 0.1428  loss_box_reg: 0.3413  loss_mask: 0.1582  loss_rpn_cls: 0.002278  loss_rpn_loc: 0.02935  time: 0.9622  data_time: 0.3135  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:25:43 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 719  total_loss: 0.6216  loss_cls: 0.1017  loss_box_reg: 0.3541  loss_mask: 0.1445  loss_rpn_cls: 0.00539  loss_rpn_loc: 0.02424  time: 0.9617  data_time: 0.2958  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:26:02 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 739  total_loss: 0.6234  loss_cls: 0.1341  loss_box_reg: 0.3017  loss_mask: 0.1395  loss_rpn_cls: 0.003311  loss_rpn_loc: 0.02598  time: 0.9616  data_time: 0.3186  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:26:21 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 759  total_loss: 0.6043  loss_cls: 0.1148  loss_box_reg: 0.3087  loss_mask: 0.1454  loss_rpn_cls: 0.002518  loss_rpn_loc: 0.02048  time: 0.9612  data_time: 0.2976  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:26:41 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 779  total_loss: 0.6316  loss_cls: 0.1166  loss_box_reg: 0.3188  loss_mask: 0.1411  loss_rpn_cls: 0.003097  loss_rpn_loc: 0.01861  time: 0.9615  data_time: 0.3417  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:26:59 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 799  total_loss: 0.6209  loss_cls: 0.1227  loss_box_reg: 0.3182  loss_mask: 0.1345  loss_rpn_cls: 0.002474  loss_rpn_loc: 0.02627  time: 0.9605  data_time: 0.2924  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:27:19 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 819  total_loss: 0.6001  loss_cls: 0.1406  loss_box_reg: 0.3096  loss_mask: 0.1275  loss_rpn_cls: 0.003602  loss_rpn_loc: 0.02464  time: 0.9609  data_time: 0.3313  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:27:38 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 839  total_loss: 0.5681  loss_cls: 0.09993  loss_box_reg: 0.2788  loss_mask: 0.1453  loss_rpn_cls: 0.001938  loss_rpn_loc: 0.02102  time: 0.9608  data_time: 0.2918  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:27:57 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 859  total_loss: 0.6009  loss_cls: 0.1196  loss_box_reg: 0.318  loss_mask: 0.1394  loss_rpn_cls: 0.002792  loss_rpn_loc: 0.02401  time: 0.9608  data_time: 0.3071  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:28:16 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 879  total_loss: 0.6092  loss_cls: 0.1398  loss_box_reg: 0.2884  loss_mask: 0.1329  loss_rpn_cls: 0.001689  loss_rpn_loc: 0.01866  time: 0.9609  data_time: 0.3173  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:28:35 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 899  total_loss: 0.6233  loss_cls: 0.1238  loss_box_reg: 0.2924  loss_mask: 0.1326  loss_rpn_cls: 0.002821  loss_rpn_loc: 0.03065  time: 0.9609  data_time: 0.2961  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:28:55 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 919  total_loss: 0.5548  loss_cls: 0.1079  loss_box_reg: 0.2959  loss_mask: 0.1313  loss_rpn_cls: 0.003817  loss_rpn_loc: 0.02435  time: 0.9611  data_time: 0.3295  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:29:13 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 939  total_loss: 0.5496  loss_cls: 0.1129  loss_box_reg: 0.2938  loss_mask: 0.139  loss_rpn_cls: 0.004626  loss_rpn_loc: 0.02941  time: 0.9603  data_time: 0.2851  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:29:33 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 959  total_loss: 0.5541  loss_cls: 0.1133  loss_box_reg: 0.2762  loss_mask: 0.1263  loss_rpn_cls: 0.003037  loss_rpn_loc: 0.02883  time: 0.9610  data_time: 0.3154  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:29:53 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 979  total_loss: 0.5655  loss_cls: 0.119  loss_box_reg: 0.2934  loss_mask: 0.1368  loss_rpn_cls: 0.002314  loss_rpn_loc: 0.02248  time: 0.9613  data_time: 0.3219  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:30:13 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 999  total_loss: 0.5672  loss_cls: 0.1166  loss_box_reg: 0.2698  loss_mask: 0.136  loss_rpn_cls: 0.003622  loss_rpn_loc: 0.02865  time: 0.9617  data_time: 0.3135  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:30:33 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 1019  total_loss: 0.5979  loss_cls: 0.1088  loss_box_reg: 0.2914  loss_mask: 0.1414  loss_rpn_cls: 0.002476  loss_rpn_loc: 0.02366  time: 0.9627  data_time: 0.3410  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:30:52 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 1039  total_loss: 0.5648  loss_cls: 0.08775  loss_box_reg: 0.2744  loss_mask: 0.1319  loss_rpn_cls: 0.002083  loss_rpn_loc: 0.02079  time: 0.9624  data_time: 0.2903  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:31:12 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1059  total_loss: 0.5466  loss_cls: 0.125  loss_box_reg: 0.2387  loss_mask: 0.1339  loss_rpn_cls: 0.003044  loss_rpn_loc: 0.02045  time: 0.9631  data_time: 0.3414  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:31:31 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1079  total_loss: 0.496  loss_cls: 0.09918  loss_box_reg: 0.2375  loss_mask: 0.134  loss_rpn_cls: 0.002651  loss_rpn_loc: 0.02417  time: 0.9635  data_time: 0.3120  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:31:50 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 1099  total_loss: 0.5431  loss_cls: 0.1036  loss_box_reg: 0.2388  loss_mask: 0.1364  loss_rpn_cls: 0.003513  loss_rpn_loc: 0.015  time: 0.9630  data_time: 0.2845  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:32:10 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 1119  total_loss: 0.503  loss_cls: 0.1057  loss_box_reg: 0.2429  loss_mask: 0.1313  loss_rpn_cls: 0.002479  loss_rpn_loc: 0.0342  time: 0.9637  data_time: 0.3320  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:32:29 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 1139  total_loss: 0.5003  loss_cls: 0.1078  loss_box_reg: 0.2371  loss_mask: 0.129  loss_rpn_cls: 0.002454  loss_rpn_loc: 0.02288  time: 0.9636  data_time: 0.3341  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:32:49 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 1159  total_loss: 0.4581  loss_cls: 0.07608  loss_box_reg: 0.2291  loss_mask: 0.1373  loss_rpn_cls: 0.00169  loss_rpn_loc: 0.02217  time: 0.9637  data_time: 0.3137  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:33:08 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 1179  total_loss: 0.4913  loss_cls: 0.09897  loss_box_reg: 0.2169  loss_mask: 0.1278  loss_rpn_cls: 0.002708  loss_rpn_loc: 0.02031  time: 0.9634  data_time: 0.3044  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:33:26 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 1199  total_loss: 0.5001  loss_cls: 0.1163  loss_box_reg: 0.2406  loss_mask: 0.1231  loss_rpn_cls: 0.003079  loss_rpn_loc: 0.02009  time: 0.9627  data_time: 0.3028  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:33:46 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 1219  total_loss: 0.5038  loss_cls: 0.09403  loss_box_reg: 0.2221  loss_mask: 0.1228  loss_rpn_cls: 0.002964  loss_rpn_loc: 0.02278  time: 0.9628  data_time: 0.2885  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:34:05 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 1239  total_loss: 0.5222  loss_cls: 0.1071  loss_box_reg: 0.267  loss_mask: 0.1319  loss_rpn_cls: 0.004042  loss_rpn_loc: 0.02421  time: 0.9626  data_time: 0.3133  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:34:25 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 1259  total_loss: 0.4446  loss_cls: 0.09116  loss_box_reg: 0.1916  loss_mask: 0.1247  loss_rpn_cls: 0.002829  loss_rpn_loc: 0.0222  time: 0.9632  data_time: 0.3430  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:34:43 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 1279  total_loss: 0.4262  loss_cls: 0.08809  loss_box_reg: 0.2015  loss_mask: 0.1195  loss_rpn_cls: 0.003206  loss_rpn_loc: 0.02738  time: 0.9628  data_time: 0.2977  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:35:03 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 1299  total_loss: 0.4595  loss_cls: 0.0985  loss_box_reg: 0.225  loss_mask: 0.1212  loss_rpn_cls: 0.002376  loss_rpn_loc: 0.02248  time: 0.9633  data_time: 0.3300  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:35:23 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 1319  total_loss: 0.5086  loss_cls: 0.1012  loss_box_reg: 0.22  loss_mask: 0.1234  loss_rpn_cls: 0.00247  loss_rpn_loc: 0.02699  time: 0.9637  data_time: 0.3239  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 11:35:43 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 1339  total_loss: 0.5393  loss_cls: 0.123  loss_box_reg: 0.2517  loss_mask: 0.1488  loss_rpn_cls: 0.003307  loss_rpn_loc: 0.02653  time: 0.9643  data_time: 0.3479  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:36:02 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 1359  total_loss: 0.4479  loss_cls: 0.09186  loss_box_reg: 0.2195  loss_mask: 0.1174  loss_rpn_cls: 0.0021  loss_rpn_loc: 0.01823  time: 0.9638  data_time: 0.2896  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:36:21 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 1379  total_loss: 0.4981  loss_cls: 0.1061  loss_box_reg: 0.2055  loss_mask: 0.1374  loss_rpn_cls: 0.003911  loss_rpn_loc: 0.02042  time: 0.9638  data_time: 0.3159  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:36:41 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1399  total_loss: 0.4326  loss_cls: 0.08212  loss_box_reg: 0.2191  loss_mask: 0.1205  loss_rpn_cls: 0.003638  loss_rpn_loc: 0.02785  time: 0.9645  data_time: 0.3311  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:37:01 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 1419  total_loss: 0.4893  loss_cls: 0.09582  loss_box_reg: 0.2242  loss_mask: 0.1234  loss_rpn_cls: 0.002462  loss_rpn_loc: 0.02494  time: 0.9646  data_time: 0.3189  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:37:21 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.5248  loss_cls: 0.1183  loss_box_reg: 0.2381  loss_mask: 0.1332  loss_rpn_cls: 0.003819  loss_rpn_loc: 0.02657  time: 0.9651  data_time: 0.3327  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:37:40 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 1459  total_loss: 0.4436  loss_cls: 0.08337  loss_box_reg: 0.2054  loss_mask: 0.12  loss_rpn_cls: 0.002173  loss_rpn_loc: 0.02005  time: 0.9650  data_time: 0.2810  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:38:00 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.4774  loss_cls: 0.09073  loss_box_reg: 0.2268  loss_mask: 0.1326  loss_rpn_cls: 0.003039  loss_rpn_loc: 0.02629  time: 0.9651  data_time: 0.3059  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:38:20 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4533  loss_cls: 0.08478  loss_box_reg: 0.2183  loss_mask: 0.1179  loss_rpn_cls: 0.00235  loss_rpn_loc: 0.02186  time: 0.9649  data_time: 0.2945  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:38:20 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:05 (0.9649 s / it)\n",
      "\u001b[32m[03/04 11:38:20 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:08 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 11:38:21 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 11:38:21 d2.data.datasets.coco]: \u001b[0mLoaded 141 images in COCO format from /host/mic21-framework/server/uploads/opera_singer_gt.json\n",
      "opera_singer\n",
      "\u001b[32m[03/04 11:38:21 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 11:38:21 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 11:38:21 d2.data.datasets.coco]: \u001b[0mLoaded 141 images in COCO format from /host/mic21-framework/server/uploads/opera_singer_gt.json\n",
      "\u001b[32m[03/04 11:38:21 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 141 images left.\n",
      "\u001b[32m[03/04 11:38:21 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|   category   | #instances   |\n",
      "|:------------:|:-------------|\n",
      "| opera singer | 303          |\n",
      "|              |              |\u001b[0m\n",
      "\u001b[32m[03/04 11:38:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 11:38:21 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 11:38:21 d2.data.common]: \u001b[0mSerializing 141 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 11:38:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.50 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 11:38:22 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 11:38:39 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 19  total_loss: 1.734  loss_cls: 0.3396  loss_box_reg: 0.8747  loss_mask: 0.521  loss_rpn_cls: 0.01586  loss_rpn_loc: 0.007808  time: 0.8330  data_time: 0.2018  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:38:55 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 39  total_loss: 0.9401  loss_cls: 0.1435  loss_box_reg: 0.5455  loss_mask: 0.2611  loss_rpn_cls: 0.006053  loss_rpn_loc: 0.009636  time: 0.8290  data_time: 0.1909  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:39:11 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 59  total_loss: 0.7495  loss_cls: 0.1307  loss_box_reg: 0.4074  loss_mask: 0.1795  loss_rpn_cls: 0.003926  loss_rpn_loc: 0.01263  time: 0.8154  data_time: 0.1653  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:39:27 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 79  total_loss: 0.5481  loss_cls: 0.09784  loss_box_reg: 0.2948  loss_mask: 0.1346  loss_rpn_cls: 0.006637  loss_rpn_loc: 0.007684  time: 0.8190  data_time: 0.1978  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:39:43 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 99  total_loss: 0.6388  loss_cls: 0.1024  loss_box_reg: 0.3302  loss_mask: 0.1681  loss_rpn_cls: 0.004011  loss_rpn_loc: 0.009817  time: 0.8105  data_time: 0.1525  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:39:59 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 119  total_loss: 0.4889  loss_cls: 0.08918  loss_box_reg: 0.2782  loss_mask: 0.1388  loss_rpn_cls: 0.002682  loss_rpn_loc: 0.00744  time: 0.8088  data_time: 0.1727  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:40:15 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 139  total_loss: 0.5469  loss_cls: 0.09672  loss_box_reg: 0.2948  loss_mask: 0.1362  loss_rpn_cls: 0.003157  loss_rpn_loc: 0.01105  time: 0.8068  data_time: 0.1548  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:40:31 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 159  total_loss: 0.4325  loss_cls: 0.07601  loss_box_reg: 0.2482  loss_mask: 0.1209  loss_rpn_cls: 0.002629  loss_rpn_loc: 0.007679  time: 0.8075  data_time: 0.1685  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:40:48 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 179  total_loss: 0.4951  loss_cls: 0.07183  loss_box_reg: 0.2792  loss_mask: 0.1266  loss_rpn_cls: 0.003424  loss_rpn_loc: 0.007253  time: 0.8104  data_time: 0.1946  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:41:04 d2.utils.events]: \u001b[0m eta: 0:17:23  iter: 199  total_loss: 0.4782  loss_cls: 0.08797  loss_box_reg: 0.2303  loss_mask: 0.142  loss_rpn_cls: 0.003455  loss_rpn_loc: 0.008572  time: 0.8080  data_time: 0.1394  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:41:19 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 219  total_loss: 0.4451  loss_cls: 0.0814  loss_box_reg: 0.2291  loss_mask: 0.1294  loss_rpn_cls: 0.00258  loss_rpn_loc: 0.007122  time: 0.8064  data_time: 0.1782  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:41:35 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 239  total_loss: 0.4165  loss_cls: 0.05003  loss_box_reg: 0.2528  loss_mask: 0.1042  loss_rpn_cls: 0.001872  loss_rpn_loc: 0.007536  time: 0.8059  data_time: 0.1683  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:41:51 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 259  total_loss: 0.4996  loss_cls: 0.09355  loss_box_reg: 0.2569  loss_mask: 0.1311  loss_rpn_cls: 0.003217  loss_rpn_loc: 0.008894  time: 0.8039  data_time: 0.1669  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:42:06 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 279  total_loss: 0.4159  loss_cls: 0.07009  loss_box_reg: 0.2257  loss_mask: 0.1015  loss_rpn_cls: 0.002959  loss_rpn_loc: 0.006629  time: 0.8008  data_time: 0.1551  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:42:22 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 299  total_loss: 0.4496  loss_cls: 0.07285  loss_box_reg: 0.2301  loss_mask: 0.1179  loss_rpn_cls: 0.001838  loss_rpn_loc: 0.007799  time: 0.8005  data_time: 0.1604  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:42:38 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 319  total_loss: 0.3719  loss_cls: 0.07444  loss_box_reg: 0.1882  loss_mask: 0.09402  loss_rpn_cls: 0.001988  loss_rpn_loc: 0.008191  time: 0.7998  data_time: 0.1708  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:42:54 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 339  total_loss: 0.4089  loss_cls: 0.0719  loss_box_reg: 0.2082  loss_mask: 0.1304  loss_rpn_cls: 0.003193  loss_rpn_loc: 0.007647  time: 0.7998  data_time: 0.1649  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:43:10 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 359  total_loss: 0.3807  loss_cls: 0.06397  loss_box_reg: 0.2051  loss_mask: 0.09073  loss_rpn_cls: 0.00176  loss_rpn_loc: 0.007306  time: 0.7992  data_time: 0.1520  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:43:26 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 379  total_loss: 0.3922  loss_cls: 0.06237  loss_box_reg: 0.2001  loss_mask: 0.1038  loss_rpn_cls: 0.001279  loss_rpn_loc: 0.007164  time: 0.7996  data_time: 0.1645  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:43:42 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 399  total_loss: 0.4257  loss_cls: 0.07313  loss_box_reg: 0.2138  loss_mask: 0.1265  loss_rpn_cls: 0.001442  loss_rpn_loc: 0.00929  time: 0.7993  data_time: 0.1535  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:43:58 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 419  total_loss: 0.4091  loss_cls: 0.06678  loss_box_reg: 0.2026  loss_mask: 0.09741  loss_rpn_cls: 0.002676  loss_rpn_loc: 0.006737  time: 0.8002  data_time: 0.1647  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:44:15 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 439  total_loss: 0.3638  loss_cls: 0.06151  loss_box_reg: 0.178  loss_mask: 0.08684  loss_rpn_cls: 0.001099  loss_rpn_loc: 0.007755  time: 0.8008  data_time: 0.1710  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:44:30 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 459  total_loss: 0.4011  loss_cls: 0.06624  loss_box_reg: 0.1986  loss_mask: 0.1137  loss_rpn_cls: 0.001139  loss_rpn_loc: 0.006381  time: 0.8002  data_time: 0.1656  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:44:46 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 479  total_loss: 0.395  loss_cls: 0.06063  loss_box_reg: 0.2131  loss_mask: 0.09533  loss_rpn_cls: 0.001497  loss_rpn_loc: 0.009691  time: 0.7998  data_time: 0.1502  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:45:02 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 499  total_loss: 0.3113  loss_cls: 0.04453  loss_box_reg: 0.1705  loss_mask: 0.09261  loss_rpn_cls: 0.00144  loss_rpn_loc: 0.004636  time: 0.7992  data_time: 0.1664  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:45:18 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 519  total_loss: 0.3985  loss_cls: 0.06379  loss_box_reg: 0.1999  loss_mask: 0.1279  loss_rpn_cls: 0.001319  loss_rpn_loc: 0.006684  time: 0.7989  data_time: 0.1608  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:45:34 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 539  total_loss: 0.3441  loss_cls: 0.07789  loss_box_reg: 0.1734  loss_mask: 0.1053  loss_rpn_cls: 0.001642  loss_rpn_loc: 0.007146  time: 0.7988  data_time: 0.1730  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:45:50 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 559  total_loss: 0.4141  loss_cls: 0.06725  loss_box_reg: 0.2124  loss_mask: 0.1145  loss_rpn_cls: 0.001531  loss_rpn_loc: 0.007083  time: 0.7986  data_time: 0.1601  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:46:06 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 579  total_loss: 0.3923  loss_cls: 0.06037  loss_box_reg: 0.1974  loss_mask: 0.122  loss_rpn_cls: 0.001067  loss_rpn_loc: 0.008395  time: 0.7986  data_time: 0.1577  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:46:21 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 599  total_loss: 0.3539  loss_cls: 0.05157  loss_box_reg: 0.1741  loss_mask: 0.09332  loss_rpn_cls: 0.001354  loss_rpn_loc: 0.006192  time: 0.7983  data_time: 0.1636  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:46:38 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 619  total_loss: 0.3654  loss_cls: 0.03959  loss_box_reg: 0.1725  loss_mask: 0.09384  loss_rpn_cls: 0.001726  loss_rpn_loc: 0.006532  time: 0.7994  data_time: 0.1859  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:46:54 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 639  total_loss: 0.3815  loss_cls: 0.06559  loss_box_reg: 0.1794  loss_mask: 0.1121  loss_rpn_cls: 0.001566  loss_rpn_loc: 0.006833  time: 0.7990  data_time: 0.1477  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:47:10 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 659  total_loss: 0.355  loss_cls: 0.05899  loss_box_reg: 0.182  loss_mask: 0.09635  loss_rpn_cls: 0.002003  loss_rpn_loc: 0.0073  time: 0.7987  data_time: 0.1503  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 11:47:25 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 679  total_loss: 0.2826  loss_cls: 0.05107  loss_box_reg: 0.1509  loss_mask: 0.0837  loss_rpn_cls: 0.0007388  loss_rpn_loc: 0.005295  time: 0.7987  data_time: 0.1611  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:47:42 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 699  total_loss: 0.2854  loss_cls: 0.03398  loss_box_reg: 0.1521  loss_mask: 0.08186  loss_rpn_cls: 0.001305  loss_rpn_loc: 0.007863  time: 0.7990  data_time: 0.1575  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:47:59 d2.utils.events]: \u001b[0m eta: 0:10:17  iter: 719  total_loss: 0.3931  loss_cls: 0.06383  loss_box_reg: 0.1912  loss_mask: 0.1004  loss_rpn_cls: 0.0009037  loss_rpn_loc: 0.006936  time: 0.8006  data_time: 0.1812  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:48:15 d2.utils.events]: \u001b[0m eta: 0:10:01  iter: 739  total_loss: 0.3115  loss_cls: 0.03939  loss_box_reg: 0.1651  loss_mask: 0.08807  loss_rpn_cls: 0.001523  loss_rpn_loc: 0.00517  time: 0.8012  data_time: 0.1737  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:48:32 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 759  total_loss: 0.2895  loss_cls: 0.0377  loss_box_reg: 0.1585  loss_mask: 0.08317  loss_rpn_cls: 0.001202  loss_rpn_loc: 0.00644  time: 0.8020  data_time: 0.1765  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:48:48 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 779  total_loss: 0.3496  loss_cls: 0.05905  loss_box_reg: 0.1829  loss_mask: 0.1058  loss_rpn_cls: 0.001336  loss_rpn_loc: 0.006201  time: 0.8017  data_time: 0.1539  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:49:03 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 799  total_loss: 0.337  loss_cls: 0.05092  loss_box_reg: 0.165  loss_mask: 0.08419  loss_rpn_cls: 0.001826  loss_rpn_loc: 0.006899  time: 0.8013  data_time: 0.1533  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:49:20 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 819  total_loss: 0.3392  loss_cls: 0.06102  loss_box_reg: 0.18  loss_mask: 0.08981  loss_rpn_cls: 0.001565  loss_rpn_loc: 0.006267  time: 0.8015  data_time: 0.1692  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:49:35 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 839  total_loss: 0.3784  loss_cls: 0.03823  loss_box_reg: 0.1933  loss_mask: 0.1037  loss_rpn_cls: 0.001127  loss_rpn_loc: 0.007765  time: 0.8012  data_time: 0.1491  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:49:52 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 859  total_loss: 0.3254  loss_cls: 0.04746  loss_box_reg: 0.1694  loss_mask: 0.09752  loss_rpn_cls: 0.001486  loss_rpn_loc: 0.006326  time: 0.8013  data_time: 0.1912  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:50:08 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 879  total_loss: 0.3483  loss_cls: 0.06312  loss_box_reg: 0.1874  loss_mask: 0.106  loss_rpn_cls: 0.001659  loss_rpn_loc: 0.006193  time: 0.8013  data_time: 0.1632  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:50:24 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 899  total_loss: 0.3476  loss_cls: 0.05542  loss_box_reg: 0.1723  loss_mask: 0.111  loss_rpn_cls: 0.0008652  loss_rpn_loc: 0.00553  time: 0.8015  data_time: 0.1648  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:50:40 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 919  total_loss: 0.3234  loss_cls: 0.04166  loss_box_reg: 0.1557  loss_mask: 0.08815  loss_rpn_cls: 0.001224  loss_rpn_loc: 0.006734  time: 0.8017  data_time: 0.1672  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:50:56 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 939  total_loss: 0.3143  loss_cls: 0.04517  loss_box_reg: 0.1539  loss_mask: 0.09665  loss_rpn_cls: 0.001144  loss_rpn_loc: 0.007338  time: 0.8014  data_time: 0.1673  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:51:12 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 959  total_loss: 0.2968  loss_cls: 0.05  loss_box_reg: 0.1546  loss_mask: 0.08829  loss_rpn_cls: 0.0009535  loss_rpn_loc: 0.005409  time: 0.8012  data_time: 0.1426  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:51:28 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 979  total_loss: 0.3498  loss_cls: 0.04407  loss_box_reg: 0.1718  loss_mask: 0.0997  loss_rpn_cls: 0.0009914  loss_rpn_loc: 0.007453  time: 0.8011  data_time: 0.1680  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:51:43 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 999  total_loss: 0.3171  loss_cls: 0.05208  loss_box_reg: 0.1588  loss_mask: 0.08949  loss_rpn_cls: 0.000956  loss_rpn_loc: 0.005732  time: 0.8009  data_time: 0.1671  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:51:59 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 1019  total_loss: 0.2774  loss_cls: 0.03338  loss_box_reg: 0.1287  loss_mask: 0.07264  loss_rpn_cls: 0.0008812  loss_rpn_loc: 0.005311  time: 0.8009  data_time: 0.1761  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:52:16 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 1039  total_loss: 0.3031  loss_cls: 0.05983  loss_box_reg: 0.1414  loss_mask: 0.09706  loss_rpn_cls: 0.001847  loss_rpn_loc: 0.006132  time: 0.8010  data_time: 0.1515  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:52:31 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 1059  total_loss: 0.264  loss_cls: 0.02765  loss_box_reg: 0.1405  loss_mask: 0.09378  loss_rpn_cls: 0.000938  loss_rpn_loc: 0.005461  time: 0.8002  data_time: 0.1219  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:52:47 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1079  total_loss: 0.2706  loss_cls: 0.04266  loss_box_reg: 0.1292  loss_mask: 0.08672  loss_rpn_cls: 0.001562  loss_rpn_loc: 0.006893  time: 0.8008  data_time: 0.1861  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:53:03 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 1099  total_loss: 0.3335  loss_cls: 0.05955  loss_box_reg: 0.1429  loss_mask: 0.1106  loss_rpn_cls: 0.001175  loss_rpn_loc: 0.007542  time: 0.8004  data_time: 0.1416  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:53:19 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 1119  total_loss: 0.2477  loss_cls: 0.04246  loss_box_reg: 0.1208  loss_mask: 0.07675  loss_rpn_cls: 0.0006761  loss_rpn_loc: 0.005363  time: 0.8005  data_time: 0.1721  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:53:35 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 1139  total_loss: 0.2899  loss_cls: 0.0442  loss_box_reg: 0.1269  loss_mask: 0.09481  loss_rpn_cls: 0.001266  loss_rpn_loc: 0.006642  time: 0.8002  data_time: 0.1425  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:53:51 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 1159  total_loss: 0.2427  loss_cls: 0.03039  loss_box_reg: 0.1232  loss_mask: 0.08501  loss_rpn_cls: 0.001119  loss_rpn_loc: 0.006344  time: 0.8006  data_time: 0.1779  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:54:08 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 1179  total_loss: 0.2445  loss_cls: 0.03105  loss_box_reg: 0.1152  loss_mask: 0.08546  loss_rpn_cls: 0.0009592  loss_rpn_loc: 0.005586  time: 0.8007  data_time: 0.1560  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:54:24 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 1199  total_loss: 0.2623  loss_cls: 0.0286  loss_box_reg: 0.1199  loss_mask: 0.08642  loss_rpn_cls: 0.0008791  loss_rpn_loc: 0.005693  time: 0.8012  data_time: 0.1800  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:54:40 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 1219  total_loss: 0.2713  loss_cls: 0.05059  loss_box_reg: 0.1197  loss_mask: 0.09302  loss_rpn_cls: 0.000604  loss_rpn_loc: 0.006755  time: 0.8009  data_time: 0.1512  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:54:56 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 1239  total_loss: 0.2757  loss_cls: 0.04902  loss_box_reg: 0.1316  loss_mask: 0.09478  loss_rpn_cls: 0.001369  loss_rpn_loc: 0.007233  time: 0.8012  data_time: 0.1645  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:55:12 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 1259  total_loss: 0.2593  loss_cls: 0.04046  loss_box_reg: 0.1274  loss_mask: 0.08765  loss_rpn_cls: 0.000991  loss_rpn_loc: 0.005743  time: 0.8009  data_time: 0.1592  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:55:28 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 1279  total_loss: 0.2555  loss_cls: 0.04555  loss_box_reg: 0.1184  loss_mask: 0.08427  loss_rpn_cls: 0.0008334  loss_rpn_loc: 0.005614  time: 0.8006  data_time: 0.1528  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:55:43 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 1299  total_loss: 0.261  loss_cls: 0.03493  loss_box_reg: 0.1135  loss_mask: 0.0819  loss_rpn_cls: 0.0006958  loss_rpn_loc: 0.005859  time: 0.8006  data_time: 0.1664  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:55:59 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 1319  total_loss: 0.3006  loss_cls: 0.05742  loss_box_reg: 0.1307  loss_mask: 0.08602  loss_rpn_cls: 0.0008788  loss_rpn_loc: 0.005793  time: 0.8005  data_time: 0.1576  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 11:56:16 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 1339  total_loss: 0.2774  loss_cls: 0.04704  loss_box_reg: 0.1192  loss_mask: 0.08896  loss_rpn_cls: 0.001022  loss_rpn_loc: 0.006329  time: 0.8009  data_time: 0.1664  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:56:32 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 1359  total_loss: 0.2522  loss_cls: 0.03208  loss_box_reg: 0.1108  loss_mask: 0.08424  loss_rpn_cls: 0.001268  loss_rpn_loc: 0.004653  time: 0.8012  data_time: 0.1726  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:56:48 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 1379  total_loss: 0.2929  loss_cls: 0.03835  loss_box_reg: 0.1248  loss_mask: 0.08196  loss_rpn_cls: 0.001105  loss_rpn_loc: 0.007271  time: 0.8009  data_time: 0.1482  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:57:05 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 1399  total_loss: 0.2297  loss_cls: 0.03265  loss_box_reg: 0.1034  loss_mask: 0.07787  loss_rpn_cls: 0.00135  loss_rpn_loc: 0.005284  time: 0.8014  data_time: 0.1814  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 11:57:21 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 1419  total_loss: 0.2772  loss_cls: 0.04085  loss_box_reg: 0.1146  loss_mask: 0.08421  loss_rpn_cls: 0.001006  loss_rpn_loc: 0.005546  time: 0.8015  data_time: 0.1685  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:57:37 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 1439  total_loss: 0.2882  loss_cls: 0.03848  loss_box_reg: 0.1292  loss_mask: 0.1136  loss_rpn_cls: 0.0005077  loss_rpn_loc: 0.006258  time: 0.8016  data_time: 0.1682  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:57:53 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 1459  total_loss: 0.2387  loss_cls: 0.04338  loss_box_reg: 0.112  loss_mask: 0.08354  loss_rpn_cls: 0.001689  loss_rpn_loc: 0.0052  time: 0.8018  data_time: 0.1663  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:58:10 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 1479  total_loss: 0.2612  loss_cls: 0.03779  loss_box_reg: 0.1113  loss_mask: 0.07201  loss_rpn_cls: 0.0007234  loss_rpn_loc: 0.005394  time: 0.8019  data_time: 0.1640  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:58:27 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.2545  loss_cls: 0.03193  loss_box_reg: 0.1165  loss_mask: 0.0813  loss_rpn_cls: 0.001277  loss_rpn_loc: 0.006654  time: 0.8019  data_time: 0.1543  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 11:58:27 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:20:01 (0.8019 s / it)\n",
      "\u001b[32m[03/04 11:58:27 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:03 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 11:58:28 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 11:58:28 d2.data.datasets.coco]: \u001b[0mLoaded 172 images in COCO format from /host/mic21-framework/server/uploads/percussionist_gt.json\n",
      "percussionist\n",
      "\u001b[32m[03/04 11:58:29 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 11:58:29 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 11:58:29 d2.data.datasets.coco]: \u001b[0mLoaded 172 images in COCO format from /host/mic21-framework/server/uploads/percussionist_gt.json\n",
      "\u001b[32m[03/04 11:58:29 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 172 images left.\n",
      "\u001b[32m[03/04 11:58:29 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
      "|  microphone   | 152          |    drum    | 356          | percussionist | 241          |\n",
      "|   bass drum   | 106          |   cymbal   | 383          |  snare drum   | 89           |\n",
      "| microphone .. | 99           |            |              |               |              |\n",
      "|     total     | 1426         |            |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 11:58:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 11:58:29 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 11:58:29 d2.data.common]: \u001b[0mSerializing 172 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 11:58:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.19 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (28, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (28,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (7, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 11:58:29 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 11:58:48 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 19  total_loss: 2.698  loss_cls: 0.9889  loss_box_reg: 0.9102  loss_mask: 0.6418  loss_rpn_cls: 0.07804  loss_rpn_loc: 0.06941  time: 0.9161  data_time: 0.2949  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:59:06 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 39  total_loss: 2.209  loss_cls: 0.7307  loss_box_reg: 0.8774  loss_mask: 0.49  loss_rpn_cls: 0.05186  loss_rpn_loc: 0.05083  time: 0.9113  data_time: 0.2483  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:59:25 d2.utils.events]: \u001b[0m eta: 0:22:21  iter: 59  total_loss: 1.851  loss_cls: 0.6169  loss_box_reg: 0.8133  loss_mask: 0.3497  loss_rpn_cls: 0.02841  loss_rpn_loc: 0.05066  time: 0.9164  data_time: 0.2740  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 11:59:43 d2.utils.events]: \u001b[0m eta: 0:22:02  iter: 79  total_loss: 1.877  loss_cls: 0.6164  loss_box_reg: 0.797  loss_mask: 0.3096  loss_rpn_cls: 0.06144  loss_rpn_loc: 0.06983  time: 0.9168  data_time: 0.2691  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:00:01 d2.utils.events]: \u001b[0m eta: 0:21:44  iter: 99  total_loss: 1.6  loss_cls: 0.5328  loss_box_reg: 0.6387  loss_mask: 0.28  loss_rpn_cls: 0.03853  loss_rpn_loc: 0.04633  time: 0.9098  data_time: 0.2503  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:00:19 d2.utils.events]: \u001b[0m eta: 0:21:25  iter: 119  total_loss: 1.492  loss_cls: 0.4764  loss_box_reg: 0.618  loss_mask: 0.2829  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.0519  time: 0.9100  data_time: 0.2783  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:00:38 d2.utils.events]: \u001b[0m eta: 0:21:10  iter: 139  total_loss: 1.525  loss_cls: 0.4882  loss_box_reg: 0.6487  loss_mask: 0.2442  loss_rpn_cls: 0.03854  loss_rpn_loc: 0.07644  time: 0.9136  data_time: 0.2683  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:00:56 d2.utils.events]: \u001b[0m eta: 0:20:51  iter: 159  total_loss: 1.452  loss_cls: 0.4997  loss_box_reg: 0.6238  loss_mask: 0.245  loss_rpn_cls: 0.03803  loss_rpn_loc: 0.05968  time: 0.9169  data_time: 0.2942  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:01:14 d2.utils.events]: \u001b[0m eta: 0:20:29  iter: 179  total_loss: 1.371  loss_cls: 0.4254  loss_box_reg: 0.5799  loss_mask: 0.2236  loss_rpn_cls: 0.02973  loss_rpn_loc: 0.06591  time: 0.9152  data_time: 0.2527  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:01:33 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 199  total_loss: 1.273  loss_cls: 0.453  loss_box_reg: 0.5533  loss_mask: 0.2088  loss_rpn_cls: 0.0311  loss_rpn_loc: 0.05136  time: 0.9165  data_time: 0.2687  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:01:51 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 219  total_loss: 1.347  loss_cls: 0.4309  loss_box_reg: 0.579  loss_mask: 0.2292  loss_rpn_cls: 0.03098  loss_rpn_loc: 0.0646  time: 0.9157  data_time: 0.2531  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:02:09 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 239  total_loss: 1.258  loss_cls: 0.4221  loss_box_reg: 0.5135  loss_mask: 0.2065  loss_rpn_cls: 0.02782  loss_rpn_loc: 0.0578  time: 0.9149  data_time: 0.2474  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:02:27 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 259  total_loss: 1.351  loss_cls: 0.4559  loss_box_reg: 0.5472  loss_mask: 0.2267  loss_rpn_cls: 0.02666  loss_rpn_loc: 0.0501  time: 0.9121  data_time: 0.2579  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:02:45 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 279  total_loss: 1.292  loss_cls: 0.4408  loss_box_reg: 0.5158  loss_mask: 0.2252  loss_rpn_cls: 0.03061  loss_rpn_loc: 0.06035  time: 0.9126  data_time: 0.2571  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:03:03 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 299  total_loss: 1.168  loss_cls: 0.3854  loss_box_reg: 0.4804  loss_mask: 0.1971  loss_rpn_cls: 0.02253  loss_rpn_loc: 0.04684  time: 0.9116  data_time: 0.2418  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:03:21 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 319  total_loss: 1.204  loss_cls: 0.4293  loss_box_reg: 0.4855  loss_mask: 0.2093  loss_rpn_cls: 0.02565  loss_rpn_loc: 0.04879  time: 0.9110  data_time: 0.2588  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:03:40 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 339  total_loss: 1.102  loss_cls: 0.4037  loss_box_reg: 0.489  loss_mask: 0.1974  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.05249  time: 0.9119  data_time: 0.2782  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:03:58 d2.utils.events]: \u001b[0m eta: 0:17:11  iter: 359  total_loss: 1.182  loss_cls: 0.3697  loss_box_reg: 0.5048  loss_mask: 0.2066  loss_rpn_cls: 0.02137  loss_rpn_loc: 0.05109  time: 0.9112  data_time: 0.2564  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:04:16 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 379  total_loss: 1.07  loss_cls: 0.3222  loss_box_reg: 0.4587  loss_mask: 0.1961  loss_rpn_cls: 0.02834  loss_rpn_loc: 0.04577  time: 0.9108  data_time: 0.2521  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:04:33 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 399  total_loss: 1.2  loss_cls: 0.3818  loss_box_reg: 0.4943  loss_mask: 0.1936  loss_rpn_cls: 0.02141  loss_rpn_loc: 0.0491  time: 0.9089  data_time: 0.2307  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:04:52 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 419  total_loss: 1.083  loss_cls: 0.3275  loss_box_reg: 0.4714  loss_mask: 0.2065  loss_rpn_cls: 0.02601  loss_rpn_loc: 0.05231  time: 0.9088  data_time: 0.2611  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:05:10 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 439  total_loss: 1.103  loss_cls: 0.325  loss_box_reg: 0.4567  loss_mask: 0.1915  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.05204  time: 0.9102  data_time: 0.2929  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:05:30 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 459  total_loss: 1.162  loss_cls: 0.3304  loss_box_reg: 0.4957  loss_mask: 0.2127  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.04336  time: 0.9123  data_time: 0.3049  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:05:48 d2.utils.events]: \u001b[0m eta: 0:15:34  iter: 479  total_loss: 1.147  loss_cls: 0.341  loss_box_reg: 0.4761  loss_mask: 0.1925  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.05099  time: 0.9125  data_time: 0.2495  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:06:07 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 499  total_loss: 1.06  loss_cls: 0.3176  loss_box_reg: 0.4766  loss_mask: 0.1908  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.0522  time: 0.9132  data_time: 0.2415  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:06:25 d2.utils.events]: \u001b[0m eta: 0:14:58  iter: 519  total_loss: 1.068  loss_cls: 0.3469  loss_box_reg: 0.4495  loss_mask: 0.1913  loss_rpn_cls: 0.01652  loss_rpn_loc: 0.04565  time: 0.9127  data_time: 0.2734  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:06:44 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 539  total_loss: 1.244  loss_cls: 0.397  loss_box_reg: 0.4899  loss_mask: 0.2186  loss_rpn_cls: 0.02143  loss_rpn_loc: 0.05472  time: 0.9144  data_time: 0.2843  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:07:02 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 559  total_loss: 1.039  loss_cls: 0.3156  loss_box_reg: 0.4094  loss_mask: 0.1889  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.04772  time: 0.9136  data_time: 0.2731  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:07:20 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 579  total_loss: 0.968  loss_cls: 0.3101  loss_box_reg: 0.4218  loss_mask: 0.1848  loss_rpn_cls: 0.01966  loss_rpn_loc: 0.04619  time: 0.9136  data_time: 0.2639  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:07:38 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 599  total_loss: 0.9119  loss_cls: 0.2989  loss_box_reg: 0.4003  loss_mask: 0.1877  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.04617  time: 0.9139  data_time: 0.2682  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:07:57 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 619  total_loss: 1.04  loss_cls: 0.3236  loss_box_reg: 0.4541  loss_mask: 0.1791  loss_rpn_cls: 0.02094  loss_rpn_loc: 0.05206  time: 0.9146  data_time: 0.2626  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:08:16 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 639  total_loss: 1.081  loss_cls: 0.3785  loss_box_reg: 0.4538  loss_mask: 0.1831  loss_rpn_cls: 0.01786  loss_rpn_loc: 0.05807  time: 0.9152  data_time: 0.2542  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:08:33 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 659  total_loss: 0.8603  loss_cls: 0.273  loss_box_reg: 0.3948  loss_mask: 0.1662  loss_rpn_cls: 0.01657  loss_rpn_loc: 0.0432  time: 0.9137  data_time: 0.2564  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 12:08:52 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 679  total_loss: 1.019  loss_cls: 0.3143  loss_box_reg: 0.439  loss_mask: 0.1914  loss_rpn_cls: 0.01696  loss_rpn_loc: 0.04787  time: 0.9141  data_time: 0.2707  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:09:10 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 699  total_loss: 1.055  loss_cls: 0.2857  loss_box_reg: 0.4697  loss_mask: 0.1873  loss_rpn_cls: 0.01604  loss_rpn_loc: 0.05254  time: 0.9141  data_time: 0.2507  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:09:28 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 719  total_loss: 0.9174  loss_cls: 0.2656  loss_box_reg: 0.4236  loss_mask: 0.1826  loss_rpn_cls: 0.01689  loss_rpn_loc: 0.04336  time: 0.9138  data_time: 0.2741  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:09:46 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 739  total_loss: 0.9324  loss_cls: 0.2444  loss_box_reg: 0.4233  loss_mask: 0.1778  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.04798  time: 0.9138  data_time: 0.2497  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:10:04 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 759  total_loss: 0.9993  loss_cls: 0.2934  loss_box_reg: 0.4261  loss_mask: 0.1883  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.04761  time: 0.9136  data_time: 0.2513  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:10:22 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 779  total_loss: 1.008  loss_cls: 0.3051  loss_box_reg: 0.4519  loss_mask: 0.1741  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.04812  time: 0.9131  data_time: 0.2406  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:10:41 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 799  total_loss: 0.8473  loss_cls: 0.2778  loss_box_reg: 0.3534  loss_mask: 0.1677  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.04289  time: 0.9129  data_time: 0.2529  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:11:00 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 819  total_loss: 0.9187  loss_cls: 0.2724  loss_box_reg: 0.397  loss_mask: 0.1724  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.04337  time: 0.9142  data_time: 0.2891  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:11:19 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 839  total_loss: 0.8626  loss_cls: 0.2513  loss_box_reg: 0.3963  loss_mask: 0.1625  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.04752  time: 0.9147  data_time: 0.2512  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:11:37 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 859  total_loss: 0.9396  loss_cls: 0.2459  loss_box_reg: 0.391  loss_mask: 0.1792  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.04427  time: 0.9149  data_time: 0.2722  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:11:56 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 879  total_loss: 0.8764  loss_cls: 0.2468  loss_box_reg: 0.3884  loss_mask: 0.1898  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.0427  time: 0.9153  data_time: 0.2809  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:12:14 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 899  total_loss: 0.8868  loss_cls: 0.2902  loss_box_reg: 0.3837  loss_mask: 0.1664  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.04854  time: 0.9152  data_time: 0.2616  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:12:32 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 919  total_loss: 0.8358  loss_cls: 0.2195  loss_box_reg: 0.3686  loss_mask: 0.1613  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.03549  time: 0.9150  data_time: 0.2753  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:12:50 d2.utils.events]: \u001b[0m eta: 0:08:34  iter: 939  total_loss: 1.023  loss_cls: 0.2746  loss_box_reg: 0.4267  loss_mask: 0.2017  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.05784  time: 0.9151  data_time: 0.2743  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:13:09 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 959  total_loss: 0.9403  loss_cls: 0.2755  loss_box_reg: 0.4089  loss_mask: 0.1853  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.05467  time: 0.9155  data_time: 0.2879  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:13:27 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 979  total_loss: 0.9811  loss_cls: 0.2748  loss_box_reg: 0.4445  loss_mask: 0.1789  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.04305  time: 0.9151  data_time: 0.2585  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:13:45 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 999  total_loss: 0.7694  loss_cls: 0.2272  loss_box_reg: 0.3635  loss_mask: 0.1822  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.03404  time: 0.9151  data_time: 0.2604  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:14:04 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 1019  total_loss: 0.8457  loss_cls: 0.2607  loss_box_reg: 0.3471  loss_mask: 0.1675  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.04015  time: 0.9156  data_time: 0.2802  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:14:23 d2.utils.events]: \u001b[0m eta: 0:07:03  iter: 1039  total_loss: 0.9006  loss_cls: 0.2544  loss_box_reg: 0.3526  loss_mask: 0.177  loss_rpn_cls: 0.008469  loss_rpn_loc: 0.0458  time: 0.9161  data_time: 0.2943  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:14:42 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 1059  total_loss: 0.8043  loss_cls: 0.2483  loss_box_reg: 0.309  loss_mask: 0.1718  loss_rpn_cls: 0.01212  loss_rpn_loc: 0.04353  time: 0.9165  data_time: 0.2662  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:15:00 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 1079  total_loss: 0.9488  loss_cls: 0.2962  loss_box_reg: 0.3661  loss_mask: 0.1856  loss_rpn_cls: 0.013  loss_rpn_loc: 0.0464  time: 0.9163  data_time: 0.2443  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:15:19 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 1099  total_loss: 0.7887  loss_cls: 0.2482  loss_box_reg: 0.3347  loss_mask: 0.1489  loss_rpn_cls: 0.009885  loss_rpn_loc: 0.04065  time: 0.9167  data_time: 0.2572  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:15:37 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1119  total_loss: 0.9143  loss_cls: 0.277  loss_box_reg: 0.3822  loss_mask: 0.1833  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.04544  time: 0.9168  data_time: 0.2778  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:15:56 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 1139  total_loss: 0.7951  loss_cls: 0.2665  loss_box_reg: 0.3321  loss_mask: 0.1754  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.03854  time: 0.9169  data_time: 0.2759  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:16:15 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1159  total_loss: 0.8144  loss_cls: 0.2266  loss_box_reg: 0.3551  loss_mask: 0.1915  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.04483  time: 0.9174  data_time: 0.2871  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:16:33 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 1179  total_loss: 0.7626  loss_cls: 0.2377  loss_box_reg: 0.3381  loss_mask: 0.155  loss_rpn_cls: 0.008415  loss_rpn_loc: 0.0495  time: 0.9174  data_time: 0.2560  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:16:51 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 1199  total_loss: 0.8234  loss_cls: 0.2356  loss_box_reg: 0.3408  loss_mask: 0.1798  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.04507  time: 0.9172  data_time: 0.2591  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:17:10 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 1219  total_loss: 0.9108  loss_cls: 0.2719  loss_box_reg: 0.3636  loss_mask: 0.1759  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.03762  time: 0.9174  data_time: 0.2686  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:17:28 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 1239  total_loss: 0.8039  loss_cls: 0.2549  loss_box_reg: 0.3398  loss_mask: 0.1675  loss_rpn_cls: 0.009069  loss_rpn_loc: 0.04631  time: 0.9175  data_time: 0.2732  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:17:47 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 1259  total_loss: 0.8003  loss_cls: 0.2206  loss_box_reg: 0.3309  loss_mask: 0.1764  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.03132  time: 0.9176  data_time: 0.2578  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:18:05 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 1279  total_loss: 0.7601  loss_cls: 0.2193  loss_box_reg: 0.3026  loss_mask: 0.1572  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.04858  time: 0.9176  data_time: 0.2631  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:18:25 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 1299  total_loss: 0.7814  loss_cls: 0.226  loss_box_reg: 0.335  loss_mask: 0.1791  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.04549  time: 0.9186  data_time: 0.3071  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:18:43 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 1319  total_loss: 0.7479  loss_cls: 0.2351  loss_box_reg: 0.3136  loss_mask: 0.1457  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.04195  time: 0.9185  data_time: 0.2593  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 12:19:02 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 1339  total_loss: 0.8185  loss_cls: 0.2026  loss_box_reg: 0.3661  loss_mask: 0.1642  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.04594  time: 0.9187  data_time: 0.2712  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:19:19 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 1359  total_loss: 0.721  loss_cls: 0.2119  loss_box_reg: 0.2809  loss_mask: 0.1597  loss_rpn_cls: 0.008936  loss_rpn_loc: 0.03278  time: 0.9182  data_time: 0.2477  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:19:38 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 1379  total_loss: 0.8673  loss_cls: 0.2336  loss_box_reg: 0.3501  loss_mask: 0.1818  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.05089  time: 0.9186  data_time: 0.2575  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:19:56 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 1399  total_loss: 0.7491  loss_cls: 0.2153  loss_box_reg: 0.3003  loss_mask: 0.166  loss_rpn_cls: 0.009432  loss_rpn_loc: 0.04296  time: 0.9184  data_time: 0.2424  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:20:15 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 1419  total_loss: 0.808  loss_cls: 0.2239  loss_box_reg: 0.3526  loss_mask: 0.1782  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.04661  time: 0.9183  data_time: 0.2664  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:20:32 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 1439  total_loss: 0.8612  loss_cls: 0.2487  loss_box_reg: 0.3589  loss_mask: 0.1761  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.03727  time: 0.9179  data_time: 0.2470  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:20:51 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 1459  total_loss: 0.8176  loss_cls: 0.2379  loss_box_reg: 0.3296  loss_mask: 0.1776  loss_rpn_cls: 0.01121  loss_rpn_loc: 0.04781  time: 0.9183  data_time: 0.2732  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:21:10 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1479  total_loss: 0.7141  loss_cls: 0.2062  loss_box_reg: 0.3108  loss_mask: 0.1659  loss_rpn_cls: 0.007803  loss_rpn_loc: 0.03902  time: 0.9183  data_time: 0.2595  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:21:30 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7613  loss_cls: 0.2291  loss_box_reg: 0.3119  loss_mask: 0.1667  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.0456  time: 0.9185  data_time: 0.2729  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:21:30 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:22:55 (0.9185 s / it)\n",
      "\u001b[32m[03/04 12:21:30 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:58 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 12:21:31 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 12:21:31 d2.data.datasets.coco]: \u001b[0mLoaded 153 images in COCO format from /host/mic21-framework/server/uploads/piano_player_gt.json\n",
      "piano_player\n",
      "\u001b[32m[03/04 12:21:31 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 12:21:31 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 12:21:31 d2.data.datasets.coco]: \u001b[0mLoaded 153 images in COCO format from /host/mic21-framework/server/uploads/piano_player_gt.json\n",
      "\u001b[32m[03/04 12:21:31 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 153 images left.\n",
      "\u001b[32m[03/04 12:21:31 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
      "|     piano     | 145          | piano player | 153          | musical score | 64           |\n",
      "| piano keybo.. | 142          | piano stool  | 75           |               |              |\n",
      "|     total     | 579          |              |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 12:21:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 12:21:31 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 12:21:31 d2.data.common]: \u001b[0mSerializing 153 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 12:21:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.63 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 12:21:31 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 12:21:50 d2.utils.events]: \u001b[0m eta: 0:22:09  iter: 19  total_loss: 2.64  loss_cls: 0.8436  loss_box_reg: 0.9496  loss_mask: 0.653  loss_rpn_cls: 0.02728  loss_rpn_loc: 0.08262  time: 0.8868  data_time: 0.2632  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:22:07 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 39  total_loss: 2.184  loss_cls: 0.6032  loss_box_reg: 0.868  loss_mask: 0.527  loss_rpn_cls: 0.04256  loss_rpn_loc: 0.08391  time: 0.8865  data_time: 0.2415  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:22:25 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 59  total_loss: 1.808  loss_cls: 0.4517  loss_box_reg: 0.8616  loss_mask: 0.3856  loss_rpn_cls: 0.0231  loss_rpn_loc: 0.05297  time: 0.8897  data_time: 0.2637  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:22:43 d2.utils.events]: \u001b[0m eta: 0:20:54  iter: 79  total_loss: 1.629  loss_cls: 0.3852  loss_box_reg: 0.7744  loss_mask: 0.335  loss_rpn_cls: 0.02128  loss_rpn_loc: 0.07586  time: 0.8876  data_time: 0.2142  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:23:01 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 99  total_loss: 1.366  loss_cls: 0.3407  loss_box_reg: 0.6153  loss_mask: 0.2887  loss_rpn_cls: 0.0297  loss_rpn_loc: 0.09217  time: 0.8857  data_time: 0.2254  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:23:18 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 119  total_loss: 1.293  loss_cls: 0.2918  loss_box_reg: 0.5613  loss_mask: 0.2616  loss_rpn_cls: 0.02185  loss_rpn_loc: 0.08728  time: 0.8862  data_time: 0.2220  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:23:36 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 139  total_loss: 1.263  loss_cls: 0.2739  loss_box_reg: 0.5959  loss_mask: 0.269  loss_rpn_cls: 0.017  loss_rpn_loc: 0.06737  time: 0.8859  data_time: 0.2151  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:23:54 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 159  total_loss: 1.128  loss_cls: 0.2799  loss_box_reg: 0.5666  loss_mask: 0.247  loss_rpn_cls: 0.01999  loss_rpn_loc: 0.06956  time: 0.8854  data_time: 0.2495  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:24:12 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 179  total_loss: 1.093  loss_cls: 0.2332  loss_box_reg: 0.5033  loss_mask: 0.2612  loss_rpn_cls: 0.01376  loss_rpn_loc: 0.07599  time: 0.8858  data_time: 0.2398  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:24:29 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 199  total_loss: 1.101  loss_cls: 0.2393  loss_box_reg: 0.5092  loss_mask: 0.2445  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.06589  time: 0.8837  data_time: 0.2033  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:24:47 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 219  total_loss: 1.068  loss_cls: 0.2482  loss_box_reg: 0.4693  loss_mask: 0.2323  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.0568  time: 0.8845  data_time: 0.2447  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:25:04 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 239  total_loss: 1.074  loss_cls: 0.2374  loss_box_reg: 0.5035  loss_mask: 0.2192  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.07432  time: 0.8846  data_time: 0.2379  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:25:23 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 259  total_loss: 0.9696  loss_cls: 0.2274  loss_box_reg: 0.4653  loss_mask: 0.2102  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.05978  time: 0.8864  data_time: 0.2509  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:25:40 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 279  total_loss: 0.9831  loss_cls: 0.2031  loss_box_reg: 0.4303  loss_mask: 0.2315  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.07748  time: 0.8861  data_time: 0.2467  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:25:58 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 299  total_loss: 0.9398  loss_cls: 0.249  loss_box_reg: 0.4384  loss_mask: 0.2053  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.05761  time: 0.8867  data_time: 0.2259  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:26:15 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 319  total_loss: 0.8948  loss_cls: 0.1767  loss_box_reg: 0.3952  loss_mask: 0.1855  loss_rpn_cls: 0.009575  loss_rpn_loc: 0.04091  time: 0.8844  data_time: 0.2083  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:26:33 d2.utils.events]: \u001b[0m eta: 0:17:00  iter: 339  total_loss: 0.8536  loss_cls: 0.1535  loss_box_reg: 0.4063  loss_mask: 0.1973  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.0554  time: 0.8851  data_time: 0.2515  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:26:51 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 359  total_loss: 0.8859  loss_cls: 0.1966  loss_box_reg: 0.4134  loss_mask: 0.1935  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.07037  time: 0.8854  data_time: 0.2253  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:27:09 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 379  total_loss: 0.8967  loss_cls: 0.1815  loss_box_reg: 0.4341  loss_mask: 0.2021  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.07123  time: 0.8850  data_time: 0.2414  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:27:27 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 399  total_loss: 0.8614  loss_cls: 0.1721  loss_box_reg: 0.4175  loss_mask: 0.1876  loss_rpn_cls: 0.009178  loss_rpn_loc: 0.05307  time: 0.8859  data_time: 0.2556  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:27:44 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 419  total_loss: 0.7533  loss_cls: 0.151  loss_box_reg: 0.368  loss_mask: 0.1666  loss_rpn_cls: 0.01016  loss_rpn_loc: 0.061  time: 0.8860  data_time: 0.2170  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:28:02 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 439  total_loss: 0.7966  loss_cls: 0.1634  loss_box_reg: 0.3951  loss_mask: 0.198  loss_rpn_cls: 0.008633  loss_rpn_loc: 0.05252  time: 0.8864  data_time: 0.2319  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:28:19 d2.utils.events]: \u001b[0m eta: 0:15:06  iter: 459  total_loss: 0.8268  loss_cls: 0.1617  loss_box_reg: 0.3866  loss_mask: 0.1845  loss_rpn_cls: 0.009817  loss_rpn_loc: 0.06303  time: 0.8846  data_time: 0.2213  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:28:37 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 479  total_loss: 0.7604  loss_cls: 0.139  loss_box_reg: 0.3348  loss_mask: 0.1742  loss_rpn_cls: 0.009845  loss_rpn_loc: 0.0565  time: 0.8851  data_time: 0.2348  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:28:55 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 499  total_loss: 0.7403  loss_cls: 0.1201  loss_box_reg: 0.3671  loss_mask: 0.1676  loss_rpn_cls: 0.007348  loss_rpn_loc: 0.05315  time: 0.8859  data_time: 0.2433  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:29:13 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 519  total_loss: 0.8424  loss_cls: 0.1809  loss_box_reg: 0.3874  loss_mask: 0.1966  loss_rpn_cls: 0.00777  loss_rpn_loc: 0.05913  time: 0.8860  data_time: 0.2571  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:29:30 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 539  total_loss: 0.7632  loss_cls: 0.1432  loss_box_reg: 0.3356  loss_mask: 0.1741  loss_rpn_cls: 0.007356  loss_rpn_loc: 0.04719  time: 0.8854  data_time: 0.2031  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:29:48 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 559  total_loss: 0.733  loss_cls: 0.1583  loss_box_reg: 0.3298  loss_mask: 0.1685  loss_rpn_cls: 0.008552  loss_rpn_loc: 0.04506  time: 0.8846  data_time: 0.2250  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:30:06 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 579  total_loss: 0.7853  loss_cls: 0.1385  loss_box_reg: 0.3584  loss_mask: 0.1788  loss_rpn_cls: 0.007897  loss_rpn_loc: 0.05231  time: 0.8859  data_time: 0.2385  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:30:24 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 599  total_loss: 0.7864  loss_cls: 0.1694  loss_box_reg: 0.3687  loss_mask: 0.1877  loss_rpn_cls: 0.007964  loss_rpn_loc: 0.04393  time: 0.8856  data_time: 0.2358  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:30:41 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 619  total_loss: 0.7059  loss_cls: 0.133  loss_box_reg: 0.3129  loss_mask: 0.1514  loss_rpn_cls: 0.005771  loss_rpn_loc: 0.06354  time: 0.8848  data_time: 0.2122  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:30:59 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 639  total_loss: 0.7264  loss_cls: 0.1383  loss_box_reg: 0.3624  loss_mask: 0.1699  loss_rpn_cls: 0.007699  loss_rpn_loc: 0.04966  time: 0.8857  data_time: 0.2330  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:31:17 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 659  total_loss: 0.6892  loss_cls: 0.1312  loss_box_reg: 0.344  loss_mask: 0.1577  loss_rpn_cls: 0.008423  loss_rpn_loc: 0.04493  time: 0.8855  data_time: 0.2257  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 12:31:35 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 679  total_loss: 0.6808  loss_cls: 0.1243  loss_box_reg: 0.3388  loss_mask: 0.147  loss_rpn_cls: 0.008416  loss_rpn_loc: 0.05429  time: 0.8854  data_time: 0.2385  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:31:52 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 699  total_loss: 0.7031  loss_cls: 0.1504  loss_box_reg: 0.316  loss_mask: 0.1689  loss_rpn_cls: 0.008758  loss_rpn_loc: 0.0552  time: 0.8851  data_time: 0.2003  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:32:09 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 719  total_loss: 0.7175  loss_cls: 0.1331  loss_box_reg: 0.3165  loss_mask: 0.164  loss_rpn_cls: 0.006458  loss_rpn_loc: 0.04506  time: 0.8842  data_time: 0.2222  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:32:27 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 739  total_loss: 0.6888  loss_cls: 0.1425  loss_box_reg: 0.3071  loss_mask: 0.1641  loss_rpn_cls: 0.008766  loss_rpn_loc: 0.05493  time: 0.8839  data_time: 0.2232  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:32:44 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 759  total_loss: 0.6141  loss_cls: 0.1111  loss_box_reg: 0.3157  loss_mask: 0.1461  loss_rpn_cls: 0.005175  loss_rpn_loc: 0.04579  time: 0.8840  data_time: 0.2484  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:33:02 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 779  total_loss: 0.6993  loss_cls: 0.1197  loss_box_reg: 0.3255  loss_mask: 0.1545  loss_rpn_cls: 0.00594  loss_rpn_loc: 0.05348  time: 0.8843  data_time: 0.2452  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:33:21 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 799  total_loss: 0.6865  loss_cls: 0.1172  loss_box_reg: 0.3239  loss_mask: 0.1545  loss_rpn_cls: 0.008151  loss_rpn_loc: 0.05975  time: 0.8852  data_time: 0.2308  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:33:38 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 819  total_loss: 0.6735  loss_cls: 0.1323  loss_box_reg: 0.3281  loss_mask: 0.1474  loss_rpn_cls: 0.008033  loss_rpn_loc: 0.05936  time: 0.8848  data_time: 0.2277  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:33:56 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 839  total_loss: 0.6775  loss_cls: 0.1286  loss_box_reg: 0.3235  loss_mask: 0.1482  loss_rpn_cls: 0.006372  loss_rpn_loc: 0.05615  time: 0.8848  data_time: 0.2324  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:34:13 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 859  total_loss: 0.6316  loss_cls: 0.106  loss_box_reg: 0.3107  loss_mask: 0.1614  loss_rpn_cls: 0.004909  loss_rpn_loc: 0.04245  time: 0.8839  data_time: 0.2194  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:34:31 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 879  total_loss: 0.67  loss_cls: 0.109  loss_box_reg: 0.3114  loss_mask: 0.1669  loss_rpn_cls: 0.007535  loss_rpn_loc: 0.06075  time: 0.8848  data_time: 0.2545  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:34:49 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 899  total_loss: 0.6607  loss_cls: 0.1298  loss_box_reg: 0.313  loss_mask: 0.1443  loss_rpn_cls: 0.005899  loss_rpn_loc: 0.03981  time: 0.8848  data_time: 0.2287  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:35:07 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 919  total_loss: 0.6233  loss_cls: 0.1328  loss_box_reg: 0.297  loss_mask: 0.147  loss_rpn_cls: 0.006987  loss_rpn_loc: 0.04897  time: 0.8849  data_time: 0.2354  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:35:24 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 939  total_loss: 0.6422  loss_cls: 0.1141  loss_box_reg: 0.3206  loss_mask: 0.1489  loss_rpn_cls: 0.005179  loss_rpn_loc: 0.03736  time: 0.8848  data_time: 0.2260  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:35:42 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 959  total_loss: 0.6349  loss_cls: 0.1062  loss_box_reg: 0.3295  loss_mask: 0.1497  loss_rpn_cls: 0.004622  loss_rpn_loc: 0.04082  time: 0.8849  data_time: 0.2409  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:36:00 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 979  total_loss: 0.6426  loss_cls: 0.1283  loss_box_reg: 0.2949  loss_mask: 0.1476  loss_rpn_cls: 0.00631  loss_rpn_loc: 0.05577  time: 0.8847  data_time: 0.2193  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:36:17 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 999  total_loss: 0.6676  loss_cls: 0.1111  loss_box_reg: 0.3216  loss_mask: 0.1683  loss_rpn_cls: 0.006907  loss_rpn_loc: 0.04885  time: 0.8843  data_time: 0.2306  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:36:34 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 1019  total_loss: 0.6071  loss_cls: 0.1063  loss_box_reg: 0.3005  loss_mask: 0.1288  loss_rpn_cls: 0.004574  loss_rpn_loc: 0.04422  time: 0.8840  data_time: 0.2278  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:36:52 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 1039  total_loss: 0.5897  loss_cls: 0.09788  loss_box_reg: 0.2725  loss_mask: 0.1381  loss_rpn_cls: 0.004787  loss_rpn_loc: 0.04496  time: 0.8842  data_time: 0.2307  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:37:10 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 1059  total_loss: 0.5741  loss_cls: 0.09466  loss_box_reg: 0.2813  loss_mask: 0.1493  loss_rpn_cls: 0.007166  loss_rpn_loc: 0.05167  time: 0.8847  data_time: 0.2467  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:37:28 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 1079  total_loss: 0.5856  loss_cls: 0.09906  loss_box_reg: 0.2808  loss_mask: 0.1473  loss_rpn_cls: 0.005316  loss_rpn_loc: 0.06402  time: 0.8848  data_time: 0.2246  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:37:46 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1099  total_loss: 0.5179  loss_cls: 0.0944  loss_box_reg: 0.2707  loss_mask: 0.1213  loss_rpn_cls: 0.004421  loss_rpn_loc: 0.03998  time: 0.8849  data_time: 0.2347  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:38:03 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 1119  total_loss: 0.5579  loss_cls: 0.1037  loss_box_reg: 0.2482  loss_mask: 0.1482  loss_rpn_cls: 0.005701  loss_rpn_loc: 0.03948  time: 0.8841  data_time: 0.2231  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:38:21 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 1139  total_loss: 0.569  loss_cls: 0.0979  loss_box_reg: 0.2586  loss_mask: 0.1259  loss_rpn_cls: 0.005966  loss_rpn_loc: 0.04412  time: 0.8843  data_time: 0.2366  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:38:39 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 1159  total_loss: 0.5564  loss_cls: 0.09745  loss_box_reg: 0.2492  loss_mask: 0.1466  loss_rpn_cls: 0.00499  loss_rpn_loc: 0.03267  time: 0.8843  data_time: 0.2282  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:38:56 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 1179  total_loss: 0.5319  loss_cls: 0.09296  loss_box_reg: 0.2383  loss_mask: 0.1296  loss_rpn_cls: 0.004899  loss_rpn_loc: 0.04659  time: 0.8838  data_time: 0.2242  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:39:13 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 1199  total_loss: 0.5419  loss_cls: 0.07394  loss_box_reg: 0.2573  loss_mask: 0.1419  loss_rpn_cls: 0.004544  loss_rpn_loc: 0.04458  time: 0.8837  data_time: 0.2216  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:39:31 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 1219  total_loss: 0.5489  loss_cls: 0.08415  loss_box_reg: 0.2567  loss_mask: 0.1428  loss_rpn_cls: 0.005751  loss_rpn_loc: 0.03653  time: 0.8839  data_time: 0.2401  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:39:49 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 1239  total_loss: 0.5223  loss_cls: 0.07047  loss_box_reg: 0.2512  loss_mask: 0.1415  loss_rpn_cls: 0.005417  loss_rpn_loc: 0.03386  time: 0.8837  data_time: 0.2167  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:40:07 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 1259  total_loss: 0.5906  loss_cls: 0.09805  loss_box_reg: 0.274  loss_mask: 0.1417  loss_rpn_cls: 0.005946  loss_rpn_loc: 0.05399  time: 0.8845  data_time: 0.2519  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:40:25 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 1279  total_loss: 0.5346  loss_cls: 0.09618  loss_box_reg: 0.2372  loss_mask: 0.1321  loss_rpn_cls: 0.005142  loss_rpn_loc: 0.0333  time: 0.8843  data_time: 0.2688  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:40:42 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 1299  total_loss: 0.5461  loss_cls: 0.07294  loss_box_reg: 0.2466  loss_mask: 0.1363  loss_rpn_cls: 0.003957  loss_rpn_loc: 0.05127  time: 0.8836  data_time: 0.2088  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:40:59 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1319  total_loss: 0.528  loss_cls: 0.09929  loss_box_reg: 0.2441  loss_mask: 0.1448  loss_rpn_cls: 0.005447  loss_rpn_loc: 0.04031  time: 0.8837  data_time: 0.2327  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 12:41:17 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 1339  total_loss: 0.5298  loss_cls: 0.1013  loss_box_reg: 0.2261  loss_mask: 0.1362  loss_rpn_cls: 0.003667  loss_rpn_loc: 0.05268  time: 0.8836  data_time: 0.2241  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:41:35 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 1359  total_loss: 0.635  loss_cls: 0.1229  loss_box_reg: 0.2602  loss_mask: 0.1423  loss_rpn_cls: 0.006058  loss_rpn_loc: 0.04983  time: 0.8838  data_time: 0.2446  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:41:53 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 1379  total_loss: 0.5486  loss_cls: 0.1091  loss_box_reg: 0.2301  loss_mask: 0.1148  loss_rpn_cls: 0.003663  loss_rpn_loc: 0.04623  time: 0.8840  data_time: 0.2429  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:42:10 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 1399  total_loss: 0.5156  loss_cls: 0.0833  loss_box_reg: 0.2465  loss_mask: 0.1367  loss_rpn_cls: 0.003955  loss_rpn_loc: 0.0434  time: 0.8838  data_time: 0.2277  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:42:28 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 1419  total_loss: 0.5107  loss_cls: 0.0828  loss_box_reg: 0.2468  loss_mask: 0.1358  loss_rpn_cls: 0.004503  loss_rpn_loc: 0.03742  time: 0.8839  data_time: 0.2172  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:42:46 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 1439  total_loss: 0.5679  loss_cls: 0.09459  loss_box_reg: 0.2715  loss_mask: 0.137  loss_rpn_cls: 0.004941  loss_rpn_loc: 0.0593  time: 0.8841  data_time: 0.2349  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:43:04 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 1459  total_loss: 0.5148  loss_cls: 0.08841  loss_box_reg: 0.2524  loss_mask: 0.1236  loss_rpn_cls: 0.004202  loss_rpn_loc: 0.04239  time: 0.8839  data_time: 0.2191  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:43:21 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.5559  loss_cls: 0.09199  loss_box_reg: 0.2327  loss_mask: 0.1426  loss_rpn_cls: 0.005106  loss_rpn_loc: 0.04563  time: 0.8838  data_time: 0.2113  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:43:40 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.5432  loss_cls: 0.09989  loss_box_reg: 0.2443  loss_mask: 0.1376  loss_rpn_cls: 0.005354  loss_rpn_loc: 0.04918  time: 0.8836  data_time: 0.2371  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 12:43:40 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:22:03 (0.8836 s / it)\n",
      "\u001b[32m[03/04 12:43:40 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:06 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 12:43:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 12:43:41 d2.data.datasets.coco]: \u001b[0mLoaded 193 images in COCO format from /host/mic21-framework/server/uploads/rapper_gt.json\n",
      "rapper\n",
      "\u001b[32m[03/04 12:43:41 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 12:43:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 12:43:41 d2.data.datasets.coco]: \u001b[0mLoaded 193 images in COCO format from /host/mic21-framework/server/uploads/rapper_gt.json\n",
      "\u001b[32m[03/04 12:43:41 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 193 images left.\n",
      "\u001b[32m[03/04 12:43:41 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    man     | 118          | microphone | 236          |   rapper   | 249          |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 603          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 12:43:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 12:43:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 12:43:41 d2.data.common]: \u001b[0mSerializing 193 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 12:43:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.91 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 12:43:42 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 12:43:59 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 19  total_loss: 2.181  loss_cls: 0.653  loss_box_reg: 0.9049  loss_mask: 0.5778  loss_rpn_cls: 0.02326  loss_rpn_loc: 0.02397  time: 0.8675  data_time: 0.2286  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:44:16 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 39  total_loss: 1.517  loss_cls: 0.3411  loss_box_reg: 0.7503  loss_mask: 0.3184  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.02821  time: 0.8469  data_time: 0.1715  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:44:33 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 59  total_loss: 1.077  loss_cls: 0.2378  loss_box_reg: 0.5639  loss_mask: 0.2392  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.02201  time: 0.8432  data_time: 0.1669  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:44:50 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 79  total_loss: 1.155  loss_cls: 0.2766  loss_box_reg: 0.5823  loss_mask: 0.2481  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.0256  time: 0.8465  data_time: 0.1882  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:45:08 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 99  total_loss: 0.8789  loss_cls: 0.1758  loss_box_reg: 0.4606  loss_mask: 0.2027  loss_rpn_cls: 0.009216  loss_rpn_loc: 0.0205  time: 0.8559  data_time: 0.2337  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:45:24 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 119  total_loss: 0.9113  loss_cls: 0.1998  loss_box_reg: 0.4769  loss_mask: 0.2054  loss_rpn_cls: 0.008963  loss_rpn_loc: 0.02021  time: 0.8511  data_time: 0.1763  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:45:41 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 139  total_loss: 0.8622  loss_cls: 0.1867  loss_box_reg: 0.4108  loss_mask: 0.1933  loss_rpn_cls: 0.009381  loss_rpn_loc: 0.02394  time: 0.8491  data_time: 0.1927  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:45:57 d2.utils.events]: \u001b[0m eta: 0:18:25  iter: 159  total_loss: 0.7653  loss_cls: 0.1736  loss_box_reg: 0.394  loss_mask: 0.1705  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.01747  time: 0.8447  data_time: 0.1745  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:46:15 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 179  total_loss: 0.8087  loss_cls: 0.1814  loss_box_reg: 0.39  loss_mask: 0.1683  loss_rpn_cls: 0.007667  loss_rpn_loc: 0.02292  time: 0.8504  data_time: 0.2010  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:46:33 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 199  total_loss: 0.8061  loss_cls: 0.2208  loss_box_reg: 0.3991  loss_mask: 0.1774  loss_rpn_cls: 0.008541  loss_rpn_loc: 0.02377  time: 0.8525  data_time: 0.2025  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:46:50 d2.utils.events]: \u001b[0m eta: 0:17:51  iter: 219  total_loss: 0.7276  loss_cls: 0.1632  loss_box_reg: 0.3581  loss_mask: 0.1677  loss_rpn_cls: 0.00643  loss_rpn_loc: 0.02246  time: 0.8541  data_time: 0.1842  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:47:08 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 239  total_loss: 0.7391  loss_cls: 0.1433  loss_box_reg: 0.389  loss_mask: 0.1681  loss_rpn_cls: 0.009002  loss_rpn_loc: 0.02263  time: 0.8569  data_time: 0.2164  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:47:26 d2.utils.events]: \u001b[0m eta: 0:17:24  iter: 259  total_loss: 0.7888  loss_cls: 0.1711  loss_box_reg: 0.4046  loss_mask: 0.183  loss_rpn_cls: 0.009386  loss_rpn_loc: 0.02425  time: 0.8605  data_time: 0.2222  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:47:43 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 279  total_loss: 0.7492  loss_cls: 0.1529  loss_box_reg: 0.388  loss_mask: 0.1678  loss_rpn_cls: 0.008753  loss_rpn_loc: 0.02013  time: 0.8617  data_time: 0.1992  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:48:01 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 299  total_loss: 0.7401  loss_cls: 0.1614  loss_box_reg: 0.3759  loss_mask: 0.1607  loss_rpn_cls: 0.006269  loss_rpn_loc: 0.02534  time: 0.8632  data_time: 0.2161  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:48:19 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 319  total_loss: 0.658  loss_cls: 0.1482  loss_box_reg: 0.3484  loss_mask: 0.1592  loss_rpn_cls: 0.007072  loss_rpn_loc: 0.02115  time: 0.8639  data_time: 0.2199  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:48:36 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 339  total_loss: 0.6771  loss_cls: 0.1496  loss_box_reg: 0.3461  loss_mask: 0.1583  loss_rpn_cls: 0.00736  loss_rpn_loc: 0.02543  time: 0.8653  data_time: 0.2007  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:48:53 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 359  total_loss: 0.7841  loss_cls: 0.1744  loss_box_reg: 0.355  loss_mask: 0.1685  loss_rpn_cls: 0.007721  loss_rpn_loc: 0.02076  time: 0.8638  data_time: 0.2019  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:49:11 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 379  total_loss: 0.702  loss_cls: 0.1692  loss_box_reg: 0.3557  loss_mask: 0.1419  loss_rpn_cls: 0.00765  loss_rpn_loc: 0.01884  time: 0.8642  data_time: 0.2185  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:49:28 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 399  total_loss: 0.7129  loss_cls: 0.1701  loss_box_reg: 0.356  loss_mask: 0.1594  loss_rpn_cls: 0.006501  loss_rpn_loc: 0.01662  time: 0.8649  data_time: 0.2259  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:49:45 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 419  total_loss: 0.7391  loss_cls: 0.1668  loss_box_reg: 0.376  loss_mask: 0.1581  loss_rpn_cls: 0.004015  loss_rpn_loc: 0.02135  time: 0.8635  data_time: 0.1885  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:50:02 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 439  total_loss: 0.6313  loss_cls: 0.1074  loss_box_reg: 0.3171  loss_mask: 0.139  loss_rpn_cls: 0.003242  loss_rpn_loc: 0.01624  time: 0.8639  data_time: 0.2104  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:50:20 d2.utils.events]: \u001b[0m eta: 0:14:45  iter: 459  total_loss: 0.7128  loss_cls: 0.141  loss_box_reg: 0.3584  loss_mask: 0.1596  loss_rpn_cls: 0.006842  loss_rpn_loc: 0.02063  time: 0.8651  data_time: 0.2051  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:50:38 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 479  total_loss: 0.6362  loss_cls: 0.1156  loss_box_reg: 0.3545  loss_mask: 0.146  loss_rpn_cls: 0.004609  loss_rpn_loc: 0.02199  time: 0.8666  data_time: 0.2433  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:50:56 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 499  total_loss: 0.6336  loss_cls: 0.1193  loss_box_reg: 0.35  loss_mask: 0.1544  loss_rpn_cls: 0.004875  loss_rpn_loc: 0.01589  time: 0.8672  data_time: 0.2179  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:51:13 d2.utils.events]: \u001b[0m eta: 0:13:54  iter: 519  total_loss: 0.5996  loss_cls: 0.1207  loss_box_reg: 0.2975  loss_mask: 0.1208  loss_rpn_cls: 0.005291  loss_rpn_loc: 0.01943  time: 0.8675  data_time: 0.1996  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:51:32 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 539  total_loss: 0.6041  loss_cls: 0.1333  loss_box_reg: 0.3083  loss_mask: 0.1392  loss_rpn_cls: 0.004443  loss_rpn_loc: 0.02005  time: 0.8691  data_time: 0.2302  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:51:48 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 559  total_loss: 0.585  loss_cls: 0.1231  loss_box_reg: 0.2899  loss_mask: 0.1588  loss_rpn_cls: 0.003014  loss_rpn_loc: 0.01843  time: 0.8682  data_time: 0.1805  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:52:05 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 579  total_loss: 0.5664  loss_cls: 0.088  loss_box_reg: 0.2974  loss_mask: 0.1526  loss_rpn_cls: 0.004006  loss_rpn_loc: 0.0186  time: 0.8675  data_time: 0.1937  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:52:23 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 599  total_loss: 0.6756  loss_cls: 0.14  loss_box_reg: 0.3179  loss_mask: 0.1686  loss_rpn_cls: 0.003477  loss_rpn_loc: 0.02353  time: 0.8678  data_time: 0.2169  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:52:40 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 619  total_loss: 0.5863  loss_cls: 0.1117  loss_box_reg: 0.2835  loss_mask: 0.1381  loss_rpn_cls: 0.005753  loss_rpn_loc: 0.01696  time: 0.8669  data_time: 0.1904  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:52:57 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 639  total_loss: 0.6095  loss_cls: 0.1021  loss_box_reg: 0.3037  loss_mask: 0.1412  loss_rpn_cls: 0.003551  loss_rpn_loc: 0.0173  time: 0.8660  data_time: 0.1882  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:53:14 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 659  total_loss: 0.6118  loss_cls: 0.1025  loss_box_reg: 0.3109  loss_mask: 0.1398  loss_rpn_cls: 0.004222  loss_rpn_loc: 0.01749  time: 0.8662  data_time: 0.1890  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 12:53:32 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 679  total_loss: 0.5594  loss_cls: 0.1023  loss_box_reg: 0.3104  loss_mask: 0.1493  loss_rpn_cls: 0.003514  loss_rpn_loc: 0.02409  time: 0.8673  data_time: 0.2320  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:53:49 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 699  total_loss: 0.5768  loss_cls: 0.0983  loss_box_reg: 0.2955  loss_mask: 0.1353  loss_rpn_cls: 0.002746  loss_rpn_loc: 0.01839  time: 0.8672  data_time: 0.2064  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:54:07 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 719  total_loss: 0.5594  loss_cls: 0.08215  loss_box_reg: 0.2867  loss_mask: 0.1431  loss_rpn_cls: 0.003098  loss_rpn_loc: 0.02062  time: 0.8678  data_time: 0.2355  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:54:24 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 739  total_loss: 0.5709  loss_cls: 0.1255  loss_box_reg: 0.3021  loss_mask: 0.1228  loss_rpn_cls: 0.004344  loss_rpn_loc: 0.01928  time: 0.8676  data_time: 0.1963  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:54:41 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 759  total_loss: 0.5662  loss_cls: 0.09889  loss_box_reg: 0.2882  loss_mask: 0.1285  loss_rpn_cls: 0.004357  loss_rpn_loc: 0.02521  time: 0.8672  data_time: 0.1994  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:54:59 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 779  total_loss: 0.5071  loss_cls: 0.09433  loss_box_reg: 0.2476  loss_mask: 0.1322  loss_rpn_cls: 0.004441  loss_rpn_loc: 0.02059  time: 0.8676  data_time: 0.2070  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:55:18 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 799  total_loss: 0.5943  loss_cls: 0.1146  loss_box_reg: 0.2965  loss_mask: 0.1327  loss_rpn_cls: 0.00295  loss_rpn_loc: 0.0177  time: 0.8692  data_time: 0.2368  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:55:34 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 819  total_loss: 0.5364  loss_cls: 0.09403  loss_box_reg: 0.2906  loss_mask: 0.1354  loss_rpn_cls: 0.002466  loss_rpn_loc: 0.01425  time: 0.8683  data_time: 0.1822  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:55:52 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 839  total_loss: 0.5372  loss_cls: 0.1006  loss_box_reg: 0.2786  loss_mask: 0.131  loss_rpn_cls: 0.003178  loss_rpn_loc: 0.01443  time: 0.8689  data_time: 0.2075  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:56:10 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 859  total_loss: 0.5512  loss_cls: 0.1077  loss_box_reg: 0.2694  loss_mask: 0.1363  loss_rpn_cls: 0.002135  loss_rpn_loc: 0.02138  time: 0.8688  data_time: 0.1884  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:56:27 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 879  total_loss: 0.5389  loss_cls: 0.09539  loss_box_reg: 0.2625  loss_mask: 0.1209  loss_rpn_cls: 0.004082  loss_rpn_loc: 0.02146  time: 0.8688  data_time: 0.2024  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:56:45 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 899  total_loss: 0.4977  loss_cls: 0.108  loss_box_reg: 0.249  loss_mask: 0.1285  loss_rpn_cls: 0.00318  loss_rpn_loc: 0.01497  time: 0.8692  data_time: 0.2182  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:57:01 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 919  total_loss: 0.5409  loss_cls: 0.1145  loss_box_reg: 0.2551  loss_mask: 0.1377  loss_rpn_cls: 0.003676  loss_rpn_loc: 0.01622  time: 0.8682  data_time: 0.1832  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:57:20 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 939  total_loss: 0.5377  loss_cls: 0.09165  loss_box_reg: 0.2492  loss_mask: 0.1428  loss_rpn_cls: 0.002543  loss_rpn_loc: 0.01989  time: 0.8696  data_time: 0.2260  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:57:37 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 959  total_loss: 0.5028  loss_cls: 0.09517  loss_box_reg: 0.2756  loss_mask: 0.1257  loss_rpn_cls: 0.00413  loss_rpn_loc: 0.01949  time: 0.8692  data_time: 0.1795  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:57:55 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 979  total_loss: 0.5278  loss_cls: 0.1093  loss_box_reg: 0.2637  loss_mask: 0.1304  loss_rpn_cls: 0.003414  loss_rpn_loc: 0.01677  time: 0.8698  data_time: 0.2219  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:58:12 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 999  total_loss: 0.5506  loss_cls: 0.1052  loss_box_reg: 0.2742  loss_mask: 0.13  loss_rpn_cls: 0.003719  loss_rpn_loc: 0.0219  time: 0.8694  data_time: 0.2043  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 12:58:30 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 1019  total_loss: 0.4879  loss_cls: 0.09969  loss_box_reg: 0.2584  loss_mask: 0.1196  loss_rpn_cls: 0.002091  loss_rpn_loc: 0.01707  time: 0.8696  data_time: 0.2143  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:58:47 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 1039  total_loss: 0.465  loss_cls: 0.09788  loss_box_reg: 0.2151  loss_mask: 0.1122  loss_rpn_cls: 0.00321  loss_rpn_loc: 0.01905  time: 0.8698  data_time: 0.2185  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:59:03 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 1059  total_loss: 0.4689  loss_cls: 0.077  loss_box_reg: 0.224  loss_mask: 0.1206  loss_rpn_cls: 0.002717  loss_rpn_loc: 0.02013  time: 0.8685  data_time: 0.1535  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:59:21 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1079  total_loss: 0.4403  loss_cls: 0.08108  loss_box_reg: 0.2214  loss_mask: 0.1201  loss_rpn_cls: 0.002483  loss_rpn_loc: 0.01691  time: 0.8685  data_time: 0.1863  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:59:38 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 1099  total_loss: 0.467  loss_cls: 0.07895  loss_box_reg: 0.2168  loss_mask: 0.1261  loss_rpn_cls: 0.002348  loss_rpn_loc: 0.01765  time: 0.8685  data_time: 0.2136  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 12:59:56 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 1119  total_loss: 0.4828  loss_cls: 0.06089  loss_box_reg: 0.2488  loss_mask: 0.1212  loss_rpn_cls: 0.002781  loss_rpn_loc: 0.0184  time: 0.8688  data_time: 0.1957  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:00:13 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 1139  total_loss: 0.4494  loss_cls: 0.07645  loss_box_reg: 0.2188  loss_mask: 0.1198  loss_rpn_cls: 0.002205  loss_rpn_loc: 0.01601  time: 0.8688  data_time: 0.2145  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:00:30 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 1159  total_loss: 0.4759  loss_cls: 0.08353  loss_box_reg: 0.2362  loss_mask: 0.119  loss_rpn_cls: 0.004482  loss_rpn_loc: 0.02064  time: 0.8685  data_time: 0.1787  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:00:47 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 1179  total_loss: 0.4806  loss_cls: 0.1085  loss_box_reg: 0.223  loss_mask: 0.1191  loss_rpn_cls: 0.002388  loss_rpn_loc: 0.01374  time: 0.8683  data_time: 0.2023  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:01:05 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 1199  total_loss: 0.4332  loss_cls: 0.07452  loss_box_reg: 0.2199  loss_mask: 0.1163  loss_rpn_cls: 0.003096  loss_rpn_loc: 0.01655  time: 0.8686  data_time: 0.1978  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:01:22 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 1219  total_loss: 0.4224  loss_cls: 0.0883  loss_box_reg: 0.2006  loss_mask: 0.1111  loss_rpn_cls: 0.001976  loss_rpn_loc: 0.01807  time: 0.8686  data_time: 0.1886  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:01:40 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 1239  total_loss: 0.4858  loss_cls: 0.0843  loss_box_reg: 0.2207  loss_mask: 0.125  loss_rpn_cls: 0.003131  loss_rpn_loc: 0.01701  time: 0.8686  data_time: 0.2171  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:01:58 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 1259  total_loss: 0.4353  loss_cls: 0.08033  loss_box_reg: 0.1891  loss_mask: 0.1263  loss_rpn_cls: 0.004352  loss_rpn_loc: 0.01611  time: 0.8691  data_time: 0.2314  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:02:15 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 1279  total_loss: 0.4172  loss_cls: 0.06996  loss_box_reg: 0.2066  loss_mask: 0.1212  loss_rpn_cls: 0.003761  loss_rpn_loc: 0.01443  time: 0.8692  data_time: 0.2275  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:02:33 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 1299  total_loss: 0.4317  loss_cls: 0.06642  loss_box_reg: 0.2024  loss_mask: 0.1173  loss_rpn_cls: 0.002254  loss_rpn_loc: 0.01699  time: 0.8694  data_time: 0.2272  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:02:50 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 1319  total_loss: 0.4044  loss_cls: 0.08492  loss_box_reg: 0.1986  loss_mask: 0.1166  loss_rpn_cls: 0.002843  loss_rpn_loc: 0.01259  time: 0.8695  data_time: 0.2111  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 13:03:08 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 1339  total_loss: 0.4586  loss_cls: 0.08488  loss_box_reg: 0.2123  loss_mask: 0.1375  loss_rpn_cls: 0.002549  loss_rpn_loc: 0.01434  time: 0.8695  data_time: 0.2309  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:03:25 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 1359  total_loss: 0.4628  loss_cls: 0.0832  loss_box_reg: 0.2132  loss_mask: 0.1248  loss_rpn_cls: 0.00246  loss_rpn_loc: 0.01408  time: 0.8695  data_time: 0.1971  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:03:43 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 1379  total_loss: 0.4029  loss_cls: 0.07215  loss_box_reg: 0.1889  loss_mask: 0.1246  loss_rpn_cls: 0.003004  loss_rpn_loc: 0.02041  time: 0.8697  data_time: 0.2239  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:04:00 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 1399  total_loss: 0.4229  loss_cls: 0.0732  loss_box_reg: 0.2182  loss_mask: 0.1328  loss_rpn_cls: 0.003307  loss_rpn_loc: 0.01847  time: 0.8694  data_time: 0.1912  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:04:17 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 1419  total_loss: 0.437  loss_cls: 0.1123  loss_box_reg: 0.2028  loss_mask: 0.1276  loss_rpn_cls: 0.00335  loss_rpn_loc: 0.01537  time: 0.8694  data_time: 0.1738  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:04:35 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 1439  total_loss: 0.4307  loss_cls: 0.06128  loss_box_reg: 0.2255  loss_mask: 0.1148  loss_rpn_cls: 0.002544  loss_rpn_loc: 0.01634  time: 0.8693  data_time: 0.1992  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:04:52 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 1459  total_loss: 0.4082  loss_cls: 0.07121  loss_box_reg: 0.2046  loss_mask: 0.1113  loss_rpn_cls: 0.00178  loss_rpn_loc: 0.01599  time: 0.8691  data_time: 0.1995  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:05:09 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.4372  loss_cls: 0.08239  loss_box_reg: 0.2004  loss_mask: 0.1087  loss_rpn_cls: 0.002208  loss_rpn_loc: 0.01737  time: 0.8690  data_time: 0.1946  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:05:29 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4578  loss_cls: 0.08644  loss_box_reg: 0.2081  loss_mask: 0.1374  loss_rpn_cls: 0.002234  loss_rpn_loc: 0.0164  time: 0.8696  data_time: 0.2412  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:05:29 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:42 (0.8696 s / it)\n",
      "\u001b[32m[03/04 13:05:29 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:45 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 13:05:30 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 13:05:30 d2.data.datasets.coco]: \u001b[0mLoaded 220 images in COCO format from /host/mic21-framework/server/uploads/saxophonist_gt.json\n",
      "saxophonist\n",
      "\u001b[32m[03/04 13:05:30 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 13:05:30 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 13:05:30 d2.data.datasets.coco]: \u001b[0mLoaded 220 images in COCO format from /host/mic21-framework/server/uploads/saxophonist_gt.json\n",
      "\u001b[32m[03/04 13:05:30 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 220 images left.\n",
      "\u001b[32m[03/04 13:05:30 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category   | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:-----------:|:-------------|\n",
      "|      man      | 65           | microphone | 172          | music stand | 54           |\n",
      "|  saxophonist  | 272          | saxophone  | 276          |  musician   | 101          |\n",
      "| microphone .. | 137          |            |              |             |              |\n",
      "|     total     | 1077         |            |              |             |              |\u001b[0m\n",
      "\u001b[32m[03/04 13:05:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 13:05:30 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 13:05:30 d2.data.common]: \u001b[0mSerializing 220 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 13:05:30 d2.data.common]: \u001b[0mSerialized dataset takes 2.97 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (28, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (28,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (7, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 13:05:30 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 13:05:50 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 19  total_loss: 2.604  loss_cls: 0.9059  loss_box_reg: 0.961  loss_mask: 0.5965  loss_rpn_cls: 0.03436  loss_rpn_loc: 0.05057  time: 0.9515  data_time: 0.3160  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:06:09 d2.utils.events]: \u001b[0m eta: 0:21:35  iter: 39  total_loss: 1.964  loss_cls: 0.6082  loss_box_reg: 0.8919  loss_mask: 0.4322  loss_rpn_cls: 0.03769  loss_rpn_loc: 0.05876  time: 0.9436  data_time: 0.2719  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:06:29 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 59  total_loss: 1.476  loss_cls: 0.4152  loss_box_reg: 0.7159  loss_mask: 0.2822  loss_rpn_cls: 0.02978  loss_rpn_loc: 0.05752  time: 0.9640  data_time: 0.3312  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:06:48 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 79  total_loss: 1.444  loss_cls: 0.4466  loss_box_reg: 0.6328  loss_mask: 0.2744  loss_rpn_cls: 0.0257  loss_rpn_loc: 0.05814  time: 0.9658  data_time: 0.3281  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:07:09 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 99  total_loss: 1.238  loss_cls: 0.3426  loss_box_reg: 0.5914  loss_mask: 0.224  loss_rpn_cls: 0.02891  loss_rpn_loc: 0.05756  time: 0.9739  data_time: 0.3515  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:07:28 d2.utils.events]: \u001b[0m eta: 0:22:39  iter: 119  total_loss: 1.17  loss_cls: 0.3352  loss_box_reg: 0.5615  loss_mask: 0.2195  loss_rpn_cls: 0.02463  loss_rpn_loc: 0.04069  time: 0.9734  data_time: 0.2965  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:07:49 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 139  total_loss: 1.117  loss_cls: 0.2836  loss_box_reg: 0.5157  loss_mask: 0.1987  loss_rpn_cls: 0.01792  loss_rpn_loc: 0.06011  time: 0.9856  data_time: 0.3468  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:08:09 d2.utils.events]: \u001b[0m eta: 0:22:15  iter: 159  total_loss: 1.251  loss_cls: 0.3678  loss_box_reg: 0.5178  loss_mask: 0.2447  loss_rpn_cls: 0.02939  loss_rpn_loc: 0.04647  time: 0.9838  data_time: 0.2962  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:08:28 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 179  total_loss: 1.125  loss_cls: 0.3209  loss_box_reg: 0.5022  loss_mask: 0.2105  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.04911  time: 0.9838  data_time: 0.3255  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:08:48 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 199  total_loss: 1.1  loss_cls: 0.3299  loss_box_reg: 0.5286  loss_mask: 0.1826  loss_rpn_cls: 0.02112  loss_rpn_loc: 0.04665  time: 0.9838  data_time: 0.3239  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:09:07 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 219  total_loss: 1.125  loss_cls: 0.3422  loss_box_reg: 0.4799  loss_mask: 0.2339  loss_rpn_cls: 0.02212  loss_rpn_loc: 0.04587  time: 0.9807  data_time: 0.2752  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:09:25 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 239  total_loss: 1.081  loss_cls: 0.3281  loss_box_reg: 0.4547  loss_mask: 0.207  loss_rpn_cls: 0.02191  loss_rpn_loc: 0.06037  time: 0.9755  data_time: 0.2754  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:09:46 d2.utils.events]: \u001b[0m eta: 0:20:07  iter: 259  total_loss: 1.093  loss_cls: 0.3416  loss_box_reg: 0.4693  loss_mask: 0.2123  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.04369  time: 0.9801  data_time: 0.3616  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:10:07 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 279  total_loss: 0.9112  loss_cls: 0.2598  loss_box_reg: 0.4452  loss_mask: 0.1715  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.05164  time: 0.9857  data_time: 0.3934  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:10:27 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 299  total_loss: 0.9155  loss_cls: 0.3006  loss_box_reg: 0.3711  loss_mask: 0.1722  loss_rpn_cls: 0.01902  loss_rpn_loc: 0.04553  time: 0.9843  data_time: 0.2994  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:10:47 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 319  total_loss: 0.8731  loss_cls: 0.2538  loss_box_reg: 0.4136  loss_mask: 0.1744  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.03829  time: 0.9856  data_time: 0.3134  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:11:07 d2.utils.events]: \u001b[0m eta: 0:18:57  iter: 339  total_loss: 0.9471  loss_cls: 0.2789  loss_box_reg: 0.4122  loss_mask: 0.1719  loss_rpn_cls: 0.02222  loss_rpn_loc: 0.05806  time: 0.9867  data_time: 0.3433  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:11:26 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 359  total_loss: 1.054  loss_cls: 0.3403  loss_box_reg: 0.4393  loss_mask: 0.1917  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.05701  time: 0.9843  data_time: 0.2995  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:11:46 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 379  total_loss: 0.8656  loss_cls: 0.2123  loss_box_reg: 0.4059  loss_mask: 0.1656  loss_rpn_cls: 0.00991  loss_rpn_loc: 0.0498  time: 0.9846  data_time: 0.3105  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:12:04 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 399  total_loss: 0.9081  loss_cls: 0.2281  loss_box_reg: 0.4047  loss_mask: 0.1924  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.05419  time: 0.9823  data_time: 0.2803  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:12:25 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 419  total_loss: 0.9183  loss_cls: 0.2687  loss_box_reg: 0.4374  loss_mask: 0.1826  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.05209  time: 0.9839  data_time: 0.3138  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:12:45 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 439  total_loss: 0.987  loss_cls: 0.2974  loss_box_reg: 0.4045  loss_mask: 0.1862  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.04583  time: 0.9842  data_time: 0.3356  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:13:05 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 459  total_loss: 0.857  loss_cls: 0.2418  loss_box_reg: 0.3963  loss_mask: 0.189  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.03772  time: 0.9851  data_time: 0.3472  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:13:23 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 479  total_loss: 0.7761  loss_cls: 0.1953  loss_box_reg: 0.3763  loss_mask: 0.1612  loss_rpn_cls: 0.01669  loss_rpn_loc: 0.04084  time: 0.9822  data_time: 0.2746  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:13:43 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 499  total_loss: 0.8799  loss_cls: 0.249  loss_box_reg: 0.4017  loss_mask: 0.1709  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.05313  time: 0.9838  data_time: 0.3436  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:14:02 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 519  total_loss: 0.9114  loss_cls: 0.2392  loss_box_reg: 0.378  loss_mask: 0.1612  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.0406  time: 0.9819  data_time: 0.2840  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:14:22 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 539  total_loss: 0.8567  loss_cls: 0.1958  loss_box_reg: 0.3991  loss_mask: 0.1676  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.04757  time: 0.9820  data_time: 0.3082  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:14:41 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 559  total_loss: 0.8393  loss_cls: 0.2605  loss_box_reg: 0.4085  loss_mask: 0.1676  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.04187  time: 0.9811  data_time: 0.3064  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:15:02 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 579  total_loss: 0.8319  loss_cls: 0.2334  loss_box_reg: 0.3692  loss_mask: 0.1769  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.03991  time: 0.9827  data_time: 0.3526  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:15:20 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 599  total_loss: 0.7836  loss_cls: 0.1986  loss_box_reg: 0.373  loss_mask: 0.1553  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.0421  time: 0.9809  data_time: 0.2642  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:15:40 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 619  total_loss: 0.9647  loss_cls: 0.2569  loss_box_reg: 0.4052  loss_mask: 0.1771  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.0495  time: 0.9814  data_time: 0.3245  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:16:00 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 639  total_loss: 0.8268  loss_cls: 0.191  loss_box_reg: 0.3881  loss_mask: 0.1773  loss_rpn_cls: 0.009101  loss_rpn_loc: 0.05035  time: 0.9823  data_time: 0.3400  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:16:19 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 659  total_loss: 0.7913  loss_cls: 0.1818  loss_box_reg: 0.3816  loss_mask: 0.1698  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.02986  time: 0.9808  data_time: 0.2686  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 13:16:38 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 679  total_loss: 0.7861  loss_cls: 0.2101  loss_box_reg: 0.3756  loss_mask: 0.1598  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.04276  time: 0.9802  data_time: 0.3066  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:16:57 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 699  total_loss: 0.8599  loss_cls: 0.2374  loss_box_reg: 0.3872  loss_mask: 0.1723  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.05048  time: 0.9794  data_time: 0.2894  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:17:17 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 719  total_loss: 0.8259  loss_cls: 0.2699  loss_box_reg: 0.3868  loss_mask: 0.1598  loss_rpn_cls: 0.007234  loss_rpn_loc: 0.03577  time: 0.9795  data_time: 0.3153  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:17:37 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 739  total_loss: 0.8654  loss_cls: 0.1778  loss_box_reg: 0.3697  loss_mask: 0.1712  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.04569  time: 0.9804  data_time: 0.3355  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:17:57 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 759  total_loss: 0.8556  loss_cls: 0.2215  loss_box_reg: 0.3833  loss_mask: 0.1676  loss_rpn_cls: 0.007334  loss_rpn_loc: 0.0377  time: 0.9806  data_time: 0.3244  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:18:17 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 779  total_loss: 0.8495  loss_cls: 0.2243  loss_box_reg: 0.3717  loss_mask: 0.1622  loss_rpn_cls: 0.009265  loss_rpn_loc: 0.04467  time: 0.9808  data_time: 0.3110  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:18:37 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 799  total_loss: 0.7928  loss_cls: 0.1926  loss_box_reg: 0.3535  loss_mask: 0.165  loss_rpn_cls: 0.009722  loss_rpn_loc: 0.0451  time: 0.9814  data_time: 0.3383  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:18:57 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 819  total_loss: 0.7362  loss_cls: 0.164  loss_box_reg: 0.3564  loss_mask: 0.145  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.03467  time: 0.9817  data_time: 0.3406  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:19:16 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 839  total_loss: 0.7982  loss_cls: 0.1877  loss_box_reg: 0.3623  loss_mask: 0.168  loss_rpn_cls: 0.009577  loss_rpn_loc: 0.04624  time: 0.9814  data_time: 0.2917  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:19:34 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 859  total_loss: 0.8117  loss_cls: 0.2096  loss_box_reg: 0.3655  loss_mask: 0.1656  loss_rpn_cls: 0.009058  loss_rpn_loc: 0.05264  time: 0.9798  data_time: 0.2504  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:19:55 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 879  total_loss: 0.7145  loss_cls: 0.1745  loss_box_reg: 0.3305  loss_mask: 0.1711  loss_rpn_cls: 0.005085  loss_rpn_loc: 0.03721  time: 0.9808  data_time: 0.3284  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:20:15 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 899  total_loss: 0.7075  loss_cls: 0.1509  loss_box_reg: 0.3423  loss_mask: 0.1587  loss_rpn_cls: 0.006001  loss_rpn_loc: 0.04711  time: 0.9809  data_time: 0.2985  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:20:34 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 919  total_loss: 0.7824  loss_cls: 0.1934  loss_box_reg: 0.3411  loss_mask: 0.1775  loss_rpn_cls: 0.006506  loss_rpn_loc: 0.04651  time: 0.9807  data_time: 0.2821  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:20:54 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 939  total_loss: 0.8363  loss_cls: 0.2113  loss_box_reg: 0.3604  loss_mask: 0.1651  loss_rpn_cls: 0.007838  loss_rpn_loc: 0.04452  time: 0.9813  data_time: 0.3591  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:21:13 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 959  total_loss: 0.6903  loss_cls: 0.207  loss_box_reg: 0.3428  loss_mask: 0.1702  loss_rpn_cls: 0.009497  loss_rpn_loc: 0.03809  time: 0.9806  data_time: 0.3028  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:21:33 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 979  total_loss: 0.7293  loss_cls: 0.1868  loss_box_reg: 0.3463  loss_mask: 0.1625  loss_rpn_cls: 0.008097  loss_rpn_loc: 0.03541  time: 0.9804  data_time: 0.3187  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:21:53 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 999  total_loss: 0.6763  loss_cls: 0.1566  loss_box_reg: 0.3229  loss_mask: 0.1461  loss_rpn_cls: 0.005954  loss_rpn_loc: 0.03699  time: 0.9809  data_time: 0.3409  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:22:12 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 1019  total_loss: 0.7165  loss_cls: 0.1719  loss_box_reg: 0.3318  loss_mask: 0.1523  loss_rpn_cls: 0.005778  loss_rpn_loc: 0.04647  time: 0.9803  data_time: 0.2662  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:22:31 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 1039  total_loss: 0.7466  loss_cls: 0.1924  loss_box_reg: 0.3274  loss_mask: 0.1595  loss_rpn_cls: 0.007301  loss_rpn_loc: 0.03165  time: 0.9796  data_time: 0.3112  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:22:50 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 1059  total_loss: 0.659  loss_cls: 0.1669  loss_box_reg: 0.3236  loss_mask: 0.1504  loss_rpn_cls: 0.007286  loss_rpn_loc: 0.03765  time: 0.9792  data_time: 0.2907  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:23:09 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 1079  total_loss: 0.6496  loss_cls: 0.1668  loss_box_reg: 0.2927  loss_mask: 0.1624  loss_rpn_cls: 0.008463  loss_rpn_loc: 0.03706  time: 0.9786  data_time: 0.2906  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:23:28 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 1099  total_loss: 0.6419  loss_cls: 0.1547  loss_box_reg: 0.2862  loss_mask: 0.1454  loss_rpn_cls: 0.004285  loss_rpn_loc: 0.03441  time: 0.9784  data_time: 0.3220  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:23:49 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 1119  total_loss: 0.6365  loss_cls: 0.1548  loss_box_reg: 0.2848  loss_mask: 0.1506  loss_rpn_cls: 0.006123  loss_rpn_loc: 0.04339  time: 0.9795  data_time: 0.3234  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:24:07 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1139  total_loss: 0.7549  loss_cls: 0.2154  loss_box_reg: 0.3189  loss_mask: 0.183  loss_rpn_cls: 0.009563  loss_rpn_loc: 0.04926  time: 0.9782  data_time: 0.2576  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:24:27 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 1159  total_loss: 0.6241  loss_cls: 0.143  loss_box_reg: 0.2781  loss_mask: 0.1463  loss_rpn_cls: 0.005267  loss_rpn_loc: 0.02838  time: 0.9781  data_time: 0.3001  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:24:46 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 1179  total_loss: 0.6756  loss_cls: 0.1528  loss_box_reg: 0.3134  loss_mask: 0.1515  loss_rpn_cls: 0.008198  loss_rpn_loc: 0.0395  time: 0.9779  data_time: 0.3051  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:25:06 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 1199  total_loss: 0.7181  loss_cls: 0.1495  loss_box_reg: 0.3132  loss_mask: 0.1645  loss_rpn_cls: 0.006611  loss_rpn_loc: 0.04447  time: 0.9779  data_time: 0.2982  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:25:25 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 1219  total_loss: 0.6572  loss_cls: 0.1891  loss_box_reg: 0.2905  loss_mask: 0.1505  loss_rpn_cls: 0.006653  loss_rpn_loc: 0.03466  time: 0.9782  data_time: 0.2958  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:25:45 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 1239  total_loss: 0.6365  loss_cls: 0.1788  loss_box_reg: 0.2987  loss_mask: 0.164  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.03897  time: 0.9779  data_time: 0.2825  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:26:05 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 1259  total_loss: 0.572  loss_cls: 0.1444  loss_box_reg: 0.2484  loss_mask: 0.1323  loss_rpn_cls: 0.006382  loss_rpn_loc: 0.0306  time: 0.9785  data_time: 0.3868  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:26:24 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 1279  total_loss: 0.6997  loss_cls: 0.1673  loss_box_reg: 0.2896  loss_mask: 0.1447  loss_rpn_cls: 0.006556  loss_rpn_loc: 0.04136  time: 0.9783  data_time: 0.2985  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:26:43 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 1299  total_loss: 0.7121  loss_cls: 0.1754  loss_box_reg: 0.2797  loss_mask: 0.1551  loss_rpn_cls: 0.009334  loss_rpn_loc: 0.02914  time: 0.9775  data_time: 0.2998  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:27:02 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 1319  total_loss: 0.6718  loss_cls: 0.156  loss_box_reg: 0.2864  loss_mask: 0.1643  loss_rpn_cls: 0.00799  loss_rpn_loc: 0.03726  time: 0.9770  data_time: 0.2752  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 13:27:22 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 1339  total_loss: 0.6463  loss_cls: 0.1637  loss_box_reg: 0.2727  loss_mask: 0.1546  loss_rpn_cls: 0.005991  loss_rpn_loc: 0.0303  time: 0.9776  data_time: 0.3575  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:27:42 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 1359  total_loss: 0.6504  loss_cls: 0.143  loss_box_reg: 0.2926  loss_mask: 0.1458  loss_rpn_cls: 0.007677  loss_rpn_loc: 0.04308  time: 0.9779  data_time: 0.3199  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:28:02 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 1379  total_loss: 0.6133  loss_cls: 0.1377  loss_box_reg: 0.2807  loss_mask: 0.1546  loss_rpn_cls: 0.007101  loss_rpn_loc: 0.04149  time: 0.9785  data_time: 0.3344  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:28:22 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 1399  total_loss: 0.6336  loss_cls: 0.151  loss_box_reg: 0.277  loss_mask: 0.1391  loss_rpn_cls: 0.002774  loss_rpn_loc: 0.02776  time: 0.9786  data_time: 0.3006  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:28:41 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 1419  total_loss: 0.7234  loss_cls: 0.1825  loss_box_reg: 0.3186  loss_mask: 0.1652  loss_rpn_cls: 0.007085  loss_rpn_loc: 0.0365  time: 0.9783  data_time: 0.3116  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:29:00 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.6467  loss_cls: 0.1607  loss_box_reg: 0.2758  loss_mask: 0.1611  loss_rpn_cls: 0.006817  loss_rpn_loc: 0.03304  time: 0.9779  data_time: 0.2706  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:29:19 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 1459  total_loss: 0.6582  loss_cls: 0.1782  loss_box_reg: 0.2646  loss_mask: 0.1632  loss_rpn_cls: 0.007847  loss_rpn_loc: 0.03261  time: 0.9773  data_time: 0.2767  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:29:40 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.696  loss_cls: 0.182  loss_box_reg: 0.3216  loss_mask: 0.1566  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.047  time: 0.9780  data_time: 0.3585  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:30:00 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.6333  loss_cls: 0.1585  loss_box_reg: 0.2672  loss_mask: 0.1598  loss_rpn_cls: 0.008988  loss_rpn_loc: 0.03701  time: 0.9774  data_time: 0.2679  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:30:00 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:24 (0.9774 s / it)\n",
      "\u001b[32m[03/04 13:30:00 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:26 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 13:30:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 13:30:01 d2.data.datasets.coco]: \u001b[0mLoaded 191 images in COCO format from /host/mic21-framework/server/uploads/singer_gt.json\n",
      "singer\n",
      "\u001b[32m[03/04 13:30:01 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 13:30:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 13:30:01 d2.data.datasets.coco]: \u001b[0mLoaded 191 images in COCO format from /host/mic21-framework/server/uploads/singer_gt.json\n",
      "\u001b[32m[03/04 13:30:01 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 188 images left.\n",
      "\u001b[32m[03/04 13:30:01 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:-------------:|:-------------|\n",
      "| microphone | 211          |   singer   | 213          | microphone .. | 129          |\n",
      "|            |              |            |              |               |              |\n",
      "|   total    | 553          |            |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 13:30:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 13:30:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 13:30:01 d2.data.common]: \u001b[0mSerializing 188 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 13:30:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.83 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 13:30:02 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 13:30:21 d2.utils.events]: \u001b[0m eta: 0:24:49  iter: 19  total_loss: 2.264  loss_cls: 0.7133  loss_box_reg: 0.9697  loss_mask: 0.5689  loss_rpn_cls: 0.02281  loss_rpn_loc: 0.03446  time: 0.9604  data_time: 0.3522  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:30:40 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 39  total_loss: 1.588  loss_cls: 0.3463  loss_box_reg: 0.835  loss_mask: 0.3008  loss_rpn_cls: 0.02501  loss_rpn_loc: 0.03482  time: 0.9373  data_time: 0.2818  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:30:58 d2.utils.events]: \u001b[0m eta: 0:21:39  iter: 59  total_loss: 1.244  loss_cls: 0.2851  loss_box_reg: 0.6612  loss_mask: 0.2245  loss_rpn_cls: 0.01389  loss_rpn_loc: 0.04978  time: 0.9379  data_time: 0.2861  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:31:18 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 79  total_loss: 1.023  loss_cls: 0.2395  loss_box_reg: 0.5242  loss_mask: 0.1974  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.04205  time: 0.9449  data_time: 0.3105  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:31:37 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 99  total_loss: 0.9339  loss_cls: 0.2033  loss_box_reg: 0.4745  loss_mask: 0.1732  loss_rpn_cls: 0.01376  loss_rpn_loc: 0.03626  time: 0.9458  data_time: 0.3096  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:31:56 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 119  total_loss: 0.9134  loss_cls: 0.175  loss_box_reg: 0.5097  loss_mask: 0.1705  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.04594  time: 0.9487  data_time: 0.3216  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:32:15 d2.utils.events]: \u001b[0m eta: 0:20:46  iter: 139  total_loss: 0.895  loss_cls: 0.2169  loss_box_reg: 0.4383  loss_mask: 0.1915  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.03373  time: 0.9502  data_time: 0.3000  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:32:33 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 159  total_loss: 0.8606  loss_cls: 0.1759  loss_box_reg: 0.457  loss_mask: 0.171  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.0448  time: 0.9443  data_time: 0.2574  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:32:52 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 179  total_loss: 0.7369  loss_cls: 0.1692  loss_box_reg: 0.3827  loss_mask: 0.1404  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.02409  time: 0.9458  data_time: 0.3126  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:33:11 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 199  total_loss: 0.819  loss_cls: 0.1828  loss_box_reg: 0.4493  loss_mask: 0.1668  loss_rpn_cls: 0.01178  loss_rpn_loc: 0.03657  time: 0.9440  data_time: 0.2767  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:33:31 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 219  total_loss: 0.7346  loss_cls: 0.1636  loss_box_reg: 0.3713  loss_mask: 0.1509  loss_rpn_cls: 0.008628  loss_rpn_loc: 0.02654  time: 0.9477  data_time: 0.3288  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:33:49 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 239  total_loss: 0.7762  loss_cls: 0.1602  loss_box_reg: 0.3566  loss_mask: 0.1672  loss_rpn_cls: 0.007013  loss_rpn_loc: 0.02873  time: 0.9464  data_time: 0.2891  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:34:10 d2.utils.events]: \u001b[0m eta: 0:19:04  iter: 259  total_loss: 0.7275  loss_cls: 0.1388  loss_box_reg: 0.3745  loss_mask: 0.1534  loss_rpn_cls: 0.009676  loss_rpn_loc: 0.03335  time: 0.9542  data_time: 0.3669  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:34:29 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 279  total_loss: 0.6722  loss_cls: 0.147  loss_box_reg: 0.3581  loss_mask: 0.1545  loss_rpn_cls: 0.006117  loss_rpn_loc: 0.03198  time: 0.9521  data_time: 0.2720  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:34:49 d2.utils.events]: \u001b[0m eta: 0:18:33  iter: 299  total_loss: 0.7181  loss_cls: 0.1389  loss_box_reg: 0.3484  loss_mask: 0.1502  loss_rpn_cls: 0.008556  loss_rpn_loc: 0.02917  time: 0.9541  data_time: 0.3134  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:35:09 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 319  total_loss: 0.7699  loss_cls: 0.1701  loss_box_reg: 0.3859  loss_mask: 0.1516  loss_rpn_cls: 0.006015  loss_rpn_loc: 0.02627  time: 0.9592  data_time: 0.3687  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:35:29 d2.utils.events]: \u001b[0m eta: 0:18:12  iter: 339  total_loss: 0.7147  loss_cls: 0.1448  loss_box_reg: 0.3663  loss_mask: 0.1566  loss_rpn_cls: 0.009038  loss_rpn_loc: 0.04123  time: 0.9597  data_time: 0.3067  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:35:48 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 359  total_loss: 0.6933  loss_cls: 0.1379  loss_box_reg: 0.3615  loss_mask: 0.1563  loss_rpn_cls: 0.008272  loss_rpn_loc: 0.02807  time: 0.9599  data_time: 0.3000  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:36:07 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 379  total_loss: 0.6875  loss_cls: 0.1324  loss_box_reg: 0.3296  loss_mask: 0.1401  loss_rpn_cls: 0.005903  loss_rpn_loc: 0.03888  time: 0.9592  data_time: 0.3129  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:36:28 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 399  total_loss: 0.672  loss_cls: 0.1321  loss_box_reg: 0.3424  loss_mask: 0.1265  loss_rpn_cls: 0.007917  loss_rpn_loc: 0.03122  time: 0.9631  data_time: 0.3729  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:36:47 d2.utils.events]: \u001b[0m eta: 0:17:04  iter: 419  total_loss: 0.6757  loss_cls: 0.1381  loss_box_reg: 0.345  loss_mask: 0.138  loss_rpn_cls: 0.003849  loss_rpn_loc: 0.03458  time: 0.9626  data_time: 0.3067  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:37:05 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 439  total_loss: 0.6285  loss_cls: 0.07936  loss_box_reg: 0.3162  loss_mask: 0.1419  loss_rpn_cls: 0.005644  loss_rpn_loc: 0.03276  time: 0.9609  data_time: 0.3133  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:37:25 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 459  total_loss: 0.6493  loss_cls: 0.1455  loss_box_reg: 0.3449  loss_mask: 0.1291  loss_rpn_cls: 0.00835  loss_rpn_loc: 0.03389  time: 0.9623  data_time: 0.3017  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:37:45 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 479  total_loss: 0.6516  loss_cls: 0.1378  loss_box_reg: 0.3384  loss_mask: 0.1286  loss_rpn_cls: 0.006018  loss_rpn_loc: 0.02525  time: 0.9630  data_time: 0.3517  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:38:04 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 499  total_loss: 0.5826  loss_cls: 0.09592  loss_box_reg: 0.3194  loss_mask: 0.1271  loss_rpn_cls: 0.004577  loss_rpn_loc: 0.02823  time: 0.9639  data_time: 0.3316  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:38:24 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 519  total_loss: 0.6478  loss_cls: 0.117  loss_box_reg: 0.3522  loss_mask: 0.1394  loss_rpn_cls: 0.006236  loss_rpn_loc: 0.02148  time: 0.9641  data_time: 0.3102  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:38:44 d2.utils.events]: \u001b[0m eta: 0:15:16  iter: 539  total_loss: 0.6287  loss_cls: 0.1005  loss_box_reg: 0.3345  loss_mask: 0.1231  loss_rpn_cls: 0.005946  loss_rpn_loc: 0.03623  time: 0.9658  data_time: 0.3377  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:39:04 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 559  total_loss: 0.583  loss_cls: 0.09977  loss_box_reg: 0.2829  loss_mask: 0.1301  loss_rpn_cls: 0.004853  loss_rpn_loc: 0.0241  time: 0.9666  data_time: 0.3308  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:39:23 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 579  total_loss: 0.5146  loss_cls: 0.09523  loss_box_reg: 0.254  loss_mask: 0.1118  loss_rpn_cls: 0.006646  loss_rpn_loc: 0.02959  time: 0.9670  data_time: 0.3353  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:39:43 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 599  total_loss: 0.6432  loss_cls: 0.141  loss_box_reg: 0.3185  loss_mask: 0.1327  loss_rpn_cls: 0.005484  loss_rpn_loc: 0.02605  time: 0.9674  data_time: 0.3245  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:40:03 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 619  total_loss: 0.5868  loss_cls: 0.08462  loss_box_reg: 0.301  loss_mask: 0.1145  loss_rpn_cls: 0.003935  loss_rpn_loc: 0.02557  time: 0.9688  data_time: 0.3533  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:40:23 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 639  total_loss: 0.55  loss_cls: 0.1047  loss_box_reg: 0.3011  loss_mask: 0.1388  loss_rpn_cls: 0.005477  loss_rpn_loc: 0.02708  time: 0.9694  data_time: 0.3241  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:40:43 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 659  total_loss: 0.5768  loss_cls: 0.09575  loss_box_reg: 0.3107  loss_mask: 0.1304  loss_rpn_cls: 0.002956  loss_rpn_loc: 0.02589  time: 0.9697  data_time: 0.3128  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 13:41:03 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 679  total_loss: 0.557  loss_cls: 0.104  loss_box_reg: 0.2895  loss_mask: 0.1198  loss_rpn_cls: 0.004508  loss_rpn_loc: 0.02799  time: 0.9708  data_time: 0.3371  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:41:22 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 699  total_loss: 0.542  loss_cls: 0.09976  loss_box_reg: 0.2788  loss_mask: 0.1185  loss_rpn_cls: 0.004803  loss_rpn_loc: 0.02495  time: 0.9705  data_time: 0.3190  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:41:41 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 719  total_loss: 0.5377  loss_cls: 0.09626  loss_box_reg: 0.2568  loss_mask: 0.1172  loss_rpn_cls: 0.003063  loss_rpn_loc: 0.02128  time: 0.9695  data_time: 0.2887  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:42:00 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 739  total_loss: 0.59  loss_cls: 0.1055  loss_box_reg: 0.2855  loss_mask: 0.1499  loss_rpn_cls: 0.004344  loss_rpn_loc: 0.02942  time: 0.9698  data_time: 0.3137  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:42:20 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 759  total_loss: 0.4924  loss_cls: 0.08787  loss_box_reg: 0.2588  loss_mask: 0.1082  loss_rpn_cls: 0.00448  loss_rpn_loc: 0.02702  time: 0.9696  data_time: 0.3283  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:42:39 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 779  total_loss: 0.4825  loss_cls: 0.08639  loss_box_reg: 0.2658  loss_mask: 0.1165  loss_rpn_cls: 0.004547  loss_rpn_loc: 0.02929  time: 0.9700  data_time: 0.3317  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:42:59 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 799  total_loss: 0.6101  loss_cls: 0.1129  loss_box_reg: 0.3116  loss_mask: 0.1325  loss_rpn_cls: 0.003801  loss_rpn_loc: 0.02386  time: 0.9700  data_time: 0.3031  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:43:18 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 819  total_loss: 0.4879  loss_cls: 0.06901  loss_box_reg: 0.264  loss_mask: 0.1078  loss_rpn_cls: 0.002124  loss_rpn_loc: 0.02661  time: 0.9695  data_time: 0.3075  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:43:37 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 839  total_loss: 0.5051  loss_cls: 0.09026  loss_box_reg: 0.2632  loss_mask: 0.1167  loss_rpn_cls: 0.005034  loss_rpn_loc: 0.03093  time: 0.9697  data_time: 0.3050  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:43:57 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 859  total_loss: 0.5517  loss_cls: 0.1007  loss_box_reg: 0.2739  loss_mask: 0.1098  loss_rpn_cls: 0.0052  loss_rpn_loc: 0.02889  time: 0.9697  data_time: 0.3143  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:44:17 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 879  total_loss: 0.5219  loss_cls: 0.08646  loss_box_reg: 0.2881  loss_mask: 0.1177  loss_rpn_cls: 0.004186  loss_rpn_loc: 0.02237  time: 0.9703  data_time: 0.3344  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:44:36 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 899  total_loss: 0.5672  loss_cls: 0.1081  loss_box_reg: 0.2936  loss_mask: 0.1209  loss_rpn_cls: 0.005474  loss_rpn_loc: 0.03013  time: 0.9704  data_time: 0.3341  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:44:56 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 919  total_loss: 0.5574  loss_cls: 0.1079  loss_box_reg: 0.2753  loss_mask: 0.1219  loss_rpn_cls: 0.005888  loss_rpn_loc: 0.02862  time: 0.9710  data_time: 0.3305  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:45:15 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 939  total_loss: 0.5266  loss_cls: 0.08306  loss_box_reg: 0.2632  loss_mask: 0.1284  loss_rpn_cls: 0.0038  loss_rpn_loc: 0.02246  time: 0.9707  data_time: 0.3048  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:45:35 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 959  total_loss: 0.5305  loss_cls: 0.1073  loss_box_reg: 0.248  loss_mask: 0.1213  loss_rpn_cls: 0.004274  loss_rpn_loc: 0.0277  time: 0.9709  data_time: 0.3123  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:45:54 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 979  total_loss: 0.4874  loss_cls: 0.08239  loss_box_reg: 0.2468  loss_mask: 0.1127  loss_rpn_cls: 0.004434  loss_rpn_loc: 0.03392  time: 0.9704  data_time: 0.2907  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:46:14 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 999  total_loss: 0.5279  loss_cls: 0.08055  loss_box_reg: 0.285  loss_mask: 0.1164  loss_rpn_cls: 0.003914  loss_rpn_loc: 0.02967  time: 0.9712  data_time: 0.3765  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:46:33 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 1019  total_loss: 0.4609  loss_cls: 0.07335  loss_box_reg: 0.2523  loss_mask: 0.1067  loss_rpn_cls: 0.003486  loss_rpn_loc: 0.02582  time: 0.9706  data_time: 0.2858  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:46:52 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 1039  total_loss: 0.5326  loss_cls: 0.09676  loss_box_reg: 0.2591  loss_mask: 0.1242  loss_rpn_cls: 0.003806  loss_rpn_loc: 0.03227  time: 0.9701  data_time: 0.3065  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:47:11 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1059  total_loss: 0.4687  loss_cls: 0.08648  loss_box_reg: 0.2348  loss_mask: 0.1076  loss_rpn_cls: 0.003255  loss_rpn_loc: 0.03114  time: 0.9700  data_time: 0.3133  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:47:30 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1079  total_loss: 0.4249  loss_cls: 0.05867  loss_box_reg: 0.2214  loss_mask: 0.1005  loss_rpn_cls: 0.002481  loss_rpn_loc: 0.01969  time: 0.9698  data_time: 0.3121  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:47:50 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 1099  total_loss: 0.4798  loss_cls: 0.07616  loss_box_reg: 0.2348  loss_mask: 0.1147  loss_rpn_cls: 0.004885  loss_rpn_loc: 0.0259  time: 0.9703  data_time: 0.3268  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:48:10 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 1119  total_loss: 0.4243  loss_cls: 0.08485  loss_box_reg: 0.2244  loss_mask: 0.1046  loss_rpn_cls: 0.003708  loss_rpn_loc: 0.03364  time: 0.9706  data_time: 0.3309  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:48:29 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 1139  total_loss: 0.4216  loss_cls: 0.06191  loss_box_reg: 0.1883  loss_mask: 0.1044  loss_rpn_cls: 0.003092  loss_rpn_loc: 0.02259  time: 0.9704  data_time: 0.3121  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:48:49 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1159  total_loss: 0.431  loss_cls: 0.06549  loss_box_reg: 0.2291  loss_mask: 0.1157  loss_rpn_cls: 0.00423  loss_rpn_loc: 0.02839  time: 0.9712  data_time: 0.3551  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:49:10 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 1179  total_loss: 0.4797  loss_cls: 0.102  loss_box_reg: 0.244  loss_mask: 0.1065  loss_rpn_cls: 0.004619  loss_rpn_loc: 0.02761  time: 0.9721  data_time: 0.3553  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:49:29 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 1199  total_loss: 0.4068  loss_cls: 0.06496  loss_box_reg: 0.2085  loss_mask: 0.1053  loss_rpn_cls: 0.003146  loss_rpn_loc: 0.02373  time: 0.9718  data_time: 0.2963  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:49:49 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1219  total_loss: 0.4449  loss_cls: 0.07262  loss_box_reg: 0.217  loss_mask: 0.105  loss_rpn_cls: 0.004504  loss_rpn_loc: 0.02881  time: 0.9720  data_time: 0.3235  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:50:08 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 1239  total_loss: 0.485  loss_cls: 0.08381  loss_box_reg: 0.2106  loss_mask: 0.1125  loss_rpn_cls: 0.003664  loss_rpn_loc: 0.02357  time: 0.9716  data_time: 0.2900  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:50:28 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 1259  total_loss: 0.4229  loss_cls: 0.061  loss_box_reg: 0.2076  loss_mask: 0.1059  loss_rpn_cls: 0.003181  loss_rpn_loc: 0.02453  time: 0.9723  data_time: 0.3660  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:50:48 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 1279  total_loss: 0.4748  loss_cls: 0.1008  loss_box_reg: 0.2216  loss_mask: 0.1049  loss_rpn_cls: 0.003155  loss_rpn_loc: 0.02876  time: 0.9728  data_time: 0.3669  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:51:07 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1299  total_loss: 0.4336  loss_cls: 0.06478  loss_box_reg: 0.2147  loss_mask: 0.1019  loss_rpn_cls: 0.003339  loss_rpn_loc: 0.02748  time: 0.9725  data_time: 0.2959  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:51:27 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 1319  total_loss: 0.4393  loss_cls: 0.08521  loss_box_reg: 0.2157  loss_mask: 0.1003  loss_rpn_cls: 0.002418  loss_rpn_loc: 0.02868  time: 0.9731  data_time: 0.3436  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 13:51:48 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1339  total_loss: 0.439  loss_cls: 0.07056  loss_box_reg: 0.2254  loss_mask: 0.1096  loss_rpn_cls: 0.004399  loss_rpn_loc: 0.02693  time: 0.9740  data_time: 0.3567  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:52:07 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 1359  total_loss: 0.4179  loss_cls: 0.08129  loss_box_reg: 0.2001  loss_mask: 0.1051  loss_rpn_cls: 0.004469  loss_rpn_loc: 0.02458  time: 0.9736  data_time: 0.3060  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:52:26 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1379  total_loss: 0.4531  loss_cls: 0.08689  loss_box_reg: 0.2159  loss_mask: 0.1116  loss_rpn_cls: 0.002164  loss_rpn_loc: 0.01696  time: 0.9734  data_time: 0.2917  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:52:46 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 1399  total_loss: 0.4387  loss_cls: 0.07972  loss_box_reg: 0.1853  loss_mask: 0.1081  loss_rpn_cls: 0.004134  loss_rpn_loc: 0.02759  time: 0.9736  data_time: 0.3468  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 13:53:05 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.4305  loss_cls: 0.09055  loss_box_reg: 0.2127  loss_mask: 0.1072  loss_rpn_cls: 0.003733  loss_rpn_loc: 0.0252  time: 0.9735  data_time: 0.2881  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:53:25 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.4198  loss_cls: 0.06978  loss_box_reg: 0.2121  loss_mask: 0.1095  loss_rpn_cls: 0.003107  loss_rpn_loc: 0.02542  time: 0.9735  data_time: 0.3412  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:53:45 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.4392  loss_cls: 0.07656  loss_box_reg: 0.2117  loss_mask: 0.1005  loss_rpn_cls: 0.003186  loss_rpn_loc: 0.02892  time: 0.9736  data_time: 0.3560  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:54:04 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.4189  loss_cls: 0.06222  loss_box_reg: 0.2038  loss_mask: 0.1087  loss_rpn_cls: 0.003721  loss_rpn_loc: 0.02003  time: 0.9739  data_time: 0.3478  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:54:25 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4472  loss_cls: 0.0616  loss_box_reg: 0.194  loss_mask: 0.1142  loss_rpn_cls: 0.00423  loss_rpn_loc: 0.02572  time: 0.9736  data_time: 0.2947  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 13:54:25 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:18 (0.9736 s / it)\n",
      "\u001b[32m[03/04 13:54:25 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:21 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 13:54:26 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 13:54:26 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /host/mic21-framework/server/uploads/trombonist_gt.json\n",
      "trombonist\n",
      "\u001b[32m[03/04 13:54:27 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 13:54:27 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 13:54:27 d2.data.datasets.coco]: \u001b[0mLoaded 146 images in COCO format from /host/mic21-framework/server/uploads/trombonist_gt.json\n",
      "\u001b[32m[03/04 13:54:27 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 146 images left.\n",
      "\u001b[32m[03/04 13:54:27 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|  category  | #instances   |   category    | #instances   |  category   | #instances   |\n",
      "|:----------:|:-------------|:-------------:|:-------------|:-----------:|:-------------|\n",
      "| microphone | 103          |  music stand  | 91           | trombonist  | 221          |\n",
      "|  trombone  | 235          | microphone .. | 78           | percussions | 63           |\n",
      "|            |              |               |              |             |              |\n",
      "|   total    | 791          |               |              |             |              |\u001b[0m\n",
      "\u001b[32m[03/04 13:54:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 13:54:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 13:54:27 d2.data.common]: \u001b[0mSerializing 146 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 13:54:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.85 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 13:54:27 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 13:54:44 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 19  total_loss: 2.565  loss_cls: 0.9314  loss_box_reg: 0.9018  loss_mask: 0.6179  loss_rpn_cls: 0.04734  loss_rpn_loc: 0.06133  time: 0.8313  data_time: 0.1938  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:55:02 d2.utils.events]: \u001b[0m eta: 0:21:02  iter: 39  total_loss: 2.206  loss_cls: 0.6111  loss_box_reg: 0.9018  loss_mask: 0.4638  loss_rpn_cls: 0.06902  loss_rpn_loc: 0.05221  time: 0.8647  data_time: 0.2546  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:55:19 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 59  total_loss: 1.646  loss_cls: 0.46  loss_box_reg: 0.7386  loss_mask: 0.3352  loss_rpn_cls: 0.04317  loss_rpn_loc: 0.05822  time: 0.8601  data_time: 0.2132  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:55:36 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 79  total_loss: 1.533  loss_cls: 0.4715  loss_box_reg: 0.6632  loss_mask: 0.3012  loss_rpn_cls: 0.03062  loss_rpn_loc: 0.05512  time: 0.8536  data_time: 0.1719  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:55:53 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 99  total_loss: 1.471  loss_cls: 0.4534  loss_box_reg: 0.609  loss_mask: 0.292  loss_rpn_cls: 0.03759  loss_rpn_loc: 0.06024  time: 0.8556  data_time: 0.2128  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:56:10 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 119  total_loss: 1.332  loss_cls: 0.3623  loss_box_reg: 0.5851  loss_mask: 0.2818  loss_rpn_cls: 0.0284  loss_rpn_loc: 0.05638  time: 0.8519  data_time: 0.1745  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:56:26 d2.utils.events]: \u001b[0m eta: 0:19:19  iter: 139  total_loss: 1.429  loss_cls: 0.3937  loss_box_reg: 0.5871  loss_mask: 0.2668  loss_rpn_cls: 0.03925  loss_rpn_loc: 0.07359  time: 0.8476  data_time: 0.1940  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:56:43 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 159  total_loss: 1.331  loss_cls: 0.341  loss_box_reg: 0.5852  loss_mask: 0.2688  loss_rpn_cls: 0.02959  loss_rpn_loc: 0.04941  time: 0.8446  data_time: 0.1962  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:57:00 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 179  total_loss: 1.283  loss_cls: 0.3573  loss_box_reg: 0.5606  loss_mask: 0.2671  loss_rpn_cls: 0.01776  loss_rpn_loc: 0.05614  time: 0.8461  data_time: 0.2075  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:57:17 d2.utils.events]: \u001b[0m eta: 0:18:16  iter: 199  total_loss: 1.31  loss_cls: 0.3614  loss_box_reg: 0.6034  loss_mask: 0.2657  loss_rpn_cls: 0.02142  loss_rpn_loc: 0.04764  time: 0.8503  data_time: 0.2041  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:57:36 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 219  total_loss: 1.253  loss_cls: 0.3333  loss_box_reg: 0.5083  loss_mask: 0.2489  loss_rpn_cls: 0.02857  loss_rpn_loc: 0.07301  time: 0.8567  data_time: 0.2574  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:57:53 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 239  total_loss: 1.175  loss_cls: 0.3255  loss_box_reg: 0.5066  loss_mask: 0.2213  loss_rpn_cls: 0.02116  loss_rpn_loc: 0.04681  time: 0.8558  data_time: 0.2000  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:58:11 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 259  total_loss: 1.241  loss_cls: 0.2818  loss_box_reg: 0.5323  loss_mask: 0.2644  loss_rpn_cls: 0.02232  loss_rpn_loc: 0.04816  time: 0.8587  data_time: 0.2032  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:58:28 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 279  total_loss: 1.063  loss_cls: 0.2845  loss_box_reg: 0.4836  loss_mask: 0.2154  loss_rpn_cls: 0.02151  loss_rpn_loc: 0.04999  time: 0.8580  data_time: 0.2158  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:58:45 d2.utils.events]: \u001b[0m eta: 0:16:53  iter: 299  total_loss: 1.17  loss_cls: 0.3082  loss_box_reg: 0.5399  loss_mask: 0.2448  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.05841  time: 0.8581  data_time: 0.2055  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:59:02 d2.utils.events]: \u001b[0m eta: 0:16:33  iter: 319  total_loss: 0.9555  loss_cls: 0.2439  loss_box_reg: 0.4565  loss_mask: 0.206  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.03864  time: 0.8577  data_time: 0.2244  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:59:20 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 339  total_loss: 1.066  loss_cls: 0.2992  loss_box_reg: 0.4489  loss_mask: 0.2264  loss_rpn_cls: 0.01962  loss_rpn_loc: 0.05131  time: 0.8607  data_time: 0.2389  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:59:37 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 359  total_loss: 1.045  loss_cls: 0.3008  loss_box_reg: 0.4702  loss_mask: 0.224  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.05055  time: 0.8600  data_time: 0.2076  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 13:59:54 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 379  total_loss: 1.079  loss_cls: 0.3022  loss_box_reg: 0.4502  loss_mask: 0.2226  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.04206  time: 0.8592  data_time: 0.1931  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:00:11 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 399  total_loss: 1.024  loss_cls: 0.2168  loss_box_reg: 0.4773  loss_mask: 0.2215  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.04977  time: 0.8595  data_time: 0.2050  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:00:29 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 419  total_loss: 1.084  loss_cls: 0.2953  loss_box_reg: 0.4666  loss_mask: 0.2498  loss_rpn_cls: 0.01846  loss_rpn_loc: 0.04251  time: 0.8605  data_time: 0.2136  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:00:46 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 439  total_loss: 1.106  loss_cls: 0.2786  loss_box_reg: 0.4568  loss_mask: 0.2303  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.05128  time: 0.8608  data_time: 0.2114  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:01:04 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 459  total_loss: 0.9554  loss_cls: 0.2392  loss_box_reg: 0.4396  loss_mask: 0.2005  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.04436  time: 0.8625  data_time: 0.2389  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:01:22 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 479  total_loss: 0.9993  loss_cls: 0.2553  loss_box_reg: 0.4522  loss_mask: 0.2178  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.03846  time: 0.8630  data_time: 0.2239  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:01:39 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 499  total_loss: 0.9464  loss_cls: 0.2525  loss_box_reg: 0.4201  loss_mask: 0.2237  loss_rpn_cls: 0.01258  loss_rpn_loc: 0.05218  time: 0.8631  data_time: 0.2159  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:01:56 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 519  total_loss: 0.8665  loss_cls: 0.206  loss_box_reg: 0.4118  loss_mask: 0.207  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.03178  time: 0.8625  data_time: 0.2191  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:02:13 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 539  total_loss: 0.9253  loss_cls: 0.201  loss_box_reg: 0.4181  loss_mask: 0.2259  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.05535  time: 0.8617  data_time: 0.1743  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:02:30 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 559  total_loss: 1.054  loss_cls: 0.2661  loss_box_reg: 0.4681  loss_mask: 0.2272  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.0557  time: 0.8620  data_time: 0.2243  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:02:47 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 579  total_loss: 0.9378  loss_cls: 0.2308  loss_box_reg: 0.4236  loss_mask: 0.2135  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.05092  time: 0.8613  data_time: 0.1761  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:03:05 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 599  total_loss: 1.011  loss_cls: 0.2263  loss_box_reg: 0.4464  loss_mask: 0.2186  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.04729  time: 0.8619  data_time: 0.2146  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:03:23 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 619  total_loss: 0.9144  loss_cls: 0.2077  loss_box_reg: 0.417  loss_mask: 0.2132  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.04485  time: 0.8630  data_time: 0.2096  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:03:40 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 639  total_loss: 0.9087  loss_cls: 0.2001  loss_box_reg: 0.4124  loss_mask: 0.234  loss_rpn_cls: 0.01003  loss_rpn_loc: 0.03606  time: 0.8631  data_time: 0.2091  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:03:57 d2.utils.events]: \u001b[0m eta: 0:11:56  iter: 659  total_loss: 0.8528  loss_cls: 0.1912  loss_box_reg: 0.375  loss_mask: 0.1845  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.04069  time: 0.8629  data_time: 0.2159  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 14:04:14 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 679  total_loss: 0.8922  loss_cls: 0.2123  loss_box_reg: 0.4126  loss_mask: 0.2029  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.04925  time: 0.8622  data_time: 0.1803  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:04:32 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 699  total_loss: 0.977  loss_cls: 0.2516  loss_box_reg: 0.428  loss_mask: 0.2152  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.04722  time: 0.8630  data_time: 0.1977  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:04:49 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 719  total_loss: 0.8597  loss_cls: 0.2174  loss_box_reg: 0.3526  loss_mask: 0.1977  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.04741  time: 0.8630  data_time: 0.2165  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:05:05 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 739  total_loss: 0.9335  loss_cls: 0.2085  loss_box_reg: 0.3948  loss_mask: 0.1983  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.04386  time: 0.8618  data_time: 0.1735  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:05:23 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 759  total_loss: 0.9105  loss_cls: 0.2213  loss_box_reg: 0.4239  loss_mask: 0.2158  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.05971  time: 0.8620  data_time: 0.2205  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:05:40 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 779  total_loss: 0.8274  loss_cls: 0.1861  loss_box_reg: 0.3502  loss_mask: 0.1824  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.05597  time: 0.8620  data_time: 0.1933  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:05:57 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 799  total_loss: 0.9032  loss_cls: 0.212  loss_box_reg: 0.3906  loss_mask: 0.2187  loss_rpn_cls: 0.01024  loss_rpn_loc: 0.04397  time: 0.8610  data_time: 0.1923  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:06:13 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 819  total_loss: 0.8191  loss_cls: 0.1726  loss_box_reg: 0.3897  loss_mask: 0.2074  loss_rpn_cls: 0.00987  loss_rpn_loc: 0.02768  time: 0.8604  data_time: 0.2056  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:06:30 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 839  total_loss: 0.8218  loss_cls: 0.1921  loss_box_reg: 0.4014  loss_mask: 0.1962  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.04953  time: 0.8602  data_time: 0.1940  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:06:48 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 859  total_loss: 0.9039  loss_cls: 0.2199  loss_box_reg: 0.4015  loss_mask: 0.2252  loss_rpn_cls: 0.007057  loss_rpn_loc: 0.048  time: 0.8605  data_time: 0.2233  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:07:05 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 879  total_loss: 0.8394  loss_cls: 0.1829  loss_box_reg: 0.372  loss_mask: 0.2064  loss_rpn_cls: 0.009257  loss_rpn_loc: 0.03751  time: 0.8607  data_time: 0.2104  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:07:23 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 899  total_loss: 0.8006  loss_cls: 0.1427  loss_box_reg: 0.3887  loss_mask: 0.1735  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.04111  time: 0.8612  data_time: 0.2187  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:07:40 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 919  total_loss: 0.7807  loss_cls: 0.1838  loss_box_reg: 0.3585  loss_mask: 0.1772  loss_rpn_cls: 0.00942  loss_rpn_loc: 0.04708  time: 0.8609  data_time: 0.1960  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:07:58 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 939  total_loss: 0.9087  loss_cls: 0.1863  loss_box_reg: 0.4016  loss_mask: 0.2017  loss_rpn_cls: 0.01041  loss_rpn_loc: 0.05814  time: 0.8614  data_time: 0.2088  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:08:15 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 959  total_loss: 0.7865  loss_cls: 0.1595  loss_box_reg: 0.3761  loss_mask: 0.1926  loss_rpn_cls: 0.007935  loss_rpn_loc: 0.03558  time: 0.8616  data_time: 0.2005  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:08:32 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 979  total_loss: 0.7685  loss_cls: 0.161  loss_box_reg: 0.339  loss_mask: 0.181  loss_rpn_cls: 0.008853  loss_rpn_loc: 0.05052  time: 0.8610  data_time: 0.2063  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:08:50 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 999  total_loss: 0.7638  loss_cls: 0.1461  loss_box_reg: 0.3678  loss_mask: 0.192  loss_rpn_cls: 0.009355  loss_rpn_loc: 0.03628  time: 0.8617  data_time: 0.2246  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:09:07 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 1019  total_loss: 0.8026  loss_cls: 0.1741  loss_box_reg: 0.3594  loss_mask: 0.1964  loss_rpn_cls: 0.0109  loss_rpn_loc: 0.04133  time: 0.8618  data_time: 0.2158  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:09:24 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 1039  total_loss: 0.7689  loss_cls: 0.1469  loss_box_reg: 0.3637  loss_mask: 0.1798  loss_rpn_cls: 0.00746  loss_rpn_loc: 0.03432  time: 0.8619  data_time: 0.2151  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:09:42 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1059  total_loss: 0.7838  loss_cls: 0.1524  loss_box_reg: 0.3436  loss_mask: 0.1923  loss_rpn_cls: 0.006454  loss_rpn_loc: 0.04248  time: 0.8618  data_time: 0.2091  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:09:59 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 1079  total_loss: 0.7646  loss_cls: 0.1721  loss_box_reg: 0.3455  loss_mask: 0.1814  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.03528  time: 0.8618  data_time: 0.2129  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:10:16 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 1099  total_loss: 0.7217  loss_cls: 0.1651  loss_box_reg: 0.2938  loss_mask: 0.1918  loss_rpn_cls: 0.007922  loss_rpn_loc: 0.05568  time: 0.8621  data_time: 0.2079  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:10:34 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 1119  total_loss: 0.7426  loss_cls: 0.1769  loss_box_reg: 0.3571  loss_mask: 0.1934  loss_rpn_cls: 0.008011  loss_rpn_loc: 0.04026  time: 0.8623  data_time: 0.2066  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:10:51 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 1139  total_loss: 0.6776  loss_cls: 0.1444  loss_box_reg: 0.3213  loss_mask: 0.1641  loss_rpn_cls: 0.008911  loss_rpn_loc: 0.03956  time: 0.8623  data_time: 0.2116  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:11:08 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 1159  total_loss: 0.7848  loss_cls: 0.1671  loss_box_reg: 0.3679  loss_mask: 0.1969  loss_rpn_cls: 0.005972  loss_rpn_loc: 0.03337  time: 0.8621  data_time: 0.2044  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:11:26 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 1179  total_loss: 0.7453  loss_cls: 0.1771  loss_box_reg: 0.3298  loss_mask: 0.1964  loss_rpn_cls: 0.008767  loss_rpn_loc: 0.04468  time: 0.8625  data_time: 0.2103  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:11:42 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 1199  total_loss: 0.6607  loss_cls: 0.1341  loss_box_reg: 0.3103  loss_mask: 0.197  loss_rpn_cls: 0.009067  loss_rpn_loc: 0.04073  time: 0.8617  data_time: 0.1753  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:11:59 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 1219  total_loss: 0.6614  loss_cls: 0.1441  loss_box_reg: 0.2927  loss_mask: 0.1751  loss_rpn_cls: 0.007639  loss_rpn_loc: 0.03715  time: 0.8616  data_time: 0.1947  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:12:16 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 1239  total_loss: 0.7561  loss_cls: 0.1384  loss_box_reg: 0.33  loss_mask: 0.1994  loss_rpn_cls: 0.008977  loss_rpn_loc: 0.04314  time: 0.8609  data_time: 0.1740  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:12:33 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 1259  total_loss: 0.7484  loss_cls: 0.1498  loss_box_reg: 0.313  loss_mask: 0.1711  loss_rpn_cls: 0.007347  loss_rpn_loc: 0.03724  time: 0.8607  data_time: 0.1727  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:12:49 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 1279  total_loss: 0.6408  loss_cls: 0.1269  loss_box_reg: 0.2656  loss_mask: 0.1801  loss_rpn_cls: 0.007101  loss_rpn_loc: 0.0451  time: 0.8603  data_time: 0.1889  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:13:06 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 1299  total_loss: 0.7176  loss_cls: 0.1616  loss_box_reg: 0.3264  loss_mask: 0.1954  loss_rpn_cls: 0.008405  loss_rpn_loc: 0.03543  time: 0.8601  data_time: 0.1800  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:13:23 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 1319  total_loss: 0.6543  loss_cls: 0.1449  loss_box_reg: 0.2906  loss_mask: 0.1735  loss_rpn_cls: 0.004718  loss_rpn_loc: 0.03698  time: 0.8600  data_time: 0.2069  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 14:13:41 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1339  total_loss: 0.7377  loss_cls: 0.137  loss_box_reg: 0.3191  loss_mask: 0.1916  loss_rpn_cls: 0.009085  loss_rpn_loc: 0.04539  time: 0.8602  data_time: 0.2158  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:13:58 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 1359  total_loss: 0.6877  loss_cls: 0.1575  loss_box_reg: 0.2803  loss_mask: 0.1922  loss_rpn_cls: 0.006746  loss_rpn_loc: 0.02953  time: 0.8602  data_time: 0.2089  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:14:16 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 1379  total_loss: 0.7035  loss_cls: 0.1386  loss_box_reg: 0.3249  loss_mask: 0.1917  loss_rpn_cls: 0.008116  loss_rpn_loc: 0.04214  time: 0.8604  data_time: 0.2065  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:14:32 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 1399  total_loss: 0.7323  loss_cls: 0.1656  loss_box_reg: 0.2925  loss_mask: 0.1881  loss_rpn_cls: 0.01003  loss_rpn_loc: 0.05091  time: 0.8601  data_time: 0.1665  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:14:50 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 1419  total_loss: 0.6046  loss_cls: 0.1077  loss_box_reg: 0.2652  loss_mask: 0.1746  loss_rpn_cls: 0.004584  loss_rpn_loc: 0.03359  time: 0.8601  data_time: 0.2086  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:15:06 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 1439  total_loss: 0.6474  loss_cls: 0.1523  loss_box_reg: 0.2822  loss_mask: 0.1858  loss_rpn_cls: 0.006852  loss_rpn_loc: 0.04165  time: 0.8598  data_time: 0.2082  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:15:23 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 1459  total_loss: 0.7641  loss_cls: 0.1695  loss_box_reg: 0.2958  loss_mask: 0.1909  loss_rpn_cls: 0.008414  loss_rpn_loc: 0.0374  time: 0.8594  data_time: 0.1834  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:15:41 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.6258  loss_cls: 0.1348  loss_box_reg: 0.2818  loss_mask: 0.1758  loss_rpn_cls: 0.00759  loss_rpn_loc: 0.03747  time: 0.8596  data_time: 0.2266  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:15:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.6888  loss_cls: 0.1397  loss_box_reg: 0.2971  loss_mask: 0.1879  loss_rpn_cls: 0.004523  loss_rpn_loc: 0.03703  time: 0.8593  data_time: 0.1716  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:15:59 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:27 (0.8593 s / it)\n",
      "\u001b[32m[03/04 14:15:59 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:29 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 14:15:59 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 14:15:59 d2.data.datasets.coco]: \u001b[0mLoaded 151 images in COCO format from /host/mic21-framework/server/uploads/trumpeter_gt.json\n",
      "trumpeter\n",
      "\u001b[32m[03/04 14:16:00 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 14:16:00 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 14:16:00 d2.data.datasets.coco]: \u001b[0mLoaded 151 images in COCO format from /host/mic21-framework/server/uploads/trumpeter_gt.json\n",
      "\u001b[32m[03/04 14:16:00 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 151 images left.\n",
      "\u001b[32m[03/04 14:16:00 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|  category  | #instances   |   category    | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
      "| microphone | 84           |   trumpeter   | 195          |  trumpet   | 204          |\n",
      "|  musician  | 74           | microphone .. | 77           |            |              |\n",
      "|   total    | 634          |               |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 14:16:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 14:16:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 14:16:00 d2.data.common]: \u001b[0mSerializing 151 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 14:16:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.94 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 14:16:00 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 14:16:18 d2.utils.events]: \u001b[0m eta: 0:21:31  iter: 19  total_loss: 2.524  loss_cls: 0.8704  loss_box_reg: 0.9251  loss_mask: 0.5974  loss_rpn_cls: 0.02994  loss_rpn_loc: 0.03013  time: 0.8412  data_time: 0.1942  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:16:35 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 39  total_loss: 1.94  loss_cls: 0.562  loss_box_reg: 0.8904  loss_mask: 0.4127  loss_rpn_cls: 0.02828  loss_rpn_loc: 0.03954  time: 0.8447  data_time: 0.1779  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:16:52 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 59  total_loss: 1.486  loss_cls: 0.3796  loss_box_reg: 0.7354  loss_mask: 0.2998  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.03521  time: 0.8472  data_time: 0.1879  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:17:08 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 79  total_loss: 1.257  loss_cls: 0.3715  loss_box_reg: 0.6113  loss_mask: 0.2856  loss_rpn_cls: 0.02909  loss_rpn_loc: 0.0409  time: 0.8457  data_time: 0.1875  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:17:26 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 99  total_loss: 1.194  loss_cls: 0.315  loss_box_reg: 0.5712  loss_mask: 0.2392  loss_rpn_cls: 0.0195  loss_rpn_loc: 0.0412  time: 0.8476  data_time: 0.1859  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:17:44 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 119  total_loss: 1.053  loss_cls: 0.3303  loss_box_reg: 0.4915  loss_mask: 0.2133  loss_rpn_cls: 0.01658  loss_rpn_loc: 0.03532  time: 0.8568  data_time: 0.2441  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:18:00 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 139  total_loss: 1.016  loss_cls: 0.2779  loss_box_reg: 0.468  loss_mask: 0.2276  loss_rpn_cls: 0.01654  loss_rpn_loc: 0.04144  time: 0.8522  data_time: 0.1729  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:18:18 d2.utils.events]: \u001b[0m eta: 0:19:09  iter: 159  total_loss: 0.9562  loss_cls: 0.2294  loss_box_reg: 0.464  loss_mask: 0.1918  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.03633  time: 0.8588  data_time: 0.2334  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:18:36 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 179  total_loss: 0.9897  loss_cls: 0.2535  loss_box_reg: 0.4518  loss_mask: 0.2205  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.03436  time: 0.8613  data_time: 0.1991  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:18:53 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 199  total_loss: 0.8909  loss_cls: 0.2125  loss_box_reg: 0.3976  loss_mask: 0.2051  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.04178  time: 0.8611  data_time: 0.2013  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:19:10 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 219  total_loss: 1.049  loss_cls: 0.2742  loss_box_reg: 0.4703  loss_mask: 0.1982  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.04511  time: 0.8590  data_time: 0.1887  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:19:27 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 239  total_loss: 0.9336  loss_cls: 0.2273  loss_box_reg: 0.4336  loss_mask: 0.2075  loss_rpn_cls: 0.0098  loss_rpn_loc: 0.0405  time: 0.8569  data_time: 0.1754  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:19:44 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 259  total_loss: 0.8999  loss_cls: 0.2478  loss_box_reg: 0.409  loss_mask: 0.1986  loss_rpn_cls: 0.01057  loss_rpn_loc: 0.03791  time: 0.8571  data_time: 0.1947  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:20:01 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 279  total_loss: 0.8225  loss_cls: 0.2248  loss_box_reg: 0.3984  loss_mask: 0.1775  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.03855  time: 0.8576  data_time: 0.2071  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:20:18 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 299  total_loss: 0.8667  loss_cls: 0.2005  loss_box_reg: 0.3937  loss_mask: 0.2118  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.03748  time: 0.8578  data_time: 0.1933  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:20:36 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 319  total_loss: 0.8767  loss_cls: 0.2102  loss_box_reg: 0.3906  loss_mask: 0.1917  loss_rpn_cls: 0.009739  loss_rpn_loc: 0.0368  time: 0.8601  data_time: 0.2187  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:20:53 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 339  total_loss: 0.8011  loss_cls: 0.1862  loss_box_reg: 0.3974  loss_mask: 0.1737  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.03015  time: 0.8583  data_time: 0.1705  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:21:10 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 359  total_loss: 0.8237  loss_cls: 0.1738  loss_box_reg: 0.3765  loss_mask: 0.1998  loss_rpn_cls: 0.008982  loss_rpn_loc: 0.04377  time: 0.8582  data_time: 0.1993  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:21:28 d2.utils.events]: \u001b[0m eta: 0:16:04  iter: 379  total_loss: 0.8353  loss_cls: 0.2148  loss_box_reg: 0.3804  loss_mask: 0.2024  loss_rpn_cls: 0.00853  loss_rpn_loc: 0.03448  time: 0.8598  data_time: 0.2160  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:21:45 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 399  total_loss: 0.8409  loss_cls: 0.201  loss_box_reg: 0.3844  loss_mask: 0.1939  loss_rpn_cls: 0.009473  loss_rpn_loc: 0.02671  time: 0.8599  data_time: 0.1800  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:22:02 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 419  total_loss: 0.7731  loss_cls: 0.1965  loss_box_reg: 0.3578  loss_mask: 0.1832  loss_rpn_cls: 0.009526  loss_rpn_loc: 0.02476  time: 0.8586  data_time: 0.1898  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:22:19 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 439  total_loss: 0.7732  loss_cls: 0.1711  loss_box_reg: 0.3471  loss_mask: 0.1955  loss_rpn_cls: 0.00776  loss_rpn_loc: 0.02986  time: 0.8580  data_time: 0.1959  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:22:36 d2.utils.events]: \u001b[0m eta: 0:14:49  iter: 459  total_loss: 0.6826  loss_cls: 0.1499  loss_box_reg: 0.3543  loss_mask: 0.1806  loss_rpn_cls: 0.004834  loss_rpn_loc: 0.03159  time: 0.8578  data_time: 0.1897  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:22:53 d2.utils.events]: \u001b[0m eta: 0:14:33  iter: 479  total_loss: 0.7777  loss_cls: 0.1985  loss_box_reg: 0.3471  loss_mask: 0.1802  loss_rpn_cls: 0.005037  loss_rpn_loc: 0.02786  time: 0.8581  data_time: 0.2042  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:23:09 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 499  total_loss: 0.7846  loss_cls: 0.1768  loss_box_reg: 0.3526  loss_mask: 0.1804  loss_rpn_cls: 0.007788  loss_rpn_loc: 0.0354  time: 0.8557  data_time: 0.1837  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:23:26 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 519  total_loss: 0.713  loss_cls: 0.1531  loss_box_reg: 0.3266  loss_mask: 0.1627  loss_rpn_cls: 0.004808  loss_rpn_loc: 0.02251  time: 0.8561  data_time: 0.1851  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:23:44 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 539  total_loss: 0.682  loss_cls: 0.1481  loss_box_reg: 0.3097  loss_mask: 0.182  loss_rpn_cls: 0.004337  loss_rpn_loc: 0.02068  time: 0.8564  data_time: 0.1880  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:24:01 d2.utils.events]: \u001b[0m eta: 0:13:23  iter: 559  total_loss: 0.7554  loss_cls: 0.1642  loss_box_reg: 0.2996  loss_mask: 0.1795  loss_rpn_cls: 0.006865  loss_rpn_loc: 0.04392  time: 0.8563  data_time: 0.1928  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:24:17 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 579  total_loss: 0.7376  loss_cls: 0.1755  loss_box_reg: 0.3529  loss_mask: 0.1836  loss_rpn_cls: 0.005932  loss_rpn_loc: 0.03568  time: 0.8550  data_time: 0.1776  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:24:35 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 599  total_loss: 0.7525  loss_cls: 0.16  loss_box_reg: 0.3641  loss_mask: 0.1968  loss_rpn_cls: 0.007127  loss_rpn_loc: 0.03719  time: 0.8558  data_time: 0.2211  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:24:52 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 619  total_loss: 0.671  loss_cls: 0.1581  loss_box_reg: 0.3285  loss_mask: 0.169  loss_rpn_cls: 0.003802  loss_rpn_loc: 0.02639  time: 0.8559  data_time: 0.2036  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:25:09 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 639  total_loss: 0.7443  loss_cls: 0.2089  loss_box_reg: 0.33  loss_mask: 0.1788  loss_rpn_cls: 0.01027  loss_rpn_loc: 0.04085  time: 0.8558  data_time: 0.2079  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:25:26 d2.utils.events]: \u001b[0m eta: 0:11:56  iter: 659  total_loss: 0.6571  loss_cls: 0.1523  loss_box_reg: 0.2917  loss_mask: 0.1748  loss_rpn_cls: 0.003254  loss_rpn_loc: 0.02319  time: 0.8561  data_time: 0.1866  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 14:25:43 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 679  total_loss: 0.7722  loss_cls: 0.1658  loss_box_reg: 0.3256  loss_mask: 0.1776  loss_rpn_cls: 0.007818  loss_rpn_loc: 0.03551  time: 0.8550  data_time: 0.1916  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:26:01 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 699  total_loss: 0.669  loss_cls: 0.1346  loss_box_reg: 0.3128  loss_mask: 0.1699  loss_rpn_cls: 0.004916  loss_rpn_loc: 0.02729  time: 0.8563  data_time: 0.2161  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:26:18 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 719  total_loss: 0.6802  loss_cls: 0.1524  loss_box_reg: 0.3287  loss_mask: 0.1901  loss_rpn_cls: 0.004903  loss_rpn_loc: 0.02492  time: 0.8562  data_time: 0.1811  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:26:36 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 739  total_loss: 0.6817  loss_cls: 0.1363  loss_box_reg: 0.3017  loss_mask: 0.1659  loss_rpn_cls: 0.006593  loss_rpn_loc: 0.03619  time: 0.8573  data_time: 0.2245  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:26:52 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 759  total_loss: 0.7005  loss_cls: 0.1398  loss_box_reg: 0.3253  loss_mask: 0.1648  loss_rpn_cls: 0.006331  loss_rpn_loc: 0.02309  time: 0.8565  data_time: 0.1678  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:27:10 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 779  total_loss: 0.6513  loss_cls: 0.1324  loss_box_reg: 0.2994  loss_mask: 0.1737  loss_rpn_cls: 0.005383  loss_rpn_loc: 0.02816  time: 0.8575  data_time: 0.2082  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:27:27 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 799  total_loss: 0.6469  loss_cls: 0.1297  loss_box_reg: 0.294  loss_mask: 0.1655  loss_rpn_cls: 0.003692  loss_rpn_loc: 0.0192  time: 0.8575  data_time: 0.2042  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:27:44 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 819  total_loss: 0.5959  loss_cls: 0.1414  loss_box_reg: 0.29  loss_mask: 0.1629  loss_rpn_cls: 0.005944  loss_rpn_loc: 0.0312  time: 0.8576  data_time: 0.1993  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:28:01 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 839  total_loss: 0.6737  loss_cls: 0.152  loss_box_reg: 0.3109  loss_mask: 0.1552  loss_rpn_cls: 0.007747  loss_rpn_loc: 0.03273  time: 0.8571  data_time: 0.2016  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:28:18 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 859  total_loss: 0.6514  loss_cls: 0.1512  loss_box_reg: 0.2881  loss_mask: 0.1672  loss_rpn_cls: 0.005936  loss_rpn_loc: 0.02818  time: 0.8570  data_time: 0.1728  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:28:36 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 879  total_loss: 0.6376  loss_cls: 0.1263  loss_box_reg: 0.2712  loss_mask: 0.1519  loss_rpn_cls: 0.004447  loss_rpn_loc: 0.03604  time: 0.8580  data_time: 0.2143  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:28:53 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 899  total_loss: 0.6147  loss_cls: 0.1371  loss_box_reg: 0.2836  loss_mask: 0.1583  loss_rpn_cls: 0.00398  loss_rpn_loc: 0.02765  time: 0.8577  data_time: 0.1926  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:29:10 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 919  total_loss: 0.5964  loss_cls: 0.1196  loss_box_reg: 0.2889  loss_mask: 0.1499  loss_rpn_cls: 0.004059  loss_rpn_loc: 0.02132  time: 0.8578  data_time: 0.2031  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:29:27 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 939  total_loss: 0.644  loss_cls: 0.1196  loss_box_reg: 0.3002  loss_mask: 0.1554  loss_rpn_cls: 0.004729  loss_rpn_loc: 0.02376  time: 0.8574  data_time: 0.1848  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:29:44 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 959  total_loss: 0.618  loss_cls: 0.1271  loss_box_reg: 0.3022  loss_mask: 0.1566  loss_rpn_cls: 0.004386  loss_rpn_loc: 0.02863  time: 0.8572  data_time: 0.1869  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:30:02 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 979  total_loss: 0.6354  loss_cls: 0.1174  loss_box_reg: 0.2852  loss_mask: 0.1551  loss_rpn_cls: 0.00451  loss_rpn_loc: 0.03588  time: 0.8577  data_time: 0.2188  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:30:19 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 999  total_loss: 0.6554  loss_cls: 0.1215  loss_box_reg: 0.2971  loss_mask: 0.1661  loss_rpn_cls: 0.004999  loss_rpn_loc: 0.03277  time: 0.8576  data_time: 0.1879  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:30:36 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 1019  total_loss: 0.5951  loss_cls: 0.1217  loss_box_reg: 0.2724  loss_mask: 0.169  loss_rpn_cls: 0.00479  loss_rpn_loc: 0.01984  time: 0.8575  data_time: 0.2023  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:30:53 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 1039  total_loss: 0.6077  loss_cls: 0.1207  loss_box_reg: 0.2631  loss_mask: 0.1639  loss_rpn_cls: 0.004951  loss_rpn_loc: 0.02419  time: 0.8571  data_time: 0.1885  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:31:10 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1059  total_loss: 0.5772  loss_cls: 0.1129  loss_box_reg: 0.2634  loss_mask: 0.156  loss_rpn_cls: 0.005435  loss_rpn_loc: 0.02611  time: 0.8572  data_time: 0.1739  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:31:27 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 1079  total_loss: 0.5643  loss_cls: 0.1315  loss_box_reg: 0.2476  loss_mask: 0.1647  loss_rpn_cls: 0.005895  loss_rpn_loc: 0.02746  time: 0.8571  data_time: 0.2032  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:31:44 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 1099  total_loss: 0.5049  loss_cls: 0.08863  loss_box_reg: 0.2541  loss_mask: 0.147  loss_rpn_cls: 0.003258  loss_rpn_loc: 0.02388  time: 0.8571  data_time: 0.1932  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:32:01 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 1119  total_loss: 0.6082  loss_cls: 0.116  loss_box_reg: 0.2431  loss_mask: 0.1656  loss_rpn_cls: 0.003386  loss_rpn_loc: 0.02279  time: 0.8570  data_time: 0.1694  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:32:18 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 1139  total_loss: 0.5087  loss_cls: 0.09363  loss_box_reg: 0.2431  loss_mask: 0.1577  loss_rpn_cls: 0.004037  loss_rpn_loc: 0.02576  time: 0.8563  data_time: 0.1573  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:32:35 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 1159  total_loss: 0.5328  loss_cls: 0.09311  loss_box_reg: 0.2513  loss_mask: 0.144  loss_rpn_cls: 0.00361  loss_rpn_loc: 0.02052  time: 0.8563  data_time: 0.2085  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:32:51 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 1179  total_loss: 0.5497  loss_cls: 0.1247  loss_box_reg: 0.2293  loss_mask: 0.1674  loss_rpn_cls: 0.005737  loss_rpn_loc: 0.02939  time: 0.8559  data_time: 0.1952  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:33:10 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 1199  total_loss: 0.4925  loss_cls: 0.1134  loss_box_reg: 0.2294  loss_mask: 0.1435  loss_rpn_cls: 0.003658  loss_rpn_loc: 0.02012  time: 0.8569  data_time: 0.2445  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:33:26 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 1219  total_loss: 0.5779  loss_cls: 0.1262  loss_box_reg: 0.2764  loss_mask: 0.1737  loss_rpn_cls: 0.004206  loss_rpn_loc: 0.02935  time: 0.8561  data_time: 0.1729  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:33:43 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 1239  total_loss: 0.5334  loss_cls: 0.1191  loss_box_reg: 0.2088  loss_mask: 0.165  loss_rpn_cls: 0.005792  loss_rpn_loc: 0.03074  time: 0.8557  data_time: 0.1772  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:34:00 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 1259  total_loss: 0.4899  loss_cls: 0.08163  loss_box_reg: 0.2201  loss_mask: 0.1552  loss_rpn_cls: 0.00502  loss_rpn_loc: 0.0215  time: 0.8560  data_time: 0.2146  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:34:17 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 1279  total_loss: 0.5784  loss_cls: 0.1138  loss_box_reg: 0.2632  loss_mask: 0.1728  loss_rpn_cls: 0.002728  loss_rpn_loc: 0.03696  time: 0.8561  data_time: 0.1957  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:34:35 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 1299  total_loss: 0.519  loss_cls: 0.09744  loss_box_reg: 0.2323  loss_mask: 0.1461  loss_rpn_cls: 0.004474  loss_rpn_loc: 0.02489  time: 0.8563  data_time: 0.2143  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:34:52 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 1319  total_loss: 0.485  loss_cls: 0.08552  loss_box_reg: 0.2056  loss_mask: 0.1649  loss_rpn_cls: 0.004152  loss_rpn_loc: 0.02849  time: 0.8561  data_time: 0.1957  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 14:35:09 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1339  total_loss: 0.5104  loss_cls: 0.0786  loss_box_reg: 0.2204  loss_mask: 0.1521  loss_rpn_cls: 0.004245  loss_rpn_loc: 0.02258  time: 0.8563  data_time: 0.2006  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:35:26 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 1359  total_loss: 0.6011  loss_cls: 0.1192  loss_box_reg: 0.245  loss_mask: 0.174  loss_rpn_cls: 0.005999  loss_rpn_loc: 0.02578  time: 0.8558  data_time: 0.1651  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:35:42 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 1379  total_loss: 0.5129  loss_cls: 0.1177  loss_box_reg: 0.2173  loss_mask: 0.1534  loss_rpn_cls: 0.003725  loss_rpn_loc: 0.01692  time: 0.8551  data_time: 0.1611  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:35:59 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 1399  total_loss: 0.5303  loss_cls: 0.1127  loss_box_reg: 0.242  loss_mask: 0.1544  loss_rpn_cls: 0.004075  loss_rpn_loc: 0.02562  time: 0.8554  data_time: 0.2116  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:36:16 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 1419  total_loss: 0.5596  loss_cls: 0.09969  loss_box_reg: 0.2323  loss_mask: 0.1637  loss_rpn_cls: 0.002925  loss_rpn_loc: 0.01905  time: 0.8551  data_time: 0.1685  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:36:33 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 1439  total_loss: 0.5308  loss_cls: 0.1101  loss_box_reg: 0.2384  loss_mask: 0.1476  loss_rpn_cls: 0.005059  loss_rpn_loc: 0.02549  time: 0.8552  data_time: 0.2123  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:36:51 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 1459  total_loss: 0.4892  loss_cls: 0.09366  loss_box_reg: 0.2371  loss_mask: 0.1609  loss_rpn_cls: 0.005084  loss_rpn_loc: 0.02588  time: 0.8554  data_time: 0.2010  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:37:08 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 1479  total_loss: 0.4607  loss_cls: 0.06195  loss_box_reg: 0.2091  loss_mask: 0.1546  loss_rpn_cls: 0.002615  loss_rpn_loc: 0.02031  time: 0.8555  data_time: 0.2085  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:37:26 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4762  loss_cls: 0.1058  loss_box_reg: 0.2023  loss_mask: 0.1444  loss_rpn_cls: 0.004983  loss_rpn_loc: 0.0198  time: 0.8551  data_time: 0.1768  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 14:37:26 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:20 (0.8551 s / it)\n",
      "\u001b[32m[03/04 14:37:26 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:23 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 14:37:27 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 14:37:27 d2.data.datasets.coco]: \u001b[0mLoaded 102 images in COCO format from /host/mic21-framework/server/uploads/violinist_gt.json\n",
      "violinist\n",
      "\u001b[32m[03/04 14:37:27 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 14:37:27 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 14:37:27 d2.data.datasets.coco]: \u001b[0mLoaded 102 images in COCO format from /host/mic21-framework/server/uploads/violinist_gt.json\n",
      "\u001b[32m[03/04 14:37:27 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 102 images left.\n",
      "\u001b[32m[03/04 14:37:27 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| violinist  | 123          |    bow     | 124          |   violin   | 122          |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 369          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 14:37:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 14:37:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 14:37:27 d2.data.common]: \u001b[0mSerializing 102 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 14:37:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.54 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 14:37:28 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 14:37:47 d2.utils.events]: \u001b[0m eta: 0:24:23  iter: 19  total_loss: 2.488  loss_cls: 0.7505  loss_box_reg: 0.9493  loss_mask: 0.5749  loss_rpn_cls: 0.02208  loss_rpn_loc: 0.05832  time: 0.9570  data_time: 0.3136  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:38:06 d2.utils.events]: \u001b[0m eta: 0:23:32  iter: 39  total_loss: 1.938  loss_cls: 0.4955  loss_box_reg: 0.9594  loss_mask: 0.3786  loss_rpn_cls: 0.02028  loss_rpn_loc: 0.05131  time: 0.9551  data_time: 0.2854  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:38:26 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 59  total_loss: 1.585  loss_cls: 0.3772  loss_box_reg: 0.8018  loss_mask: 0.2669  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.06638  time: 0.9586  data_time: 0.2741  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:38:44 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 79  total_loss: 1.315  loss_cls: 0.3204  loss_box_reg: 0.6714  loss_mask: 0.2229  loss_rpn_cls: 0.01056  loss_rpn_loc: 0.05079  time: 0.9532  data_time: 0.2525  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:39:03 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 99  total_loss: 1.198  loss_cls: 0.3242  loss_box_reg: 0.5885  loss_mask: 0.2118  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.05323  time: 0.9486  data_time: 0.2735  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:39:22 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 119  total_loss: 1.072  loss_cls: 0.2736  loss_box_reg: 0.5489  loss_mask: 0.1932  loss_rpn_cls: 0.01022  loss_rpn_loc: 0.03935  time: 0.9456  data_time: 0.2723  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:39:41 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 139  total_loss: 1.12  loss_cls: 0.2784  loss_box_reg: 0.5172  loss_mask: 0.1858  loss_rpn_cls: 0.009111  loss_rpn_loc: 0.04875  time: 0.9481  data_time: 0.2677  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:40:01 d2.utils.events]: \u001b[0m eta: 0:21:05  iter: 159  total_loss: 1.064  loss_cls: 0.2377  loss_box_reg: 0.5277  loss_mask: 0.1855  loss_rpn_cls: 0.009823  loss_rpn_loc: 0.0484  time: 0.9544  data_time: 0.3233  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:40:19 d2.utils.events]: \u001b[0m eta: 0:20:46  iter: 179  total_loss: 0.9403  loss_cls: 0.2392  loss_box_reg: 0.4602  loss_mask: 0.1782  loss_rpn_cls: 0.00401  loss_rpn_loc: 0.04134  time: 0.9493  data_time: 0.2559  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:40:39 d2.utils.events]: \u001b[0m eta: 0:20:36  iter: 199  total_loss: 0.859  loss_cls: 0.2364  loss_box_reg: 0.3974  loss_mask: 0.1627  loss_rpn_cls: 0.005632  loss_rpn_loc: 0.05832  time: 0.9540  data_time: 0.3021  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:40:59 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 219  total_loss: 0.8757  loss_cls: 0.1998  loss_box_reg: 0.4249  loss_mask: 0.1815  loss_rpn_cls: 0.004914  loss_rpn_loc: 0.04951  time: 0.9569  data_time: 0.2960  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:41:17 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 239  total_loss: 0.8236  loss_cls: 0.1853  loss_box_reg: 0.4164  loss_mask: 0.1659  loss_rpn_cls: 0.007422  loss_rpn_loc: 0.04665  time: 0.9535  data_time: 0.2534  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:41:35 d2.utils.events]: \u001b[0m eta: 0:19:30  iter: 259  total_loss: 0.8491  loss_cls: 0.1872  loss_box_reg: 0.4395  loss_mask: 0.1671  loss_rpn_cls: 0.005032  loss_rpn_loc: 0.03826  time: 0.9500  data_time: 0.2516  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:41:53 d2.utils.events]: \u001b[0m eta: 0:19:06  iter: 279  total_loss: 0.8397  loss_cls: 0.17  loss_box_reg: 0.4325  loss_mask: 0.1707  loss_rpn_cls: 0.00568  loss_rpn_loc: 0.04186  time: 0.9467  data_time: 0.2585  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:42:12 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 299  total_loss: 0.8315  loss_cls: 0.1864  loss_box_reg: 0.4302  loss_mask: 0.1662  loss_rpn_cls: 0.004455  loss_rpn_loc: 0.04435  time: 0.9458  data_time: 0.2718  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:42:31 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 319  total_loss: 0.7552  loss_cls: 0.1587  loss_box_reg: 0.372  loss_mask: 0.1533  loss_rpn_cls: 0.007521  loss_rpn_loc: 0.04952  time: 0.9451  data_time: 0.2744  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:42:49 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 339  total_loss: 0.781  loss_cls: 0.1863  loss_box_reg: 0.3755  loss_mask: 0.1556  loss_rpn_cls: 0.005884  loss_rpn_loc: 0.04415  time: 0.9421  data_time: 0.2328  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:43:07 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 359  total_loss: 0.821  loss_cls: 0.1734  loss_box_reg: 0.412  loss_mask: 0.1415  loss_rpn_cls: 0.007195  loss_rpn_loc: 0.04943  time: 0.9408  data_time: 0.2507  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:43:25 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 379  total_loss: 0.7498  loss_cls: 0.1528  loss_box_reg: 0.3892  loss_mask: 0.1529  loss_rpn_cls: 0.004792  loss_rpn_loc: 0.03806  time: 0.9382  data_time: 0.2217  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:43:43 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 399  total_loss: 0.7641  loss_cls: 0.1239  loss_box_reg: 0.3879  loss_mask: 0.146  loss_rpn_cls: 0.004359  loss_rpn_loc: 0.03596  time: 0.9377  data_time: 0.2674  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:44:02 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 419  total_loss: 0.7711  loss_cls: 0.1501  loss_box_reg: 0.4239  loss_mask: 0.145  loss_rpn_cls: 0.003929  loss_rpn_loc: 0.0544  time: 0.9382  data_time: 0.2884  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:44:22 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 439  total_loss: 0.713  loss_cls: 0.1492  loss_box_reg: 0.3568  loss_mask: 0.1513  loss_rpn_cls: 0.00566  loss_rpn_loc: 0.04062  time: 0.9408  data_time: 0.2888  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:44:40 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 459  total_loss: 0.7044  loss_cls: 0.1424  loss_box_reg: 0.3785  loss_mask: 0.1406  loss_rpn_cls: 0.006439  loss_rpn_loc: 0.04046  time: 0.9383  data_time: 0.2358  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:44:59 d2.utils.events]: \u001b[0m eta: 0:16:04  iter: 479  total_loss: 0.6957  loss_cls: 0.1337  loss_box_reg: 0.3442  loss_mask: 0.1435  loss_rpn_cls: 0.005747  loss_rpn_loc: 0.03984  time: 0.9395  data_time: 0.2831  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:45:19 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 499  total_loss: 0.7001  loss_cls: 0.1564  loss_box_reg: 0.3611  loss_mask: 0.1388  loss_rpn_cls: 0.003659  loss_rpn_loc: 0.04132  time: 0.9406  data_time: 0.2863  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:45:38 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 519  total_loss: 0.673  loss_cls: 0.1377  loss_box_reg: 0.3384  loss_mask: 0.1413  loss_rpn_cls: 0.003556  loss_rpn_loc: 0.04329  time: 0.9419  data_time: 0.2885  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:45:57 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 539  total_loss: 0.7412  loss_cls: 0.1735  loss_box_reg: 0.3638  loss_mask: 0.1394  loss_rpn_cls: 0.003409  loss_rpn_loc: 0.03884  time: 0.9409  data_time: 0.2539  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:46:16 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 559  total_loss: 0.7565  loss_cls: 0.1533  loss_box_reg: 0.3704  loss_mask: 0.1484  loss_rpn_cls: 0.004118  loss_rpn_loc: 0.04492  time: 0.9412  data_time: 0.2643  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:46:34 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 579  total_loss: 0.678  loss_cls: 0.1339  loss_box_reg: 0.3534  loss_mask: 0.139  loss_rpn_cls: 0.004165  loss_rpn_loc: 0.04999  time: 0.9412  data_time: 0.2663  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:46:53 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 599  total_loss: 0.6913  loss_cls: 0.1393  loss_box_reg: 0.3177  loss_mask: 0.1406  loss_rpn_cls: 0.003578  loss_rpn_loc: 0.05899  time: 0.9409  data_time: 0.2503  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:47:11 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 619  total_loss: 0.6472  loss_cls: 0.1144  loss_box_reg: 0.3368  loss_mask: 0.1282  loss_rpn_cls: 0.003432  loss_rpn_loc: 0.03357  time: 0.9396  data_time: 0.2590  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:47:30 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 639  total_loss: 0.6675  loss_cls: 0.1196  loss_box_reg: 0.353  loss_mask: 0.1379  loss_rpn_cls: 0.00354  loss_rpn_loc: 0.04041  time: 0.9392  data_time: 0.2812  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:47:47 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 659  total_loss: 0.6466  loss_cls: 0.138  loss_box_reg: 0.3195  loss_mask: 0.1369  loss_rpn_cls: 0.005273  loss_rpn_loc: 0.03017  time: 0.9377  data_time: 0.2413  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 14:48:06 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 679  total_loss: 0.6556  loss_cls: 0.1311  loss_box_reg: 0.3451  loss_mask: 0.1345  loss_rpn_cls: 0.004489  loss_rpn_loc: 0.04945  time: 0.9375  data_time: 0.2478  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:48:25 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 699  total_loss: 0.6511  loss_cls: 0.15  loss_box_reg: 0.3156  loss_mask: 0.1312  loss_rpn_cls: 0.00276  loss_rpn_loc: 0.03743  time: 0.9379  data_time: 0.2888  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:48:44 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 719  total_loss: 0.5926  loss_cls: 0.09666  loss_box_reg: 0.3152  loss_mask: 0.1336  loss_rpn_cls: 0.004675  loss_rpn_loc: 0.03964  time: 0.9385  data_time: 0.2933  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:49:03 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 739  total_loss: 0.6368  loss_cls: 0.112  loss_box_reg: 0.3325  loss_mask: 0.1279  loss_rpn_cls: 0.002343  loss_rpn_loc: 0.03686  time: 0.9388  data_time: 0.2762  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:49:22 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 759  total_loss: 0.5658  loss_cls: 0.09875  loss_box_reg: 0.2975  loss_mask: 0.1195  loss_rpn_cls: 0.002944  loss_rpn_loc: 0.03828  time: 0.9393  data_time: 0.2801  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:49:41 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 779  total_loss: 0.5991  loss_cls: 0.1101  loss_box_reg: 0.2933  loss_mask: 0.1293  loss_rpn_cls: 0.003283  loss_rpn_loc: 0.04153  time: 0.9395  data_time: 0.2642  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:50:00 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 799  total_loss: 0.5737  loss_cls: 0.1021  loss_box_reg: 0.2989  loss_mask: 0.1231  loss_rpn_cls: 0.002529  loss_rpn_loc: 0.04393  time: 0.9392  data_time: 0.2855  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:50:19 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 819  total_loss: 0.5771  loss_cls: 0.1218  loss_box_reg: 0.2949  loss_mask: 0.1139  loss_rpn_cls: 0.002759  loss_rpn_loc: 0.03214  time: 0.9393  data_time: 0.2533  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:50:37 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 839  total_loss: 0.597  loss_cls: 0.09183  loss_box_reg: 0.3054  loss_mask: 0.1257  loss_rpn_cls: 0.003022  loss_rpn_loc: 0.04179  time: 0.9388  data_time: 0.2650  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:50:56 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 859  total_loss: 0.5767  loss_cls: 0.09213  loss_box_reg: 0.2987  loss_mask: 0.1163  loss_rpn_cls: 0.002874  loss_rpn_loc: 0.02826  time: 0.9385  data_time: 0.2547  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:51:14 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 879  total_loss: 0.5861  loss_cls: 0.1014  loss_box_reg: 0.3018  loss_mask: 0.1255  loss_rpn_cls: 0.003642  loss_rpn_loc: 0.04566  time: 0.9381  data_time: 0.2661  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:51:33 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 899  total_loss: 0.5826  loss_cls: 0.1094  loss_box_reg: 0.3117  loss_mask: 0.1269  loss_rpn_cls: 0.002408  loss_rpn_loc: 0.0326  time: 0.9384  data_time: 0.2764  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:51:52 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 919  total_loss: 0.5902  loss_cls: 0.1069  loss_box_reg: 0.3113  loss_mask: 0.1224  loss_rpn_cls: 0.002858  loss_rpn_loc: 0.04232  time: 0.9382  data_time: 0.2636  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:52:11 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 939  total_loss: 0.5517  loss_cls: 0.1091  loss_box_reg: 0.2965  loss_mask: 0.123  loss_rpn_cls: 0.003216  loss_rpn_loc: 0.03416  time: 0.9382  data_time: 0.2600  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:52:30 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 959  total_loss: 0.5605  loss_cls: 0.08727  loss_box_reg: 0.2742  loss_mask: 0.1164  loss_rpn_cls: 0.002127  loss_rpn_loc: 0.03531  time: 0.9383  data_time: 0.2699  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:52:49 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 979  total_loss: 0.621  loss_cls: 0.1195  loss_box_reg: 0.3192  loss_mask: 0.1328  loss_rpn_cls: 0.003442  loss_rpn_loc: 0.0439  time: 0.9391  data_time: 0.2986  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:53:08 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 999  total_loss: 0.5455  loss_cls: 0.09397  loss_box_reg: 0.3017  loss_mask: 0.108  loss_rpn_cls: 0.002657  loss_rpn_loc: 0.03722  time: 0.9387  data_time: 0.2653  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 14:53:26 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 1019  total_loss: 0.5418  loss_cls: 0.09279  loss_box_reg: 0.282  loss_mask: 0.1259  loss_rpn_cls: 0.002676  loss_rpn_loc: 0.02877  time: 0.9384  data_time: 0.2505  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:53:44 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 1039  total_loss: 0.5183  loss_cls: 0.09184  loss_box_reg: 0.265  loss_mask: 0.1163  loss_rpn_cls: 0.002844  loss_rpn_loc: 0.03048  time: 0.9379  data_time: 0.2591  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:54:02 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 1059  total_loss: 0.5254  loss_cls: 0.08668  loss_box_reg: 0.2833  loss_mask: 0.1129  loss_rpn_cls: 0.00178  loss_rpn_loc: 0.0335  time: 0.9365  data_time: 0.2537  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:54:21 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 1079  total_loss: 0.5242  loss_cls: 0.09908  loss_box_reg: 0.254  loss_mask: 0.1156  loss_rpn_cls: 0.002633  loss_rpn_loc: 0.04474  time: 0.9371  data_time: 0.2877  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:54:39 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 1099  total_loss: 0.5036  loss_cls: 0.09462  loss_box_reg: 0.2417  loss_mask: 0.1257  loss_rpn_cls: 0.002633  loss_rpn_loc: 0.03232  time: 0.9366  data_time: 0.2722  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:54:58 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 1119  total_loss: 0.5478  loss_cls: 0.09135  loss_box_reg: 0.2571  loss_mask: 0.1171  loss_rpn_cls: 0.002717  loss_rpn_loc: 0.04119  time: 0.9367  data_time: 0.2917  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:55:17 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 1139  total_loss: 0.4574  loss_cls: 0.07599  loss_box_reg: 0.2262  loss_mask: 0.1217  loss_rpn_cls: 0.002554  loss_rpn_loc: 0.03492  time: 0.9369  data_time: 0.2934  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:55:36 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 1159  total_loss: 0.4623  loss_cls: 0.08387  loss_box_reg: 0.2215  loss_mask: 0.1057  loss_rpn_cls: 0.003143  loss_rpn_loc: 0.03425  time: 0.9371  data_time: 0.2941  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:55:54 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 1179  total_loss: 0.5228  loss_cls: 0.1027  loss_box_reg: 0.2404  loss_mask: 0.1097  loss_rpn_cls: 0.001545  loss_rpn_loc: 0.02649  time: 0.9368  data_time: 0.2564  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:56:12 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 1199  total_loss: 0.5163  loss_cls: 0.103  loss_box_reg: 0.2494  loss_mask: 0.1205  loss_rpn_cls: 0.002679  loss_rpn_loc: 0.04055  time: 0.9362  data_time: 0.2354  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:56:31 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 1219  total_loss: 0.4583  loss_cls: 0.08263  loss_box_reg: 0.2265  loss_mask: 0.1059  loss_rpn_cls: 0.002591  loss_rpn_loc: 0.04012  time: 0.9359  data_time: 0.2621  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:56:51 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 1239  total_loss: 0.4738  loss_cls: 0.081  loss_box_reg: 0.21  loss_mask: 0.1072  loss_rpn_cls: 0.002573  loss_rpn_loc: 0.03257  time: 0.9370  data_time: 0.3156  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:57:10 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 1259  total_loss: 0.4747  loss_cls: 0.08355  loss_box_reg: 0.222  loss_mask: 0.1133  loss_rpn_cls: 0.002301  loss_rpn_loc: 0.04313  time: 0.9371  data_time: 0.2993  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:57:28 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 1279  total_loss: 0.5084  loss_cls: 0.1037  loss_box_reg: 0.2403  loss_mask: 0.1237  loss_rpn_cls: 0.002622  loss_rpn_loc: 0.03366  time: 0.9367  data_time: 0.2637  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:57:47 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 1299  total_loss: 0.4925  loss_cls: 0.08151  loss_box_reg: 0.2238  loss_mask: 0.1215  loss_rpn_cls: 0.003558  loss_rpn_loc: 0.04682  time: 0.9368  data_time: 0.2782  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:58:07 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 1319  total_loss: 0.4848  loss_cls: 0.08623  loss_box_reg: 0.2339  loss_mask: 0.1129  loss_rpn_cls: 0.002652  loss_rpn_loc: 0.04304  time: 0.9375  data_time: 0.3014  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 14:58:25 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 1339  total_loss: 0.5057  loss_cls: 0.08694  loss_box_reg: 0.257  loss_mask: 0.1132  loss_rpn_cls: 0.002103  loss_rpn_loc: 0.02794  time: 0.9373  data_time: 0.2790  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:58:43 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 1359  total_loss: 0.4914  loss_cls: 0.08815  loss_box_reg: 0.2227  loss_mask: 0.1167  loss_rpn_cls: 0.002322  loss_rpn_loc: 0.03453  time: 0.9370  data_time: 0.2557  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:59:03 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 1379  total_loss: 0.4961  loss_cls: 0.08393  loss_box_reg: 0.2506  loss_mask: 0.1047  loss_rpn_cls: 0.002341  loss_rpn_loc: 0.03384  time: 0.9377  data_time: 0.2954  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:59:21 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 1399  total_loss: 0.4981  loss_cls: 0.08588  loss_box_reg: 0.2447  loss_mask: 0.1071  loss_rpn_cls: 0.002151  loss_rpn_loc: 0.03644  time: 0.9374  data_time: 0.2480  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 14:59:40 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 1419  total_loss: 0.4465  loss_cls: 0.0788  loss_box_reg: 0.2328  loss_mask: 0.1096  loss_rpn_cls: 0.00234  loss_rpn_loc: 0.03043  time: 0.9373  data_time: 0.2803  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:00:00 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 1439  total_loss: 0.459  loss_cls: 0.07259  loss_box_reg: 0.219  loss_mask: 0.1178  loss_rpn_cls: 0.002328  loss_rpn_loc: 0.03653  time: 0.9379  data_time: 0.2926  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:00:19 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 1459  total_loss: 0.497  loss_cls: 0.09486  loss_box_reg: 0.2286  loss_mask: 0.109  loss_rpn_cls: 0.002625  loss_rpn_loc: 0.0309  time: 0.9380  data_time: 0.2741  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:00:38 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1479  total_loss: 0.4681  loss_cls: 0.09956  loss_box_reg: 0.2274  loss_mask: 0.1143  loss_rpn_cls: 0.003011  loss_rpn_loc: 0.03277  time: 0.9382  data_time: 0.2804  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:00:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4896  loss_cls: 0.1069  loss_box_reg: 0.2312  loss_mask: 0.1086  loss_rpn_cls: 0.002915  loss_rpn_loc: 0.037  time: 0.9380  data_time: 0.2866  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:00:58 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:23:25 (0.9381 s / it)\n",
      "\u001b[32m[03/04 15:00:58 d2.engine.hooks]: \u001b[0mTotal training time: 0:23:27 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 15:00:59 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 15:00:59 d2.data.datasets.coco]: \u001b[0mLoaded 194 images in COCO format from /host/mic21-framework/server/uploads/ballet_dancer_gt.json\n",
      "ballet_dancer\n",
      "\u001b[32m[03/04 15:00:59 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 15:00:59 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 15:00:59 d2.data.datasets.coco]: \u001b[0mLoaded 194 images in COCO format from /host/mic21-framework/server/uploads/ballet_dancer_gt.json\n",
      "\u001b[32m[03/04 15:00:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 194 images left.\n",
      "\u001b[32m[03/04 15:00:59 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category   | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:-----------:|:-------------|\n",
      "| ballet dancer | 235          |  leotard   | 119          |  ballerina  | 426          |\n",
      "| ballerina s.. | 56           |    tutu    | 56           | pointe shoe | 308          |\n",
      "| ballet barre  | 64           |            |              |             |              |\n",
      "|     total     | 1264         |            |              |             |              |\u001b[0m\n",
      "\u001b[32m[03/04 15:00:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 15:00:59 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 15:00:59 d2.data.common]: \u001b[0mSerializing 194 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 15:00:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.68 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (28, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (28,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (7, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 15:01:00 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 15:01:19 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 19  total_loss: 2.661  loss_cls: 0.9648  loss_box_reg: 0.9201  loss_mask: 0.6113  loss_rpn_cls: 0.06248  loss_rpn_loc: 0.05053  time: 0.9409  data_time: 0.3206  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:01:38 d2.utils.events]: \u001b[0m eta: 0:22:45  iter: 39  total_loss: 2.178  loss_cls: 0.7385  loss_box_reg: 0.8581  loss_mask: 0.4933  loss_rpn_cls: 0.04553  loss_rpn_loc: 0.04808  time: 0.9484  data_time: 0.2722  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:01:57 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 59  total_loss: 1.777  loss_cls: 0.5644  loss_box_reg: 0.7778  loss_mask: 0.3619  loss_rpn_cls: 0.03796  loss_rpn_loc: 0.04154  time: 0.9461  data_time: 0.2641  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:02:16 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 79  total_loss: 1.618  loss_cls: 0.4972  loss_box_reg: 0.6957  loss_mask: 0.3315  loss_rpn_cls: 0.02982  loss_rpn_loc: 0.04374  time: 0.9386  data_time: 0.2729  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:02:35 d2.utils.events]: \u001b[0m eta: 0:21:14  iter: 99  total_loss: 1.555  loss_cls: 0.4871  loss_box_reg: 0.6496  loss_mask: 0.3318  loss_rpn_cls: 0.02757  loss_rpn_loc: 0.04545  time: 0.9407  data_time: 0.2638  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:02:53 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 119  total_loss: 1.385  loss_cls: 0.434  loss_box_reg: 0.5677  loss_mask: 0.3079  loss_rpn_cls: 0.02764  loss_rpn_loc: 0.04323  time: 0.9357  data_time: 0.2558  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:03:12 d2.utils.events]: \u001b[0m eta: 0:21:02  iter: 139  total_loss: 1.395  loss_cls: 0.4397  loss_box_reg: 0.546  loss_mask: 0.3035  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.03396  time: 0.9418  data_time: 0.3180  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:03:32 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 159  total_loss: 1.365  loss_cls: 0.4329  loss_box_reg: 0.5841  loss_mask: 0.2941  loss_rpn_cls: 0.02701  loss_rpn_loc: 0.04914  time: 0.9453  data_time: 0.2853  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:03:51 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 179  total_loss: 1.261  loss_cls: 0.3984  loss_box_reg: 0.5134  loss_mask: 0.2699  loss_rpn_cls: 0.02533  loss_rpn_loc: 0.04529  time: 0.9452  data_time: 0.2687  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:04:10 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 199  total_loss: 1.239  loss_cls: 0.4295  loss_box_reg: 0.4594  loss_mask: 0.2843  loss_rpn_cls: 0.02054  loss_rpn_loc: 0.03989  time: 0.9477  data_time: 0.3082  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:04:29 d2.utils.events]: \u001b[0m eta: 0:20:01  iter: 219  total_loss: 1.214  loss_cls: 0.3776  loss_box_reg: 0.5061  loss_mask: 0.265  loss_rpn_cls: 0.02024  loss_rpn_loc: 0.03532  time: 0.9491  data_time: 0.3068  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:04:49 d2.utils.events]: \u001b[0m eta: 0:19:41  iter: 239  total_loss: 1.202  loss_cls: 0.3853  loss_box_reg: 0.5027  loss_mask: 0.2539  loss_rpn_cls: 0.01647  loss_rpn_loc: 0.05033  time: 0.9509  data_time: 0.3057  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:05:09 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 259  total_loss: 1.136  loss_cls: 0.3728  loss_box_reg: 0.4636  loss_mask: 0.2607  loss_rpn_cls: 0.01875  loss_rpn_loc: 0.04199  time: 0.9534  data_time: 0.3109  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:05:28 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 279  total_loss: 1.126  loss_cls: 0.3516  loss_box_reg: 0.4969  loss_mask: 0.256  loss_rpn_cls: 0.01621  loss_rpn_loc: 0.04576  time: 0.9545  data_time: 0.2984  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:05:48 d2.utils.events]: \u001b[0m eta: 0:19:06  iter: 299  total_loss: 1.089  loss_cls: 0.3197  loss_box_reg: 0.4489  loss_mask: 0.252  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.04354  time: 0.9572  data_time: 0.2993  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:06:07 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 319  total_loss: 1.125  loss_cls: 0.3649  loss_box_reg: 0.4782  loss_mask: 0.2479  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.02988  time: 0.9573  data_time: 0.3068  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:06:27 d2.utils.events]: \u001b[0m eta: 0:18:40  iter: 339  total_loss: 1.131  loss_cls: 0.3426  loss_box_reg: 0.4849  loss_mask: 0.2493  loss_rpn_cls: 0.01836  loss_rpn_loc: 0.05308  time: 0.9610  data_time: 0.3344  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:06:47 d2.utils.events]: \u001b[0m eta: 0:18:25  iter: 359  total_loss: 1.061  loss_cls: 0.3086  loss_box_reg: 0.4615  loss_mask: 0.2389  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.04381  time: 0.9619  data_time: 0.3073  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:07:06 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 379  total_loss: 1.051  loss_cls: 0.3273  loss_box_reg: 0.4296  loss_mask: 0.2206  loss_rpn_cls: 0.01772  loss_rpn_loc: 0.05504  time: 0.9626  data_time: 0.3052  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:07:25 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 399  total_loss: 1.067  loss_cls: 0.3317  loss_box_reg: 0.4785  loss_mask: 0.2195  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.04151  time: 0.9617  data_time: 0.3074  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:07:45 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 419  total_loss: 1.022  loss_cls: 0.3163  loss_box_reg: 0.433  loss_mask: 0.2162  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.04141  time: 0.9619  data_time: 0.3174  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:08:04 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 439  total_loss: 0.9717  loss_cls: 0.2782  loss_box_reg: 0.4324  loss_mask: 0.2409  loss_rpn_cls: 0.01527  loss_rpn_loc: 0.03633  time: 0.9628  data_time: 0.3175  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:08:25 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 459  total_loss: 1.081  loss_cls: 0.3005  loss_box_reg: 0.461  loss_mask: 0.2375  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.03774  time: 0.9649  data_time: 0.3146  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:08:45 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 479  total_loss: 0.9387  loss_cls: 0.2846  loss_box_reg: 0.4005  loss_mask: 0.2266  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.04198  time: 0.9662  data_time: 0.3168  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:09:04 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 499  total_loss: 0.9678  loss_cls: 0.301  loss_box_reg: 0.375  loss_mask: 0.2042  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.03532  time: 0.9664  data_time: 0.3024  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:09:23 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 519  total_loss: 0.9416  loss_cls: 0.279  loss_box_reg: 0.4397  loss_mask: 0.2177  loss_rpn_cls: 0.009716  loss_rpn_loc: 0.03798  time: 0.9657  data_time: 0.2950  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:09:43 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 539  total_loss: 1.017  loss_cls: 0.2984  loss_box_reg: 0.4287  loss_mask: 0.2253  loss_rpn_cls: 0.01321  loss_rpn_loc: 0.04032  time: 0.9670  data_time: 0.3153  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:10:02 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 559  total_loss: 0.9248  loss_cls: 0.2785  loss_box_reg: 0.4144  loss_mask: 0.2436  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.03505  time: 0.9657  data_time: 0.2972  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:10:21 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 579  total_loss: 1.016  loss_cls: 0.2933  loss_box_reg: 0.4018  loss_mask: 0.2219  loss_rpn_cls: 0.01586  loss_rpn_loc: 0.039  time: 0.9660  data_time: 0.3010  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:10:41 d2.utils.events]: \u001b[0m eta: 0:14:34  iter: 599  total_loss: 0.9694  loss_cls: 0.2689  loss_box_reg: 0.4164  loss_mask: 0.2413  loss_rpn_cls: 0.009853  loss_rpn_loc: 0.03989  time: 0.9669  data_time: 0.3154  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:11:00 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 619  total_loss: 0.9174  loss_cls: 0.2598  loss_box_reg: 0.3973  loss_mask: 0.2053  loss_rpn_cls: 0.01048  loss_rpn_loc: 0.03875  time: 0.9672  data_time: 0.3083  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:11:18 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 639  total_loss: 0.9342  loss_cls: 0.278  loss_box_reg: 0.3985  loss_mask: 0.2217  loss_rpn_cls: 0.009403  loss_rpn_loc: 0.03099  time: 0.9650  data_time: 0.2564  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:11:38 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 659  total_loss: 0.914  loss_cls: 0.2384  loss_box_reg: 0.3841  loss_mask: 0.2436  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.04525  time: 0.9657  data_time: 0.3099  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 15:11:58 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 679  total_loss: 0.8891  loss_cls: 0.2411  loss_box_reg: 0.4053  loss_mask: 0.214  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.03673  time: 0.9668  data_time: 0.3263  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:12:17 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 699  total_loss: 0.9789  loss_cls: 0.2706  loss_box_reg: 0.427  loss_mask: 0.2128  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.04239  time: 0.9663  data_time: 0.2990  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:12:37 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 719  total_loss: 0.9085  loss_cls: 0.2405  loss_box_reg: 0.3876  loss_mask: 0.2033  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.03804  time: 0.9668  data_time: 0.3084  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:12:56 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 739  total_loss: 0.8928  loss_cls: 0.2173  loss_box_reg: 0.3864  loss_mask: 0.2197  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.03339  time: 0.9668  data_time: 0.3188  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:13:16 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 759  total_loss: 0.9002  loss_cls: 0.2238  loss_box_reg: 0.3898  loss_mask: 0.206  loss_rpn_cls: 0.0099  loss_rpn_loc: 0.02932  time: 0.9670  data_time: 0.2915  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:13:35 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 779  total_loss: 0.7809  loss_cls: 0.2265  loss_box_reg: 0.3539  loss_mask: 0.2018  loss_rpn_cls: 0.0144  loss_rpn_loc: 0.04617  time: 0.9665  data_time: 0.2840  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:13:54 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 799  total_loss: 0.8766  loss_cls: 0.2232  loss_box_reg: 0.3559  loss_mask: 0.2303  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.03901  time: 0.9668  data_time: 0.2965  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:14:14 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 819  total_loss: 0.8748  loss_cls: 0.2314  loss_box_reg: 0.379  loss_mask: 0.2242  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.03495  time: 0.9669  data_time: 0.3024  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:14:34 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 839  total_loss: 0.8265  loss_cls: 0.2134  loss_box_reg: 0.359  loss_mask: 0.196  loss_rpn_cls: 0.007023  loss_rpn_loc: 0.03074  time: 0.9676  data_time: 0.3138  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:14:53 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 859  total_loss: 0.8522  loss_cls: 0.2512  loss_box_reg: 0.3572  loss_mask: 0.2032  loss_rpn_cls: 0.009971  loss_rpn_loc: 0.03641  time: 0.9671  data_time: 0.3002  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:15:12 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 879  total_loss: 0.9135  loss_cls: 0.2438  loss_box_reg: 0.3864  loss_mask: 0.2339  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.036  time: 0.9676  data_time: 0.2957  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:15:32 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 899  total_loss: 0.8209  loss_cls: 0.2038  loss_box_reg: 0.3525  loss_mask: 0.2076  loss_rpn_cls: 0.007465  loss_rpn_loc: 0.03297  time: 0.9678  data_time: 0.3032  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:15:51 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 919  total_loss: 0.8744  loss_cls: 0.2066  loss_box_reg: 0.3592  loss_mask: 0.1984  loss_rpn_cls: 0.009043  loss_rpn_loc: 0.03559  time: 0.9678  data_time: 0.3032  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:16:11 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 939  total_loss: 0.9033  loss_cls: 0.262  loss_box_reg: 0.36  loss_mask: 0.2058  loss_rpn_cls: 0.009226  loss_rpn_loc: 0.0309  time: 0.9677  data_time: 0.3044  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:16:30 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 959  total_loss: 0.8089  loss_cls: 0.2178  loss_box_reg: 0.3397  loss_mask: 0.2145  loss_rpn_cls: 0.006378  loss_rpn_loc: 0.03854  time: 0.9681  data_time: 0.3008  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:16:50 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 979  total_loss: 0.8491  loss_cls: 0.2307  loss_box_reg: 0.3528  loss_mask: 0.196  loss_rpn_cls: 0.007229  loss_rpn_loc: 0.03156  time: 0.9679  data_time: 0.3016  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:17:09 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 999  total_loss: 0.8441  loss_cls: 0.2012  loss_box_reg: 0.3802  loss_mask: 0.2152  loss_rpn_cls: 0.007085  loss_rpn_loc: 0.038  time: 0.9675  data_time: 0.3014  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:17:28 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 1019  total_loss: 0.833  loss_cls: 0.2207  loss_box_reg: 0.3261  loss_mask: 0.1886  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.03019  time: 0.9672  data_time: 0.3017  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:17:47 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 1039  total_loss: 0.7491  loss_cls: 0.2056  loss_box_reg: 0.3308  loss_mask: 0.2025  loss_rpn_cls: 0.006089  loss_rpn_loc: 0.03443  time: 0.9672  data_time: 0.2945  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:18:07 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 1059  total_loss: 0.7908  loss_cls: 0.2149  loss_box_reg: 0.3426  loss_mask: 0.1897  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.04136  time: 0.9675  data_time: 0.2911  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:18:26 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 1079  total_loss: 0.7305  loss_cls: 0.1951  loss_box_reg: 0.2846  loss_mask: 0.207  loss_rpn_cls: 0.006183  loss_rpn_loc: 0.03236  time: 0.9673  data_time: 0.3108  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:18:45 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 1099  total_loss: 0.6482  loss_cls: 0.154  loss_box_reg: 0.2926  loss_mask: 0.192  loss_rpn_cls: 0.005731  loss_rpn_loc: 0.0245  time: 0.9668  data_time: 0.2825  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:19:04 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 1119  total_loss: 0.7955  loss_cls: 0.2149  loss_box_reg: 0.3065  loss_mask: 0.2123  loss_rpn_cls: 0.009146  loss_rpn_loc: 0.03478  time: 0.9671  data_time: 0.3163  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:19:24 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 1139  total_loss: 0.7169  loss_cls: 0.1912  loss_box_reg: 0.3087  loss_mask: 0.2057  loss_rpn_cls: 0.005464  loss_rpn_loc: 0.03116  time: 0.9671  data_time: 0.2925  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:19:43 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1159  total_loss: 0.7563  loss_cls: 0.1745  loss_box_reg: 0.3421  loss_mask: 0.1878  loss_rpn_cls: 0.008499  loss_rpn_loc: 0.03337  time: 0.9673  data_time: 0.3158  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:20:04 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 1179  total_loss: 0.775  loss_cls: 0.2327  loss_box_reg: 0.3098  loss_mask: 0.2041  loss_rpn_cls: 0.005402  loss_rpn_loc: 0.03102  time: 0.9683  data_time: 0.3328  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:20:24 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 1199  total_loss: 0.7165  loss_cls: 0.192  loss_box_reg: 0.3237  loss_mask: 0.1902  loss_rpn_cls: 0.007683  loss_rpn_loc: 0.03883  time: 0.9687  data_time: 0.3084  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:20:42 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1219  total_loss: 0.7281  loss_cls: 0.1882  loss_box_reg: 0.2923  loss_mask: 0.2067  loss_rpn_cls: 0.006613  loss_rpn_loc: 0.02845  time: 0.9680  data_time: 0.2866  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:21:02 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 1239  total_loss: 0.6674  loss_cls: 0.1408  loss_box_reg: 0.2711  loss_mask: 0.1898  loss_rpn_cls: 0.007936  loss_rpn_loc: 0.0266  time: 0.9680  data_time: 0.3032  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:21:21 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 1259  total_loss: 0.8007  loss_cls: 0.2094  loss_box_reg: 0.325  loss_mask: 0.1976  loss_rpn_cls: 0.007836  loss_rpn_loc: 0.03984  time: 0.9683  data_time: 0.3021  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:21:42 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 1279  total_loss: 0.7267  loss_cls: 0.1724  loss_box_reg: 0.303  loss_mask: 0.1865  loss_rpn_cls: 0.004359  loss_rpn_loc: 0.02729  time: 0.9690  data_time: 0.3261  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:22:01 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1299  total_loss: 0.7997  loss_cls: 0.212  loss_box_reg: 0.3325  loss_mask: 0.1881  loss_rpn_cls: 0.008275  loss_rpn_loc: 0.03584  time: 0.9688  data_time: 0.3047  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:22:20 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 1319  total_loss: 0.716  loss_cls: 0.1839  loss_box_reg: 0.2835  loss_mask: 0.2032  loss_rpn_cls: 0.005774  loss_rpn_loc: 0.03405  time: 0.9687  data_time: 0.3214  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 15:22:40 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1339  total_loss: 0.7178  loss_cls: 0.1701  loss_box_reg: 0.2792  loss_mask: 0.2068  loss_rpn_cls: 0.007239  loss_rpn_loc: 0.03511  time: 0.9694  data_time: 0.3353  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:23:00 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1359  total_loss: 0.6884  loss_cls: 0.14  loss_box_reg: 0.3072  loss_mask: 0.2043  loss_rpn_cls: 0.00652  loss_rpn_loc: 0.02935  time: 0.9694  data_time: 0.2962  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:23:19 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1379  total_loss: 0.6415  loss_cls: 0.163  loss_box_reg: 0.292  loss_mask: 0.1962  loss_rpn_cls: 0.006098  loss_rpn_loc: 0.02467  time: 0.9693  data_time: 0.3065  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:23:38 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1399  total_loss: 0.8317  loss_cls: 0.2099  loss_box_reg: 0.3227  loss_mask: 0.2088  loss_rpn_cls: 0.006654  loss_rpn_loc: 0.03623  time: 0.9693  data_time: 0.3018  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:23:58 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.6782  loss_cls: 0.1641  loss_box_reg: 0.2812  loss_mask: 0.1704  loss_rpn_cls: 0.007836  loss_rpn_loc: 0.02902  time: 0.9692  data_time: 0.3040  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:24:18 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.6705  loss_cls: 0.2259  loss_box_reg: 0.273  loss_mask: 0.2135  loss_rpn_cls: 0.007023  loss_rpn_loc: 0.03868  time: 0.9696  data_time: 0.3194  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:24:37 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.7269  loss_cls: 0.1715  loss_box_reg: 0.2964  loss_mask: 0.1797  loss_rpn_cls: 0.005792  loss_rpn_loc: 0.03988  time: 0.9696  data_time: 0.2933  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:24:56 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.6904  loss_cls: 0.1656  loss_box_reg: 0.2768  loss_mask: 0.2204  loss_rpn_cls: 0.006593  loss_rpn_loc: 0.03415  time: 0.9696  data_time: 0.2981  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:25:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7395  loss_cls: 0.2003  loss_box_reg: 0.3118  loss_mask: 0.198  loss_rpn_cls: 0.006027  loss_rpn_loc: 0.02775  time: 0.9699  data_time: 0.3351  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:25:18 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:12 (0.9699 s / it)\n",
      "\u001b[32m[03/04 15:25:18 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:15 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 15:25:19 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 15:25:19 d2.data.datasets.coco]: \u001b[0mLoaded 141 images in COCO format from /host/mic21-framework/server/uploads/cameraman_gt.json\n",
      "cameraman\n",
      "\u001b[32m[03/04 15:25:19 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 15:25:19 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 15:25:19 d2.data.datasets.coco]: \u001b[0mLoaded 141 images in COCO format from /host/mic21-framework/server/uploads/cameraman_gt.json\n",
      "\u001b[32m[03/04 15:25:19 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 141 images left.\n",
      "\u001b[32m[03/04 15:25:19 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|  category  | #instances   |   category   | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n",
      "|    man     | 110          |    woman     | 59           | cameraman  | 156          |\n",
      "| sports cap | 61           | movie camera | 156          |            |              |\n",
      "|   total    | 542          |              |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 15:25:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 15:25:19 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 15:25:19 d2.data.common]: \u001b[0mSerializing 141 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 15:25:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 15:25:19 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 15:25:40 d2.utils.events]: \u001b[0m eta: 0:25:05  iter: 19  total_loss: 2.55  loss_cls: 0.877  loss_box_reg: 0.9459  loss_mask: 0.6363  loss_rpn_cls: 0.02602  loss_rpn_loc: 0.03239  time: 1.0071  data_time: 0.3272  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:26:00 d2.utils.events]: \u001b[0m eta: 0:24:28  iter: 39  total_loss: 1.96  loss_cls: 0.5775  loss_box_reg: 0.8909  loss_mask: 0.4604  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.02954  time: 1.0068  data_time: 0.3085  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:26:20 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 59  total_loss: 1.652  loss_cls: 0.4337  loss_box_reg: 0.7913  loss_mask: 0.3143  loss_rpn_cls: 0.01658  loss_rpn_loc: 0.03151  time: 1.0046  data_time: 0.3282  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:26:41 d2.utils.events]: \u001b[0m eta: 0:24:10  iter: 79  total_loss: 1.415  loss_cls: 0.3796  loss_box_reg: 0.7542  loss_mask: 0.2569  loss_rpn_cls: 0.01577  loss_rpn_loc: 0.0439  time: 1.0087  data_time: 0.2999  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:27:01 d2.utils.events]: \u001b[0m eta: 0:24:18  iter: 99  total_loss: 1.19  loss_cls: 0.3184  loss_box_reg: 0.6126  loss_mask: 0.2202  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.02952  time: 1.0139  data_time: 0.3376  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:27:22 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 119  total_loss: 1.185  loss_cls: 0.3056  loss_box_reg: 0.6095  loss_mask: 0.2128  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.0307  time: 1.0145  data_time: 0.3029  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:27:42 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 139  total_loss: 1.135  loss_cls: 0.2987  loss_box_reg: 0.5625  loss_mask: 0.1993  loss_rpn_cls: 0.008145  loss_rpn_loc: 0.02679  time: 1.0119  data_time: 0.3144  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:28:02 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 159  total_loss: 0.9497  loss_cls: 0.2392  loss_box_reg: 0.5157  loss_mask: 0.1857  loss_rpn_cls: 0.006791  loss_rpn_loc: 0.02864  time: 1.0132  data_time: 0.3242  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:28:22 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 179  total_loss: 1.042  loss_cls: 0.278  loss_box_reg: 0.4613  loss_mask: 0.1918  loss_rpn_cls: 0.007245  loss_rpn_loc: 0.02754  time: 1.0134  data_time: 0.3228  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:28:42 d2.utils.events]: \u001b[0m eta: 0:22:00  iter: 199  total_loss: 1.033  loss_cls: 0.277  loss_box_reg: 0.5005  loss_mask: 0.1972  loss_rpn_cls: 0.005306  loss_rpn_loc: 0.02819  time: 1.0117  data_time: 0.3262  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:29:03 d2.utils.events]: \u001b[0m eta: 0:21:40  iter: 219  total_loss: 0.9811  loss_cls: 0.2906  loss_box_reg: 0.4566  loss_mask: 0.1986  loss_rpn_cls: 0.006109  loss_rpn_loc: 0.02779  time: 1.0130  data_time: 0.3311  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:29:23 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 239  total_loss: 0.935  loss_cls: 0.2431  loss_box_reg: 0.4479  loss_mask: 0.1856  loss_rpn_cls: 0.007826  loss_rpn_loc: 0.02228  time: 1.0107  data_time: 0.3117  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:29:43 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 259  total_loss: 0.8991  loss_cls: 0.2227  loss_box_reg: 0.4306  loss_mask: 0.1692  loss_rpn_cls: 0.007221  loss_rpn_loc: 0.02275  time: 1.0115  data_time: 0.3340  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:30:03 d2.utils.events]: \u001b[0m eta: 0:20:22  iter: 279  total_loss: 0.8442  loss_cls: 0.2212  loss_box_reg: 0.4219  loss_mask: 0.1917  loss_rpn_cls: 0.006566  loss_rpn_loc: 0.02325  time: 1.0115  data_time: 0.3127  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:30:24 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 299  total_loss: 0.8592  loss_cls: 0.2342  loss_box_reg: 0.4059  loss_mask: 0.1949  loss_rpn_cls: 0.004182  loss_rpn_loc: 0.03033  time: 1.0148  data_time: 0.3294  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:30:44 d2.utils.events]: \u001b[0m eta: 0:19:54  iter: 319  total_loss: 0.8223  loss_cls: 0.2213  loss_box_reg: 0.3889  loss_mask: 0.1808  loss_rpn_cls: 0.006105  loss_rpn_loc: 0.02802  time: 1.0132  data_time: 0.2966  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:31:05 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 339  total_loss: 0.7717  loss_cls: 0.1949  loss_box_reg: 0.3642  loss_mask: 0.1754  loss_rpn_cls: 0.006169  loss_rpn_loc: 0.02496  time: 1.0141  data_time: 0.3589  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:31:24 d2.utils.events]: \u001b[0m eta: 0:19:10  iter: 359  total_loss: 0.7942  loss_cls: 0.2056  loss_box_reg: 0.3825  loss_mask: 0.1775  loss_rpn_cls: 0.005402  loss_rpn_loc: 0.01737  time: 1.0114  data_time: 0.3122  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:31:44 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 379  total_loss: 0.7781  loss_cls: 0.1982  loss_box_reg: 0.3747  loss_mask: 0.1572  loss_rpn_cls: 0.005495  loss_rpn_loc: 0.02686  time: 1.0105  data_time: 0.3095  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:32:03 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 399  total_loss: 0.8187  loss_cls: 0.1894  loss_box_reg: 0.3715  loss_mask: 0.1666  loss_rpn_cls: 0.004239  loss_rpn_loc: 0.0187  time: 1.0080  data_time: 0.2882  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:32:24 d2.utils.events]: \u001b[0m eta: 0:18:03  iter: 419  total_loss: 0.7397  loss_cls: 0.1672  loss_box_reg: 0.3526  loss_mask: 0.1662  loss_rpn_cls: 0.006095  loss_rpn_loc: 0.02319  time: 1.0088  data_time: 0.3262  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:32:44 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 439  total_loss: 0.7833  loss_cls: 0.2224  loss_box_reg: 0.3627  loss_mask: 0.1792  loss_rpn_cls: 0.005789  loss_rpn_loc: 0.0319  time: 1.0097  data_time: 0.3204  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:33:05 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 459  total_loss: 0.7336  loss_cls: 0.173  loss_box_reg: 0.3573  loss_mask: 0.1708  loss_rpn_cls: 0.005218  loss_rpn_loc: 0.02945  time: 1.0100  data_time: 0.3303  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:33:25 d2.utils.events]: \u001b[0m eta: 0:17:02  iter: 479  total_loss: 0.7435  loss_cls: 0.1731  loss_box_reg: 0.3441  loss_mask: 0.1755  loss_rpn_cls: 0.00665  loss_rpn_loc: 0.02552  time: 1.0100  data_time: 0.3272  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:33:44 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 499  total_loss: 0.6502  loss_cls: 0.1708  loss_box_reg: 0.3246  loss_mask: 0.1367  loss_rpn_cls: 0.002765  loss_rpn_loc: 0.02016  time: 1.0082  data_time: 0.3219  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:34:05 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 519  total_loss: 0.7293  loss_cls: 0.1694  loss_box_reg: 0.3471  loss_mask: 0.1623  loss_rpn_cls: 0.001894  loss_rpn_loc: 0.02362  time: 1.0094  data_time: 0.3359  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:34:25 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 539  total_loss: 0.7131  loss_cls: 0.1772  loss_box_reg: 0.3542  loss_mask: 0.1601  loss_rpn_cls: 0.004466  loss_rpn_loc: 0.02455  time: 1.0092  data_time: 0.3295  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:34:46 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 559  total_loss: 0.6638  loss_cls: 0.1593  loss_box_reg: 0.338  loss_mask: 0.1513  loss_rpn_cls: 0.003381  loss_rpn_loc: 0.0208  time: 1.0109  data_time: 0.3378  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:35:06 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 579  total_loss: 0.6505  loss_cls: 0.1382  loss_box_reg: 0.3328  loss_mask: 0.1534  loss_rpn_cls: 0.003523  loss_rpn_loc: 0.02115  time: 1.0107  data_time: 0.3154  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:35:27 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 599  total_loss: 0.6951  loss_cls: 0.2034  loss_box_reg: 0.3326  loss_mask: 0.1514  loss_rpn_cls: 0.002383  loss_rpn_loc: 0.02178  time: 1.0105  data_time: 0.3224  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:35:47 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 619  total_loss: 0.6042  loss_cls: 0.153  loss_box_reg: 0.2991  loss_mask: 0.1513  loss_rpn_cls: 0.004602  loss_rpn_loc: 0.02573  time: 1.0108  data_time: 0.3202  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:36:07 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 639  total_loss: 0.6942  loss_cls: 0.1977  loss_box_reg: 0.3333  loss_mask: 0.1581  loss_rpn_cls: 0.005969  loss_rpn_loc: 0.02139  time: 1.0100  data_time: 0.2875  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:36:27 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 659  total_loss: 0.6231  loss_cls: 0.1316  loss_box_reg: 0.3225  loss_mask: 0.142  loss_rpn_cls: 0.002959  loss_rpn_loc: 0.02446  time: 1.0106  data_time: 0.3387  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 15:36:48 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 679  total_loss: 0.5977  loss_cls: 0.1711  loss_box_reg: 0.2771  loss_mask: 0.1377  loss_rpn_cls: 0.003139  loss_rpn_loc: 0.02422  time: 1.0109  data_time: 0.3079  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:37:09 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 699  total_loss: 0.6171  loss_cls: 0.1572  loss_box_reg: 0.2801  loss_mask: 0.1472  loss_rpn_cls: 0.001712  loss_rpn_loc: 0.02444  time: 1.0119  data_time: 0.3503  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:37:28 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 719  total_loss: 0.6617  loss_cls: 0.1785  loss_box_reg: 0.3235  loss_mask: 0.1309  loss_rpn_cls: 0.003275  loss_rpn_loc: 0.02506  time: 1.0110  data_time: 0.3208  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:37:49 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 739  total_loss: 0.6183  loss_cls: 0.1549  loss_box_reg: 0.2834  loss_mask: 0.1445  loss_rpn_cls: 0.003455  loss_rpn_loc: 0.01768  time: 1.0113  data_time: 0.3331  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:38:08 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 759  total_loss: 0.6634  loss_cls: 0.1759  loss_box_reg: 0.2862  loss_mask: 0.1509  loss_rpn_cls: 0.00378  loss_rpn_loc: 0.0243  time: 1.0097  data_time: 0.2859  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:38:27 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 779  total_loss: 0.6445  loss_cls: 0.175  loss_box_reg: 0.306  loss_mask: 0.1447  loss_rpn_cls: 0.002843  loss_rpn_loc: 0.02146  time: 1.0088  data_time: 0.3061  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:38:48 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 799  total_loss: 0.6384  loss_cls: 0.182  loss_box_reg: 0.2759  loss_mask: 0.1537  loss_rpn_cls: 0.002198  loss_rpn_loc: 0.02417  time: 1.0092  data_time: 0.3118  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:39:08 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 819  total_loss: 0.638  loss_cls: 0.1791  loss_box_reg: 0.294  loss_mask: 0.1452  loss_rpn_cls: 0.002892  loss_rpn_loc: 0.02059  time: 1.0095  data_time: 0.3505  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:39:28 d2.utils.events]: \u001b[0m eta: 0:11:09  iter: 839  total_loss: 0.6447  loss_cls: 0.1758  loss_box_reg: 0.2975  loss_mask: 0.1411  loss_rpn_cls: 0.003345  loss_rpn_loc: 0.0195  time: 1.0093  data_time: 0.2928  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:39:49 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 859  total_loss: 0.5764  loss_cls: 0.1378  loss_box_reg: 0.2761  loss_mask: 0.1341  loss_rpn_cls: 0.002537  loss_rpn_loc: 0.02206  time: 1.0097  data_time: 0.3188  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:40:09 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 879  total_loss: 0.6687  loss_cls: 0.1668  loss_box_reg: 0.2883  loss_mask: 0.1542  loss_rpn_cls: 0.003088  loss_rpn_loc: 0.02422  time: 1.0097  data_time: 0.3213  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:40:29 d2.utils.events]: \u001b[0m eta: 0:10:08  iter: 899  total_loss: 0.6204  loss_cls: 0.1458  loss_box_reg: 0.2999  loss_mask: 0.1366  loss_rpn_cls: 0.00256  loss_rpn_loc: 0.02176  time: 1.0096  data_time: 0.3235  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:40:49 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 919  total_loss: 0.6018  loss_cls: 0.1335  loss_box_reg: 0.2671  loss_mask: 0.1422  loss_rpn_cls: 0.003777  loss_rpn_loc: 0.02346  time: 1.0091  data_time: 0.3201  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:41:09 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 939  total_loss: 0.5692  loss_cls: 0.1125  loss_box_reg: 0.2817  loss_mask: 0.1374  loss_rpn_cls: 0.003707  loss_rpn_loc: 0.02056  time: 1.0089  data_time: 0.3064  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:41:29 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 959  total_loss: 0.6186  loss_cls: 0.1784  loss_box_reg: 0.3015  loss_mask: 0.1504  loss_rpn_cls: 0.003929  loss_rpn_loc: 0.02007  time: 1.0086  data_time: 0.3135  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:41:50 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 979  total_loss: 0.5693  loss_cls: 0.1256  loss_box_reg: 0.2679  loss_mask: 0.1299  loss_rpn_cls: 0.002583  loss_rpn_loc: 0.01847  time: 1.0095  data_time: 0.3433  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:42:10 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 999  total_loss: 0.5541  loss_cls: 0.1231  loss_box_reg: 0.2775  loss_mask: 0.1405  loss_rpn_cls: 0.00375  loss_rpn_loc: 0.02671  time: 1.0098  data_time: 0.3221  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:42:31 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 1019  total_loss: 0.604  loss_cls: 0.1327  loss_box_reg: 0.2558  loss_mask: 0.142  loss_rpn_cls: 0.003325  loss_rpn_loc: 0.01941  time: 1.0101  data_time: 0.3270  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:42:51 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 1039  total_loss: 0.5264  loss_cls: 0.1064  loss_box_reg: 0.2223  loss_mask: 0.1275  loss_rpn_cls: 0.001839  loss_rpn_loc: 0.02023  time: 1.0099  data_time: 0.3263  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:43:10 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 1059  total_loss: 0.5289  loss_cls: 0.1349  loss_box_reg: 0.2294  loss_mask: 0.1285  loss_rpn_cls: 0.002045  loss_rpn_loc: 0.02253  time: 1.0092  data_time: 0.3148  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:43:30 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 1079  total_loss: 0.5418  loss_cls: 0.1477  loss_box_reg: 0.2338  loss_mask: 0.1333  loss_rpn_cls: 0.00326  loss_rpn_loc: 0.02047  time: 1.0089  data_time: 0.3207  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:43:50 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 1099  total_loss: 0.5091  loss_cls: 0.1046  loss_box_reg: 0.2374  loss_mask: 0.1335  loss_rpn_cls: 0.00298  loss_rpn_loc: 0.01962  time: 1.0089  data_time: 0.3175  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:44:11 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 1119  total_loss: 0.4468  loss_cls: 0.0956  loss_box_reg: 0.211  loss_mask: 0.1216  loss_rpn_cls: 0.002535  loss_rpn_loc: 0.01912  time: 1.0092  data_time: 0.3267  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:44:32 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1139  total_loss: 0.5056  loss_cls: 0.09374  loss_box_reg: 0.2532  loss_mask: 0.132  loss_rpn_cls: 0.002834  loss_rpn_loc: 0.02935  time: 1.0098  data_time: 0.3268  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:44:52 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 1159  total_loss: 0.5551  loss_cls: 0.1447  loss_box_reg: 0.232  loss_mask: 0.1203  loss_rpn_cls: 0.002449  loss_rpn_loc: 0.01814  time: 1.0095  data_time: 0.3131  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:45:12 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 1179  total_loss: 0.4749  loss_cls: 0.1102  loss_box_reg: 0.2071  loss_mask: 0.1219  loss_rpn_cls: 0.001926  loss_rpn_loc: 0.01809  time: 1.0094  data_time: 0.3081  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:45:32 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 1199  total_loss: 0.4789  loss_cls: 0.1191  loss_box_reg: 0.2347  loss_mask: 0.1273  loss_rpn_cls: 0.002476  loss_rpn_loc: 0.0223  time: 1.0092  data_time: 0.2950  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:45:51 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 1219  total_loss: 0.5255  loss_cls: 0.1203  loss_box_reg: 0.2131  loss_mask: 0.1378  loss_rpn_cls: 0.00545  loss_rpn_loc: 0.02946  time: 1.0086  data_time: 0.2954  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:46:11 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 1239  total_loss: 0.5378  loss_cls: 0.113  loss_box_reg: 0.2337  loss_mask: 0.1341  loss_rpn_cls: 0.001522  loss_rpn_loc: 0.01794  time: 1.0085  data_time: 0.3184  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:46:32 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 1259  total_loss: 0.5413  loss_cls: 0.1195  loss_box_reg: 0.2268  loss_mask: 0.1369  loss_rpn_cls: 0.003148  loss_rpn_loc: 0.02695  time: 1.0087  data_time: 0.3171  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:46:52 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 1279  total_loss: 0.5035  loss_cls: 0.1047  loss_box_reg: 0.2218  loss_mask: 0.136  loss_rpn_cls: 0.002795  loss_rpn_loc: 0.02007  time: 1.0092  data_time: 0.3501  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:47:12 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 1299  total_loss: 0.495  loss_cls: 0.1133  loss_box_reg: 0.2183  loss_mask: 0.1418  loss_rpn_cls: 0.002608  loss_rpn_loc: 0.0241  time: 1.0089  data_time: 0.3213  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:47:32 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 1319  total_loss: 0.4704  loss_cls: 0.1069  loss_box_reg: 0.2166  loss_mask: 0.1347  loss_rpn_cls: 0.001977  loss_rpn_loc: 0.0189  time: 1.0087  data_time: 0.3425  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 15:47:52 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 1339  total_loss: 0.4605  loss_cls: 0.09382  loss_box_reg: 0.2175  loss_mask: 0.135  loss_rpn_cls: 0.002334  loss_rpn_loc: 0.01564  time: 1.0084  data_time: 0.2847  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:48:12 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 1359  total_loss: 0.4715  loss_cls: 0.09168  loss_box_reg: 0.2204  loss_mask: 0.1417  loss_rpn_cls: 0.002303  loss_rpn_loc: 0.02066  time: 1.0085  data_time: 0.3219  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:48:32 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 1379  total_loss: 0.4891  loss_cls: 0.1038  loss_box_reg: 0.216  loss_mask: 0.1384  loss_rpn_cls: 0.002187  loss_rpn_loc: 0.02228  time: 1.0084  data_time: 0.3002  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:48:52 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 1399  total_loss: 0.4984  loss_cls: 0.09854  loss_box_reg: 0.2151  loss_mask: 0.1278  loss_rpn_cls: 0.002655  loss_rpn_loc: 0.01888  time: 1.0083  data_time: 0.3230  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 15:49:12 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 1419  total_loss: 0.5508  loss_cls: 0.1239  loss_box_reg: 0.2271  loss_mask: 0.1411  loss_rpn_cls: 0.003173  loss_rpn_loc: 0.0286  time: 1.0079  data_time: 0.3086  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:49:32 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 1439  total_loss: 0.4925  loss_cls: 0.09793  loss_box_reg: 0.2365  loss_mask: 0.134  loss_rpn_cls: 0.002505  loss_rpn_loc: 0.02384  time: 1.0080  data_time: 0.3161  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:49:53 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 1459  total_loss: 0.4661  loss_cls: 0.1139  loss_box_reg: 0.2021  loss_mask: 0.1335  loss_rpn_cls: 0.002133  loss_rpn_loc: 0.01865  time: 1.0084  data_time: 0.3420  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:50:13 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 1479  total_loss: 0.4249  loss_cls: 0.07722  loss_box_reg: 0.2177  loss_mask: 0.1219  loss_rpn_cls: 0.002183  loss_rpn_loc: 0.01751  time: 1.0081  data_time: 0.3145  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:50:34 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4897  loss_cls: 0.1259  loss_box_reg: 0.2031  loss_mask: 0.127  loss_rpn_cls: 0.001931  loss_rpn_loc: 0.02035  time: 1.0080  data_time: 0.3121  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 15:50:34 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:25:10 (1.0080 s / it)\n",
      "\u001b[32m[03/04 15:50:34 d2.engine.hooks]: \u001b[0mTotal training time: 0:25:12 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 15:50:35 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 15:50:35 d2.data.datasets.coco]: \u001b[0mLoaded 108 images in COCO format from /host/mic21-framework/server/uploads/clown_gt.json\n",
      "clown\n",
      "\u001b[32m[03/04 15:50:36 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 15:50:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 15:50:36 d2.data.datasets.coco]: \u001b[0mLoaded 108 images in COCO format from /host/mic21-framework/server/uploads/clown_gt.json\n",
      "\u001b[32m[03/04 15:50:36 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 108 images left.\n",
      "\u001b[32m[03/04 15:50:36 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   clown    | 140          |   motley   | 96           | false hair | 62           |\n",
      "| clown nose | 83           | clown hat  | 72           |            |              |\n",
      "|   total    | 453          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 15:50:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 15:50:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 15:50:36 d2.data.common]: \u001b[0mSerializing 108 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 15:50:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.77 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 15:50:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 15:50:53 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 19  total_loss: 2.442  loss_cls: 0.803  loss_box_reg: 0.8678  loss_mask: 0.6233  loss_rpn_cls: 0.03367  loss_rpn_loc: 0.04437  time: 0.8651  data_time: 0.2091  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:51:11 d2.utils.events]: \u001b[0m eta: 0:22:10  iter: 39  total_loss: 1.9  loss_cls: 0.5602  loss_box_reg: 0.8226  loss_mask: 0.4476  loss_rpn_cls: 0.02055  loss_rpn_loc: 0.06238  time: 0.8833  data_time: 0.2160  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:51:29 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 59  total_loss: 1.433  loss_cls: 0.3677  loss_box_reg: 0.7476  loss_mask: 0.2737  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.05791  time: 0.8736  data_time: 0.2043  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:51:46 d2.utils.events]: \u001b[0m eta: 0:21:07  iter: 79  total_loss: 1.226  loss_cls: 0.2846  loss_box_reg: 0.6026  loss_mask: 0.25  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.05238  time: 0.8718  data_time: 0.1856  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:52:04 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 99  total_loss: 1.08  loss_cls: 0.2576  loss_box_reg: 0.5007  loss_mask: 0.2279  loss_rpn_cls: 0.01443  loss_rpn_loc: 0.04201  time: 0.8765  data_time: 0.2226  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:52:22 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 119  total_loss: 1.024  loss_cls: 0.2595  loss_box_reg: 0.4645  loss_mask: 0.1984  loss_rpn_cls: 0.008094  loss_rpn_loc: 0.04996  time: 0.8809  data_time: 0.2403  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:52:39 d2.utils.events]: \u001b[0m eta: 0:20:07  iter: 139  total_loss: 1.053  loss_cls: 0.2316  loss_box_reg: 0.4554  loss_mask: 0.2  loss_rpn_cls: 0.008587  loss_rpn_loc: 0.04023  time: 0.8769  data_time: 0.1894  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:52:57 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 159  total_loss: 0.8491  loss_cls: 0.2138  loss_box_reg: 0.399  loss_mask: 0.1729  loss_rpn_cls: 0.007505  loss_rpn_loc: 0.03686  time: 0.8783  data_time: 0.2380  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:53:14 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 179  total_loss: 0.8  loss_cls: 0.227  loss_box_reg: 0.367  loss_mask: 0.1691  loss_rpn_cls: 0.007343  loss_rpn_loc: 0.04124  time: 0.8786  data_time: 0.2101  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:53:32 d2.utils.events]: \u001b[0m eta: 0:19:19  iter: 199  total_loss: 0.7607  loss_cls: 0.1962  loss_box_reg: 0.3566  loss_mask: 0.1708  loss_rpn_cls: 0.006107  loss_rpn_loc: 0.03612  time: 0.8797  data_time: 0.2246  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:53:51 d2.utils.events]: \u001b[0m eta: 0:19:03  iter: 219  total_loss: 0.7941  loss_cls: 0.1974  loss_box_reg: 0.3828  loss_mask: 0.1639  loss_rpn_cls: 0.009461  loss_rpn_loc: 0.0407  time: 0.8838  data_time: 0.2530  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:54:08 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 239  total_loss: 0.7854  loss_cls: 0.2126  loss_box_reg: 0.3688  loss_mask: 0.1433  loss_rpn_cls: 0.006777  loss_rpn_loc: 0.04454  time: 0.8812  data_time: 0.2023  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:54:26 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 259  total_loss: 0.759  loss_cls: 0.1804  loss_box_reg: 0.3492  loss_mask: 0.159  loss_rpn_cls: 0.005065  loss_rpn_loc: 0.03461  time: 0.8820  data_time: 0.2324  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:54:43 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 279  total_loss: 0.6974  loss_cls: 0.1574  loss_box_reg: 0.3316  loss_mask: 0.1252  loss_rpn_cls: 0.006697  loss_rpn_loc: 0.05059  time: 0.8829  data_time: 0.2131  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:55:01 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 299  total_loss: 0.6624  loss_cls: 0.1688  loss_box_reg: 0.3164  loss_mask: 0.1295  loss_rpn_cls: 0.006966  loss_rpn_loc: 0.03708  time: 0.8823  data_time: 0.2258  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:55:19 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 319  total_loss: 0.6529  loss_cls: 0.1747  loss_box_reg: 0.2951  loss_mask: 0.1254  loss_rpn_cls: 0.005948  loss_rpn_loc: 0.03517  time: 0.8833  data_time: 0.2425  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:55:36 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 339  total_loss: 0.67  loss_cls: 0.1667  loss_box_reg: 0.3242  loss_mask: 0.1295  loss_rpn_cls: 0.003994  loss_rpn_loc: 0.06023  time: 0.8812  data_time: 0.2117  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:55:53 d2.utils.events]: \u001b[0m eta: 0:16:53  iter: 359  total_loss: 0.7175  loss_cls: 0.163  loss_box_reg: 0.3674  loss_mask: 0.135  loss_rpn_cls: 0.006944  loss_rpn_loc: 0.03739  time: 0.8804  data_time: 0.2214  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:56:11 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 379  total_loss: 0.657  loss_cls: 0.1488  loss_box_reg: 0.3416  loss_mask: 0.1289  loss_rpn_cls: 0.004227  loss_rpn_loc: 0.0355  time: 0.8814  data_time: 0.2215  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:56:29 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 399  total_loss: 0.6259  loss_cls: 0.1613  loss_box_reg: 0.3007  loss_mask: 0.1203  loss_rpn_cls: 0.005867  loss_rpn_loc: 0.04088  time: 0.8819  data_time: 0.2147  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:56:47 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 419  total_loss: 0.6253  loss_cls: 0.127  loss_box_reg: 0.3176  loss_mask: 0.1247  loss_rpn_cls: 0.004312  loss_rpn_loc: 0.0427  time: 0.8823  data_time: 0.2252  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:57:05 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 439  total_loss: 0.6059  loss_cls: 0.1541  loss_box_reg: 0.2791  loss_mask: 0.1251  loss_rpn_cls: 0.004055  loss_rpn_loc: 0.04217  time: 0.8830  data_time: 0.2378  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:57:22 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 459  total_loss: 0.6223  loss_cls: 0.145  loss_box_reg: 0.2927  loss_mask: 0.1218  loss_rpn_cls: 0.004964  loss_rpn_loc: 0.04313  time: 0.8827  data_time: 0.2044  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:57:40 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 479  total_loss: 0.5663  loss_cls: 0.1337  loss_box_reg: 0.2729  loss_mask: 0.1048  loss_rpn_cls: 0.003638  loss_rpn_loc: 0.03896  time: 0.8823  data_time: 0.2117  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:57:58 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 499  total_loss: 0.6132  loss_cls: 0.1709  loss_box_reg: 0.2951  loss_mask: 0.1255  loss_rpn_cls: 0.004719  loss_rpn_loc: 0.02962  time: 0.8825  data_time: 0.2245  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:58:15 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 519  total_loss: 0.5947  loss_cls: 0.1325  loss_box_reg: 0.2856  loss_mask: 0.1172  loss_rpn_cls: 0.004614  loss_rpn_loc: 0.04818  time: 0.8820  data_time: 0.1900  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:58:33 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 539  total_loss: 0.5334  loss_cls: 0.1057  loss_box_reg: 0.2648  loss_mask: 0.1146  loss_rpn_cls: 0.00479  loss_rpn_loc: 0.03749  time: 0.8829  data_time: 0.2525  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:58:52 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 559  total_loss: 0.556  loss_cls: 0.1295  loss_box_reg: 0.2451  loss_mask: 0.1155  loss_rpn_cls: 0.003266  loss_rpn_loc: 0.04845  time: 0.8841  data_time: 0.2459  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:59:09 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 579  total_loss: 0.5301  loss_cls: 0.07956  loss_box_reg: 0.2531  loss_mask: 0.1019  loss_rpn_cls: 0.003129  loss_rpn_loc: 0.04577  time: 0.8841  data_time: 0.2311  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:59:27 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 599  total_loss: 0.5163  loss_cls: 0.1041  loss_box_reg: 0.2727  loss_mask: 0.1056  loss_rpn_cls: 0.00358  loss_rpn_loc: 0.03625  time: 0.8846  data_time: 0.2189  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 15:59:45 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 619  total_loss: 0.5622  loss_cls: 0.1303  loss_box_reg: 0.262  loss_mask: 0.1053  loss_rpn_cls: 0.003011  loss_rpn_loc: 0.03583  time: 0.8848  data_time: 0.2300  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:00:03 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 639  total_loss: 0.5403  loss_cls: 0.128  loss_box_reg: 0.2622  loss_mask: 0.1016  loss_rpn_cls: 0.00286  loss_rpn_loc: 0.04134  time: 0.8847  data_time: 0.2313  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:00:22 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 659  total_loss: 0.5165  loss_cls: 0.09609  loss_box_reg: 0.2591  loss_mask: 0.1035  loss_rpn_cls: 0.00318  loss_rpn_loc: 0.03219  time: 0.8864  data_time: 0.2622  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 16:00:40 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 679  total_loss: 0.5597  loss_cls: 0.1304  loss_box_reg: 0.2503  loss_mask: 0.101  loss_rpn_cls: 0.004061  loss_rpn_loc: 0.0284  time: 0.8870  data_time: 0.2189  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:00:58 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 699  total_loss: 0.5271  loss_cls: 0.1207  loss_box_reg: 0.2638  loss_mask: 0.1075  loss_rpn_cls: 0.003262  loss_rpn_loc: 0.03411  time: 0.8882  data_time: 0.2525  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:01:15 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 719  total_loss: 0.5225  loss_cls: 0.1081  loss_box_reg: 0.2414  loss_mask: 0.1049  loss_rpn_cls: 0.002537  loss_rpn_loc: 0.04013  time: 0.8872  data_time: 0.1927  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:01:34 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 739  total_loss: 0.5138  loss_cls: 0.1127  loss_box_reg: 0.2624  loss_mask: 0.1036  loss_rpn_cls: 0.003793  loss_rpn_loc: 0.04232  time: 0.8879  data_time: 0.2425  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:01:51 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 759  total_loss: 0.4798  loss_cls: 0.09957  loss_box_reg: 0.2296  loss_mask: 0.1042  loss_rpn_cls: 0.002172  loss_rpn_loc: 0.03382  time: 0.8874  data_time: 0.2050  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:02:09 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 779  total_loss: 0.4526  loss_cls: 0.08478  loss_box_reg: 0.227  loss_mask: 0.1012  loss_rpn_cls: 0.003153  loss_rpn_loc: 0.03247  time: 0.8882  data_time: 0.2509  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:02:27 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 799  total_loss: 0.4885  loss_cls: 0.07834  loss_box_reg: 0.2516  loss_mask: 0.1013  loss_rpn_cls: 0.003137  loss_rpn_loc: 0.04346  time: 0.8880  data_time: 0.2138  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:02:45 d2.utils.events]: \u001b[0m eta: 0:10:01  iter: 819  total_loss: 0.5147  loss_cls: 0.1088  loss_box_reg: 0.2496  loss_mask: 0.1002  loss_rpn_cls: 0.003992  loss_rpn_loc: 0.03246  time: 0.8882  data_time: 0.2387  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:03:02 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 839  total_loss: 0.5169  loss_cls: 0.1057  loss_box_reg: 0.2545  loss_mask: 0.1079  loss_rpn_cls: 0.004229  loss_rpn_loc: 0.04282  time: 0.8879  data_time: 0.2147  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:03:21 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 859  total_loss: 0.4845  loss_cls: 0.09513  loss_box_reg: 0.238  loss_mask: 0.09548  loss_rpn_cls: 0.002535  loss_rpn_loc: 0.02988  time: 0.8888  data_time: 0.2280  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:03:39 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 879  total_loss: 0.4555  loss_cls: 0.09307  loss_box_reg: 0.235  loss_mask: 0.1008  loss_rpn_cls: 0.002613  loss_rpn_loc: 0.0386  time: 0.8895  data_time: 0.2644  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:03:57 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 899  total_loss: 0.4538  loss_cls: 0.0961  loss_box_reg: 0.2236  loss_mask: 0.0917  loss_rpn_cls: 0.00275  loss_rpn_loc: 0.04127  time: 0.8895  data_time: 0.2094  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:04:15 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 919  total_loss: 0.4938  loss_cls: 0.09592  loss_box_reg: 0.2402  loss_mask: 0.1032  loss_rpn_cls: 0.002373  loss_rpn_loc: 0.03405  time: 0.8897  data_time: 0.2280  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:04:34 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 939  total_loss: 0.4633  loss_cls: 0.1056  loss_box_reg: 0.2103  loss_mask: 0.09874  loss_rpn_cls: 0.002371  loss_rpn_loc: 0.03835  time: 0.8905  data_time: 0.2366  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:04:51 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 959  total_loss: 0.4526  loss_cls: 0.06874  loss_box_reg: 0.218  loss_mask: 0.09837  loss_rpn_cls: 0.003117  loss_rpn_loc: 0.03492  time: 0.8897  data_time: 0.1991  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:05:10 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 979  total_loss: 0.4702  loss_cls: 0.09708  loss_box_reg: 0.2264  loss_mask: 0.1057  loss_rpn_cls: 0.002547  loss_rpn_loc: 0.02711  time: 0.8906  data_time: 0.2341  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:05:27 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 999  total_loss: 0.4704  loss_cls: 0.09332  loss_box_reg: 0.2192  loss_mask: 0.09907  loss_rpn_cls: 0.003329  loss_rpn_loc: 0.03706  time: 0.8903  data_time: 0.2299  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:05:45 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1019  total_loss: 0.4384  loss_cls: 0.06745  loss_box_reg: 0.2162  loss_mask: 0.08692  loss_rpn_cls: 0.003258  loss_rpn_loc: 0.03096  time: 0.8900  data_time: 0.1998  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:06:03 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 1039  total_loss: 0.4383  loss_cls: 0.09496  loss_box_reg: 0.2139  loss_mask: 0.0883  loss_rpn_cls: 0.002891  loss_rpn_loc: 0.03004  time: 0.8902  data_time: 0.2416  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:06:20 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 1059  total_loss: 0.4328  loss_cls: 0.08714  loss_box_reg: 0.2059  loss_mask: 0.09878  loss_rpn_cls: 0.001831  loss_rpn_loc: 0.03698  time: 0.8902  data_time: 0.2205  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:06:37 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 1079  total_loss: 0.402  loss_cls: 0.08946  loss_box_reg: 0.1865  loss_mask: 0.0957  loss_rpn_cls: 0.002118  loss_rpn_loc: 0.02737  time: 0.8894  data_time: 0.1998  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:06:54 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 1099  total_loss: 0.3855  loss_cls: 0.07085  loss_box_reg: 0.1709  loss_mask: 0.08504  loss_rpn_cls: 0.002881  loss_rpn_loc: 0.02844  time: 0.8888  data_time: 0.2278  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:07:12 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 1119  total_loss: 0.3798  loss_cls: 0.0807  loss_box_reg: 0.1827  loss_mask: 0.09465  loss_rpn_cls: 0.00235  loss_rpn_loc: 0.03594  time: 0.8883  data_time: 0.2237  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:07:29 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 1139  total_loss: 0.3897  loss_cls: 0.07978  loss_box_reg: 0.17  loss_mask: 0.1003  loss_rpn_cls: 0.002506  loss_rpn_loc: 0.02843  time: 0.8880  data_time: 0.2185  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:07:47 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 1159  total_loss: 0.4121  loss_cls: 0.08564  loss_box_reg: 0.1879  loss_mask: 0.08291  loss_rpn_cls: 0.001911  loss_rpn_loc: 0.0283  time: 0.8884  data_time: 0.2412  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:08:05 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 1179  total_loss: 0.3698  loss_cls: 0.07866  loss_box_reg: 0.1742  loss_mask: 0.08909  loss_rpn_cls: 0.00307  loss_rpn_loc: 0.03286  time: 0.8879  data_time: 0.2036  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:08:22 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 1199  total_loss: 0.4148  loss_cls: 0.0856  loss_box_reg: 0.1845  loss_mask: 0.09972  loss_rpn_cls: 0.003459  loss_rpn_loc: 0.03122  time: 0.8876  data_time: 0.2221  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:08:40 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 1219  total_loss: 0.3939  loss_cls: 0.06129  loss_box_reg: 0.1719  loss_mask: 0.0896  loss_rpn_cls: 0.00268  loss_rpn_loc: 0.02994  time: 0.8877  data_time: 0.2093  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:08:57 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 1239  total_loss: 0.4011  loss_cls: 0.08567  loss_box_reg: 0.1619  loss_mask: 0.08807  loss_rpn_cls: 0.002391  loss_rpn_loc: 0.0311  time: 0.8874  data_time: 0.2160  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:09:14 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 1259  total_loss: 0.4064  loss_cls: 0.09763  loss_box_reg: 0.186  loss_mask: 0.09998  loss_rpn_cls: 0.003203  loss_rpn_loc: 0.02939  time: 0.8863  data_time: 0.1910  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:09:31 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 1279  total_loss: 0.3591  loss_cls: 0.07634  loss_box_reg: 0.1676  loss_mask: 0.08897  loss_rpn_cls: 0.002406  loss_rpn_loc: 0.03724  time: 0.8863  data_time: 0.2340  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:09:49 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 1299  total_loss: 0.3798  loss_cls: 0.08304  loss_box_reg: 0.1661  loss_mask: 0.09932  loss_rpn_cls: 0.003184  loss_rpn_loc: 0.03316  time: 0.8859  data_time: 0.1972  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:10:06 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 1319  total_loss: 0.3885  loss_cls: 0.08081  loss_box_reg: 0.1682  loss_mask: 0.09167  loss_rpn_cls: 0.002785  loss_rpn_loc: 0.02802  time: 0.8860  data_time: 0.2061  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 16:10:25 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 1339  total_loss: 0.3451  loss_cls: 0.05862  loss_box_reg: 0.1661  loss_mask: 0.08475  loss_rpn_cls: 0.00228  loss_rpn_loc: 0.02407  time: 0.8864  data_time: 0.2421  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:10:43 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 1359  total_loss: 0.4048  loss_cls: 0.07588  loss_box_reg: 0.1679  loss_mask: 0.09269  loss_rpn_cls: 0.002067  loss_rpn_loc: 0.04189  time: 0.8866  data_time: 0.2318  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:11:00 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 1379  total_loss: 0.3859  loss_cls: 0.08069  loss_box_reg: 0.1589  loss_mask: 0.09295  loss_rpn_cls: 0.002417  loss_rpn_loc: 0.02647  time: 0.8865  data_time: 0.2289  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:11:19 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 1399  total_loss: 0.3809  loss_cls: 0.07256  loss_box_reg: 0.1691  loss_mask: 0.08907  loss_rpn_cls: 0.002806  loss_rpn_loc: 0.03329  time: 0.8869  data_time: 0.2471  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:11:36 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 1419  total_loss: 0.377  loss_cls: 0.09314  loss_box_reg: 0.163  loss_mask: 0.0905  loss_rpn_cls: 0.002573  loss_rpn_loc: 0.03088  time: 0.8868  data_time: 0.2208  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:11:54 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 1439  total_loss: 0.3441  loss_cls: 0.06504  loss_box_reg: 0.1666  loss_mask: 0.08819  loss_rpn_cls: 0.002782  loss_rpn_loc: 0.02934  time: 0.8870  data_time: 0.2349  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:12:12 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 1459  total_loss: 0.3974  loss_cls: 0.07773  loss_box_reg: 0.1677  loss_mask: 0.09336  loss_rpn_cls: 0.002089  loss_rpn_loc: 0.03474  time: 0.8868  data_time: 0.1925  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:12:29 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.4227  loss_cls: 0.1013  loss_box_reg: 0.1722  loss_mask: 0.1009  loss_rpn_cls: 0.002434  loss_rpn_loc: 0.03466  time: 0.8865  data_time: 0.1920  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:12:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.3676  loss_cls: 0.08094  loss_box_reg: 0.1505  loss_mask: 0.08041  loss_rpn_cls: 0.003483  loss_rpn_loc: 0.03175  time: 0.8869  data_time: 0.2572  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:12:49 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:22:08 (0.8869 s / it)\n",
      "\u001b[32m[03/04 16:12:49 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:11 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 16:12:50 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 16:12:50 d2.data.datasets.coco]: \u001b[0mLoaded 172 images in COCO format from /host/mic21-framework/server/uploads/dancer_gt.json\n",
      "dancer\n",
      "\u001b[32m[03/04 16:12:50 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 16:12:51 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 16:12:51 d2.data.datasets.coco]: \u001b[0mLoaded 172 images in COCO format from /host/mic21-framework/server/uploads/dancer_gt.json\n",
      "\u001b[32m[03/04 16:12:51 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 172 images left.\n",
      "\u001b[32m[03/04 16:12:51 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   dancer   | 405          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[03/04 16:12:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 16:12:51 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 16:12:51 d2.data.common]: \u001b[0mSerializing 172 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 16:12:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.12 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 16:12:51 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 16:13:11 d2.utils.events]: \u001b[0m eta: 0:21:38  iter: 19  total_loss: 1.691  loss_cls: 0.318  loss_box_reg: 0.8604  loss_mask: 0.4966  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.01746  time: 0.9551  data_time: 0.3284  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:13:29 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 39  total_loss: 0.9712  loss_cls: 0.1241  loss_box_reg: 0.5381  loss_mask: 0.2103  loss_rpn_cls: 0.005319  loss_rpn_loc: 0.01728  time: 0.9297  data_time: 0.3109  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:13:49 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 59  total_loss: 0.6831  loss_cls: 0.1088  loss_box_reg: 0.4075  loss_mask: 0.1532  loss_rpn_cls: 0.003835  loss_rpn_loc: 0.01607  time: 0.9491  data_time: 0.3331  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:14:08 d2.utils.events]: \u001b[0m eta: 0:22:52  iter: 79  total_loss: 0.7365  loss_cls: 0.1115  loss_box_reg: 0.3415  loss_mask: 0.2507  loss_rpn_cls: 0.006496  loss_rpn_loc: 0.01778  time: 0.9593  data_time: 0.3106  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:14:28 d2.utils.events]: \u001b[0m eta: 0:22:32  iter: 99  total_loss: 0.723  loss_cls: 0.08256  loss_box_reg: 0.3596  loss_mask: 0.2377  loss_rpn_cls: 0.003132  loss_rpn_loc: 0.01516  time: 0.9662  data_time: 0.3301  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:14:48 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 119  total_loss: 0.5956  loss_cls: 0.07249  loss_box_reg: 0.3332  loss_mask: 0.1812  loss_rpn_cls: 0.0053  loss_rpn_loc: 0.01275  time: 0.9715  data_time: 0.3264  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:15:08 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 139  total_loss: 0.7465  loss_cls: 0.07508  loss_box_reg: 0.3756  loss_mask: 0.22  loss_rpn_cls: 0.003736  loss_rpn_loc: 0.0159  time: 0.9714  data_time: 0.3134  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:15:28 d2.utils.events]: \u001b[0m eta: 0:21:53  iter: 159  total_loss: 0.5919  loss_cls: 0.07845  loss_box_reg: 0.289  loss_mask: 0.18  loss_rpn_cls: 0.003907  loss_rpn_loc: 0.01374  time: 0.9742  data_time: 0.3264  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:15:47 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 179  total_loss: 0.5698  loss_cls: 0.06303  loss_box_reg: 0.3064  loss_mask: 0.18  loss_rpn_cls: 0.003068  loss_rpn_loc: 0.01671  time: 0.9756  data_time: 0.3069  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:16:07 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 199  total_loss: 0.5663  loss_cls: 0.0793  loss_box_reg: 0.2987  loss_mask: 0.158  loss_rpn_cls: 0.003252  loss_rpn_loc: 0.01196  time: 0.9744  data_time: 0.3166  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:16:26 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 219  total_loss: 0.5551  loss_cls: 0.07098  loss_box_reg: 0.2751  loss_mask: 0.1723  loss_rpn_cls: 0.001986  loss_rpn_loc: 0.01497  time: 0.9726  data_time: 0.2903  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:16:45 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 239  total_loss: 0.5158  loss_cls: 0.06514  loss_box_reg: 0.283  loss_mask: 0.1722  loss_rpn_cls: 0.002465  loss_rpn_loc: 0.01182  time: 0.9699  data_time: 0.2759  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:17:04 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 259  total_loss: 0.5993  loss_cls: 0.09172  loss_box_reg: 0.3036  loss_mask: 0.2039  loss_rpn_cls: 0.003162  loss_rpn_loc: 0.0155  time: 0.9682  data_time: 0.3158  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:17:22 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 279  total_loss: 0.5602  loss_cls: 0.07215  loss_box_reg: 0.2815  loss_mask: 0.1556  loss_rpn_cls: 0.002858  loss_rpn_loc: 0.01375  time: 0.9663  data_time: 0.3012  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:17:43 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 299  total_loss: 0.6116  loss_cls: 0.0708  loss_box_reg: 0.3006  loss_mask: 0.1943  loss_rpn_cls: 0.003373  loss_rpn_loc: 0.01238  time: 0.9689  data_time: 0.3228  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:18:02 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 319  total_loss: 0.5384  loss_cls: 0.07354  loss_box_reg: 0.2911  loss_mask: 0.1766  loss_rpn_cls: 0.002749  loss_rpn_loc: 0.01447  time: 0.9686  data_time: 0.2958  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:18:21 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 339  total_loss: 0.5256  loss_cls: 0.07122  loss_box_reg: 0.2553  loss_mask: 0.1678  loss_rpn_cls: 0.002521  loss_rpn_loc: 0.01185  time: 0.9673  data_time: 0.2831  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:18:40 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 359  total_loss: 0.5594  loss_cls: 0.07046  loss_box_reg: 0.2798  loss_mask: 0.1849  loss_rpn_cls: 0.002672  loss_rpn_loc: 0.01103  time: 0.9668  data_time: 0.3113  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:19:00 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 379  total_loss: 0.4789  loss_cls: 0.05644  loss_box_reg: 0.2481  loss_mask: 0.1471  loss_rpn_cls: 0.002165  loss_rpn_loc: 0.01263  time: 0.9680  data_time: 0.3216  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:19:19 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 399  total_loss: 0.4952  loss_cls: 0.06803  loss_box_reg: 0.2514  loss_mask: 0.1841  loss_rpn_cls: 0.001989  loss_rpn_loc: 0.01168  time: 0.9667  data_time: 0.2910  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:19:39 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 419  total_loss: 0.5317  loss_cls: 0.07842  loss_box_reg: 0.2598  loss_mask: 0.1754  loss_rpn_cls: 0.002952  loss_rpn_loc: 0.01501  time: 0.9681  data_time: 0.3113  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:19:59 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 439  total_loss: 0.4433  loss_cls: 0.06233  loss_box_reg: 0.2405  loss_mask: 0.129  loss_rpn_cls: 0.001849  loss_rpn_loc: 0.009942  time: 0.9695  data_time: 0.3213  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:20:17 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 459  total_loss: 0.4774  loss_cls: 0.05929  loss_box_reg: 0.2353  loss_mask: 0.1432  loss_rpn_cls: 0.003575  loss_rpn_loc: 0.01191  time: 0.9678  data_time: 0.2745  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:20:37 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 479  total_loss: 0.5874  loss_cls: 0.05904  loss_box_reg: 0.2772  loss_mask: 0.2077  loss_rpn_cls: 0.002953  loss_rpn_loc: 0.01831  time: 0.9679  data_time: 0.3123  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:20:56 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 499  total_loss: 0.5298  loss_cls: 0.06531  loss_box_reg: 0.2688  loss_mask: 0.1854  loss_rpn_cls: 0.003656  loss_rpn_loc: 0.01195  time: 0.9688  data_time: 0.3256  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:21:15 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 519  total_loss: 0.4992  loss_cls: 0.07056  loss_box_reg: 0.2487  loss_mask: 0.1547  loss_rpn_cls: 0.002606  loss_rpn_loc: 0.01091  time: 0.9664  data_time: 0.2719  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:21:34 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 539  total_loss: 0.4709  loss_cls: 0.05273  loss_box_reg: 0.25  loss_mask: 0.1322  loss_rpn_cls: 0.001671  loss_rpn_loc: 0.01116  time: 0.9666  data_time: 0.3038  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:21:53 d2.utils.events]: \u001b[0m eta: 0:15:06  iter: 559  total_loss: 0.4382  loss_cls: 0.05841  loss_box_reg: 0.2265  loss_mask: 0.1474  loss_rpn_cls: 0.002433  loss_rpn_loc: 0.01308  time: 0.9667  data_time: 0.3000  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:22:13 d2.utils.events]: \u001b[0m eta: 0:14:45  iter: 579  total_loss: 0.4734  loss_cls: 0.0647  loss_box_reg: 0.2496  loss_mask: 0.1405  loss_rpn_cls: 0.001826  loss_rpn_loc: 0.01137  time: 0.9665  data_time: 0.2882  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:22:31 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 599  total_loss: 0.5274  loss_cls: 0.05372  loss_box_reg: 0.2628  loss_mask: 0.1732  loss_rpn_cls: 0.0027  loss_rpn_loc: 0.0153  time: 0.9652  data_time: 0.2800  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:22:50 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 619  total_loss: 0.4931  loss_cls: 0.05766  loss_box_reg: 0.2284  loss_mask: 0.1628  loss_rpn_cls: 0.001633  loss_rpn_loc: 0.01311  time: 0.9649  data_time: 0.3121  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:23:10 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 639  total_loss: 0.5112  loss_cls: 0.0577  loss_box_reg: 0.2385  loss_mask: 0.1535  loss_rpn_cls: 0.002053  loss_rpn_loc: 0.01406  time: 0.9655  data_time: 0.3037  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:23:29 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 659  total_loss: 0.4423  loss_cls: 0.05383  loss_box_reg: 0.2404  loss_mask: 0.139  loss_rpn_cls: 0.002015  loss_rpn_loc: 0.01291  time: 0.9649  data_time: 0.2906  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 16:23:48 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 679  total_loss: 0.5031  loss_cls: 0.05776  loss_box_reg: 0.2622  loss_mask: 0.138  loss_rpn_cls: 0.003762  loss_rpn_loc: 0.01556  time: 0.9643  data_time: 0.2850  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:24:07 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 699  total_loss: 0.4691  loss_cls: 0.05295  loss_box_reg: 0.2465  loss_mask: 0.1469  loss_rpn_cls: 0.002378  loss_rpn_loc: 0.01357  time: 0.9644  data_time: 0.3191  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:24:26 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 719  total_loss: 0.4441  loss_cls: 0.04073  loss_box_reg: 0.218  loss_mask: 0.1505  loss_rpn_cls: 0.001326  loss_rpn_loc: 0.009614  time: 0.9635  data_time: 0.2759  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:24:46 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 739  total_loss: 0.4638  loss_cls: 0.04847  loss_box_reg: 0.2269  loss_mask: 0.1542  loss_rpn_cls: 0.002991  loss_rpn_loc: 0.01016  time: 0.9645  data_time: 0.3132  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:25:06 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 759  total_loss: 0.5095  loss_cls: 0.06098  loss_box_reg: 0.2511  loss_mask: 0.1626  loss_rpn_cls: 0.001912  loss_rpn_loc: 0.01403  time: 0.9652  data_time: 0.3273  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:25:25 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 779  total_loss: 0.4456  loss_cls: 0.05365  loss_box_reg: 0.2181  loss_mask: 0.1547  loss_rpn_cls: 0.00206  loss_rpn_loc: 0.01192  time: 0.9649  data_time: 0.3119  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:25:44 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 799  total_loss: 0.4502  loss_cls: 0.06798  loss_box_reg: 0.2402  loss_mask: 0.1308  loss_rpn_cls: 0.001722  loss_rpn_loc: 0.01161  time: 0.9651  data_time: 0.3065  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:26:04 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 819  total_loss: 0.4356  loss_cls: 0.06073  loss_box_reg: 0.2094  loss_mask: 0.1434  loss_rpn_cls: 0.002561  loss_rpn_loc: 0.01093  time: 0.9655  data_time: 0.3160  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:26:23 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 839  total_loss: 0.4489  loss_cls: 0.05824  loss_box_reg: 0.199  loss_mask: 0.1299  loss_rpn_cls: 0.002023  loss_rpn_loc: 0.009798  time: 0.9656  data_time: 0.3224  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:26:43 d2.utils.events]: \u001b[0m eta: 0:10:20  iter: 859  total_loss: 0.4722  loss_cls: 0.06531  loss_box_reg: 0.2615  loss_mask: 0.1539  loss_rpn_cls: 0.002044  loss_rpn_loc: 0.01391  time: 0.9658  data_time: 0.3082  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:27:03 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 879  total_loss: 0.4781  loss_cls: 0.06054  loss_box_reg: 0.233  loss_mask: 0.1531  loss_rpn_cls: 0.001758  loss_rpn_loc: 0.01136  time: 0.9663  data_time: 0.3165  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:27:22 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 899  total_loss: 0.4475  loss_cls: 0.05695  loss_box_reg: 0.2204  loss_mask: 0.1422  loss_rpn_cls: 0.002426  loss_rpn_loc: 0.01187  time: 0.9666  data_time: 0.3142  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:27:42 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 919  total_loss: 0.4054  loss_cls: 0.04769  loss_box_reg: 0.2031  loss_mask: 0.1287  loss_rpn_cls: 0.001612  loss_rpn_loc: 0.01263  time: 0.9674  data_time: 0.3322  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:28:01 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 939  total_loss: 0.449  loss_cls: 0.04226  loss_box_reg: 0.2186  loss_mask: 0.1637  loss_rpn_cls: 0.0019  loss_rpn_loc: 0.01492  time: 0.9670  data_time: 0.3108  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:28:21 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 959  total_loss: 0.424  loss_cls: 0.06767  loss_box_reg: 0.223  loss_mask: 0.1435  loss_rpn_cls: 0.002042  loss_rpn_loc: 0.01117  time: 0.9671  data_time: 0.3160  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:28:40 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 979  total_loss: 0.4558  loss_cls: 0.05401  loss_box_reg: 0.2166  loss_mask: 0.1762  loss_rpn_cls: 0.002042  loss_rpn_loc: 0.01467  time: 0.9672  data_time: 0.3281  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:29:01 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 999  total_loss: 0.3954  loss_cls: 0.03558  loss_box_reg: 0.2014  loss_mask: 0.1258  loss_rpn_cls: 0.001264  loss_rpn_loc: 0.01115  time: 0.9685  data_time: 0.3500  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:29:21 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 1019  total_loss: 0.4528  loss_cls: 0.07392  loss_box_reg: 0.2179  loss_mask: 0.1647  loss_rpn_cls: 0.001603  loss_rpn_loc: 0.01413  time: 0.9689  data_time: 0.3287  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:29:41 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 1039  total_loss: 0.3421  loss_cls: 0.03767  loss_box_reg: 0.1704  loss_mask: 0.1187  loss_rpn_cls: 0.00216  loss_rpn_loc: 0.0112  time: 0.9700  data_time: 0.3332  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:30:01 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 1059  total_loss: 0.3948  loss_cls: 0.04316  loss_box_reg: 0.1839  loss_mask: 0.1579  loss_rpn_cls: 0.002372  loss_rpn_loc: 0.01076  time: 0.9700  data_time: 0.3113  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:30:20 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 1079  total_loss: 0.4342  loss_cls: 0.04787  loss_box_reg: 0.196  loss_mask: 0.1457  loss_rpn_cls: 0.002376  loss_rpn_loc: 0.01404  time: 0.9699  data_time: 0.3128  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:30:40 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 1099  total_loss: 0.3744  loss_cls: 0.03956  loss_box_reg: 0.1828  loss_mask: 0.1456  loss_rpn_cls: 0.00203  loss_rpn_loc: 0.01166  time: 0.9704  data_time: 0.3341  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:31:00 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 1119  total_loss: 0.4087  loss_cls: 0.04235  loss_box_reg: 0.1852  loss_mask: 0.1403  loss_rpn_cls: 0.001842  loss_rpn_loc: 0.009896  time: 0.9710  data_time: 0.3437  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:31:19 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1139  total_loss: 0.3467  loss_cls: 0.04112  loss_box_reg: 0.1506  loss_mask: 0.1399  loss_rpn_cls: 0.002163  loss_rpn_loc: 0.0106  time: 0.9708  data_time: 0.2998  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:31:39 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 1159  total_loss: 0.4115  loss_cls: 0.04603  loss_box_reg: 0.1749  loss_mask: 0.1349  loss_rpn_cls: 0.001453  loss_rpn_loc: 0.01246  time: 0.9714  data_time: 0.3368  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:31:58 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 1179  total_loss: 0.3932  loss_cls: 0.04559  loss_box_reg: 0.1899  loss_mask: 0.1414  loss_rpn_cls: 0.001736  loss_rpn_loc: 0.01092  time: 0.9710  data_time: 0.3197  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:32:18 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 1199  total_loss: 0.36  loss_cls: 0.04119  loss_box_reg: 0.1702  loss_mask: 0.1235  loss_rpn_cls: 0.001196  loss_rpn_loc: 0.01181  time: 0.9709  data_time: 0.2979  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:32:37 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 1219  total_loss: 0.3951  loss_cls: 0.06257  loss_box_reg: 0.1666  loss_mask: 0.1353  loss_rpn_cls: 0.001872  loss_rpn_loc: 0.01079  time: 0.9708  data_time: 0.3164  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:32:56 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 1239  total_loss: 0.3199  loss_cls: 0.04346  loss_box_reg: 0.1605  loss_mask: 0.1145  loss_rpn_cls: 0.001789  loss_rpn_loc: 0.0107  time: 0.9708  data_time: 0.3410  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:33:16 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 1259  total_loss: 0.4035  loss_cls: 0.05001  loss_box_reg: 0.1758  loss_mask: 0.1623  loss_rpn_cls: 0.001908  loss_rpn_loc: 0.01024  time: 0.9710  data_time: 0.3214  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:33:36 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 1279  total_loss: 0.4215  loss_cls: 0.05153  loss_box_reg: 0.1779  loss_mask: 0.1456  loss_rpn_cls: 0.001244  loss_rpn_loc: 0.01041  time: 0.9714  data_time: 0.3272  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:33:55 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1299  total_loss: 0.3326  loss_cls: 0.03637  loss_box_reg: 0.156  loss_mask: 0.1235  loss_rpn_cls: 0.001378  loss_rpn_loc: 0.01231  time: 0.9711  data_time: 0.3028  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:34:15 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 1319  total_loss: 0.3694  loss_cls: 0.03737  loss_box_reg: 0.1685  loss_mask: 0.1241  loss_rpn_cls: 0.001657  loss_rpn_loc: 0.009481  time: 0.9716  data_time: 0.3308  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 16:34:35 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1339  total_loss: 0.3783  loss_cls: 0.04584  loss_box_reg: 0.165  loss_mask: 0.1626  loss_rpn_cls: 0.001824  loss_rpn_loc: 0.01645  time: 0.9719  data_time: 0.3256  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:34:55 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1359  total_loss: 0.4056  loss_cls: 0.03589  loss_box_reg: 0.1781  loss_mask: 0.1679  loss_rpn_cls: 0.001717  loss_rpn_loc: 0.0102  time: 0.9725  data_time: 0.3443  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:35:15 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1379  total_loss: 0.3537  loss_cls: 0.04311  loss_box_reg: 0.1526  loss_mask: 0.1288  loss_rpn_cls: 0.001242  loss_rpn_loc: 0.008977  time: 0.9727  data_time: 0.3291  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:35:35 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1399  total_loss: 0.3779  loss_cls: 0.04737  loss_box_reg: 0.1699  loss_mask: 0.1315  loss_rpn_cls: 0.00137  loss_rpn_loc: 0.01196  time: 0.9733  data_time: 0.3522  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:35:54 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.4122  loss_cls: 0.03471  loss_box_reg: 0.1809  loss_mask: 0.1498  loss_rpn_cls: 0.001347  loss_rpn_loc: 0.01179  time: 0.9731  data_time: 0.3292  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:36:14 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.3551  loss_cls: 0.04021  loss_box_reg: 0.1597  loss_mask: 0.1203  loss_rpn_cls: 0.001507  loss_rpn_loc: 0.01102  time: 0.9734  data_time: 0.3297  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:36:33 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.4  loss_cls: 0.04146  loss_box_reg: 0.177  loss_mask: 0.1575  loss_rpn_cls: 0.0013  loss_rpn_loc: 0.01379  time: 0.9728  data_time: 0.3006  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:36:53 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.3738  loss_cls: 0.05268  loss_box_reg: 0.1776  loss_mask: 0.1377  loss_rpn_cls: 0.001711  loss_rpn_loc: 0.009818  time: 0.9729  data_time: 0.3199  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:37:14 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.3976  loss_cls: 0.03444  loss_box_reg: 0.1762  loss_mask: 0.1488  loss_rpn_cls: 0.001796  loss_rpn_loc: 0.01391  time: 0.9733  data_time: 0.3447  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:37:14 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:17 (0.9733 s / it)\n",
      "\u001b[32m[03/04 16:37:14 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:20 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 16:37:15 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 16:37:15 d2.data.datasets.coco]: \u001b[0mLoaded 111 images in COCO format from /host/mic21-framework/server/uploads/makeup_artist_gt.json\n",
      "makeup_artist\n",
      "\u001b[32m[03/04 16:37:16 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 16:37:16 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 16:37:16 d2.data.datasets.coco]: \u001b[0mLoaded 111 images in COCO format from /host/mic21-framework/server/uploads/makeup_artist_gt.json\n",
      "\u001b[32m[03/04 16:37:16 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 111 images left.\n",
      "\u001b[32m[03/04 16:37:16 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n",
      "\u001b[36m|   category    | #instances   |   category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n",
      "|     woman     | 82           | makeup brush | 184          |  eyebrow   | 265          |\n",
      "|     face      | 178          |     eye      | 179          |    lip     | 288          |\n",
      "| makeup artist | 114          |              |              |            |              |\n",
      "|     total     | 1290         |              |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 16:37:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 16:37:16 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 16:37:16 d2.data.common]: \u001b[0mSerializing 111 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 16:37:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.72 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (28, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (28,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (7, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 16:37:16 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 16:37:34 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 19  total_loss: 2.945  loss_cls: 1.032  loss_box_reg: 0.7836  loss_mask: 0.6739  loss_rpn_cls: 0.1969  loss_rpn_loc: 0.3045  time: 0.8819  data_time: 0.2589  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:37:52 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 39  total_loss: 2.703  loss_cls: 0.8306  loss_box_reg: 0.87  loss_mask: 0.5945  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.3839  time: 0.8893  data_time: 0.2318  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:38:10 d2.utils.events]: \u001b[0m eta: 0:21:54  iter: 59  total_loss: 2.42  loss_cls: 0.7022  loss_box_reg: 0.8166  loss_mask: 0.5108  loss_rpn_cls: 0.08338  loss_rpn_loc: 0.3186  time: 0.8958  data_time: 0.2325  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:38:28 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 79  total_loss: 2.182  loss_cls: 0.5746  loss_box_reg: 0.8611  loss_mask: 0.4399  loss_rpn_cls: 0.06429  loss_rpn_loc: 0.2372  time: 0.8906  data_time: 0.2239  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:38:45 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 99  total_loss: 2.051  loss_cls: 0.4992  loss_box_reg: 0.8098  loss_mask: 0.4048  loss_rpn_cls: 0.0503  loss_rpn_loc: 0.2732  time: 0.8854  data_time: 0.2113  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:39:03 d2.utils.events]: \u001b[0m eta: 0:20:47  iter: 119  total_loss: 1.795  loss_cls: 0.436  loss_box_reg: 0.7717  loss_mask: 0.3872  loss_rpn_cls: 0.05379  loss_rpn_loc: 0.1874  time: 0.8837  data_time: 0.2412  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:39:20 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 139  total_loss: 1.719  loss_cls: 0.3497  loss_box_reg: 0.6855  loss_mask: 0.3731  loss_rpn_cls: 0.05224  loss_rpn_loc: 0.2939  time: 0.8835  data_time: 0.2231  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:39:38 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 159  total_loss: 1.64  loss_cls: 0.3335  loss_box_reg: 0.6804  loss_mask: 0.3439  loss_rpn_cls: 0.05082  loss_rpn_loc: 0.2498  time: 0.8824  data_time: 0.2077  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:39:56 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 179  total_loss: 1.665  loss_cls: 0.4032  loss_box_reg: 0.6133  loss_mask: 0.3549  loss_rpn_cls: 0.04629  loss_rpn_loc: 0.2395  time: 0.8856  data_time: 0.2499  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:40:14 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 199  total_loss: 1.713  loss_cls: 0.3721  loss_box_reg: 0.7337  loss_mask: 0.3434  loss_rpn_cls: 0.04143  loss_rpn_loc: 0.1989  time: 0.8851  data_time: 0.2072  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:40:32 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 219  total_loss: 1.668  loss_cls: 0.3427  loss_box_reg: 0.6347  loss_mask: 0.3407  loss_rpn_cls: 0.04574  loss_rpn_loc: 0.2734  time: 0.8857  data_time: 0.2281  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:40:49 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 239  total_loss: 1.63  loss_cls: 0.3481  loss_box_reg: 0.6004  loss_mask: 0.3503  loss_rpn_cls: 0.04276  loss_rpn_loc: 0.2065  time: 0.8846  data_time: 0.2411  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:41:06 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 259  total_loss: 1.586  loss_cls: 0.3556  loss_box_reg: 0.5906  loss_mask: 0.3065  loss_rpn_cls: 0.04052  loss_rpn_loc: 0.2304  time: 0.8811  data_time: 0.2250  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:41:23 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 279  total_loss: 1.483  loss_cls: 0.3181  loss_box_reg: 0.5377  loss_mask: 0.3227  loss_rpn_cls: 0.03253  loss_rpn_loc: 0.2473  time: 0.8798  data_time: 0.2212  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:41:41 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 299  total_loss: 1.526  loss_cls: 0.3354  loss_box_reg: 0.5276  loss_mask: 0.3092  loss_rpn_cls: 0.04287  loss_rpn_loc: 0.2257  time: 0.8795  data_time: 0.2196  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:41:59 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 319  total_loss: 1.499  loss_cls: 0.3223  loss_box_reg: 0.5696  loss_mask: 0.3042  loss_rpn_cls: 0.03092  loss_rpn_loc: 0.2008  time: 0.8817  data_time: 0.2378  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:42:16 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 339  total_loss: 1.44  loss_cls: 0.3044  loss_box_reg: 0.5894  loss_mask: 0.3257  loss_rpn_cls: 0.03051  loss_rpn_loc: 0.1798  time: 0.8808  data_time: 0.2316  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:42:35 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 359  total_loss: 1.419  loss_cls: 0.3276  loss_box_reg: 0.5704  loss_mask: 0.2899  loss_rpn_cls: 0.0302  loss_rpn_loc: 0.214  time: 0.8827  data_time: 0.2452  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:42:53 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 379  total_loss: 1.444  loss_cls: 0.31  loss_box_reg: 0.5599  loss_mask: 0.2988  loss_rpn_cls: 0.02997  loss_rpn_loc: 0.2041  time: 0.8839  data_time: 0.2384  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:43:10 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 399  total_loss: 1.426  loss_cls: 0.2898  loss_box_reg: 0.5635  loss_mask: 0.3049  loss_rpn_cls: 0.02623  loss_rpn_loc: 0.1816  time: 0.8840  data_time: 0.2256  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:43:29 d2.utils.events]: \u001b[0m eta: 0:16:04  iter: 419  total_loss: 1.338  loss_cls: 0.2712  loss_box_reg: 0.5079  loss_mask: 0.3067  loss_rpn_cls: 0.03511  loss_rpn_loc: 0.2357  time: 0.8861  data_time: 0.2626  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:43:47 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 439  total_loss: 1.376  loss_cls: 0.2914  loss_box_reg: 0.5175  loss_mask: 0.2982  loss_rpn_cls: 0.02752  loss_rpn_loc: 0.1923  time: 0.8874  data_time: 0.2515  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:44:05 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 459  total_loss: 1.389  loss_cls: 0.2789  loss_box_reg: 0.5434  loss_mask: 0.2987  loss_rpn_cls: 0.02913  loss_rpn_loc: 0.2216  time: 0.8875  data_time: 0.2561  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:44:23 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 479  total_loss: 1.354  loss_cls: 0.2808  loss_box_reg: 0.5576  loss_mask: 0.2716  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.189  time: 0.8877  data_time: 0.2582  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:44:41 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 499  total_loss: 1.308  loss_cls: 0.2848  loss_box_reg: 0.5257  loss_mask: 0.3012  loss_rpn_cls: 0.02426  loss_rpn_loc: 0.1872  time: 0.8877  data_time: 0.2232  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:44:59 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 519  total_loss: 1.254  loss_cls: 0.2504  loss_box_reg: 0.5495  loss_mask: 0.2866  loss_rpn_cls: 0.02731  loss_rpn_loc: 0.1735  time: 0.8897  data_time: 0.2824  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:45:17 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 539  total_loss: 1.315  loss_cls: 0.2806  loss_box_reg: 0.4973  loss_mask: 0.2938  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.1632  time: 0.8899  data_time: 0.2480  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:45:35 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 559  total_loss: 1.219  loss_cls: 0.2795  loss_box_reg: 0.4769  loss_mask: 0.2778  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.1549  time: 0.8887  data_time: 0.2242  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:45:52 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 579  total_loss: 1.267  loss_cls: 0.2789  loss_box_reg: 0.4949  loss_mask: 0.2855  loss_rpn_cls: 0.02317  loss_rpn_loc: 0.1863  time: 0.8890  data_time: 0.2411  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:46:10 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 599  total_loss: 1.307  loss_cls: 0.2826  loss_box_reg: 0.5582  loss_mask: 0.2827  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.1514  time: 0.8879  data_time: 0.2503  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:46:28 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 619  total_loss: 1.219  loss_cls: 0.2653  loss_box_reg: 0.5011  loss_mask: 0.2328  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.1636  time: 0.8894  data_time: 0.2791  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:46:46 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 639  total_loss: 1.217  loss_cls: 0.2615  loss_box_reg: 0.4677  loss_mask: 0.2801  loss_rpn_cls: 0.0211  loss_rpn_loc: 0.1815  time: 0.8890  data_time: 0.2335  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:47:04 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 659  total_loss: 1.254  loss_cls: 0.2776  loss_box_reg: 0.5113  loss_mask: 0.2806  loss_rpn_cls: 0.02138  loss_rpn_loc: 0.221  time: 0.8902  data_time: 0.2580  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 16:47:22 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 679  total_loss: 1.267  loss_cls: 0.2697  loss_box_reg: 0.4653  loss_mask: 0.2704  loss_rpn_cls: 0.02157  loss_rpn_loc: 0.16  time: 0.8901  data_time: 0.2374  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:47:41 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 699  total_loss: 1.166  loss_cls: 0.2552  loss_box_reg: 0.465  loss_mask: 0.2602  loss_rpn_cls: 0.02126  loss_rpn_loc: 0.1739  time: 0.8909  data_time: 0.2561  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:47:59 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 719  total_loss: 1.221  loss_cls: 0.2554  loss_box_reg: 0.482  loss_mask: 0.2556  loss_rpn_cls: 0.02208  loss_rpn_loc: 0.1787  time: 0.8921  data_time: 0.2624  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:48:17 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 739  total_loss: 1.211  loss_cls: 0.2616  loss_box_reg: 0.5137  loss_mask: 0.2405  loss_rpn_cls: 0.02462  loss_rpn_loc: 0.2064  time: 0.8921  data_time: 0.2341  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:48:35 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 759  total_loss: 1.135  loss_cls: 0.2262  loss_box_reg: 0.4952  loss_mask: 0.2644  loss_rpn_cls: 0.01756  loss_rpn_loc: 0.187  time: 0.8918  data_time: 0.2440  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:48:53 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 779  total_loss: 1.168  loss_cls: 0.2359  loss_box_reg: 0.4833  loss_mask: 0.2534  loss_rpn_cls: 0.02042  loss_rpn_loc: 0.1488  time: 0.8921  data_time: 0.2562  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:49:10 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 799  total_loss: 1.171  loss_cls: 0.2328  loss_box_reg: 0.4349  loss_mask: 0.2525  loss_rpn_cls: 0.02188  loss_rpn_loc: 0.1692  time: 0.8917  data_time: 0.2440  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:49:29 d2.utils.events]: \u001b[0m eta: 0:10:08  iter: 819  total_loss: 1.104  loss_cls: 0.2013  loss_box_reg: 0.408  loss_mask: 0.2547  loss_rpn_cls: 0.01989  loss_rpn_loc: 0.1509  time: 0.8921  data_time: 0.2612  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:49:47 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 839  total_loss: 1.197  loss_cls: 0.2545  loss_box_reg: 0.503  loss_mask: 0.2686  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.157  time: 0.8931  data_time: 0.2734  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:50:05 d2.utils.events]: \u001b[0m eta: 0:09:32  iter: 859  total_loss: 1.221  loss_cls: 0.2386  loss_box_reg: 0.462  loss_mask: 0.2744  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.1457  time: 0.8924  data_time: 0.2247  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:50:23 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 879  total_loss: 1.103  loss_cls: 0.2136  loss_box_reg: 0.4681  loss_mask: 0.2394  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.1393  time: 0.8933  data_time: 0.2781  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:50:41 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 899  total_loss: 1.244  loss_cls: 0.2916  loss_box_reg: 0.4728  loss_mask: 0.2666  loss_rpn_cls: 0.01717  loss_rpn_loc: 0.166  time: 0.8932  data_time: 0.2575  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:50:59 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 919  total_loss: 1.2  loss_cls: 0.2508  loss_box_reg: 0.455  loss_mask: 0.2598  loss_rpn_cls: 0.01864  loss_rpn_loc: 0.1547  time: 0.8930  data_time: 0.2235  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:51:17 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 939  total_loss: 1.132  loss_cls: 0.2148  loss_box_reg: 0.4455  loss_mask: 0.2344  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.1538  time: 0.8933  data_time: 0.2663  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:51:35 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 959  total_loss: 1.131  loss_cls: 0.2217  loss_box_reg: 0.4537  loss_mask: 0.2633  loss_rpn_cls: 0.01569  loss_rpn_loc: 0.1334  time: 0.8937  data_time: 0.2618  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:51:53 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 979  total_loss: 1.091  loss_cls: 0.2358  loss_box_reg: 0.4397  loss_mask: 0.2743  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.16  time: 0.8938  data_time: 0.2644  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:52:11 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 999  total_loss: 1.168  loss_cls: 0.2724  loss_box_reg: 0.4544  loss_mask: 0.2335  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.1566  time: 0.8941  data_time: 0.2382  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 16:52:29 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 1019  total_loss: 1.08  loss_cls: 0.205  loss_box_reg: 0.4216  loss_mask: 0.2208  loss_rpn_cls: 0.01527  loss_rpn_loc: 0.1888  time: 0.8941  data_time: 0.2600  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:52:48 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 1039  total_loss: 1.099  loss_cls: 0.2189  loss_box_reg: 0.4412  loss_mask: 0.2468  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.1645  time: 0.8946  data_time: 0.2773  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:53:06 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 1059  total_loss: 1.003  loss_cls: 0.2216  loss_box_reg: 0.4185  loss_mask: 0.2208  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.1198  time: 0.8952  data_time: 0.2780  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:53:24 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 1079  total_loss: 1.026  loss_cls: 0.2336  loss_box_reg: 0.3942  loss_mask: 0.245  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.1471  time: 0.8954  data_time: 0.2450  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:53:43 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 1099  total_loss: 1.008  loss_cls: 0.2065  loss_box_reg: 0.399  loss_mask: 0.2411  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.1792  time: 0.8962  data_time: 0.2805  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:54:01 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 1119  total_loss: 1.034  loss_cls: 0.2064  loss_box_reg: 0.4071  loss_mask: 0.2361  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.1392  time: 0.8959  data_time: 0.2452  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:54:18 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 1139  total_loss: 1.002  loss_cls: 0.199  loss_box_reg: 0.3573  loss_mask: 0.2372  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.1469  time: 0.8956  data_time: 0.2168  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:54:36 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 1159  total_loss: 0.9874  loss_cls: 0.1936  loss_box_reg: 0.3867  loss_mask: 0.2553  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.1404  time: 0.8951  data_time: 0.2324  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:54:53 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 1179  total_loss: 1.023  loss_cls: 0.1761  loss_box_reg: 0.3812  loss_mask: 0.2477  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.1332  time: 0.8947  data_time: 0.2350  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:55:11 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 1199  total_loss: 0.973  loss_cls: 0.156  loss_box_reg: 0.3862  loss_mask: 0.2186  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.1665  time: 0.8948  data_time: 0.2590  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:55:30 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 1219  total_loss: 1.004  loss_cls: 0.2046  loss_box_reg: 0.3779  loss_mask: 0.2359  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.1396  time: 0.8954  data_time: 0.2683  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:55:48 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 1239  total_loss: 0.9912  loss_cls: 0.2005  loss_box_reg: 0.3878  loss_mask: 0.262  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.1408  time: 0.8957  data_time: 0.2556  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:56:06 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 1259  total_loss: 1.018  loss_cls: 0.1891  loss_box_reg: 0.3974  loss_mask: 0.2438  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.1538  time: 0.8954  data_time: 0.2328  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:56:23 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 1279  total_loss: 0.9932  loss_cls: 0.1821  loss_box_reg: 0.3861  loss_mask: 0.2288  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.1511  time: 0.8947  data_time: 0.2168  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:56:40 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 1299  total_loss: 0.9739  loss_cls: 0.2017  loss_box_reg: 0.382  loss_mask: 0.2423  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.1316  time: 0.8946  data_time: 0.2309  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:56:58 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 1319  total_loss: 1.048  loss_cls: 0.2384  loss_box_reg: 0.3799  loss_mask: 0.2306  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.1442  time: 0.8947  data_time: 0.2459  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:57:17 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 1339  total_loss: 1.057  loss_cls: 0.184  loss_box_reg: 0.3753  loss_mask: 0.2307  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.1839  time: 0.8956  data_time: 0.3037  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 16:57:36 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 1359  total_loss: 1.006  loss_cls: 0.2012  loss_box_reg: 0.3945  loss_mask: 0.2519  loss_rpn_cls: 0.01669  loss_rpn_loc: 0.1571  time: 0.8958  data_time: 0.2686  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:57:54 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 1379  total_loss: 0.9866  loss_cls: 0.2028  loss_box_reg: 0.389  loss_mask: 0.2357  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.1575  time: 0.8960  data_time: 0.2647  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:58:11 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 1399  total_loss: 0.9816  loss_cls: 0.1941  loss_box_reg: 0.3884  loss_mask: 0.2389  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.1611  time: 0.8957  data_time: 0.2256  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 16:58:29 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 1419  total_loss: 0.9694  loss_cls: 0.2106  loss_box_reg: 0.3755  loss_mask: 0.2484  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.1073  time: 0.8955  data_time: 0.2435  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:58:47 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 1439  total_loss: 0.9731  loss_cls: 0.1743  loss_box_reg: 0.3602  loss_mask: 0.238  loss_rpn_cls: 0.01744  loss_rpn_loc: 0.1824  time: 0.8958  data_time: 0.2493  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:59:06 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 1459  total_loss: 1.02  loss_cls: 0.1795  loss_box_reg: 0.3875  loss_mask: 0.2535  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.1227  time: 0.8960  data_time: 0.2825  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:59:24 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1479  total_loss: 1.053  loss_cls: 0.2173  loss_box_reg: 0.4016  loss_mask: 0.2456  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.1205  time: 0.8961  data_time: 0.2430  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:59:43 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.9353  loss_cls: 0.2226  loss_box_reg: 0.3769  loss_mask: 0.2373  loss_rpn_cls: 0.01367  loss_rpn_loc: 0.14  time: 0.8963  data_time: 0.2581  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 16:59:44 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:22:22 (0.8963 s / it)\n",
      "\u001b[32m[03/04 16:59:44 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:25 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 16:59:44 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 16:59:44 d2.data.datasets.coco]: \u001b[0mLoaded 160 images in COCO format from /host/mic21-framework/server/uploads/photographer_gt.json\n",
      "photographer\n",
      "\u001b[32m[03/04 16:59:45 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 16:59:45 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 16:59:45 d2.data.datasets.coco]: \u001b[0mLoaded 160 images in COCO format from /host/mic21-framework/server/uploads/photographer_gt.json\n",
      "\u001b[32m[03/04 16:59:45 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 160 images left.\n",
      "\u001b[32m[03/04 16:59:45 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |   category   | #instances   |\n",
      "|:----------:|:-------------|:------------:|:-------------|\n",
      "|   camera   | 162          | photographer | 157          |\n",
      "|            |              |              |              |\n",
      "|   total    | 319          |              |              |\u001b[0m\n",
      "\u001b[32m[03/04 16:59:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 16:59:45 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 16:59:45 d2.data.common]: \u001b[0mSerializing 160 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 16:59:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.59 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 16:59:45 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 17:00:06 d2.utils.events]: \u001b[0m eta: 0:24:39  iter: 19  total_loss: 2.007  loss_cls: 0.5187  loss_box_reg: 0.8837  loss_mask: 0.5447  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.01199  time: 1.0079  data_time: 0.3882  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:00:26 d2.utils.events]: \u001b[0m eta: 0:24:14  iter: 39  total_loss: 1.196  loss_cls: 0.2094  loss_box_reg: 0.6686  loss_mask: 0.2414  loss_rpn_cls: 0.005899  loss_rpn_loc: 0.01388  time: 0.9923  data_time: 0.3289  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:00:45 d2.utils.events]: \u001b[0m eta: 0:24:04  iter: 59  total_loss: 0.8646  loss_cls: 0.1609  loss_box_reg: 0.4976  loss_mask: 0.1948  loss_rpn_cls: 0.003812  loss_rpn_loc: 0.01526  time: 0.9876  data_time: 0.3114  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:01:06 d2.utils.events]: \u001b[0m eta: 0:24:06  iter: 79  total_loss: 0.7147  loss_cls: 0.1123  loss_box_reg: 0.3974  loss_mask: 0.171  loss_rpn_cls: 0.003264  loss_rpn_loc: 0.01387  time: 1.0062  data_time: 0.4244  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:01:26 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 99  total_loss: 0.6766  loss_cls: 0.09703  loss_box_reg: 0.3624  loss_mask: 0.17  loss_rpn_cls: 0.002339  loss_rpn_loc: 0.01214  time: 1.0020  data_time: 0.3300  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:01:47 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 119  total_loss: 0.6556  loss_cls: 0.09777  loss_box_reg: 0.38  loss_mask: 0.1557  loss_rpn_cls: 0.002039  loss_rpn_loc: 0.009257  time: 1.0121  data_time: 0.3996  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:02:08 d2.utils.events]: \u001b[0m eta: 0:22:21  iter: 139  total_loss: 0.6377  loss_cls: 0.1064  loss_box_reg: 0.3649  loss_mask: 0.1553  loss_rpn_cls: 0.001374  loss_rpn_loc: 0.01626  time: 1.0125  data_time: 0.3982  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:02:28 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 159  total_loss: 0.57  loss_cls: 0.0933  loss_box_reg: 0.3152  loss_mask: 0.1406  loss_rpn_cls: 0.00277  loss_rpn_loc: 0.0109  time: 1.0116  data_time: 0.3273  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:02:48 d2.utils.events]: \u001b[0m eta: 0:21:43  iter: 179  total_loss: 0.5836  loss_cls: 0.1007  loss_box_reg: 0.3229  loss_mask: 0.1461  loss_rpn_cls: 0.00238  loss_rpn_loc: 0.01295  time: 1.0087  data_time: 0.3188  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:03:08 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 199  total_loss: 0.542  loss_cls: 0.09193  loss_box_reg: 0.29  loss_mask: 0.138  loss_rpn_cls: 0.001656  loss_rpn_loc: 0.009164  time: 1.0102  data_time: 0.3780  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:03:29 d2.utils.events]: \u001b[0m eta: 0:21:10  iter: 219  total_loss: 0.5013  loss_cls: 0.07651  loss_box_reg: 0.2627  loss_mask: 0.1253  loss_rpn_cls: 0.001906  loss_rpn_loc: 0.01036  time: 1.0115  data_time: 0.3687  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:03:48 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 239  total_loss: 0.5105  loss_cls: 0.06272  loss_box_reg: 0.2809  loss_mask: 0.1145  loss_rpn_cls: 0.001965  loss_rpn_loc: 0.009499  time: 1.0097  data_time: 0.3374  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:04:08 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 259  total_loss: 0.5014  loss_cls: 0.07966  loss_box_reg: 0.2806  loss_mask: 0.1147  loss_rpn_cls: 0.001261  loss_rpn_loc: 0.01034  time: 1.0060  data_time: 0.2999  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:04:29 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 279  total_loss: 0.4421  loss_cls: 0.06097  loss_box_reg: 0.2484  loss_mask: 0.114  loss_rpn_cls: 0.002393  loss_rpn_loc: 0.01294  time: 1.0106  data_time: 0.4246  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:04:50 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 299  total_loss: 0.4834  loss_cls: 0.07636  loss_box_reg: 0.2509  loss_mask: 0.1219  loss_rpn_cls: 0.001231  loss_rpn_loc: 0.008297  time: 1.0131  data_time: 0.3817  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:05:10 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 319  total_loss: 0.4684  loss_cls: 0.06197  loss_box_reg: 0.2676  loss_mask: 0.1213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009738  time: 1.0112  data_time: 0.3268  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:05:29 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 339  total_loss: 0.47  loss_cls: 0.06041  loss_box_reg: 0.2345  loss_mask: 0.1214  loss_rpn_cls: 0.001262  loss_rpn_loc: 0.009919  time: 1.0083  data_time: 0.3031  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:05:49 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 359  total_loss: 0.4472  loss_cls: 0.06883  loss_box_reg: 0.2425  loss_mask: 0.1219  loss_rpn_cls: 0.0009841  loss_rpn_loc: 0.00871  time: 1.0080  data_time: 0.3660  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:06:09 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 379  total_loss: 0.4005  loss_cls: 0.04831  loss_box_reg: 0.2214  loss_mask: 0.1106  loss_rpn_cls: 0.002334  loss_rpn_loc: 0.009242  time: 1.0078  data_time: 0.3365  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:06:30 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 399  total_loss: 0.4387  loss_cls: 0.06296  loss_box_reg: 0.218  loss_mask: 0.1246  loss_rpn_cls: 0.001165  loss_rpn_loc: 0.01084  time: 1.0091  data_time: 0.3878  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:06:49 d2.utils.events]: \u001b[0m eta: 0:17:44  iter: 419  total_loss: 0.4255  loss_cls: 0.073  loss_box_reg: 0.2362  loss_mask: 0.1056  loss_rpn_cls: 0.00101  loss_rpn_loc: 0.008901  time: 1.0077  data_time: 0.3428  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:07:10 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 439  total_loss: 0.411  loss_cls: 0.05571  loss_box_reg: 0.2209  loss_mask: 0.1175  loss_rpn_cls: 0.001153  loss_rpn_loc: 0.007745  time: 1.0088  data_time: 0.3726  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:07:30 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 459  total_loss: 0.404  loss_cls: 0.05139  loss_box_reg: 0.2204  loss_mask: 0.1105  loss_rpn_cls: 0.001599  loss_rpn_loc: 0.01099  time: 1.0092  data_time: 0.3495  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:07:50 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 479  total_loss: 0.4322  loss_cls: 0.07662  loss_box_reg: 0.2395  loss_mask: 0.1131  loss_rpn_cls: 0.001477  loss_rpn_loc: 0.009912  time: 1.0089  data_time: 0.3546  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:08:10 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 499  total_loss: 0.4136  loss_cls: 0.05371  loss_box_reg: 0.2142  loss_mask: 0.1121  loss_rpn_cls: 0.001545  loss_rpn_loc: 0.009516  time: 1.0077  data_time: 0.3215  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:08:30 d2.utils.events]: \u001b[0m eta: 0:16:06  iter: 519  total_loss: 0.4295  loss_cls: 0.05915  loss_box_reg: 0.2447  loss_mask: 0.1028  loss_rpn_cls: 0.001519  loss_rpn_loc: 0.01139  time: 1.0081  data_time: 0.3771  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:08:51 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 539  total_loss: 0.3936  loss_cls: 0.05003  loss_box_reg: 0.2269  loss_mask: 0.1092  loss_rpn_cls: 0.000855  loss_rpn_loc: 0.01063  time: 1.0097  data_time: 0.3895  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:09:12 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 559  total_loss: 0.4079  loss_cls: 0.04902  loss_box_reg: 0.2124  loss_mask: 0.1101  loss_rpn_cls: 0.001956  loss_rpn_loc: 0.01008  time: 1.0096  data_time: 0.3304  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:09:31 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 579  total_loss: 0.3818  loss_cls: 0.052  loss_box_reg: 0.2009  loss_mask: 0.1012  loss_rpn_cls: 0.00143  loss_rpn_loc: 0.009868  time: 1.0089  data_time: 0.3244  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:09:53 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 599  total_loss: 0.3622  loss_cls: 0.05972  loss_box_reg: 0.1886  loss_mask: 0.1028  loss_rpn_cls: 0.001888  loss_rpn_loc: 0.008041  time: 1.0105  data_time: 0.4160  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:10:13 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 619  total_loss: 0.3621  loss_cls: 0.04363  loss_box_reg: 0.1921  loss_mask: 0.1049  loss_rpn_cls: 0.001233  loss_rpn_loc: 0.008339  time: 1.0110  data_time: 0.3658  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:10:33 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 639  total_loss: 0.3612  loss_cls: 0.04804  loss_box_reg: 0.1845  loss_mask: 0.09984  loss_rpn_cls: 0.001425  loss_rpn_loc: 0.008942  time: 1.0111  data_time: 0.3831  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:10:54 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 659  total_loss: 0.3646  loss_cls: 0.03666  loss_box_reg: 0.2032  loss_mask: 0.09839  loss_rpn_cls: 0.001407  loss_rpn_loc: 0.007872  time: 1.0112  data_time: 0.3790  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:11:14 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 679  total_loss: 0.3564  loss_cls: 0.04715  loss_box_reg: 0.1795  loss_mask: 0.1037  loss_rpn_cls: 0.0008332  loss_rpn_loc: 0.006689  time: 1.0118  data_time: 0.3769  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:11:35 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 699  total_loss: 0.3704  loss_cls: 0.05886  loss_box_reg: 0.1974  loss_mask: 0.1009  loss_rpn_cls: 0.001013  loss_rpn_loc: 0.01511  time: 1.0118  data_time: 0.3500  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:11:56 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 719  total_loss: 0.3593  loss_cls: 0.03466  loss_box_reg: 0.2128  loss_mask: 0.1011  loss_rpn_cls: 0.00115  loss_rpn_loc: 0.008654  time: 1.0132  data_time: 0.4156  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:12:15 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 739  total_loss: 0.3327  loss_cls: 0.04291  loss_box_reg: 0.1842  loss_mask: 0.08914  loss_rpn_cls: 0.001153  loss_rpn_loc: 0.01076  time: 1.0122  data_time: 0.3070  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:12:37 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 759  total_loss: 0.3919  loss_cls: 0.05782  loss_box_reg: 0.2239  loss_mask: 0.09567  loss_rpn_cls: 0.001166  loss_rpn_loc: 0.007836  time: 1.0134  data_time: 0.3965  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:12:57 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 779  total_loss: 0.3426  loss_cls: 0.04987  loss_box_reg: 0.1814  loss_mask: 0.09716  loss_rpn_cls: 0.001984  loss_rpn_loc: 0.009085  time: 1.0141  data_time: 0.4044  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:13:18 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 799  total_loss: 0.3411  loss_cls: 0.04106  loss_box_reg: 0.1805  loss_mask: 0.09437  loss_rpn_cls: 0.001733  loss_rpn_loc: 0.009622  time: 1.0146  data_time: 0.3770  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:13:39 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 819  total_loss: 0.3413  loss_cls: 0.04109  loss_box_reg: 0.1837  loss_mask: 0.09191  loss_rpn_cls: 0.0007949  loss_rpn_loc: 0.009356  time: 1.0154  data_time: 0.3772  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:14:00 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 839  total_loss: 0.3444  loss_cls: 0.04121  loss_box_reg: 0.1919  loss_mask: 0.09878  loss_rpn_cls: 0.001151  loss_rpn_loc: 0.009785  time: 1.0158  data_time: 0.3696  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:14:21 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 859  total_loss: 0.3242  loss_cls: 0.04146  loss_box_reg: 0.1774  loss_mask: 0.09321  loss_rpn_cls: 0.0007158  loss_rpn_loc: 0.01072  time: 1.0168  data_time: 0.3947  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:14:41 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 879  total_loss: 0.3463  loss_cls: 0.04011  loss_box_reg: 0.1914  loss_mask: 0.09607  loss_rpn_cls: 0.001031  loss_rpn_loc: 0.009015  time: 1.0164  data_time: 0.3514  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:15:01 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 899  total_loss: 0.3231  loss_cls: 0.03459  loss_box_reg: 0.1723  loss_mask: 0.09716  loss_rpn_cls: 0.001479  loss_rpn_loc: 0.008396  time: 1.0157  data_time: 0.3249  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:15:22 d2.utils.events]: \u001b[0m eta: 0:09:32  iter: 919  total_loss: 0.3378  loss_cls: 0.04223  loss_box_reg: 0.1876  loss_mask: 0.09736  loss_rpn_cls: 0.001347  loss_rpn_loc: 0.01107  time: 1.0168  data_time: 0.4258  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:15:43 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 939  total_loss: 0.3682  loss_cls: 0.04197  loss_box_reg: 0.1843  loss_mask: 0.09889  loss_rpn_cls: 0.001272  loss_rpn_loc: 0.00915  time: 1.0175  data_time: 0.4164  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:16:03 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 959  total_loss: 0.3254  loss_cls: 0.02854  loss_box_reg: 0.1855  loss_mask: 0.08752  loss_rpn_cls: 0.0009255  loss_rpn_loc: 0.007296  time: 1.0176  data_time: 0.3641  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:16:24 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 979  total_loss: 0.3362  loss_cls: 0.05399  loss_box_reg: 0.1757  loss_mask: 0.096  loss_rpn_cls: 0.001093  loss_rpn_loc: 0.0077  time: 1.0180  data_time: 0.3597  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:16:46 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 999  total_loss: 0.3402  loss_cls: 0.04227  loss_box_reg: 0.1905  loss_mask: 0.09038  loss_rpn_cls: 0.0008619  loss_rpn_loc: 0.008054  time: 1.0192  data_time: 0.4126  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:17:07 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 1019  total_loss: 0.3138  loss_cls: 0.03424  loss_box_reg: 0.1758  loss_mask: 0.08631  loss_rpn_cls: 0.001176  loss_rpn_loc: 0.01057  time: 1.0196  data_time: 0.4094  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:17:26 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 1039  total_loss: 0.3024  loss_cls: 0.02805  loss_box_reg: 0.1567  loss_mask: 0.09171  loss_rpn_cls: 0.001334  loss_rpn_loc: 0.006851  time: 1.0188  data_time: 0.3535  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:17:46 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 1059  total_loss: 0.3032  loss_cls: 0.04276  loss_box_reg: 0.1556  loss_mask: 0.08479  loss_rpn_cls: 0.001589  loss_rpn_loc: 0.008381  time: 1.0182  data_time: 0.3455  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:18:07 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 1079  total_loss: 0.2839  loss_cls: 0.04289  loss_box_reg: 0.148  loss_mask: 0.09023  loss_rpn_cls: 0.001208  loss_rpn_loc: 0.006922  time: 1.0187  data_time: 0.3970  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:18:28 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 1099  total_loss: 0.295  loss_cls: 0.04273  loss_box_reg: 0.1443  loss_mask: 0.09112  loss_rpn_cls: 0.001185  loss_rpn_loc: 0.007255  time: 1.0191  data_time: 0.4033  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:18:48 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1119  total_loss: 0.2929  loss_cls: 0.03591  loss_box_reg: 0.1499  loss_mask: 0.08952  loss_rpn_cls: 0.001497  loss_rpn_loc: 0.008354  time: 1.0193  data_time: 0.3797  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:19:09 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 1139  total_loss: 0.2632  loss_cls: 0.03552  loss_box_reg: 0.1306  loss_mask: 0.0834  loss_rpn_cls: 0.0009288  loss_rpn_loc: 0.007061  time: 1.0192  data_time: 0.3849  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:19:29 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 1159  total_loss: 0.282  loss_cls: 0.03102  loss_box_reg: 0.1368  loss_mask: 0.09008  loss_rpn_cls: 0.002475  loss_rpn_loc: 0.008299  time: 1.0192  data_time: 0.3502  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:19:50 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 1179  total_loss: 0.2899  loss_cls: 0.03586  loss_box_reg: 0.1412  loss_mask: 0.08414  loss_rpn_cls: 0.001252  loss_rpn_loc: 0.006721  time: 1.0197  data_time: 0.4226  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:20:09 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 1199  total_loss: 0.2731  loss_cls: 0.03078  loss_box_reg: 0.14  loss_mask: 0.09179  loss_rpn_cls: 0.001115  loss_rpn_loc: 0.006865  time: 1.0184  data_time: 0.3001  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:20:29 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 1219  total_loss: 0.287  loss_cls: 0.03265  loss_box_reg: 0.132  loss_mask: 0.08686  loss_rpn_cls: 0.0008637  loss_rpn_loc: 0.008178  time: 1.0183  data_time: 0.3506  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:20:50 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 1239  total_loss: 0.2896  loss_cls: 0.04346  loss_box_reg: 0.1433  loss_mask: 0.0905  loss_rpn_cls: 0.0007548  loss_rpn_loc: 0.005864  time: 1.0189  data_time: 0.4001  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:21:10 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 1259  total_loss: 0.2761  loss_cls: 0.04094  loss_box_reg: 0.1357  loss_mask: 0.0889  loss_rpn_cls: 0.0008786  loss_rpn_loc: 0.007969  time: 1.0182  data_time: 0.3165  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:21:30 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 1279  total_loss: 0.2608  loss_cls: 0.03403  loss_box_reg: 0.1335  loss_mask: 0.08396  loss_rpn_cls: 0.001109  loss_rpn_loc: 0.008807  time: 1.0185  data_time: 0.3950  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:21:51 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 1299  total_loss: 0.2814  loss_cls: 0.04835  loss_box_reg: 0.129  loss_mask: 0.08909  loss_rpn_cls: 0.0008321  loss_rpn_loc: 0.007074  time: 1.0187  data_time: 0.3890  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:22:11 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 1319  total_loss: 0.2836  loss_cls: 0.03495  loss_box_reg: 0.1321  loss_mask: 0.08606  loss_rpn_cls: 0.0009869  loss_rpn_loc: 0.007314  time: 1.0183  data_time: 0.3478  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:22:33 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 1339  total_loss: 0.2679  loss_cls: 0.03561  loss_box_reg: 0.1301  loss_mask: 0.08722  loss_rpn_cls: 0.0006989  loss_rpn_loc: 0.008429  time: 1.0197  data_time: 0.4904  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:22:52 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 1359  total_loss: 0.2788  loss_cls: 0.04271  loss_box_reg: 0.1347  loss_mask: 0.09094  loss_rpn_cls: 0.0008898  loss_rpn_loc: 0.00684  time: 1.0189  data_time: 0.3147  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:23:12 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 1379  total_loss: 0.2631  loss_cls: 0.0355  loss_box_reg: 0.1307  loss_mask: 0.08236  loss_rpn_cls: 0.0004937  loss_rpn_loc: 0.005956  time: 1.0185  data_time: 0.3525  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:23:34 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 1399  total_loss: 0.2674  loss_cls: 0.03347  loss_box_reg: 0.1323  loss_mask: 0.0804  loss_rpn_cls: 0.0007696  loss_rpn_loc: 0.009033  time: 1.0193  data_time: 0.4153  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:23:56 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 1419  total_loss: 0.2892  loss_cls: 0.02917  loss_box_reg: 0.1328  loss_mask: 0.08792  loss_rpn_cls: 0.001651  loss_rpn_loc: 0.007178  time: 1.0207  data_time: 0.4609  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:24:15 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 1439  total_loss: 0.2879  loss_cls: 0.04379  loss_box_reg: 0.142  loss_mask: 0.09184  loss_rpn_cls: 0.0009973  loss_rpn_loc: 0.008938  time: 1.0199  data_time: 0.3089  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:24:36 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.2601  loss_cls: 0.02476  loss_box_reg: 0.1267  loss_mask: 0.08256  loss_rpn_cls: 0.000893  loss_rpn_loc: 0.007495  time: 1.0199  data_time: 0.3798  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:24:57 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.2747  loss_cls: 0.0331  loss_box_reg: 0.1384  loss_mask: 0.09  loss_rpn_cls: 0.001026  loss_rpn_loc: 0.007466  time: 1.0204  data_time: 0.3873  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:25:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.2839  loss_cls: 0.03168  loss_box_reg: 0.1353  loss_mask: 0.086  loss_rpn_cls: 0.001005  loss_rpn_loc: 0.008571  time: 1.0200  data_time: 0.3244  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:25:18 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:25:27 (1.0200 s / it)\n",
      "\u001b[32m[03/04 17:25:18 d2.engine.hooks]: \u001b[0mTotal training time: 0:25:30 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:25:19 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 17:25:19 d2.data.datasets.coco]: \u001b[0mLoaded 145 images in COCO format from /host/mic21-framework/server/uploads/writer_gt.json\n",
      "writer\n",
      "\u001b[32m[03/04 17:25:20 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=8, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=28, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:25:20 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 17:25:20 d2.data.datasets.coco]: \u001b[0mLoaded 145 images in COCO format from /host/mic21-framework/server/uploads/writer_gt.json\n",
      "\u001b[32m[03/04 17:25:20 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 145 images left.\n",
      "\u001b[32m[03/04 17:25:20 d2.data.build]: \u001b[0mDistribution of instances among all 7 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    man     | 98           |   woman    | 109          |   chair    | 94           |\n",
      "|    book    | 1342         |  ballpen   | 167          |   writer   | 150          |\n",
      "|   table    | 131          |            |              |            |              |\n",
      "|   total    | 2091         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 17:25:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 17:25:20 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 17:25:20 d2.data.common]: \u001b[0mSerializing 145 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 17:25:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.04 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (28, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (28,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (7, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:25:20 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 17:25:38 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 19  total_loss: 2.736  loss_cls: 0.9985  loss_box_reg: 0.8698  loss_mask: 0.6476  loss_rpn_cls: 0.09122  loss_rpn_loc: 0.1095  time: 0.8682  data_time: 0.2597  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:25:56 d2.utils.events]: \u001b[0m eta: 0:21:14  iter: 39  total_loss: 2.287  loss_cls: 0.746  loss_box_reg: 0.8871  loss_mask: 0.5156  loss_rpn_cls: 0.06349  loss_rpn_loc: 0.1248  time: 0.8853  data_time: 0.2466  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:26:13 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 59  total_loss: 1.935  loss_cls: 0.5803  loss_box_reg: 0.7992  loss_mask: 0.3652  loss_rpn_cls: 0.04615  loss_rpn_loc: 0.1039  time: 0.8806  data_time: 0.2287  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:26:32 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 79  total_loss: 1.696  loss_cls: 0.5035  loss_box_reg: 0.7141  loss_mask: 0.3368  loss_rpn_cls: 0.04228  loss_rpn_loc: 0.1035  time: 0.8968  data_time: 0.2363  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:26:50 d2.utils.events]: \u001b[0m eta: 0:20:21  iter: 99  total_loss: 1.518  loss_cls: 0.4359  loss_box_reg: 0.6298  loss_mask: 0.2975  loss_rpn_cls: 0.05629  loss_rpn_loc: 0.08658  time: 0.8924  data_time: 0.2502  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:27:07 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 119  total_loss: 1.576  loss_cls: 0.4728  loss_box_reg: 0.6868  loss_mask: 0.2786  loss_rpn_cls: 0.03712  loss_rpn_loc: 0.1089  time: 0.8853  data_time: 0.2181  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:27:24 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 139  total_loss: 1.511  loss_cls: 0.4373  loss_box_reg: 0.6601  loss_mask: 0.2748  loss_rpn_cls: 0.04946  loss_rpn_loc: 0.104  time: 0.8808  data_time: 0.2231  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:27:41 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 159  total_loss: 1.293  loss_cls: 0.3549  loss_box_reg: 0.5579  loss_mask: 0.2363  loss_rpn_cls: 0.02565  loss_rpn_loc: 0.09515  time: 0.8748  data_time: 0.2031  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:27:57 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 179  total_loss: 1.364  loss_cls: 0.4137  loss_box_reg: 0.5675  loss_mask: 0.2314  loss_rpn_cls: 0.04659  loss_rpn_loc: 0.1051  time: 0.8710  data_time: 0.2000  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:28:15 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 199  total_loss: 1.385  loss_cls: 0.3932  loss_box_reg: 0.5675  loss_mask: 0.275  loss_rpn_cls: 0.04721  loss_rpn_loc: 0.1033  time: 0.8705  data_time: 0.2229  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:28:33 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 219  total_loss: 1.268  loss_cls: 0.3477  loss_box_reg: 0.5498  loss_mask: 0.2551  loss_rpn_cls: 0.02988  loss_rpn_loc: 0.08762  time: 0.8721  data_time: 0.2245  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:28:50 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 239  total_loss: 1.346  loss_cls: 0.4003  loss_box_reg: 0.5625  loss_mask: 0.2615  loss_rpn_cls: 0.03078  loss_rpn_loc: 0.09763  time: 0.8704  data_time: 0.2098  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:29:07 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 259  total_loss: 1.287  loss_cls: 0.3442  loss_box_reg: 0.553  loss_mask: 0.2631  loss_rpn_cls: 0.03253  loss_rpn_loc: 0.08063  time: 0.8694  data_time: 0.2100  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:29:24 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 279  total_loss: 1.248  loss_cls: 0.38  loss_box_reg: 0.4937  loss_mask: 0.2548  loss_rpn_cls: 0.03195  loss_rpn_loc: 0.09294  time: 0.8695  data_time: 0.2212  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:29:41 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 299  total_loss: 1.191  loss_cls: 0.3335  loss_box_reg: 0.4501  loss_mask: 0.2728  loss_rpn_cls: 0.03022  loss_rpn_loc: 0.09281  time: 0.8674  data_time: 0.1957  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:29:58 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 319  total_loss: 1.16  loss_cls: 0.3372  loss_box_reg: 0.4677  loss_mask: 0.222  loss_rpn_cls: 0.03163  loss_rpn_loc: 0.0903  time: 0.8670  data_time: 0.2299  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:30:16 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 339  total_loss: 1.165  loss_cls: 0.3157  loss_box_reg: 0.47  loss_mask: 0.2469  loss_rpn_cls: 0.02601  loss_rpn_loc: 0.08949  time: 0.8675  data_time: 0.2156  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:30:33 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 359  total_loss: 1.156  loss_cls: 0.3158  loss_box_reg: 0.5337  loss_mask: 0.2103  loss_rpn_cls: 0.02542  loss_rpn_loc: 0.08119  time: 0.8683  data_time: 0.2373  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:30:51 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 379  total_loss: 1.16  loss_cls: 0.3258  loss_box_reg: 0.4768  loss_mask: 0.2251  loss_rpn_cls: 0.02284  loss_rpn_loc: 0.09656  time: 0.8687  data_time: 0.2164  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:31:08 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 399  total_loss: 1.055  loss_cls: 0.2868  loss_box_reg: 0.4718  loss_mask: 0.2248  loss_rpn_cls: 0.02529  loss_rpn_loc: 0.07874  time: 0.8688  data_time: 0.2204  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:31:26 d2.utils.events]: \u001b[0m eta: 0:15:31  iter: 419  total_loss: 1.108  loss_cls: 0.2751  loss_box_reg: 0.4958  loss_mask: 0.2429  loss_rpn_cls: 0.02594  loss_rpn_loc: 0.08746  time: 0.8694  data_time: 0.2251  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:31:44 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 439  total_loss: 1.101  loss_cls: 0.2795  loss_box_reg: 0.4349  loss_mask: 0.2261  loss_rpn_cls: 0.02347  loss_rpn_loc: 0.103  time: 0.8703  data_time: 0.2388  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:32:01 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 459  total_loss: 1.094  loss_cls: 0.3197  loss_box_reg: 0.4343  loss_mask: 0.2178  loss_rpn_cls: 0.02566  loss_rpn_loc: 0.09055  time: 0.8702  data_time: 0.2336  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:32:19 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 479  total_loss: 1.068  loss_cls: 0.2729  loss_box_reg: 0.468  loss_mask: 0.216  loss_rpn_cls: 0.02159  loss_rpn_loc: 0.09141  time: 0.8708  data_time: 0.2262  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:32:36 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 499  total_loss: 1.124  loss_cls: 0.3144  loss_box_reg: 0.4577  loss_mask: 0.2066  loss_rpn_cls: 0.01885  loss_rpn_loc: 0.08982  time: 0.8708  data_time: 0.2163  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:32:54 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 519  total_loss: 1.063  loss_cls: 0.2718  loss_box_reg: 0.4803  loss_mask: 0.2346  loss_rpn_cls: 0.01834  loss_rpn_loc: 0.07838  time: 0.8705  data_time: 0.2325  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:33:11 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 539  total_loss: 1.134  loss_cls: 0.2863  loss_box_reg: 0.462  loss_mask: 0.2323  loss_rpn_cls: 0.02454  loss_rpn_loc: 0.08659  time: 0.8710  data_time: 0.2497  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:33:29 d2.utils.events]: \u001b[0m eta: 0:13:23  iter: 559  total_loss: 1.097  loss_cls: 0.3094  loss_box_reg: 0.4628  loss_mask: 0.234  loss_rpn_cls: 0.02143  loss_rpn_loc: 0.08474  time: 0.8712  data_time: 0.2223  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:33:45 d2.utils.events]: \u001b[0m eta: 0:13:05  iter: 579  total_loss: 1.129  loss_cls: 0.3066  loss_box_reg: 0.429  loss_mask: 0.2317  loss_rpn_cls: 0.02219  loss_rpn_loc: 0.08702  time: 0.8694  data_time: 0.1995  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:34:02 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 599  total_loss: 1.076  loss_cls: 0.3009  loss_box_reg: 0.4516  loss_mask: 0.2399  loss_rpn_cls: 0.0217  loss_rpn_loc: 0.09528  time: 0.8691  data_time: 0.2172  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:34:19 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 619  total_loss: 0.9593  loss_cls: 0.2809  loss_box_reg: 0.4082  loss_mask: 0.1989  loss_rpn_cls: 0.01966  loss_rpn_loc: 0.06585  time: 0.8685  data_time: 0.2194  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:34:37 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 639  total_loss: 1.036  loss_cls: 0.2882  loss_box_reg: 0.4401  loss_mask: 0.2276  loss_rpn_cls: 0.02039  loss_rpn_loc: 0.08122  time: 0.8688  data_time: 0.2113  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:34:55 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 659  total_loss: 0.9915  loss_cls: 0.2351  loss_box_reg: 0.3902  loss_mask: 0.2217  loss_rpn_cls: 0.02082  loss_rpn_loc: 0.08298  time: 0.8694  data_time: 0.2178  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:35:13 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 679  total_loss: 1.015  loss_cls: 0.2522  loss_box_reg: 0.4175  loss_mask: 0.2302  loss_rpn_cls: 0.01933  loss_rpn_loc: 0.08619  time: 0.8699  data_time: 0.2400  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:35:30 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 699  total_loss: 1.031  loss_cls: 0.2539  loss_box_reg: 0.4096  loss_mask: 0.2315  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.09569  time: 0.8695  data_time: 0.1958  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:35:47 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 719  total_loss: 0.9744  loss_cls: 0.2517  loss_box_reg: 0.4167  loss_mask: 0.2053  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.07782  time: 0.8700  data_time: 0.2365  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:36:05 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 739  total_loss: 0.9556  loss_cls: 0.243  loss_box_reg: 0.4125  loss_mask: 0.1912  loss_rpn_cls: 0.01756  loss_rpn_loc: 0.07545  time: 0.8703  data_time: 0.2341  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:36:23 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 759  total_loss: 1.038  loss_cls: 0.2609  loss_box_reg: 0.434  loss_mask: 0.2242  loss_rpn_cls: 0.02095  loss_rpn_loc: 0.08552  time: 0.8704  data_time: 0.2066  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:36:41 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 779  total_loss: 1.016  loss_cls: 0.2964  loss_box_reg: 0.4053  loss_mask: 0.1939  loss_rpn_cls: 0.02019  loss_rpn_loc: 0.08723  time: 0.8721  data_time: 0.2757  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:36:57 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 799  total_loss: 0.9539  loss_cls: 0.2318  loss_box_reg: 0.3927  loss_mask: 0.2289  loss_rpn_cls: 0.01529  loss_rpn_loc: 0.07122  time: 0.8702  data_time: 0.1634  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:37:15 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 819  total_loss: 1.006  loss_cls: 0.2554  loss_box_reg: 0.4076  loss_mask: 0.2155  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.08867  time: 0.8703  data_time: 0.2331  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:37:32 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 839  total_loss: 0.9877  loss_cls: 0.2589  loss_box_reg: 0.4117  loss_mask: 0.2121  loss_rpn_cls: 0.01611  loss_rpn_loc: 0.07793  time: 0.8704  data_time: 0.2064  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:37:50 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 859  total_loss: 0.9879  loss_cls: 0.2814  loss_box_reg: 0.3793  loss_mask: 0.1911  loss_rpn_cls: 0.01872  loss_rpn_loc: 0.09075  time: 0.8702  data_time: 0.2361  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:38:07 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 879  total_loss: 0.9191  loss_cls: 0.2928  loss_box_reg: 0.3378  loss_mask: 0.1886  loss_rpn_cls: 0.01461  loss_rpn_loc: 0.0941  time: 0.8698  data_time: 0.2094  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:38:24 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 899  total_loss: 0.9657  loss_cls: 0.252  loss_box_reg: 0.4028  loss_mask: 0.1901  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.08959  time: 0.8697  data_time: 0.2076  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:38:42 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 919  total_loss: 0.9155  loss_cls: 0.2284  loss_box_reg: 0.3621  loss_mask: 0.1894  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.06756  time: 0.8702  data_time: 0.2369  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:38:59 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 939  total_loss: 0.9933  loss_cls: 0.2475  loss_box_reg: 0.4113  loss_mask: 0.2035  loss_rpn_cls: 0.01796  loss_rpn_loc: 0.08219  time: 0.8704  data_time: 0.2193  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:39:16 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 959  total_loss: 0.8088  loss_cls: 0.2275  loss_box_reg: 0.3327  loss_mask: 0.1959  loss_rpn_cls: 0.01429  loss_rpn_loc: 0.0735  time: 0.8693  data_time: 0.1970  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:39:33 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 979  total_loss: 0.9652  loss_cls: 0.2772  loss_box_reg: 0.4007  loss_mask: 0.2057  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.07622  time: 0.8689  data_time: 0.2241  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:39:51 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 999  total_loss: 0.945  loss_cls: 0.2345  loss_box_reg: 0.4048  loss_mask: 0.204  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.07906  time: 0.8695  data_time: 0.2333  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:40:09 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 1019  total_loss: 0.9579  loss_cls: 0.225  loss_box_reg: 0.3953  loss_mask: 0.1942  loss_rpn_cls: 0.01056  loss_rpn_loc: 0.06638  time: 0.8700  data_time: 0.2301  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:40:26 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 1039  total_loss: 0.9233  loss_cls: 0.2256  loss_box_reg: 0.3721  loss_mask: 0.2083  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.06828  time: 0.8700  data_time: 0.2380  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:40:44 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 1059  total_loss: 0.9983  loss_cls: 0.2584  loss_box_reg: 0.3905  loss_mask: 0.1849  loss_rpn_cls: 0.01692  loss_rpn_loc: 0.08462  time: 0.8701  data_time: 0.2300  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:41:01 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 1079  total_loss: 0.9095  loss_cls: 0.2379  loss_box_reg: 0.3632  loss_mask: 0.2015  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.07487  time: 0.8698  data_time: 0.2144  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:41:18 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 1099  total_loss: 0.8134  loss_cls: 0.2147  loss_box_reg: 0.3005  loss_mask: 0.1941  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.0642  time: 0.8701  data_time: 0.2191  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:41:36 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 1119  total_loss: 0.8187  loss_cls: 0.2024  loss_box_reg: 0.3647  loss_mask: 0.1876  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.07557  time: 0.8699  data_time: 0.2150  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:41:53 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 1139  total_loss: 0.8631  loss_cls: 0.2088  loss_box_reg: 0.3341  loss_mask: 0.1881  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.07475  time: 0.8703  data_time: 0.2359  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:42:10 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 1159  total_loss: 0.832  loss_cls: 0.2227  loss_box_reg: 0.3146  loss_mask: 0.1707  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.07563  time: 0.8699  data_time: 0.1957  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:42:28 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 1179  total_loss: 0.9332  loss_cls: 0.2235  loss_box_reg: 0.3571  loss_mask: 0.1827  loss_rpn_cls: 0.01838  loss_rpn_loc: 0.08468  time: 0.8704  data_time: 0.2456  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:42:46 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 1199  total_loss: 0.8633  loss_cls: 0.2155  loss_box_reg: 0.3489  loss_mask: 0.2013  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.07722  time: 0.8702  data_time: 0.2045  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:43:03 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 1219  total_loss: 0.893  loss_cls: 0.2194  loss_box_reg: 0.3419  loss_mask: 0.2007  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.07859  time: 0.8700  data_time: 0.2217  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:43:20 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 1239  total_loss: 0.8261  loss_cls: 0.2087  loss_box_reg: 0.3297  loss_mask: 0.1761  loss_rpn_cls: 0.008581  loss_rpn_loc: 0.07512  time: 0.8699  data_time: 0.2278  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:43:38 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 1259  total_loss: 0.8831  loss_cls: 0.2218  loss_box_reg: 0.3485  loss_mask: 0.1903  loss_rpn_cls: 0.0107  loss_rpn_loc: 0.06822  time: 0.8701  data_time: 0.2376  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:43:56 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 1279  total_loss: 0.9114  loss_cls: 0.2447  loss_box_reg: 0.3416  loss_mask: 0.2051  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.07424  time: 0.8706  data_time: 0.2396  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:44:13 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 1299  total_loss: 0.8401  loss_cls: 0.2098  loss_box_reg: 0.3399  loss_mask: 0.1893  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.07465  time: 0.8706  data_time: 0.2259  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:44:30 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 1319  total_loss: 0.8012  loss_cls: 0.2102  loss_box_reg: 0.3219  loss_mask: 0.201  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.07043  time: 0.8704  data_time: 0.2197  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:44:49 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 1339  total_loss: 0.7758  loss_cls: 0.2062  loss_box_reg: 0.3207  loss_mask: 0.1723  loss_rpn_cls: 0.008326  loss_rpn_loc: 0.06723  time: 0.8710  data_time: 0.2585  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:45:06 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 1359  total_loss: 0.8395  loss_cls: 0.2253  loss_box_reg: 0.3192  loss_mask: 0.1881  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.08323  time: 0.8711  data_time: 0.2258  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:45:24 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 1379  total_loss: 0.9523  loss_cls: 0.2292  loss_box_reg: 0.3386  loss_mask: 0.2001  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.0722  time: 0.8717  data_time: 0.2493  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:45:42 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 1399  total_loss: 0.8241  loss_cls: 0.2072  loss_box_reg: 0.3402  loss_mask: 0.221  loss_rpn_cls: 0.01738  loss_rpn_loc: 0.08463  time: 0.8717  data_time: 0.2287  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 17:46:00 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 1419  total_loss: 0.7688  loss_cls: 0.2331  loss_box_reg: 0.3026  loss_mask: 0.1536  loss_rpn_cls: 0.009792  loss_rpn_loc: 0.05784  time: 0.8722  data_time: 0.2709  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:46:18 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 1439  total_loss: 0.8236  loss_cls: 0.199  loss_box_reg: 0.3549  loss_mask: 0.2004  loss_rpn_cls: 0.01253  loss_rpn_loc: 0.07698  time: 0.8724  data_time: 0.2321  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:46:36 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 1459  total_loss: 0.8619  loss_cls: 0.207  loss_box_reg: 0.3553  loss_mask: 0.1959  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.06455  time: 0.8726  data_time: 0.2546  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:46:53 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.8198  loss_cls: 0.2007  loss_box_reg: 0.3313  loss_mask: 0.1886  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.06559  time: 0.8728  data_time: 0.2510  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:47:12 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.8089  loss_cls: 0.2027  loss_box_reg: 0.3337  loss_mask: 0.1807  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.07779  time: 0.8728  data_time: 0.2290  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 17:47:12 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:47 (0.8728 s / it)\n",
      "\u001b[32m[03/04 17:47:12 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:49 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:47:13 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 17:47:13 d2.data.datasets.coco]: \u001b[0mLoaded 160 images in COCO format from /host/mic21-framework/server/uploads/figure_skating_gt.json\n",
      "figure_skating\n",
      "\u001b[32m[03/04 17:47:14 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:47:14 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 17:47:14 d2.data.datasets.coco]: \u001b[0mLoaded 160 images in COCO format from /host/mic21-framework/server/uploads/figure_skating_gt.json\n",
      "\u001b[32m[03/04 17:47:14 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 160 images left.\n",
      "\u001b[32m[03/04 17:47:14 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|   category    | #instances   |   category   | #instances   |\n",
      "|:-------------:|:-------------|:------------:|:-------------|\n",
      "| figure skater | 212          | figure skate | 385          |\n",
      "|               |              |              |              |\n",
      "|     total     | 597          |              |              |\u001b[0m\n",
      "\u001b[32m[03/04 17:47:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 17:47:14 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 17:47:14 d2.data.common]: \u001b[0mSerializing 160 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 17:47:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.37 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:47:14 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[03/04 17:47:14 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"/detectron2/detectron2/engine/train_loop.py\", line 149, in train\n",
      "    self.run_step()\n",
      "  File \"/detectron2/detectron2/engine/defaults.py\", line 494, in run_step\n",
      "    self._trainer.run_step()\n",
      "  File \"/detectron2/detectron2/engine/train_loop.py\", line 267, in run_step\n",
      "    data = next(self._data_loader_iter)\n",
      "  File \"/detectron2/detectron2/data/common.py\", line 234, in __iter__\n",
      "    for d in self.dataset:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "  File \"/detectron2/detectron2/data/common.py\", line 201, in __iter__\n",
      "    yield self.dataset[idx]\n",
      "  File \"/detectron2/detectron2/data/common.py\", line 90, in __getitem__\n",
      "    data = self._map_func(self._dataset[cur_idx])\n",
      "  File \"/detectron2/detectron2/utils/serialize.py\", line 26, in __call__\n",
      "    return self._obj(*args, **kwargs)\n",
      "  File \"/detectron2/detectron2/data/dataset_mapper.py\", line 154, in __call__\n",
      "    image = utils.read_image(dataset_dict[\"file_name\"], format=self.image_format)\n",
      "  File \"/detectron2/detectron2/data/detection_utils.py\", line 180, in read_image\n",
      "    with PathManager.open(file_name, \"rb\") as f:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/iopath/common/file_io.py\", line 1012, in open\n",
      "    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/iopath/common/file_io.py\", line 612, in _open\n",
      "    opener=opener,\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/host/mic21-framework/server/uploads/figure_skating/pexels_6539403.jpeg'\n",
      "\n",
      "\u001b[32m[03/04 17:47:14 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n",
      "\u001b[32m[03/04 17:47:14 d2.utils.events]: \u001b[0m iter: 0    lr: N/A  max_mem: 0M\n",
      "New dataset\n",
      "\u001b[32m[03/04 17:47:19 d2.data.datasets.coco]: \u001b[0mLoading /host/mic21-framework/server/uploads/off_road_motorcycling_gt.json takes 5.06 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:47:19 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 17:47:19 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /host/mic21-framework/server/uploads/off_road_motorcycling_gt.json\n",
      "off_road_motorcycling\n",
      "\u001b[32m[03/04 17:47:20 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 17:47:20 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 17:47:20 d2.data.datasets.coco]: \u001b[0mLoaded 190 images in COCO format from /host/mic21-framework/server/uploads/off_road_motorcycling_gt.json\n",
      "\u001b[32m[03/04 17:47:20 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 190 images left.\n",
      "\u001b[32m[03/04 17:47:20 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
      "| motorcycle .. | 204          | off road mo.. | 207          |  pathway   | 78           |\n",
      "| off road mo.. | 206          |               |              |            |              |\n",
      "|     total     | 695          |               |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 17:47:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 17:47:20 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 17:47:20 d2.data.common]: \u001b[0mSerializing 190 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 17:47:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.05 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:47:20 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 17:47:39 d2.utils.events]: \u001b[0m eta: 0:22:15  iter: 19  total_loss: 2.283  loss_cls: 0.7347  loss_box_reg: 0.8879  loss_mask: 0.5838  loss_rpn_cls: 0.03488  loss_rpn_loc: 0.02361  time: 0.9323  data_time: 0.3186  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:47:59 d2.utils.events]: \u001b[0m eta: 0:23:00  iter: 39  total_loss: 1.476  loss_cls: 0.3362  loss_box_reg: 0.7638  loss_mask: 0.3294  loss_rpn_cls: 0.007983  loss_rpn_loc: 0.0203  time: 0.9707  data_time: 0.3223  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:48:19 d2.utils.events]: \u001b[0m eta: 0:22:41  iter: 59  total_loss: 1.115  loss_cls: 0.2437  loss_box_reg: 0.6178  loss_mask: 0.2369  loss_rpn_cls: 0.007801  loss_rpn_loc: 0.02298  time: 0.9744  data_time: 0.3150  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:48:39 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 79  total_loss: 0.8438  loss_cls: 0.1938  loss_box_reg: 0.4331  loss_mask: 0.1809  loss_rpn_cls: 0.003908  loss_rpn_loc: 0.01991  time: 0.9803  data_time: 0.3362  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:48:59 d2.utils.events]: \u001b[0m eta: 0:22:38  iter: 99  total_loss: 0.8135  loss_cls: 0.1511  loss_box_reg: 0.431  loss_mask: 0.1729  loss_rpn_cls: 0.005826  loss_rpn_loc: 0.02008  time: 0.9859  data_time: 0.3218  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:49:20 d2.utils.events]: \u001b[0m eta: 0:22:33  iter: 119  total_loss: 0.7424  loss_cls: 0.145  loss_box_reg: 0.3981  loss_mask: 0.1845  loss_rpn_cls: 0.004098  loss_rpn_loc: 0.01977  time: 0.9915  data_time: 0.3348  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:49:39 d2.utils.events]: \u001b[0m eta: 0:22:17  iter: 139  total_loss: 0.7321  loss_cls: 0.1649  loss_box_reg: 0.3938  loss_mask: 0.1479  loss_rpn_cls: 0.003196  loss_rpn_loc: 0.01746  time: 0.9915  data_time: 0.2982  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:49:58 d2.utils.events]: \u001b[0m eta: 0:21:54  iter: 159  total_loss: 0.7019  loss_cls: 0.1276  loss_box_reg: 0.3807  loss_mask: 0.1762  loss_rpn_cls: 0.004587  loss_rpn_loc: 0.01862  time: 0.9850  data_time: 0.2881  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:50:18 d2.utils.events]: \u001b[0m eta: 0:21:32  iter: 179  total_loss: 0.6889  loss_cls: 0.1382  loss_box_reg: 0.3519  loss_mask: 0.1559  loss_rpn_cls: 0.003457  loss_rpn_loc: 0.02097  time: 0.9831  data_time: 0.3040  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:50:37 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 199  total_loss: 0.641  loss_cls: 0.134  loss_box_reg: 0.3478  loss_mask: 0.1454  loss_rpn_cls: 0.006199  loss_rpn_loc: 0.01364  time: 0.9839  data_time: 0.3303  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:50:57 d2.utils.events]: \u001b[0m eta: 0:20:56  iter: 219  total_loss: 0.5968  loss_cls: 0.1187  loss_box_reg: 0.3046  loss_mask: 0.1448  loss_rpn_cls: 0.0027  loss_rpn_loc: 0.01931  time: 0.9819  data_time: 0.2922  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:51:16 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 239  total_loss: 0.5877  loss_cls: 0.1075  loss_box_reg: 0.3215  loss_mask: 0.1497  loss_rpn_cls: 0.003631  loss_rpn_loc: 0.02148  time: 0.9794  data_time: 0.2840  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:51:34 d2.utils.events]: \u001b[0m eta: 0:20:09  iter: 259  total_loss: 0.6185  loss_cls: 0.1256  loss_box_reg: 0.3289  loss_mask: 0.1428  loss_rpn_cls: 0.0036  loss_rpn_loc: 0.01989  time: 0.9749  data_time: 0.2847  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:51:54 d2.utils.events]: \u001b[0m eta: 0:19:54  iter: 279  total_loss: 0.597  loss_cls: 0.1445  loss_box_reg: 0.3028  loss_mask: 0.1497  loss_rpn_cls: 0.002348  loss_rpn_loc: 0.01589  time: 0.9767  data_time: 0.3354  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:52:14 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 299  total_loss: 0.6065  loss_cls: 0.1244  loss_box_reg: 0.2993  loss_mask: 0.1377  loss_rpn_cls: 0.00426  loss_rpn_loc: 0.01486  time: 0.9776  data_time: 0.3336  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:52:34 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 319  total_loss: 0.5726  loss_cls: 0.1018  loss_box_reg: 0.309  loss_mask: 0.1396  loss_rpn_cls: 0.002815  loss_rpn_loc: 0.01801  time: 0.9779  data_time: 0.3023  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:52:52 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 339  total_loss: 0.5744  loss_cls: 0.1269  loss_box_reg: 0.295  loss_mask: 0.131  loss_rpn_cls: 0.002401  loss_rpn_loc: 0.01546  time: 0.9752  data_time: 0.2641  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:53:12 d2.utils.events]: \u001b[0m eta: 0:18:32  iter: 359  total_loss: 0.6093  loss_cls: 0.1351  loss_box_reg: 0.2931  loss_mask: 0.1252  loss_rpn_cls: 0.002771  loss_rpn_loc: 0.01698  time: 0.9763  data_time: 0.3237  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:53:32 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 379  total_loss: 0.5802  loss_cls: 0.1251  loss_box_reg: 0.2898  loss_mask: 0.1295  loss_rpn_cls: 0.002127  loss_rpn_loc: 0.01602  time: 0.9761  data_time: 0.2968  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:53:51 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 399  total_loss: 0.5648  loss_cls: 0.1231  loss_box_reg: 0.2643  loss_mask: 0.1355  loss_rpn_cls: 0.004132  loss_rpn_loc: 0.01673  time: 0.9761  data_time: 0.3049  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:54:11 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 419  total_loss: 0.5042  loss_cls: 0.08971  loss_box_reg: 0.2654  loss_mask: 0.1184  loss_rpn_cls: 0.003192  loss_rpn_loc: 0.01773  time: 0.9779  data_time: 0.3370  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:54:32 d2.utils.events]: \u001b[0m eta: 0:17:20  iter: 439  total_loss: 0.5057  loss_cls: 0.09819  loss_box_reg: 0.2525  loss_mask: 0.1199  loss_rpn_cls: 0.001939  loss_rpn_loc: 0.01576  time: 0.9790  data_time: 0.3272  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:54:50 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 459  total_loss: 0.5279  loss_cls: 0.1216  loss_box_reg: 0.2793  loss_mask: 0.1148  loss_rpn_cls: 0.003177  loss_rpn_loc: 0.01673  time: 0.9776  data_time: 0.2604  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:55:10 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 479  total_loss: 0.5162  loss_cls: 0.1185  loss_box_reg: 0.2582  loss_mask: 0.1279  loss_rpn_cls: 0.001959  loss_rpn_loc: 0.01548  time: 0.9784  data_time: 0.3057  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:55:30 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 499  total_loss: 0.5227  loss_cls: 0.1014  loss_box_reg: 0.2668  loss_mask: 0.1176  loss_rpn_cls: 0.001894  loss_rpn_loc: 0.01785  time: 0.9778  data_time: 0.3191  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:55:49 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 519  total_loss: 0.5009  loss_cls: 0.1142  loss_box_reg: 0.259  loss_mask: 0.1099  loss_rpn_cls: 0.002836  loss_rpn_loc: 0.01611  time: 0.9773  data_time: 0.2703  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:56:08 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 539  total_loss: 0.4725  loss_cls: 0.09646  loss_box_reg: 0.2487  loss_mask: 0.1055  loss_rpn_cls: 0.00104  loss_rpn_loc: 0.01252  time: 0.9770  data_time: 0.2849  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:56:28 d2.utils.events]: \u001b[0m eta: 0:15:20  iter: 559  total_loss: 0.5422  loss_cls: 0.09881  loss_box_reg: 0.2907  loss_mask: 0.1222  loss_rpn_cls: 0.002974  loss_rpn_loc: 0.01721  time: 0.9774  data_time: 0.3157  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:56:48 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 579  total_loss: 0.5225  loss_cls: 0.1146  loss_box_reg: 0.2571  loss_mask: 0.1181  loss_rpn_cls: 0.001917  loss_rpn_loc: 0.01502  time: 0.9772  data_time: 0.3056  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:57:07 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 599  total_loss: 0.4785  loss_cls: 0.08965  loss_box_reg: 0.2523  loss_mask: 0.1137  loss_rpn_cls: 0.002148  loss_rpn_loc: 0.0134  time: 0.9777  data_time: 0.3182  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:57:27 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 619  total_loss: 0.5445  loss_cls: 0.1095  loss_box_reg: 0.2824  loss_mask: 0.13  loss_rpn_cls: 0.001707  loss_rpn_loc: 0.01669  time: 0.9771  data_time: 0.2751  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:57:47 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 639  total_loss: 0.5061  loss_cls: 0.115  loss_box_reg: 0.2354  loss_mask: 0.1195  loss_rpn_cls: 0.001569  loss_rpn_loc: 0.0208  time: 0.9782  data_time: 0.3347  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:58:07 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 659  total_loss: 0.5045  loss_cls: 0.121  loss_box_reg: 0.2584  loss_mask: 0.1221  loss_rpn_cls: 0.002065  loss_rpn_loc: 0.01347  time: 0.9796  data_time: 0.3356  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 17:58:27 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 679  total_loss: 0.4628  loss_cls: 0.08887  loss_box_reg: 0.2474  loss_mask: 0.1247  loss_rpn_cls: 0.001862  loss_rpn_loc: 0.01258  time: 0.9801  data_time: 0.3072  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:58:47 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 699  total_loss: 0.4981  loss_cls: 0.107  loss_box_reg: 0.2207  loss_mask: 0.1269  loss_rpn_cls: 0.002188  loss_rpn_loc: 0.01664  time: 0.9804  data_time: 0.2963  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:59:07 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 719  total_loss: 0.4722  loss_cls: 0.08759  loss_box_reg: 0.2373  loss_mask: 0.1066  loss_rpn_cls: 0.001917  loss_rpn_loc: 0.01429  time: 0.9800  data_time: 0.2973  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:59:25 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 739  total_loss: 0.468  loss_cls: 0.07235  loss_box_reg: 0.2402  loss_mask: 0.1149  loss_rpn_cls: 0.00176  loss_rpn_loc: 0.01479  time: 0.9788  data_time: 0.2958  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 17:59:45 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 759  total_loss: 0.4677  loss_cls: 0.07264  loss_box_reg: 0.2526  loss_mask: 0.1116  loss_rpn_cls: 0.002101  loss_rpn_loc: 0.01583  time: 0.9784  data_time: 0.2997  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:00:06 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 779  total_loss: 0.4838  loss_cls: 0.09462  loss_box_reg: 0.2494  loss_mask: 0.1154  loss_rpn_cls: 0.00162  loss_rpn_loc: 0.01384  time: 0.9801  data_time: 0.3636  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:00:25 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 799  total_loss: 0.503  loss_cls: 0.09605  loss_box_reg: 0.2251  loss_mask: 0.129  loss_rpn_cls: 0.001518  loss_rpn_loc: 0.01633  time: 0.9798  data_time: 0.2877  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:00:44 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 819  total_loss: 0.4641  loss_cls: 0.08035  loss_box_reg: 0.245  loss_mask: 0.1156  loss_rpn_cls: 0.001695  loss_rpn_loc: 0.01116  time: 0.9798  data_time: 0.2938  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:01:05 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 839  total_loss: 0.4884  loss_cls: 0.09552  loss_box_reg: 0.2263  loss_mask: 0.114  loss_rpn_cls: 0.002175  loss_rpn_loc: 0.01731  time: 0.9805  data_time: 0.3154  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:01:24 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 859  total_loss: 0.4704  loss_cls: 0.1029  loss_box_reg: 0.254  loss_mask: 0.1188  loss_rpn_cls: 0.002881  loss_rpn_loc: 0.01668  time: 0.9807  data_time: 0.3199  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:01:44 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 879  total_loss: 0.4527  loss_cls: 0.07882  loss_box_reg: 0.2201  loss_mask: 0.1112  loss_rpn_cls: 0.002349  loss_rpn_loc: 0.01578  time: 0.9804  data_time: 0.3097  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:02:03 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 899  total_loss: 0.4816  loss_cls: 0.09777  loss_box_reg: 0.2402  loss_mask: 0.1162  loss_rpn_cls: 0.001449  loss_rpn_loc: 0.01249  time: 0.9794  data_time: 0.2966  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:02:22 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 919  total_loss: 0.4386  loss_cls: 0.08495  loss_box_reg: 0.2241  loss_mask: 0.105  loss_rpn_cls: 0.001602  loss_rpn_loc: 0.0175  time: 0.9791  data_time: 0.3054  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:02:42 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 939  total_loss: 0.4546  loss_cls: 0.09717  loss_box_reg: 0.2226  loss_mask: 0.1118  loss_rpn_cls: 0.0021  loss_rpn_loc: 0.01363  time: 0.9800  data_time: 0.3418  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:03:02 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 959  total_loss: 0.477  loss_cls: 0.101  loss_box_reg: 0.2439  loss_mask: 0.1158  loss_rpn_cls: 0.001793  loss_rpn_loc: 0.01319  time: 0.9804  data_time: 0.3252  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:03:22 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 979  total_loss: 0.4355  loss_cls: 0.07438  loss_box_reg: 0.2148  loss_mask: 0.1099  loss_rpn_cls: 0.000999  loss_rpn_loc: 0.01447  time: 0.9802  data_time: 0.2835  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:03:42 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 999  total_loss: 0.4359  loss_cls: 0.09635  loss_box_reg: 0.2196  loss_mask: 0.105  loss_rpn_cls: 0.001922  loss_rpn_loc: 0.01789  time: 0.9807  data_time: 0.3388  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:04:02 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 1019  total_loss: 0.5121  loss_cls: 0.08254  loss_box_reg: 0.2546  loss_mask: 0.1099  loss_rpn_cls: 0.002104  loss_rpn_loc: 0.01388  time: 0.9808  data_time: 0.3060  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:04:22 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 1039  total_loss: 0.4171  loss_cls: 0.09667  loss_box_reg: 0.1956  loss_mask: 0.1088  loss_rpn_cls: 0.001767  loss_rpn_loc: 0.01187  time: 0.9813  data_time: 0.3307  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:04:42 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 1059  total_loss: 0.4017  loss_cls: 0.07774  loss_box_reg: 0.193  loss_mask: 0.1105  loss_rpn_cls: 0.001025  loss_rpn_loc: 0.01289  time: 0.9817  data_time: 0.3093  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:05:01 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 1079  total_loss: 0.4154  loss_cls: 0.07706  loss_box_reg: 0.1881  loss_mask: 0.1094  loss_rpn_cls: 0.003087  loss_rpn_loc: 0.01658  time: 0.9817  data_time: 0.3014  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:05:20 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 1099  total_loss: 0.3807  loss_cls: 0.07684  loss_box_reg: 0.1895  loss_mask: 0.1033  loss_rpn_cls: 0.001725  loss_rpn_loc: 0.01208  time: 0.9808  data_time: 0.2694  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:05:40 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 1119  total_loss: 0.4715  loss_cls: 0.0879  loss_box_reg: 0.2172  loss_mask: 0.1114  loss_rpn_cls: 0.002442  loss_rpn_loc: 0.01673  time: 0.9810  data_time: 0.3253  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:05:58 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 1139  total_loss: 0.4003  loss_cls: 0.09522  loss_box_reg: 0.1838  loss_mask: 0.1091  loss_rpn_cls: 0.002048  loss_rpn_loc: 0.01302  time: 0.9799  data_time: 0.2696  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:06:18 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1159  total_loss: 0.4104  loss_cls: 0.09632  loss_box_reg: 0.1874  loss_mask: 0.114  loss_rpn_cls: 0.001134  loss_rpn_loc: 0.01771  time: 0.9795  data_time: 0.2702  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:06:36 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1179  total_loss: 0.3798  loss_cls: 0.09784  loss_box_reg: 0.1975  loss_mask: 0.11  loss_rpn_cls: 0.0009699  loss_rpn_loc: 0.0134  time: 0.9787  data_time: 0.2790  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:06:56 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 1199  total_loss: 0.4128  loss_cls: 0.1017  loss_box_reg: 0.1959  loss_mask: 0.1104  loss_rpn_cls: 0.001252  loss_rpn_loc: 0.01236  time: 0.9786  data_time: 0.3252  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:07:15 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1219  total_loss: 0.3928  loss_cls: 0.07513  loss_box_reg: 0.1855  loss_mask: 0.1039  loss_rpn_cls: 0.001221  loss_rpn_loc: 0.01676  time: 0.9786  data_time: 0.2917  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:07:34 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 1239  total_loss: 0.3668  loss_cls: 0.07031  loss_box_reg: 0.1793  loss_mask: 0.1037  loss_rpn_cls: 0.001405  loss_rpn_loc: 0.01203  time: 0.9780  data_time: 0.2746  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:07:54 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 1259  total_loss: 0.4285  loss_cls: 0.09634  loss_box_reg: 0.1984  loss_mask: 0.1124  loss_rpn_cls: 0.001045  loss_rpn_loc: 0.01243  time: 0.9781  data_time: 0.3140  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:08:14 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 1279  total_loss: 0.3878  loss_cls: 0.07466  loss_box_reg: 0.1733  loss_mask: 0.1167  loss_rpn_cls: 0.001481  loss_rpn_loc: 0.01337  time: 0.9786  data_time: 0.3227  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:08:34 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1299  total_loss: 0.419  loss_cls: 0.08607  loss_box_reg: 0.1848  loss_mask: 0.1135  loss_rpn_cls: 0.001703  loss_rpn_loc: 0.01852  time: 0.9786  data_time: 0.3110  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:08:53 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 1319  total_loss: 0.3949  loss_cls: 0.1038  loss_box_reg: 0.1741  loss_mask: 0.1086  loss_rpn_cls: 0.001908  loss_rpn_loc: 0.01243  time: 0.9787  data_time: 0.3096  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 18:09:14 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1339  total_loss: 0.405  loss_cls: 0.07477  loss_box_reg: 0.1746  loss_mask: 0.1059  loss_rpn_cls: 0.001025  loss_rpn_loc: 0.01046  time: 0.9797  data_time: 0.3345  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:09:33 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 1359  total_loss: 0.3757  loss_cls: 0.07882  loss_box_reg: 0.1776  loss_mask: 0.1205  loss_rpn_cls: 0.001582  loss_rpn_loc: 0.01658  time: 0.9790  data_time: 0.2700  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:09:51 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1379  total_loss: 0.3903  loss_cls: 0.07986  loss_box_reg: 0.1777  loss_mask: 0.1043  loss_rpn_cls: 0.002192  loss_rpn_loc: 0.01587  time: 0.9783  data_time: 0.2743  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:10:11 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1399  total_loss: 0.3842  loss_cls: 0.07883  loss_box_reg: 0.1787  loss_mask: 0.1077  loss_rpn_cls: 0.001946  loss_rpn_loc: 0.01461  time: 0.9782  data_time: 0.2903  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:10:31 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.4054  loss_cls: 0.1035  loss_box_reg: 0.1721  loss_mask: 0.1115  loss_rpn_cls: 0.001382  loss_rpn_loc: 0.01486  time: 0.9783  data_time: 0.2873  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:10:51 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.3985  loss_cls: 0.06466  loss_box_reg: 0.179  loss_mask: 0.1135  loss_rpn_cls: 0.001415  loss_rpn_loc: 0.01386  time: 0.9785  data_time: 0.3299  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:11:10 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.4077  loss_cls: 0.07966  loss_box_reg: 0.1897  loss_mask: 0.1105  loss_rpn_cls: 0.001762  loss_rpn_loc: 0.01451  time: 0.9782  data_time: 0.2905  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:11:29 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.3859  loss_cls: 0.06523  loss_box_reg: 0.201  loss_mask: 0.1066  loss_rpn_cls: 0.001045  loss_rpn_loc: 0.01517  time: 0.9782  data_time: 0.3341  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:11:50 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.3697  loss_cls: 0.08761  loss_box_reg: 0.1803  loss_mask: 0.1012  loss_rpn_cls: 0.001538  loss_rpn_loc: 0.01442  time: 0.9781  data_time: 0.2852  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:11:50 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:25 (0.9781 s / it)\n",
      "\u001b[32m[03/04 18:11:50 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:27 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 18:11:51 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 18:11:51 d2.data.datasets.coco]: \u001b[0mLoaded 98 images in COCO format from /host/mic21-framework/server/uploads/motorcycle_racing_gt.json\n",
      "motorcycle_racing\n",
      "\u001b[32m[03/04 18:11:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 18:11:52 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 18:11:52 d2.data.datasets.coco]: \u001b[0mLoaded 98 images in COCO format from /host/mic21-framework/server/uploads/motorcycle_racing_gt.json\n",
      "\u001b[32m[03/04 18:11:52 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 98 images left.\n",
      "\u001b[32m[03/04 18:11:52 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:-------------:|:-------------|\n",
      "| motorcycle .. | 135          | race number | 112          | racing moto.. | 137          |\n",
      "| racing moto.. | 134          |             |              |               |              |\n",
      "|     total     | 518          |             |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 18:11:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 18:11:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 18:11:52 d2.data.common]: \u001b[0mSerializing 98 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 18:11:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.56 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 18:11:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 18:12:11 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 19  total_loss: 2.384  loss_cls: 0.8178  loss_box_reg: 0.9137  loss_mask: 0.6146  loss_rpn_cls: 0.06109  loss_rpn_loc: 0.02969  time: 0.9469  data_time: 0.3178  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:12:30 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 39  total_loss: 1.793  loss_cls: 0.5091  loss_box_reg: 0.8328  loss_mask: 0.431  loss_rpn_cls: 0.03029  loss_rpn_loc: 0.0283  time: 0.9417  data_time: 0.2556  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:12:49 d2.utils.events]: \u001b[0m eta: 0:22:40  iter: 59  total_loss: 1.453  loss_cls: 0.3524  loss_box_reg: 0.6573  loss_mask: 0.3207  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.02348  time: 0.9378  data_time: 0.2738  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:13:07 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 79  total_loss: 1.1  loss_cls: 0.2322  loss_box_reg: 0.5509  loss_mask: 0.2545  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.02454  time: 0.9342  data_time: 0.2672  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:13:26 d2.utils.events]: \u001b[0m eta: 0:21:57  iter: 99  total_loss: 1.014  loss_cls: 0.2424  loss_box_reg: 0.493  loss_mask: 0.2147  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.02058  time: 0.9317  data_time: 0.2674  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:13:44 d2.utils.events]: \u001b[0m eta: 0:21:39  iter: 119  total_loss: 1.007  loss_cls: 0.2442  loss_box_reg: 0.4798  loss_mask: 0.2351  loss_rpn_cls: 0.01482  loss_rpn_loc: 0.02525  time: 0.9329  data_time: 0.2838  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:14:03 d2.utils.events]: \u001b[0m eta: 0:21:18  iter: 139  total_loss: 0.9592  loss_cls: 0.2338  loss_box_reg: 0.4658  loss_mask: 0.2288  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.02272  time: 0.9328  data_time: 0.2634  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:14:21 d2.utils.events]: \u001b[0m eta: 0:20:56  iter: 159  total_loss: 0.893  loss_cls: 0.1979  loss_box_reg: 0.465  loss_mask: 0.2043  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.02688  time: 0.9315  data_time: 0.2801  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:14:40 d2.utils.events]: \u001b[0m eta: 0:20:37  iter: 179  total_loss: 0.8461  loss_cls: 0.2011  loss_box_reg: 0.4442  loss_mask: 0.2008  loss_rpn_cls: 0.008216  loss_rpn_loc: 0.02381  time: 0.9331  data_time: 0.2721  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:14:59 d2.utils.events]: \u001b[0m eta: 0:20:19  iter: 199  total_loss: 0.8316  loss_cls: 0.1762  loss_box_reg: 0.4178  loss_mask: 0.2095  loss_rpn_cls: 0.009322  loss_rpn_loc: 0.0258  time: 0.9346  data_time: 0.2730  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:15:18 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 219  total_loss: 0.7609  loss_cls: 0.1698  loss_box_reg: 0.3882  loss_mask: 0.1808  loss_rpn_cls: 0.008318  loss_rpn_loc: 0.0219  time: 0.9327  data_time: 0.2616  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:15:37 d2.utils.events]: \u001b[0m eta: 0:19:40  iter: 239  total_loss: 0.8404  loss_cls: 0.1793  loss_box_reg: 0.4001  loss_mask: 0.1979  loss_rpn_cls: 0.007805  loss_rpn_loc: 0.02134  time: 0.9340  data_time: 0.2454  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:15:55 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 259  total_loss: 0.7754  loss_cls: 0.1517  loss_box_reg: 0.3982  loss_mask: 0.1883  loss_rpn_cls: 0.008485  loss_rpn_loc: 0.02501  time: 0.9344  data_time: 0.2560  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:16:14 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 279  total_loss: 0.7347  loss_cls: 0.1984  loss_box_reg: 0.3527  loss_mask: 0.1799  loss_rpn_cls: 0.00683  loss_rpn_loc: 0.01964  time: 0.9350  data_time: 0.2723  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:16:33 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 299  total_loss: 0.7414  loss_cls: 0.1698  loss_box_reg: 0.3502  loss_mask: 0.1826  loss_rpn_cls: 0.004813  loss_rpn_loc: 0.02168  time: 0.9345  data_time: 0.2793  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:16:51 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 319  total_loss: 0.711  loss_cls: 0.1483  loss_box_reg: 0.3759  loss_mask: 0.1884  loss_rpn_cls: 0.007534  loss_rpn_loc: 0.02078  time: 0.9341  data_time: 0.2712  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:17:10 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 339  total_loss: 0.7193  loss_cls: 0.1484  loss_box_reg: 0.3473  loss_mask: 0.1804  loss_rpn_cls: 0.006517  loss_rpn_loc: 0.01818  time: 0.9347  data_time: 0.2559  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:17:28 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 359  total_loss: 0.7453  loss_cls: 0.1803  loss_box_reg: 0.3366  loss_mask: 0.1826  loss_rpn_cls: 0.00701  loss_rpn_loc: 0.02005  time: 0.9328  data_time: 0.2507  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:17:48 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 379  total_loss: 0.7042  loss_cls: 0.1647  loss_box_reg: 0.3594  loss_mask: 0.1613  loss_rpn_cls: 0.00406  loss_rpn_loc: 0.01789  time: 0.9345  data_time: 0.2774  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:18:06 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 399  total_loss: 0.6663  loss_cls: 0.117  loss_box_reg: 0.3361  loss_mask: 0.1627  loss_rpn_cls: 0.005319  loss_rpn_loc: 0.0211  time: 0.9338  data_time: 0.2647  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:18:25 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 419  total_loss: 0.6793  loss_cls: 0.1347  loss_box_reg: 0.3484  loss_mask: 0.168  loss_rpn_cls: 0.004909  loss_rpn_loc: 0.02162  time: 0.9337  data_time: 0.2523  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:18:44 d2.utils.events]: \u001b[0m eta: 0:16:36  iter: 439  total_loss: 0.6516  loss_cls: 0.1486  loss_box_reg: 0.3094  loss_mask: 0.1625  loss_rpn_cls: 0.003902  loss_rpn_loc: 0.02072  time: 0.9348  data_time: 0.2776  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:19:03 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 459  total_loss: 0.633  loss_cls: 0.1217  loss_box_reg: 0.2943  loss_mask: 0.1543  loss_rpn_cls: 0.005261  loss_rpn_loc: 0.02164  time: 0.9354  data_time: 0.2702  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:19:21 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 479  total_loss: 0.6813  loss_cls: 0.1579  loss_box_reg: 0.3492  loss_mask: 0.1591  loss_rpn_cls: 0.003022  loss_rpn_loc: 0.01606  time: 0.9339  data_time: 0.2628  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:19:39 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 499  total_loss: 0.5759  loss_cls: 0.146  loss_box_reg: 0.2886  loss_mask: 0.1452  loss_rpn_cls: 0.005083  loss_rpn_loc: 0.02155  time: 0.9324  data_time: 0.2577  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:19:57 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 519  total_loss: 0.6284  loss_cls: 0.1204  loss_box_reg: 0.3118  loss_mask: 0.1645  loss_rpn_cls: 0.006629  loss_rpn_loc: 0.02059  time: 0.9323  data_time: 0.2618  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:20:17 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 539  total_loss: 0.6403  loss_cls: 0.1146  loss_box_reg: 0.3186  loss_mask: 0.1578  loss_rpn_cls: 0.00348  loss_rpn_loc: 0.01807  time: 0.9332  data_time: 0.2691  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:20:35 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 559  total_loss: 0.5737  loss_cls: 0.1253  loss_box_reg: 0.2779  loss_mask: 0.1522  loss_rpn_cls: 0.002871  loss_rpn_loc: 0.01979  time: 0.9322  data_time: 0.2601  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:20:54 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 579  total_loss: 0.6399  loss_cls: 0.1509  loss_box_reg: 0.3099  loss_mask: 0.1586  loss_rpn_cls: 0.002878  loss_rpn_loc: 0.01723  time: 0.9334  data_time: 0.2976  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:21:13 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 599  total_loss: 0.5991  loss_cls: 0.125  loss_box_reg: 0.2976  loss_mask: 0.1547  loss_rpn_cls: 0.002426  loss_rpn_loc: 0.01721  time: 0.9340  data_time: 0.2886  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:21:32 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 619  total_loss: 0.6021  loss_cls: 0.1249  loss_box_reg: 0.2975  loss_mask: 0.1654  loss_rpn_cls: 0.003145  loss_rpn_loc: 0.01881  time: 0.9345  data_time: 0.2766  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:21:52 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 639  total_loss: 0.5849  loss_cls: 0.1136  loss_box_reg: 0.2805  loss_mask: 0.163  loss_rpn_cls: 0.00356  loss_rpn_loc: 0.02007  time: 0.9361  data_time: 0.3154  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:22:11 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 659  total_loss: 0.5564  loss_cls: 0.1125  loss_box_reg: 0.2866  loss_mask: 0.1377  loss_rpn_cls: 0.002576  loss_rpn_loc: 0.01654  time: 0.9366  data_time: 0.2831  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 18:22:29 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 679  total_loss: 0.5709  loss_cls: 0.1073  loss_box_reg: 0.2706  loss_mask: 0.1499  loss_rpn_cls: 0.002499  loss_rpn_loc: 0.01703  time: 0.9361  data_time: 0.2854  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:22:49 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 699  total_loss: 0.5246  loss_cls: 0.1002  loss_box_reg: 0.2661  loss_mask: 0.137  loss_rpn_cls: 0.002482  loss_rpn_loc: 0.01928  time: 0.9373  data_time: 0.2923  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:23:08 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 719  total_loss: 0.5128  loss_cls: 0.1011  loss_box_reg: 0.2718  loss_mask: 0.1338  loss_rpn_cls: 0.002458  loss_rpn_loc: 0.0184  time: 0.9378  data_time: 0.2943  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:23:27 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 739  total_loss: 0.5554  loss_cls: 0.108  loss_box_reg: 0.2795  loss_mask: 0.1531  loss_rpn_cls: 0.001332  loss_rpn_loc: 0.01721  time: 0.9381  data_time: 0.2985  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:23:46 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 759  total_loss: 0.5412  loss_cls: 0.0961  loss_box_reg: 0.2811  loss_mask: 0.1416  loss_rpn_cls: 0.002691  loss_rpn_loc: 0.01448  time: 0.9390  data_time: 0.3031  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:24:05 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 779  total_loss: 0.5523  loss_cls: 0.1268  loss_box_reg: 0.277  loss_mask: 0.1379  loss_rpn_cls: 0.004872  loss_rpn_loc: 0.01627  time: 0.9387  data_time: 0.2857  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:24:24 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 799  total_loss: 0.5846  loss_cls: 0.1122  loss_box_reg: 0.2847  loss_mask: 0.14  loss_rpn_cls: 0.002309  loss_rpn_loc: 0.02166  time: 0.9387  data_time: 0.3033  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:24:43 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 819  total_loss: 0.5318  loss_cls: 0.1121  loss_box_reg: 0.2716  loss_mask: 0.1387  loss_rpn_cls: 0.002107  loss_rpn_loc: 0.01575  time: 0.9396  data_time: 0.2926  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:25:02 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 839  total_loss: 0.5407  loss_cls: 0.1035  loss_box_reg: 0.2796  loss_mask: 0.1393  loss_rpn_cls: 0.00159  loss_rpn_loc: 0.01783  time: 0.9397  data_time: 0.2885  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:25:22 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 859  total_loss: 0.5165  loss_cls: 0.09848  loss_box_reg: 0.2457  loss_mask: 0.1492  loss_rpn_cls: 0.00295  loss_rpn_loc: 0.01769  time: 0.9408  data_time: 0.3058  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:25:40 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 879  total_loss: 0.525  loss_cls: 0.09718  loss_box_reg: 0.2685  loss_mask: 0.1433  loss_rpn_cls: 0.001946  loss_rpn_loc: 0.01936  time: 0.9405  data_time: 0.2655  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:25:59 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 899  total_loss: 0.5105  loss_cls: 0.09763  loss_box_reg: 0.2654  loss_mask: 0.1462  loss_rpn_cls: 0.001981  loss_rpn_loc: 0.01706  time: 0.9405  data_time: 0.2714  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:26:18 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 919  total_loss: 0.5242  loss_cls: 0.09315  loss_box_reg: 0.2949  loss_mask: 0.1373  loss_rpn_cls: 0.002731  loss_rpn_loc: 0.0173  time: 0.9402  data_time: 0.2650  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:26:37 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 939  total_loss: 0.4804  loss_cls: 0.07374  loss_box_reg: 0.2522  loss_mask: 0.132  loss_rpn_cls: 0.001709  loss_rpn_loc: 0.0166  time: 0.9408  data_time: 0.3101  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:26:57 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 959  total_loss: 0.533  loss_cls: 0.09319  loss_box_reg: 0.2465  loss_mask: 0.146  loss_rpn_cls: 0.00231  loss_rpn_loc: 0.01791  time: 0.9413  data_time: 0.3127  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:27:16 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 979  total_loss: 0.5062  loss_cls: 0.1037  loss_box_reg: 0.2627  loss_mask: 0.1308  loss_rpn_cls: 0.001173  loss_rpn_loc: 0.01546  time: 0.9415  data_time: 0.2838  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:27:34 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 999  total_loss: 0.5393  loss_cls: 0.09586  loss_box_reg: 0.277  loss_mask: 0.1469  loss_rpn_cls: 0.001491  loss_rpn_loc: 0.01744  time: 0.9416  data_time: 0.2990  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:27:53 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 1019  total_loss: 0.4761  loss_cls: 0.1042  loss_box_reg: 0.2377  loss_mask: 0.138  loss_rpn_cls: 0.002517  loss_rpn_loc: 0.01312  time: 0.9417  data_time: 0.2799  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:28:13 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 1039  total_loss: 0.4808  loss_cls: 0.1108  loss_box_reg: 0.2257  loss_mask: 0.1311  loss_rpn_cls: 0.002185  loss_rpn_loc: 0.01609  time: 0.9421  data_time: 0.2987  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:28:32 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 1059  total_loss: 0.4591  loss_cls: 0.07662  loss_box_reg: 0.2131  loss_mask: 0.1384  loss_rpn_cls: 0.002918  loss_rpn_loc: 0.01881  time: 0.9427  data_time: 0.3025  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:28:51 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 1079  total_loss: 0.4958  loss_cls: 0.1086  loss_box_reg: 0.217  loss_mask: 0.1298  loss_rpn_cls: 0.001963  loss_rpn_loc: 0.01422  time: 0.9429  data_time: 0.2845  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:29:10 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 1099  total_loss: 0.48  loss_cls: 0.07969  loss_box_reg: 0.2272  loss_mask: 0.1465  loss_rpn_cls: 0.002541  loss_rpn_loc: 0.0147  time: 0.9431  data_time: 0.3001  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:29:29 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 1119  total_loss: 0.432  loss_cls: 0.08884  loss_box_reg: 0.203  loss_mask: 0.1315  loss_rpn_cls: 0.001761  loss_rpn_loc: 0.01389  time: 0.9433  data_time: 0.2794  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:29:49 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 1139  total_loss: 0.4809  loss_cls: 0.08726  loss_box_reg: 0.2022  loss_mask: 0.1334  loss_rpn_cls: 0.001848  loss_rpn_loc: 0.01391  time: 0.9438  data_time: 0.3118  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:30:08 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 1159  total_loss: 0.4485  loss_cls: 0.07555  loss_box_reg: 0.2147  loss_mask: 0.1457  loss_rpn_cls: 0.002095  loss_rpn_loc: 0.01573  time: 0.9441  data_time: 0.2907  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:30:27 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 1179  total_loss: 0.4526  loss_cls: 0.08824  loss_box_reg: 0.2107  loss_mask: 0.1331  loss_rpn_cls: 0.001962  loss_rpn_loc: 0.01628  time: 0.9445  data_time: 0.2915  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:30:48 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 1199  total_loss: 0.4566  loss_cls: 0.08517  loss_box_reg: 0.2011  loss_mask: 0.138  loss_rpn_cls: 0.00196  loss_rpn_loc: 0.0162  time: 0.9455  data_time: 0.3234  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:31:07 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 1219  total_loss: 0.4198  loss_cls: 0.06802  loss_box_reg: 0.2067  loss_mask: 0.1412  loss_rpn_cls: 0.002455  loss_rpn_loc: 0.01664  time: 0.9459  data_time: 0.2820  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:31:26 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 1239  total_loss: 0.4242  loss_cls: 0.09866  loss_box_reg: 0.1968  loss_mask: 0.1226  loss_rpn_cls: 0.00163  loss_rpn_loc: 0.01514  time: 0.9460  data_time: 0.2936  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:31:46 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 1259  total_loss: 0.4091  loss_cls: 0.0725  loss_box_reg: 0.1908  loss_mask: 0.1217  loss_rpn_cls: 0.001654  loss_rpn_loc: 0.01548  time: 0.9468  data_time: 0.2852  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:32:05 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 1279  total_loss: 0.4283  loss_cls: 0.0839  loss_box_reg: 0.1887  loss_mask: 0.1345  loss_rpn_cls: 0.001703  loss_rpn_loc: 0.01701  time: 0.9465  data_time: 0.2868  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:32:24 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 1299  total_loss: 0.4181  loss_cls: 0.08656  loss_box_reg: 0.2003  loss_mask: 0.1394  loss_rpn_cls: 0.001903  loss_rpn_loc: 0.01564  time: 0.9466  data_time: 0.2988  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:32:43 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 1319  total_loss: 0.4447  loss_cls: 0.0747  loss_box_reg: 0.2047  loss_mask: 0.1303  loss_rpn_cls: 0.001975  loss_rpn_loc: 0.01475  time: 0.9468  data_time: 0.3021  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 18:33:01 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 1339  total_loss: 0.4316  loss_cls: 0.07417  loss_box_reg: 0.1942  loss_mask: 0.1322  loss_rpn_cls: 0.001817  loss_rpn_loc: 0.01543  time: 0.9461  data_time: 0.2538  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:33:20 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 1359  total_loss: 0.3997  loss_cls: 0.07198  loss_box_reg: 0.1818  loss_mask: 0.1288  loss_rpn_cls: 0.001814  loss_rpn_loc: 0.01497  time: 0.9466  data_time: 0.2879  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:33:39 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 1379  total_loss: 0.3967  loss_cls: 0.07283  loss_box_reg: 0.1872  loss_mask: 0.1121  loss_rpn_cls: 0.001476  loss_rpn_loc: 0.01109  time: 0.9463  data_time: 0.2847  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:33:59 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 1399  total_loss: 0.4259  loss_cls: 0.07641  loss_box_reg: 0.1834  loss_mask: 0.1366  loss_rpn_cls: 0.001588  loss_rpn_loc: 0.01612  time: 0.9468  data_time: 0.3080  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:34:17 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 1419  total_loss: 0.4566  loss_cls: 0.09458  loss_box_reg: 0.1999  loss_mask: 0.1307  loss_rpn_cls: 0.002402  loss_rpn_loc: 0.01396  time: 0.9466  data_time: 0.3036  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:34:36 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 1439  total_loss: 0.4434  loss_cls: 0.08497  loss_box_reg: 0.1993  loss_mask: 0.1364  loss_rpn_cls: 0.00136  loss_rpn_loc: 0.01419  time: 0.9465  data_time: 0.2867  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:34:56 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 1459  total_loss: 0.3885  loss_cls: 0.07156  loss_box_reg: 0.1786  loss_mask: 0.1285  loss_rpn_cls: 0.001128  loss_rpn_loc: 0.01433  time: 0.9469  data_time: 0.3049  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:35:14 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.4331  loss_cls: 0.08359  loss_box_reg: 0.1981  loss_mask: 0.1272  loss_rpn_cls: 0.001649  loss_rpn_loc: 0.01866  time: 0.9467  data_time: 0.2848  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:35:35 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4056  loss_cls: 0.06464  loss_box_reg: 0.1792  loss_mask: 0.1338  loss_rpn_cls: 0.001497  loss_rpn_loc: 0.01557  time: 0.9470  data_time: 0.2877  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:35:35 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:23:38 (0.9470 s / it)\n",
      "\u001b[32m[03/04 18:35:35 d2.engine.hooks]: \u001b[0mTotal training time: 0:23:41 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 18:35:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 18:35:36 d2.data.datasets.coco]: \u001b[0mLoaded 168 images in COCO format from /host/mic21-framework/server/uploads/baby_carriage_gt.json\n",
      "baby_carriage\n",
      "\u001b[32m[03/04 18:35:37 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 18:35:37 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 18:35:37 d2.data.datasets.coco]: \u001b[0mLoaded 168 images in COCO format from /host/mic21-framework/server/uploads/baby_carriage_gt.json\n",
      "\u001b[32m[03/04 18:35:37 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 168 images left.\n",
      "\u001b[32m[03/04 18:35:37 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|     baby      | 81           |    man     | 79           |   woman    | 126          |\n",
      "| baby carriage | 197          | baby shoe  | 76           |            |              |\n",
      "|     total     | 559          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 18:35:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 18:35:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 18:35:37 d2.data.common]: \u001b[0mSerializing 168 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 18:35:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.01 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 18:35:37 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 18:35:54 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 19  total_loss: 2.37  loss_cls: 0.8102  loss_box_reg: 0.9175  loss_mask: 0.6322  loss_rpn_cls: 0.02232  loss_rpn_loc: 0.02774  time: 0.8423  data_time: 0.1784  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:36:12 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 39  total_loss: 1.81  loss_cls: 0.5019  loss_box_reg: 0.8659  loss_mask: 0.4192  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.02447  time: 0.8720  data_time: 0.2462  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:36:30 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 59  total_loss: 1.448  loss_cls: 0.4192  loss_box_reg: 0.6494  loss_mask: 0.3169  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.02404  time: 0.8711  data_time: 0.2055  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:36:47 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 79  total_loss: 1.324  loss_cls: 0.3535  loss_box_reg: 0.5916  loss_mask: 0.266  loss_rpn_cls: 0.009954  loss_rpn_loc: 0.03385  time: 0.8659  data_time: 0.1545  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:37:03 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 99  total_loss: 1.165  loss_cls: 0.3191  loss_box_reg: 0.6061  loss_mask: 0.2329  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.02325  time: 0.8580  data_time: 0.1622  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:37:20 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 119  total_loss: 1.014  loss_cls: 0.2923  loss_box_reg: 0.4899  loss_mask: 0.21  loss_rpn_cls: 0.007608  loss_rpn_loc: 0.024  time: 0.8542  data_time: 0.1584  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:37:38 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 139  total_loss: 1.004  loss_cls: 0.2872  loss_box_reg: 0.4465  loss_mask: 0.2169  loss_rpn_cls: 0.009651  loss_rpn_loc: 0.03063  time: 0.8585  data_time: 0.2067  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:37:56 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 159  total_loss: 1  loss_cls: 0.2863  loss_box_reg: 0.5019  loss_mask: 0.1921  loss_rpn_cls: 0.005083  loss_rpn_loc: 0.01903  time: 0.8659  data_time: 0.2397  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:38:14 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 179  total_loss: 0.8239  loss_cls: 0.2176  loss_box_reg: 0.4209  loss_mask: 0.1812  loss_rpn_cls: 0.009976  loss_rpn_loc: 0.02524  time: 0.8721  data_time: 0.2185  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:38:32 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 199  total_loss: 0.9211  loss_cls: 0.2234  loss_box_reg: 0.4255  loss_mask: 0.1906  loss_rpn_cls: 0.00842  loss_rpn_loc: 0.02443  time: 0.8719  data_time: 0.1929  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:38:49 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 219  total_loss: 0.8766  loss_cls: 0.2579  loss_box_reg: 0.3887  loss_mask: 0.1882  loss_rpn_cls: 0.004134  loss_rpn_loc: 0.02582  time: 0.8703  data_time: 0.1740  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:39:06 d2.utils.events]: \u001b[0m eta: 0:17:52  iter: 239  total_loss: 0.8194  loss_cls: 0.2374  loss_box_reg: 0.3952  loss_mask: 0.1742  loss_rpn_cls: 0.007419  loss_rpn_loc: 0.02396  time: 0.8683  data_time: 0.1695  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:39:23 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 259  total_loss: 0.7715  loss_cls: 0.2102  loss_box_reg: 0.355  loss_mask: 0.1658  loss_rpn_cls: 0.006077  loss_rpn_loc: 0.03189  time: 0.8669  data_time: 0.1801  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:39:40 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 279  total_loss: 0.7632  loss_cls: 0.1928  loss_box_reg: 0.3679  loss_mask: 0.1675  loss_rpn_cls: 0.004337  loss_rpn_loc: 0.01986  time: 0.8660  data_time: 0.1832  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:39:57 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 299  total_loss: 0.7821  loss_cls: 0.1931  loss_box_reg: 0.3608  loss_mask: 0.1633  loss_rpn_cls: 0.007292  loss_rpn_loc: 0.02043  time: 0.8648  data_time: 0.1683  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:40:14 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 319  total_loss: 0.6761  loss_cls: 0.1761  loss_box_reg: 0.3302  loss_mask: 0.1591  loss_rpn_cls: 0.004724  loss_rpn_loc: 0.02207  time: 0.8648  data_time: 0.1908  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:40:31 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 339  total_loss: 0.7483  loss_cls: 0.2066  loss_box_reg: 0.3525  loss_mask: 0.1576  loss_rpn_cls: 0.004063  loss_rpn_loc: 0.02532  time: 0.8623  data_time: 0.1634  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:40:48 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 359  total_loss: 0.7101  loss_cls: 0.1746  loss_box_reg: 0.3403  loss_mask: 0.1696  loss_rpn_cls: 0.003582  loss_rpn_loc: 0.02427  time: 0.8619  data_time: 0.2136  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:41:05 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 379  total_loss: 0.7467  loss_cls: 0.2068  loss_box_reg: 0.3471  loss_mask: 0.1628  loss_rpn_cls: 0.004933  loss_rpn_loc: 0.02179  time: 0.8607  data_time: 0.1716  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:41:23 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 399  total_loss: 0.6493  loss_cls: 0.1941  loss_box_reg: 0.3147  loss_mask: 0.1519  loss_rpn_cls: 0.004902  loss_rpn_loc: 0.01782  time: 0.8626  data_time: 0.2168  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:41:40 d2.utils.events]: \u001b[0m eta: 0:15:04  iter: 419  total_loss: 0.6678  loss_cls: 0.1791  loss_box_reg: 0.3232  loss_mask: 0.1485  loss_rpn_cls: 0.004064  loss_rpn_loc: 0.02126  time: 0.8622  data_time: 0.1657  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:41:58 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 439  total_loss: 0.6192  loss_cls: 0.1366  loss_box_reg: 0.3196  loss_mask: 0.1401  loss_rpn_cls: 0.004152  loss_rpn_loc: 0.02204  time: 0.8637  data_time: 0.1964  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:42:15 d2.utils.events]: \u001b[0m eta: 0:14:34  iter: 459  total_loss: 0.6829  loss_cls: 0.1761  loss_box_reg: 0.3284  loss_mask: 0.1538  loss_rpn_cls: 0.004435  loss_rpn_loc: 0.02019  time: 0.8635  data_time: 0.1992  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:42:32 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 479  total_loss: 0.6546  loss_cls: 0.1565  loss_box_reg: 0.3057  loss_mask: 0.1431  loss_rpn_cls: 0.005864  loss_rpn_loc: 0.02166  time: 0.8634  data_time: 0.1897  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:42:49 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 499  total_loss: 0.6548  loss_cls: 0.1855  loss_box_reg: 0.2994  loss_mask: 0.1506  loss_rpn_cls: 0.003606  loss_rpn_loc: 0.02288  time: 0.8618  data_time: 0.1532  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:43:05 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 519  total_loss: 0.6701  loss_cls: 0.1784  loss_box_reg: 0.2993  loss_mask: 0.1384  loss_rpn_cls: 0.006456  loss_rpn_loc: 0.02155  time: 0.8608  data_time: 0.1440  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:43:23 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 539  total_loss: 0.6104  loss_cls: 0.1384  loss_box_reg: 0.295  loss_mask: 0.1559  loss_rpn_cls: 0.002617  loss_rpn_loc: 0.01862  time: 0.8621  data_time: 0.2220  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:43:40 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 559  total_loss: 0.6494  loss_cls: 0.1564  loss_box_reg: 0.3003  loss_mask: 0.1347  loss_rpn_cls: 0.003261  loss_rpn_loc: 0.02106  time: 0.8619  data_time: 0.1912  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:43:58 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 579  total_loss: 0.5645  loss_cls: 0.1397  loss_box_reg: 0.2828  loss_mask: 0.1413  loss_rpn_cls: 0.003226  loss_rpn_loc: 0.01847  time: 0.8620  data_time: 0.1813  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:44:16 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 599  total_loss: 0.6426  loss_cls: 0.1637  loss_box_reg: 0.3112  loss_mask: 0.1484  loss_rpn_cls: 0.003168  loss_rpn_loc: 0.02473  time: 0.8639  data_time: 0.2325  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:44:33 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 619  total_loss: 0.5854  loss_cls: 0.1507  loss_box_reg: 0.2798  loss_mask: 0.1321  loss_rpn_cls: 0.003064  loss_rpn_loc: 0.0219  time: 0.8637  data_time: 0.1772  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:44:49 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 639  total_loss: 0.6398  loss_cls: 0.1619  loss_box_reg: 0.2901  loss_mask: 0.1592  loss_rpn_cls: 0.002467  loss_rpn_loc: 0.0236  time: 0.8617  data_time: 0.1546  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:45:07 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 659  total_loss: 0.5324  loss_cls: 0.1262  loss_box_reg: 0.2693  loss_mask: 0.1241  loss_rpn_cls: 0.00243  loss_rpn_loc: 0.02153  time: 0.8624  data_time: 0.2298  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 18:45:23 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 679  total_loss: 0.5653  loss_cls: 0.1197  loss_box_reg: 0.2571  loss_mask: 0.131  loss_rpn_cls: 0.00231  loss_rpn_loc: 0.0235  time: 0.8612  data_time: 0.1522  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:45:40 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 699  total_loss: 0.6192  loss_cls: 0.169  loss_box_reg: 0.2903  loss_mask: 0.1374  loss_rpn_cls: 0.002356  loss_rpn_loc: 0.0143  time: 0.8597  data_time: 0.1695  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:45:56 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 719  total_loss: 0.6139  loss_cls: 0.1377  loss_box_reg: 0.2865  loss_mask: 0.1444  loss_rpn_cls: 0.004951  loss_rpn_loc: 0.02298  time: 0.8587  data_time: 0.1752  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:46:13 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 739  total_loss: 0.5924  loss_cls: 0.1544  loss_box_reg: 0.2752  loss_mask: 0.1354  loss_rpn_cls: 0.004359  loss_rpn_loc: 0.02159  time: 0.8584  data_time: 0.1746  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:46:30 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 759  total_loss: 0.5593  loss_cls: 0.1373  loss_box_reg: 0.269  loss_mask: 0.1451  loss_rpn_cls: 0.003209  loss_rpn_loc: 0.01732  time: 0.8580  data_time: 0.1722  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:46:47 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 779  total_loss: 0.5692  loss_cls: 0.1464  loss_box_reg: 0.2791  loss_mask: 0.1239  loss_rpn_cls: 0.002256  loss_rpn_loc: 0.02238  time: 0.8582  data_time: 0.1643  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:47:04 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 799  total_loss: 0.583  loss_cls: 0.1238  loss_box_reg: 0.262  loss_mask: 0.1397  loss_rpn_cls: 0.00328  loss_rpn_loc: 0.01766  time: 0.8573  data_time: 0.1615  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:47:22 d2.utils.events]: \u001b[0m eta: 0:09:32  iter: 819  total_loss: 0.5539  loss_cls: 0.13  loss_box_reg: 0.2611  loss_mask: 0.126  loss_rpn_cls: 0.002119  loss_rpn_loc: 0.01909  time: 0.8589  data_time: 0.2259  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:47:39 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 839  total_loss: 0.6044  loss_cls: 0.131  loss_box_reg: 0.2988  loss_mask: 0.1441  loss_rpn_cls: 0.003619  loss_rpn_loc: 0.02071  time: 0.8585  data_time: 0.1692  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:47:56 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 859  total_loss: 0.5482  loss_cls: 0.1255  loss_box_reg: 0.2658  loss_mask: 0.1329  loss_rpn_cls: 0.002872  loss_rpn_loc: 0.02093  time: 0.8580  data_time: 0.1814  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:48:12 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 879  total_loss: 0.5599  loss_cls: 0.128  loss_box_reg: 0.2539  loss_mask: 0.1287  loss_rpn_cls: 0.002813  loss_rpn_loc: 0.02059  time: 0.8569  data_time: 0.1650  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:48:30 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 899  total_loss: 0.5807  loss_cls: 0.1417  loss_box_reg: 0.2732  loss_mask: 0.1414  loss_rpn_cls: 0.002413  loss_rpn_loc: 0.02314  time: 0.8579  data_time: 0.2052  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:48:47 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 919  total_loss: 0.5159  loss_cls: 0.1437  loss_box_reg: 0.2499  loss_mask: 0.1252  loss_rpn_cls: 0.002223  loss_rpn_loc: 0.01939  time: 0.8574  data_time: 0.1810  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:49:03 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 939  total_loss: 0.534  loss_cls: 0.1205  loss_box_reg: 0.2343  loss_mask: 0.1473  loss_rpn_cls: 0.003027  loss_rpn_loc: 0.01404  time: 0.8566  data_time: 0.1570  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:49:20 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 959  total_loss: 0.5286  loss_cls: 0.1049  loss_box_reg: 0.2588  loss_mask: 0.1173  loss_rpn_cls: 0.00336  loss_rpn_loc: 0.01817  time: 0.8567  data_time: 0.2049  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:49:37 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 979  total_loss: 0.5685  loss_cls: 0.1359  loss_box_reg: 0.254  loss_mask: 0.1409  loss_rpn_cls: 0.004169  loss_rpn_loc: 0.02198  time: 0.8562  data_time: 0.1696  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:49:54 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 999  total_loss: 0.5385  loss_cls: 0.09517  loss_box_reg: 0.2634  loss_mask: 0.1416  loss_rpn_cls: 0.002239  loss_rpn_loc: 0.01683  time: 0.8560  data_time: 0.1876  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:50:11 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 1019  total_loss: 0.5498  loss_cls: 0.1147  loss_box_reg: 0.26  loss_mask: 0.1371  loss_rpn_cls: 0.003647  loss_rpn_loc: 0.01813  time: 0.8560  data_time: 0.1799  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:50:28 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 1039  total_loss: 0.4876  loss_cls: 0.124  loss_box_reg: 0.2151  loss_mask: 0.1224  loss_rpn_cls: 0.002584  loss_rpn_loc: 0.01834  time: 0.8560  data_time: 0.1835  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:50:46 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 1059  total_loss: 0.4739  loss_cls: 0.09944  loss_box_reg: 0.2046  loss_mask: 0.1206  loss_rpn_cls: 0.002267  loss_rpn_loc: 0.01807  time: 0.8561  data_time: 0.2012  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:51:03 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 1079  total_loss: 0.4951  loss_cls: 0.1266  loss_box_reg: 0.2341  loss_mask: 0.1222  loss_rpn_cls: 0.00249  loss_rpn_loc: 0.02156  time: 0.8564  data_time: 0.2108  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:51:20 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1099  total_loss: 0.4612  loss_cls: 0.122  loss_box_reg: 0.2077  loss_mask: 0.1239  loss_rpn_cls: 0.00245  loss_rpn_loc: 0.02086  time: 0.8562  data_time: 0.1757  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:51:37 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 1119  total_loss: 0.4944  loss_cls: 0.1068  loss_box_reg: 0.2237  loss_mask: 0.1166  loss_rpn_cls: 0.003081  loss_rpn_loc: 0.01767  time: 0.8560  data_time: 0.1999  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:51:55 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 1139  total_loss: 0.4537  loss_cls: 0.09896  loss_box_reg: 0.1935  loss_mask: 0.1249  loss_rpn_cls: 0.002284  loss_rpn_loc: 0.02661  time: 0.8568  data_time: 0.2014  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:52:12 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 1159  total_loss: 0.4305  loss_cls: 0.07879  loss_box_reg: 0.2122  loss_mask: 0.1154  loss_rpn_cls: 0.002393  loss_rpn_loc: 0.01895  time: 0.8568  data_time: 0.1742  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:52:29 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 1179  total_loss: 0.5098  loss_cls: 0.1451  loss_box_reg: 0.2121  loss_mask: 0.1225  loss_rpn_cls: 0.003677  loss_rpn_loc: 0.0171  time: 0.8565  data_time: 0.1758  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:52:46 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 1199  total_loss: 0.4332  loss_cls: 0.09166  loss_box_reg: 0.2054  loss_mask: 0.1202  loss_rpn_cls: 0.003047  loss_rpn_loc: 0.01973  time: 0.8569  data_time: 0.2037  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:53:04 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 1219  total_loss: 0.4842  loss_cls: 0.12  loss_box_reg: 0.2253  loss_mask: 0.1158  loss_rpn_cls: 0.00247  loss_rpn_loc: 0.01899  time: 0.8577  data_time: 0.2142  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:53:22 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 1239  total_loss: 0.4197  loss_cls: 0.0896  loss_box_reg: 0.1843  loss_mask: 0.1126  loss_rpn_cls: 0.002094  loss_rpn_loc: 0.02068  time: 0.8577  data_time: 0.1849  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:53:39 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 1259  total_loss: 0.451  loss_cls: 0.1037  loss_box_reg: 0.2128  loss_mask: 0.1215  loss_rpn_cls: 0.002855  loss_rpn_loc: 0.01585  time: 0.8575  data_time: 0.1704  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:53:56 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 1279  total_loss: 0.4552  loss_cls: 0.1044  loss_box_reg: 0.2039  loss_mask: 0.1297  loss_rpn_cls: 0.002149  loss_rpn_loc: 0.01752  time: 0.8579  data_time: 0.2029  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:54:13 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 1299  total_loss: 0.4556  loss_cls: 0.1164  loss_box_reg: 0.2064  loss_mask: 0.1206  loss_rpn_cls: 0.001838  loss_rpn_loc: 0.02156  time: 0.8573  data_time: 0.1485  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:54:30 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 1319  total_loss: 0.4299  loss_cls: 0.1014  loss_box_reg: 0.1965  loss_mask: 0.1111  loss_rpn_cls: 0.002229  loss_rpn_loc: 0.02178  time: 0.8571  data_time: 0.1866  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 18:54:46 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 1339  total_loss: 0.4292  loss_cls: 0.09487  loss_box_reg: 0.194  loss_mask: 0.124  loss_rpn_cls: 0.002247  loss_rpn_loc: 0.01707  time: 0.8564  data_time: 0.1595  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:55:02 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 1359  total_loss: 0.4675  loss_cls: 0.09738  loss_box_reg: 0.2081  loss_mask: 0.1264  loss_rpn_cls: 0.003158  loss_rpn_loc: 0.02049  time: 0.8558  data_time: 0.1623  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:55:19 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 1379  total_loss: 0.4591  loss_cls: 0.1085  loss_box_reg: 0.211  loss_mask: 0.1255  loss_rpn_cls: 0.002089  loss_rpn_loc: 0.01526  time: 0.8559  data_time: 0.1771  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:55:36 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 1399  total_loss: 0.4084  loss_cls: 0.09252  loss_box_reg: 0.1782  loss_mask: 0.1086  loss_rpn_cls: 0.001688  loss_rpn_loc: 0.02092  time: 0.8558  data_time: 0.1786  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 18:55:54 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 1419  total_loss: 0.4703  loss_cls: 0.1075  loss_box_reg: 0.2021  loss_mask: 0.1369  loss_rpn_cls: 0.002666  loss_rpn_loc: 0.01782  time: 0.8558  data_time: 0.1905  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:56:12 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 1439  total_loss: 0.4451  loss_cls: 0.1455  loss_box_reg: 0.1845  loss_mask: 0.1263  loss_rpn_cls: 0.002215  loss_rpn_loc: 0.01613  time: 0.8566  data_time: 0.2410  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:56:29 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 1459  total_loss: 0.437  loss_cls: 0.104  loss_box_reg: 0.1857  loss_mask: 0.1116  loss_rpn_cls: 0.001789  loss_rpn_loc: 0.0167  time: 0.8567  data_time: 0.1933  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:56:47 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 1479  total_loss: 0.4329  loss_cls: 0.0804  loss_box_reg: 0.1933  loss_mask: 0.1161  loss_rpn_cls: 0.001996  loss_rpn_loc: 0.01818  time: 0.8574  data_time: 0.2225  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:57:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.474  loss_cls: 0.115  loss_box_reg: 0.1944  loss_mask: 0.1229  loss_rpn_cls: 0.002746  loss_rpn_loc: 0.01992  time: 0.8571  data_time: 0.1635  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 18:57:06 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:24 (0.8572 s / it)\n",
      "\u001b[32m[03/04 18:57:06 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:26 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 18:57:06 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 18:57:06 d2.data.datasets.coco]: \u001b[0mLoaded 297 images in COCO format from /host/mic21-framework/server/uploads/fire_engine_gt.json\n",
      "fire_engine\n",
      "\u001b[32m[03/04 18:57:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=21, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=80, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 18:57:07 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 18:57:07 d2.data.datasets.coco]: \u001b[0mLoaded 297 images in COCO format from /host/mic21-framework/server/uploads/fire_engine_gt.json\n",
      "\u001b[32m[03/04 18:57:07 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 297 images left.\n",
      "\u001b[32m[03/04 18:57:07 d2.data.build]: \u001b[0mDistribution of instances among all 20 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      man      | 70           |     woman     | 70           |      car      | 297          |\n",
      "|    person     | 153          | traffic light | 54           |   hard hat    | 75           |\n",
      "| emergency s.. | 867          | extension l.. | 135          | fire engine.. | 1126         |\n",
      "| fire engine.. | 552          | fire engine.. | 810          | fire engine.. | 446          |\n",
      "| fire engine.. | 333          | aerial ladder | 52           | bunker jacket | 54           |\n",
      "|  bunker boot  | 63           |  fire engine  | 360          |    fireman    | 239          |\n",
      "| fire engine.. | 204          | bunker trou.. | 59           |               |              |\n",
      "|     total     | 6019         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 18:57:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 18:57:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 18:57:07 d2.data.common]: \u001b[0mSerializing 297 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 18:57:07 d2.data.common]: \u001b[0mSerialized dataset takes 3.04 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (21, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (21,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (80, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (80,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (20, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 18:57:08 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 18:57:28 d2.utils.events]: \u001b[0m eta: 0:25:36  iter: 19  total_loss: 3.407  loss_cls: 1.458  loss_box_reg: 0.8067  loss_mask: 0.6684  loss_rpn_cls: 0.2108  loss_rpn_loc: 0.264  time: 1.0060  data_time: 0.3526  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:57:48 d2.utils.events]: \u001b[0m eta: 0:24:42  iter: 39  total_loss: 2.909  loss_cls: 1.082  loss_box_reg: 0.7973  loss_mask: 0.5728  loss_rpn_cls: 0.1643  loss_rpn_loc: 0.2683  time: 0.9961  data_time: 0.2909  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:58:07 d2.utils.events]: \u001b[0m eta: 0:24:03  iter: 59  total_loss: 2.414  loss_cls: 0.8854  loss_box_reg: 0.7938  loss_mask: 0.4759  loss_rpn_cls: 0.1211  loss_rpn_loc: 0.2439  time: 0.9861  data_time: 0.2864  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:58:27 d2.utils.events]: \u001b[0m eta: 0:23:29  iter: 79  total_loss: 2.236  loss_cls: 0.7259  loss_box_reg: 0.7787  loss_mask: 0.3823  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.2103  time: 0.9863  data_time: 0.2980  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:58:48 d2.utils.events]: \u001b[0m eta: 0:23:27  iter: 99  total_loss: 1.969  loss_cls: 0.578  loss_box_reg: 0.6465  loss_mask: 0.3277  loss_rpn_cls: 0.1185  loss_rpn_loc: 0.2496  time: 0.9953  data_time: 0.3211  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:59:07 d2.utils.events]: \u001b[0m eta: 0:22:54  iter: 119  total_loss: 2.005  loss_cls: 0.5772  loss_box_reg: 0.7095  loss_mask: 0.321  loss_rpn_cls: 0.1135  loss_rpn_loc: 0.2249  time: 0.9923  data_time: 0.2884  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:59:27 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 139  total_loss: 1.871  loss_cls: 0.5333  loss_box_reg: 0.6694  loss_mask: 0.3237  loss_rpn_cls: 0.1175  loss_rpn_loc: 0.2323  time: 0.9912  data_time: 0.2882  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 18:59:47 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 159  total_loss: 1.847  loss_cls: 0.5069  loss_box_reg: 0.6746  loss_mask: 0.2909  loss_rpn_cls: 0.09092  loss_rpn_loc: 0.2221  time: 0.9903  data_time: 0.2744  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:00:07 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 179  total_loss: 1.849  loss_cls: 0.5161  loss_box_reg: 0.6413  loss_mask: 0.3229  loss_rpn_cls: 0.09581  loss_rpn_loc: 0.2309  time: 0.9950  data_time: 0.3319  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:00:27 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 199  total_loss: 1.646  loss_cls: 0.5023  loss_box_reg: 0.5559  loss_mask: 0.2681  loss_rpn_cls: 0.09134  loss_rpn_loc: 0.2174  time: 0.9936  data_time: 0.3043  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:00:47 d2.utils.events]: \u001b[0m eta: 0:21:29  iter: 219  total_loss: 1.591  loss_cls: 0.4564  loss_box_reg: 0.5582  loss_mask: 0.2798  loss_rpn_cls: 0.09618  loss_rpn_loc: 0.1945  time: 0.9925  data_time: 0.2952  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:01:06 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 239  total_loss: 1.62  loss_cls: 0.4285  loss_box_reg: 0.5764  loss_mask: 0.2562  loss_rpn_cls: 0.08603  loss_rpn_loc: 0.2355  time: 0.9919  data_time: 0.2847  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:01:26 d2.utils.events]: \u001b[0m eta: 0:20:47  iter: 259  total_loss: 1.475  loss_cls: 0.4037  loss_box_reg: 0.5243  loss_mask: 0.2679  loss_rpn_cls: 0.08653  loss_rpn_loc: 0.2021  time: 0.9920  data_time: 0.2866  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:01:45 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 279  total_loss: 1.582  loss_cls: 0.4536  loss_box_reg: 0.5318  loss_mask: 0.2794  loss_rpn_cls: 0.08953  loss_rpn_loc: 0.218  time: 0.9878  data_time: 0.2789  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:02:05 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 299  total_loss: 1.589  loss_cls: 0.4533  loss_box_reg: 0.5489  loss_mask: 0.2805  loss_rpn_cls: 0.08239  loss_rpn_loc: 0.2094  time: 0.9879  data_time: 0.3113  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:02:24 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 319  total_loss: 1.615  loss_cls: 0.4089  loss_box_reg: 0.5335  loss_mask: 0.2958  loss_rpn_cls: 0.0838  loss_rpn_loc: 0.231  time: 0.9874  data_time: 0.2672  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:02:44 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 339  total_loss: 1.55  loss_cls: 0.42  loss_box_reg: 0.5246  loss_mask: 0.2693  loss_rpn_cls: 0.0789  loss_rpn_loc: 0.2048  time: 0.9868  data_time: 0.2883  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:03:04 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 359  total_loss: 1.395  loss_cls: 0.3949  loss_box_reg: 0.4682  loss_mask: 0.2554  loss_rpn_cls: 0.06368  loss_rpn_loc: 0.211  time: 0.9868  data_time: 0.2841  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:03:23 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 379  total_loss: 1.459  loss_cls: 0.3863  loss_box_reg: 0.513  loss_mask: 0.2493  loss_rpn_cls: 0.07029  loss_rpn_loc: 0.2139  time: 0.9842  data_time: 0.2937  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:03:42 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 399  total_loss: 1.492  loss_cls: 0.3906  loss_box_reg: 0.5448  loss_mask: 0.2498  loss_rpn_cls: 0.07674  loss_rpn_loc: 0.2159  time: 0.9841  data_time: 0.2718  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:04:02 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 419  total_loss: 1.539  loss_cls: 0.4396  loss_box_reg: 0.521  loss_mask: 0.2576  loss_rpn_cls: 0.07425  loss_rpn_loc: 0.2011  time: 0.9841  data_time: 0.2896  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:04:21 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 439  total_loss: 1.432  loss_cls: 0.4026  loss_box_reg: 0.5095  loss_mask: 0.2638  loss_rpn_cls: 0.07508  loss_rpn_loc: 0.1983  time: 0.9838  data_time: 0.2838  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:04:41 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 459  total_loss: 1.42  loss_cls: 0.4073  loss_box_reg: 0.4769  loss_mask: 0.2784  loss_rpn_cls: 0.07254  loss_rpn_loc: 0.1975  time: 0.9842  data_time: 0.2946  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:05:00 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 479  total_loss: 1.442  loss_cls: 0.3583  loss_box_reg: 0.5396  loss_mask: 0.2697  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.1901  time: 0.9831  data_time: 0.2733  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:05:20 d2.utils.events]: \u001b[0m eta: 0:16:28  iter: 499  total_loss: 1.566  loss_cls: 0.3814  loss_box_reg: 0.5182  loss_mask: 0.268  loss_rpn_cls: 0.06871  loss_rpn_loc: 0.2381  time: 0.9829  data_time: 0.3020  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:05:39 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 519  total_loss: 1.474  loss_cls: 0.3649  loss_box_reg: 0.5006  loss_mask: 0.2435  loss_rpn_cls: 0.07276  loss_rpn_loc: 0.2124  time: 0.9813  data_time: 0.2831  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:05:58 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 539  total_loss: 1.465  loss_cls: 0.3781  loss_box_reg: 0.5103  loss_mask: 0.2547  loss_rpn_cls: 0.06868  loss_rpn_loc: 0.1945  time: 0.9799  data_time: 0.2722  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:06:17 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 559  total_loss: 1.293  loss_cls: 0.3301  loss_box_reg: 0.4597  loss_mask: 0.2321  loss_rpn_cls: 0.06321  loss_rpn_loc: 0.192  time: 0.9799  data_time: 0.2914  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:06:37 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 579  total_loss: 1.503  loss_cls: 0.3516  loss_box_reg: 0.5641  loss_mask: 0.2858  loss_rpn_cls: 0.06882  loss_rpn_loc: 0.2132  time: 0.9795  data_time: 0.2745  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:06:56 d2.utils.events]: \u001b[0m eta: 0:14:49  iter: 599  total_loss: 1.378  loss_cls: 0.3427  loss_box_reg: 0.4849  loss_mask: 0.2482  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.2014  time: 0.9788  data_time: 0.2957  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:07:15 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 619  total_loss: 1.277  loss_cls: 0.3454  loss_box_reg: 0.4625  loss_mask: 0.2215  loss_rpn_cls: 0.06687  loss_rpn_loc: 0.1906  time: 0.9786  data_time: 0.2786  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:07:35 d2.utils.events]: \u001b[0m eta: 0:14:09  iter: 639  total_loss: 1.478  loss_cls: 0.3817  loss_box_reg: 0.4882  loss_mask: 0.2604  loss_rpn_cls: 0.06357  loss_rpn_loc: 0.202  time: 0.9784  data_time: 0.3086  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:07:55 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 659  total_loss: 1.339  loss_cls: 0.3316  loss_box_reg: 0.4788  loss_mask: 0.2503  loss_rpn_cls: 0.06408  loss_rpn_loc: 0.1951  time: 0.9788  data_time: 0.2913  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 19:08:14 d2.utils.events]: \u001b[0m eta: 0:13:30  iter: 679  total_loss: 1.363  loss_cls: 0.3462  loss_box_reg: 0.4585  loss_mask: 0.2443  loss_rpn_cls: 0.06535  loss_rpn_loc: 0.2362  time: 0.9780  data_time: 0.2788  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:08:33 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 699  total_loss: 1.339  loss_cls: 0.3391  loss_box_reg: 0.461  loss_mask: 0.2313  loss_rpn_cls: 0.05987  loss_rpn_loc: 0.2012  time: 0.9772  data_time: 0.2439  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:08:53 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 719  total_loss: 1.338  loss_cls: 0.3479  loss_box_reg: 0.4759  loss_mask: 0.2344  loss_rpn_cls: 0.05762  loss_rpn_loc: 0.1992  time: 0.9781  data_time: 0.3064  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:09:13 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 739  total_loss: 1.43  loss_cls: 0.3533  loss_box_reg: 0.5413  loss_mask: 0.2455  loss_rpn_cls: 0.06442  loss_rpn_loc: 0.1927  time: 0.9780  data_time: 0.3006  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:09:32 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 759  total_loss: 1.25  loss_cls: 0.3023  loss_box_reg: 0.4657  loss_mask: 0.2465  loss_rpn_cls: 0.05425  loss_rpn_loc: 0.1672  time: 0.9775  data_time: 0.2541  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:09:51 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 779  total_loss: 1.308  loss_cls: 0.3429  loss_box_reg: 0.5115  loss_mask: 0.261  loss_rpn_cls: 0.06205  loss_rpn_loc: 0.1864  time: 0.9772  data_time: 0.2776  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:10:11 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 799  total_loss: 1.234  loss_cls: 0.2775  loss_box_reg: 0.4646  loss_mask: 0.2389  loss_rpn_cls: 0.05693  loss_rpn_loc: 0.2087  time: 0.9772  data_time: 0.2890  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:10:30 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 819  total_loss: 1.323  loss_cls: 0.3036  loss_box_reg: 0.4745  loss_mask: 0.2341  loss_rpn_cls: 0.0561  loss_rpn_loc: 0.1814  time: 0.9773  data_time: 0.2848  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:10:50 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 839  total_loss: 1.308  loss_cls: 0.3285  loss_box_reg: 0.4815  loss_mask: 0.2489  loss_rpn_cls: 0.0572  loss_rpn_loc: 0.2038  time: 0.9778  data_time: 0.2975  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:11:09 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 859  total_loss: 1.303  loss_cls: 0.3017  loss_box_reg: 0.429  loss_mask: 0.2468  loss_rpn_cls: 0.05064  loss_rpn_loc: 0.2094  time: 0.9770  data_time: 0.2826  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:11:28 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 879  total_loss: 1.128  loss_cls: 0.3039  loss_box_reg: 0.4232  loss_mask: 0.2059  loss_rpn_cls: 0.0532  loss_rpn_loc: 0.1796  time: 0.9764  data_time: 0.2685  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:11:47 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 899  total_loss: 1.351  loss_cls: 0.3191  loss_box_reg: 0.4903  loss_mask: 0.2597  loss_rpn_cls: 0.05093  loss_rpn_loc: 0.1755  time: 0.9756  data_time: 0.2762  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:12:07 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 919  total_loss: 1.234  loss_cls: 0.2989  loss_box_reg: 0.4623  loss_mask: 0.2397  loss_rpn_cls: 0.0532  loss_rpn_loc: 0.19  time: 0.9761  data_time: 0.3058  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:12:26 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 939  total_loss: 1.378  loss_cls: 0.3211  loss_box_reg: 0.5086  loss_mask: 0.2794  loss_rpn_cls: 0.05775  loss_rpn_loc: 0.2089  time: 0.9759  data_time: 0.2720  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:12:46 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 959  total_loss: 1.238  loss_cls: 0.3012  loss_box_reg: 0.4358  loss_mask: 0.234  loss_rpn_cls: 0.05382  loss_rpn_loc: 0.1885  time: 0.9758  data_time: 0.2957  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:13:04 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 979  total_loss: 1.201  loss_cls: 0.2988  loss_box_reg: 0.4128  loss_mask: 0.2229  loss_rpn_cls: 0.0488  loss_rpn_loc: 0.1887  time: 0.9748  data_time: 0.2611  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:13:24 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 999  total_loss: 1.27  loss_cls: 0.3174  loss_box_reg: 0.4776  loss_mask: 0.2273  loss_rpn_cls: 0.05071  loss_rpn_loc: 0.1832  time: 0.9746  data_time: 0.2939  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:13:43 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 1019  total_loss: 1.222  loss_cls: 0.3387  loss_box_reg: 0.4119  loss_mask: 0.2299  loss_rpn_cls: 0.0541  loss_rpn_loc: 0.1857  time: 0.9742  data_time: 0.2569  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:14:02 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 1039  total_loss: 1.231  loss_cls: 0.3176  loss_box_reg: 0.436  loss_mask: 0.2191  loss_rpn_cls: 0.05214  loss_rpn_loc: 0.1889  time: 0.9739  data_time: 0.2926  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:14:21 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 1059  total_loss: 1.235  loss_cls: 0.2975  loss_box_reg: 0.4406  loss_mask: 0.2332  loss_rpn_cls: 0.04718  loss_rpn_loc: 0.1797  time: 0.9737  data_time: 0.2834  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:14:42 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 1079  total_loss: 1.207  loss_cls: 0.3045  loss_box_reg: 0.4188  loss_mask: 0.2261  loss_rpn_cls: 0.05255  loss_rpn_loc: 0.2065  time: 0.9747  data_time: 0.3160  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:15:02 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 1099  total_loss: 1.196  loss_cls: 0.3276  loss_box_reg: 0.4318  loss_mask: 0.2329  loss_rpn_cls: 0.0521  loss_rpn_loc: 0.1924  time: 0.9753  data_time: 0.3043  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:15:20 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 1119  total_loss: 1.159  loss_cls: 0.3432  loss_box_reg: 0.4298  loss_mask: 0.2392  loss_rpn_cls: 0.03874  loss_rpn_loc: 0.1601  time: 0.9743  data_time: 0.2622  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:15:40 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 1139  total_loss: 1.393  loss_cls: 0.3735  loss_box_reg: 0.5083  loss_mask: 0.2568  loss_rpn_cls: 0.054  loss_rpn_loc: 0.1972  time: 0.9747  data_time: 0.2944  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:15:59 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1159  total_loss: 1.187  loss_cls: 0.2916  loss_box_reg: 0.4421  loss_mask: 0.2412  loss_rpn_cls: 0.04782  loss_rpn_loc: 0.1733  time: 0.9742  data_time: 0.2776  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:16:18 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1179  total_loss: 1.226  loss_cls: 0.285  loss_box_reg: 0.4408  loss_mask: 0.2125  loss_rpn_cls: 0.04659  loss_rpn_loc: 0.1679  time: 0.9740  data_time: 0.2894  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:16:38 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 1199  total_loss: 1.18  loss_cls: 0.3314  loss_box_reg: 0.4017  loss_mask: 0.2191  loss_rpn_cls: 0.05088  loss_rpn_loc: 0.2006  time: 0.9739  data_time: 0.2943  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:16:58 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1219  total_loss: 1.115  loss_cls: 0.2428  loss_box_reg: 0.4294  loss_mask: 0.2135  loss_rpn_cls: 0.04587  loss_rpn_loc: 0.1768  time: 0.9746  data_time: 0.3019  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:17:18 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 1239  total_loss: 1.176  loss_cls: 0.2802  loss_box_reg: 0.4149  loss_mask: 0.2075  loss_rpn_cls: 0.04896  loss_rpn_loc: 0.1619  time: 0.9747  data_time: 0.2823  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:17:37 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 1259  total_loss: 1.256  loss_cls: 0.3471  loss_box_reg: 0.426  loss_mask: 0.2413  loss_rpn_cls: 0.05396  loss_rpn_loc: 0.1665  time: 0.9742  data_time: 0.2615  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:17:55 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 1279  total_loss: 1.161  loss_cls: 0.3217  loss_box_reg: 0.411  loss_mask: 0.2212  loss_rpn_cls: 0.04923  loss_rpn_loc: 0.1737  time: 0.9732  data_time: 0.2318  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:18:14 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1299  total_loss: 1.206  loss_cls: 0.2908  loss_box_reg: 0.4516  loss_mask: 0.2329  loss_rpn_cls: 0.04996  loss_rpn_loc: 0.1878  time: 0.9733  data_time: 0.3094  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:18:33 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 1319  total_loss: 1.101  loss_cls: 0.2477  loss_box_reg: 0.3782  loss_mask: 0.2165  loss_rpn_cls: 0.04911  loss_rpn_loc: 0.1754  time: 0.9729  data_time: 0.2891  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:18:52 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 1339  total_loss: 1.242  loss_cls: 0.3018  loss_box_reg: 0.4385  loss_mask: 0.2232  loss_rpn_cls: 0.05145  loss_rpn_loc: 0.1752  time: 0.9722  data_time: 0.2602  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 19:19:11 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 1359  total_loss: 1.183  loss_cls: 0.3017  loss_box_reg: 0.4416  loss_mask: 0.2324  loss_rpn_cls: 0.05088  loss_rpn_loc: 0.1758  time: 0.9719  data_time: 0.2846  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:19:30 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 1379  total_loss: 1.096  loss_cls: 0.2696  loss_box_reg: 0.3927  loss_mask: 0.2224  loss_rpn_cls: 0.04329  loss_rpn_loc: 0.1669  time: 0.9717  data_time: 0.2796  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:19:50 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1399  total_loss: 1.2  loss_cls: 0.3033  loss_box_reg: 0.3983  loss_mask: 0.2435  loss_rpn_cls: 0.04669  loss_rpn_loc: 0.1748  time: 0.9719  data_time: 0.2785  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:20:10 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 1419  total_loss: 1.195  loss_cls: 0.2744  loss_box_reg: 0.4451  loss_mask: 0.2155  loss_rpn_cls: 0.05817  loss_rpn_loc: 0.1712  time: 0.9726  data_time: 0.3212  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:20:30 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 1.183  loss_cls: 0.2378  loss_box_reg: 0.4048  loss_mask: 0.2261  loss_rpn_cls: 0.04757  loss_rpn_loc: 0.1837  time: 0.9724  data_time: 0.2853  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:20:49 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 1459  total_loss: 1.138  loss_cls: 0.2637  loss_box_reg: 0.3959  loss_mask: 0.2162  loss_rpn_cls: 0.0463  loss_rpn_loc: 0.1665  time: 0.9721  data_time: 0.2644  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:21:08 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 1.181  loss_cls: 0.2899  loss_box_reg: 0.4295  loss_mask: 0.2402  loss_rpn_cls: 0.04373  loss_rpn_loc: 0.1834  time: 0.9722  data_time: 0.2917  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:21:28 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 1.214  loss_cls: 0.286  loss_box_reg: 0.431  loss_mask: 0.229  loss_rpn_cls: 0.05428  loss_rpn_loc: 0.1993  time: 0.9719  data_time: 0.2830  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:21:29 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:15 (0.9719 s / it)\n",
      "\u001b[32m[03/04 19:21:29 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:18 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 19:21:29 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 19:21:29 d2.data.datasets.coco]: \u001b[0mLoaded 132 images in COCO format from /host/mic21-framework/server/uploads/fireman_gt.json\n",
      "fireman\n",
      "\u001b[32m[03/04 19:21:30 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=32, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 19:21:30 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 19:21:30 d2.data.datasets.coco]: \u001b[0mLoaded 132 images in COCO format from /host/mic21-framework/server/uploads/fireman_gt.json\n",
      "\u001b[32m[03/04 19:21:30 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 132 images left.\n",
      "\u001b[32m[03/04 19:21:30 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      man      | 76           |   hard hat    | 228          |    gasmask    | 88           |\n",
      "| bunker jacket | 167          |  bunker boot  | 169          | fireman glove | 203          |\n",
      "|    fireman    | 280          | bunker trou.. | 120          |               |              |\n",
      "|     total     | 1331         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 19:21:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 19:21:30 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 19:21:30 d2.data.common]: \u001b[0mSerializing 132 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 19:21:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (9, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (9,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (32, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (32,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (8, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 19:21:30 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 19:21:50 d2.utils.events]: \u001b[0m eta: 0:24:38  iter: 19  total_loss: 2.754  loss_cls: 1.074  loss_box_reg: 0.8717  loss_mask: 0.6697  loss_rpn_cls: 0.08181  loss_rpn_loc: 0.072  time: 0.9510  data_time: 0.3305  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:22:09 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 39  total_loss: 2.442  loss_cls: 0.8225  loss_box_reg: 0.8979  loss_mask: 0.5994  loss_rpn_cls: 0.06122  loss_rpn_loc: 0.06743  time: 0.9575  data_time: 0.3070  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:22:28 d2.utils.events]: \u001b[0m eta: 0:23:17  iter: 59  total_loss: 2.244  loss_cls: 0.7738  loss_box_reg: 0.8574  loss_mask: 0.4911  loss_rpn_cls: 0.04803  loss_rpn_loc: 0.06474  time: 0.9546  data_time: 0.2839  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:22:47 d2.utils.events]: \u001b[0m eta: 0:22:57  iter: 79  total_loss: 1.988  loss_cls: 0.6817  loss_box_reg: 0.7818  loss_mask: 0.4196  loss_rpn_cls: 0.04198  loss_rpn_loc: 0.06868  time: 0.9536  data_time: 0.2707  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:23:06 d2.utils.events]: \u001b[0m eta: 0:22:33  iter: 99  total_loss: 1.856  loss_cls: 0.5861  loss_box_reg: 0.7856  loss_mask: 0.3601  loss_rpn_cls: 0.0449  loss_rpn_loc: 0.07843  time: 0.9523  data_time: 0.2988  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:23:26 d2.utils.events]: \u001b[0m eta: 0:22:05  iter: 119  total_loss: 1.752  loss_cls: 0.5757  loss_box_reg: 0.7061  loss_mask: 0.3438  loss_rpn_cls: 0.03884  loss_rpn_loc: 0.06526  time: 0.9574  data_time: 0.2959  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:23:44 d2.utils.events]: \u001b[0m eta: 0:21:54  iter: 139  total_loss: 1.666  loss_cls: 0.5097  loss_box_reg: 0.6798  loss_mask: 0.3238  loss_rpn_cls: 0.03855  loss_rpn_loc: 0.06686  time: 0.9517  data_time: 0.2717  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:24:03 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 159  total_loss: 1.569  loss_cls: 0.4986  loss_box_reg: 0.6615  loss_mask: 0.3126  loss_rpn_cls: 0.04004  loss_rpn_loc: 0.05535  time: 0.9515  data_time: 0.2903  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:24:22 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 179  total_loss: 1.437  loss_cls: 0.432  loss_box_reg: 0.5963  loss_mask: 0.2954  loss_rpn_cls: 0.03525  loss_rpn_loc: 0.04845  time: 0.9500  data_time: 0.2776  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:24:42 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 199  total_loss: 1.479  loss_cls: 0.4533  loss_box_reg: 0.603  loss_mask: 0.3137  loss_rpn_cls: 0.03068  loss_rpn_loc: 0.06687  time: 0.9540  data_time: 0.3099  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:25:01 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 219  total_loss: 1.351  loss_cls: 0.4375  loss_box_reg: 0.5522  loss_mask: 0.3033  loss_rpn_cls: 0.02248  loss_rpn_loc: 0.05672  time: 0.9550  data_time: 0.2808  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:25:19 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 239  total_loss: 1.331  loss_cls: 0.4104  loss_box_reg: 0.5709  loss_mask: 0.2914  loss_rpn_cls: 0.02819  loss_rpn_loc: 0.05508  time: 0.9521  data_time: 0.2688  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:25:38 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 259  total_loss: 1.339  loss_cls: 0.386  loss_box_reg: 0.5305  loss_mask: 0.2663  loss_rpn_cls: 0.02876  loss_rpn_loc: 0.05561  time: 0.9496  data_time: 0.2671  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:25:57 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 279  total_loss: 1.286  loss_cls: 0.3776  loss_box_reg: 0.5356  loss_mask: 0.2975  loss_rpn_cls: 0.02423  loss_rpn_loc: 0.05197  time: 0.9504  data_time: 0.2751  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:26:17 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 299  total_loss: 1.372  loss_cls: 0.4192  loss_box_reg: 0.5382  loss_mask: 0.2852  loss_rpn_cls: 0.02418  loss_rpn_loc: 0.06243  time: 0.9528  data_time: 0.3117  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:26:35 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 319  total_loss: 1.204  loss_cls: 0.3152  loss_box_reg: 0.5321  loss_mask: 0.2592  loss_rpn_cls: 0.02837  loss_rpn_loc: 0.05864  time: 0.9504  data_time: 0.2701  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:26:54 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 339  total_loss: 1.253  loss_cls: 0.3545  loss_box_reg: 0.5116  loss_mask: 0.287  loss_rpn_cls: 0.02188  loss_rpn_loc: 0.05238  time: 0.9488  data_time: 0.2627  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:27:12 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 359  total_loss: 1.168  loss_cls: 0.3688  loss_box_reg: 0.5066  loss_mask: 0.2451  loss_rpn_cls: 0.02295  loss_rpn_loc: 0.05721  time: 0.9482  data_time: 0.2720  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:27:32 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 379  total_loss: 1.192  loss_cls: 0.3162  loss_box_reg: 0.5056  loss_mask: 0.2547  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.06007  time: 0.9486  data_time: 0.2930  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:27:52 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 399  total_loss: 1.19  loss_cls: 0.3848  loss_box_reg: 0.5211  loss_mask: 0.2668  loss_rpn_cls: 0.0145  loss_rpn_loc: 0.05486  time: 0.9511  data_time: 0.3105  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:28:11 d2.utils.events]: \u001b[0m eta: 0:17:23  iter: 419  total_loss: 1.203  loss_cls: 0.3391  loss_box_reg: 0.4959  loss_mask: 0.2708  loss_rpn_cls: 0.01814  loss_rpn_loc: 0.05117  time: 0.9517  data_time: 0.3032  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:28:30 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 439  total_loss: 1.181  loss_cls: 0.3237  loss_box_reg: 0.4956  loss_mask: 0.2582  loss_rpn_cls: 0.02112  loss_rpn_loc: 0.05874  time: 0.9530  data_time: 0.2998  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:28:49 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 459  total_loss: 1.152  loss_cls: 0.3618  loss_box_reg: 0.4665  loss_mask: 0.2507  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.05186  time: 0.9521  data_time: 0.2798  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:29:08 d2.utils.events]: \u001b[0m eta: 0:16:28  iter: 479  total_loss: 1.115  loss_cls: 0.2998  loss_box_reg: 0.4884  loss_mask: 0.2429  loss_rpn_cls: 0.02035  loss_rpn_loc: 0.05628  time: 0.9525  data_time: 0.2864  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:29:27 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 499  total_loss: 1.196  loss_cls: 0.3451  loss_box_reg: 0.5123  loss_mask: 0.2729  loss_rpn_cls: 0.0163  loss_rpn_loc: 0.05298  time: 0.9519  data_time: 0.2781  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:29:46 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 519  total_loss: 1.095  loss_cls: 0.3148  loss_box_reg: 0.4541  loss_mask: 0.249  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.04588  time: 0.9513  data_time: 0.2668  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:30:05 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 539  total_loss: 1.179  loss_cls: 0.3652  loss_box_reg: 0.5168  loss_mask: 0.2809  loss_rpn_cls: 0.01777  loss_rpn_loc: 0.05926  time: 0.9509  data_time: 0.2781  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:30:24 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 559  total_loss: 1.061  loss_cls: 0.2693  loss_box_reg: 0.4896  loss_mask: 0.2388  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.04488  time: 0.9518  data_time: 0.2969  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:30:43 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 579  total_loss: 1.068  loss_cls: 0.2907  loss_box_reg: 0.4727  loss_mask: 0.2296  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.04177  time: 0.9513  data_time: 0.2676  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:31:02 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 599  total_loss: 1.07  loss_cls: 0.2928  loss_box_reg: 0.4622  loss_mask: 0.2556  loss_rpn_cls: 0.01844  loss_rpn_loc: 0.05405  time: 0.9513  data_time: 0.2818  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:31:21 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 619  total_loss: 0.9661  loss_cls: 0.2366  loss_box_reg: 0.425  loss_mask: 0.2386  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.04039  time: 0.9517  data_time: 0.2921  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:31:41 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 639  total_loss: 0.9339  loss_cls: 0.2365  loss_box_reg: 0.4292  loss_mask: 0.2171  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.04564  time: 0.9525  data_time: 0.3170  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:32:00 d2.utils.events]: \u001b[0m eta: 0:13:30  iter: 659  total_loss: 0.9848  loss_cls: 0.3096  loss_box_reg: 0.4262  loss_mask: 0.2123  loss_rpn_cls: 0.01752  loss_rpn_loc: 0.05419  time: 0.9525  data_time: 0.2834  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 19:32:19 d2.utils.events]: \u001b[0m eta: 0:13:11  iter: 679  total_loss: 1.045  loss_cls: 0.2637  loss_box_reg: 0.4412  loss_mask: 0.2473  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.04604  time: 0.9531  data_time: 0.3078  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:32:38 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 699  total_loss: 1.008  loss_cls: 0.2657  loss_box_reg: 0.4356  loss_mask: 0.2349  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.05267  time: 0.9526  data_time: 0.2579  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:32:57 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 719  total_loss: 0.9967  loss_cls: 0.2845  loss_box_reg: 0.4267  loss_mask: 0.2101  loss_rpn_cls: 0.01377  loss_rpn_loc: 0.05091  time: 0.9529  data_time: 0.2969  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:33:17 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 739  total_loss: 0.9963  loss_cls: 0.2419  loss_box_reg: 0.4089  loss_mask: 0.2176  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.05036  time: 0.9533  data_time: 0.2805  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:33:35 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 759  total_loss: 0.9305  loss_cls: 0.2494  loss_box_reg: 0.4045  loss_mask: 0.2216  loss_rpn_cls: 0.01339  loss_rpn_loc: 0.04704  time: 0.9528  data_time: 0.2762  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:33:54 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 779  total_loss: 0.9073  loss_cls: 0.2516  loss_box_reg: 0.3899  loss_mask: 0.1947  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.0414  time: 0.9519  data_time: 0.2597  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:34:13 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 799  total_loss: 0.9439  loss_cls: 0.2603  loss_box_reg: 0.4302  loss_mask: 0.2242  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.04002  time: 0.9521  data_time: 0.2908  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:34:31 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 819  total_loss: 0.8873  loss_cls: 0.2288  loss_box_reg: 0.3799  loss_mask: 0.2034  loss_rpn_cls: 0.009239  loss_rpn_loc: 0.04735  time: 0.9513  data_time: 0.2856  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:34:50 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 839  total_loss: 0.9725  loss_cls: 0.2632  loss_box_reg: 0.4132  loss_mask: 0.2439  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.06058  time: 0.9513  data_time: 0.2784  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:35:10 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 859  total_loss: 0.857  loss_cls: 0.1882  loss_box_reg: 0.3888  loss_mask: 0.2241  loss_rpn_cls: 0.00889  loss_rpn_loc: 0.03857  time: 0.9523  data_time: 0.3222  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:35:30 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 879  total_loss: 0.9441  loss_cls: 0.247  loss_box_reg: 0.4134  loss_mask: 0.2258  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.04639  time: 0.9532  data_time: 0.3161  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:35:50 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 899  total_loss: 0.9675  loss_cls: 0.2336  loss_box_reg: 0.4546  loss_mask: 0.2152  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.04193  time: 0.9536  data_time: 0.3062  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:36:09 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 919  total_loss: 0.8836  loss_cls: 0.2506  loss_box_reg: 0.3822  loss_mask: 0.2048  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.04789  time: 0.9539  data_time: 0.3082  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:36:28 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 939  total_loss: 0.8407  loss_cls: 0.1976  loss_box_reg: 0.3593  loss_mask: 0.1942  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.04646  time: 0.9538  data_time: 0.2949  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:36:48 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 959  total_loss: 0.8868  loss_cls: 0.2298  loss_box_reg: 0.376  loss_mask: 0.2037  loss_rpn_cls: 0.009951  loss_rpn_loc: 0.04694  time: 0.9545  data_time: 0.2969  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:37:08 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 979  total_loss: 0.8692  loss_cls: 0.2288  loss_box_reg: 0.3698  loss_mask: 0.2016  loss_rpn_cls: 0.01011  loss_rpn_loc: 0.04446  time: 0.9553  data_time: 0.3120  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:37:26 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 999  total_loss: 0.8697  loss_cls: 0.2307  loss_box_reg: 0.3657  loss_mask: 0.2207  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.04189  time: 0.9547  data_time: 0.3014  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:37:46 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 1019  total_loss: 0.851  loss_cls: 0.2052  loss_box_reg: 0.3647  loss_mask: 0.1894  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.04305  time: 0.9550  data_time: 0.3049  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:38:06 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 1039  total_loss: 0.9187  loss_cls: 0.2245  loss_box_reg: 0.3851  loss_mask: 0.2126  loss_rpn_cls: 0.008637  loss_rpn_loc: 0.04354  time: 0.9558  data_time: 0.3323  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:38:25 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 1059  total_loss: 0.8171  loss_cls: 0.1777  loss_box_reg: 0.3774  loss_mask: 0.1857  loss_rpn_cls: 0.00878  loss_rpn_loc: 0.04849  time: 0.9560  data_time: 0.3068  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:38:44 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 1079  total_loss: 0.8616  loss_cls: 0.2272  loss_box_reg: 0.3536  loss_mask: 0.2163  loss_rpn_cls: 0.009455  loss_rpn_loc: 0.05396  time: 0.9562  data_time: 0.2893  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:39:04 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 1099  total_loss: 0.7591  loss_cls: 0.1887  loss_box_reg: 0.3246  loss_mask: 0.1902  loss_rpn_cls: 0.00784  loss_rpn_loc: 0.03868  time: 0.9564  data_time: 0.3172  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:39:23 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 1119  total_loss: 0.8321  loss_cls: 0.2127  loss_box_reg: 0.3455  loss_mask: 0.212  loss_rpn_cls: 0.005995  loss_rpn_loc: 0.04572  time: 0.9569  data_time: 0.3032  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:39:43 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1139  total_loss: 0.8648  loss_cls: 0.2366  loss_box_reg: 0.3334  loss_mask: 0.211  loss_rpn_cls: 0.009248  loss_rpn_loc: 0.04693  time: 0.9571  data_time: 0.3194  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:40:02 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 1159  total_loss: 0.7591  loss_cls: 0.1974  loss_box_reg: 0.3213  loss_mask: 0.1885  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.04329  time: 0.9575  data_time: 0.3030  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:40:22 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 1179  total_loss: 0.7729  loss_cls: 0.1899  loss_box_reg: 0.2985  loss_mask: 0.1939  loss_rpn_cls: 0.00957  loss_rpn_loc: 0.03799  time: 0.9579  data_time: 0.2961  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:40:41 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 1199  total_loss: 0.7196  loss_cls: 0.206  loss_box_reg: 0.3073  loss_mask: 0.1897  loss_rpn_cls: 0.007557  loss_rpn_loc: 0.04307  time: 0.9576  data_time: 0.2960  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:41:00 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 1219  total_loss: 0.7687  loss_cls: 0.2061  loss_box_reg: 0.3237  loss_mask: 0.1811  loss_rpn_cls: 0.006293  loss_rpn_loc: 0.03828  time: 0.9578  data_time: 0.3044  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:41:20 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 1239  total_loss: 0.7604  loss_cls: 0.1917  loss_box_reg: 0.3315  loss_mask: 0.1938  loss_rpn_cls: 0.009838  loss_rpn_loc: 0.03823  time: 0.9581  data_time: 0.3112  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:41:40 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 1259  total_loss: 0.7889  loss_cls: 0.2193  loss_box_reg: 0.3152  loss_mask: 0.1903  loss_rpn_cls: 0.01215  loss_rpn_loc: 0.04574  time: 0.9587  data_time: 0.3234  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:41:59 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 1279  total_loss: 0.7539  loss_cls: 0.1837  loss_box_reg: 0.3085  loss_mask: 0.1865  loss_rpn_cls: 0.006975  loss_rpn_loc: 0.04503  time: 0.9586  data_time: 0.3072  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:42:18 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 1299  total_loss: 0.7659  loss_cls: 0.2051  loss_box_reg: 0.3134  loss_mask: 0.1826  loss_rpn_cls: 0.006862  loss_rpn_loc: 0.04134  time: 0.9589  data_time: 0.3100  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:42:37 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 1319  total_loss: 0.7828  loss_cls: 0.2164  loss_box_reg: 0.3255  loss_mask: 0.1987  loss_rpn_cls: 0.008533  loss_rpn_loc: 0.04542  time: 0.9588  data_time: 0.3094  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 19:42:57 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1339  total_loss: 0.7287  loss_cls: 0.1759  loss_box_reg: 0.3102  loss_mask: 0.1699  loss_rpn_cls: 0.008419  loss_rpn_loc: 0.04197  time: 0.9591  data_time: 0.3056  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:43:17 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 1359  total_loss: 0.7727  loss_cls: 0.1933  loss_box_reg: 0.3168  loss_mask: 0.2002  loss_rpn_cls: 0.009631  loss_rpn_loc: 0.03896  time: 0.9596  data_time: 0.3439  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:43:36 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1379  total_loss: 0.7153  loss_cls: 0.1702  loss_box_reg: 0.3077  loss_mask: 0.1808  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.04827  time: 0.9597  data_time: 0.2847  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:43:55 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1399  total_loss: 0.7551  loss_cls: 0.1902  loss_box_reg: 0.3437  loss_mask: 0.1884  loss_rpn_cls: 0.008886  loss_rpn_loc: 0.04535  time: 0.9597  data_time: 0.2951  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 19:44:15 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.7831  loss_cls: 0.2083  loss_box_reg: 0.3279  loss_mask: 0.1813  loss_rpn_cls: 0.006959  loss_rpn_loc: 0.03927  time: 0.9598  data_time: 0.3087  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:44:34 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.7446  loss_cls: 0.2012  loss_box_reg: 0.2849  loss_mask: 0.2139  loss_rpn_cls: 0.009988  loss_rpn_loc: 0.04589  time: 0.9597  data_time: 0.2846  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:44:54 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.759  loss_cls: 0.185  loss_box_reg: 0.3403  loss_mask: 0.185  loss_rpn_cls: 0.006424  loss_rpn_loc: 0.03547  time: 0.9601  data_time: 0.3117  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:45:13 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.789  loss_cls: 0.1849  loss_box_reg: 0.3222  loss_mask: 0.2052  loss_rpn_cls: 0.007729  loss_rpn_loc: 0.04569  time: 0.9604  data_time: 0.2998  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:45:35 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7644  loss_cls: 0.1755  loss_box_reg: 0.3358  loss_mask: 0.1925  loss_rpn_cls: 0.008904  loss_rpn_loc: 0.03875  time: 0.9609  data_time: 0.3330  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 19:45:35 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:23:59 (0.9609 s / it)\n",
      "\u001b[32m[03/04 19:45:35 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:02 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 19:45:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 19:45:36 d2.data.datasets.coco]: \u001b[0mLoaded 432 images in COCO format from /host/mic21-framework/server/uploads/police_car_gt.json\n",
      "police_car\n",
      "\u001b[32m[03/04 19:45:36 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=56, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 19:45:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 19:45:36 d2.data.datasets.coco]: \u001b[0mLoaded 432 images in COCO format from /host/mic21-framework/server/uploads/police_car_gt.json\n",
      "\u001b[32m[03/04 19:45:36 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 432 images left.\n",
      "\u001b[32m[03/04 19:45:37 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      car      | 312          |    person     | 251          | traffic light | 94           |\n",
      "|  car window   | 143          |   car wheel   | 82           |  police car   | 508          |\n",
      "| police car .. | 1163         | police car .. | 777          | police car .. | 1145         |\n",
      "| police car .. | 576          | police car .. | 318          | emergency s.. | 513          |\n",
      "| car headlight | 55           |   policeman   | 105          |               |              |\n",
      "|     total     | 6042         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 19:45:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 19:45:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 19:45:37 d2.data.common]: \u001b[0mSerializing 432 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 19:45:37 d2.data.common]: \u001b[0mSerialized dataset takes 3.17 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (56, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (56,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (14, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 19:45:37 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 19:45:57 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 19  total_loss: 3.248  loss_cls: 1.361  loss_box_reg: 0.8719  loss_mask: 0.6664  loss_rpn_cls: 0.1277  loss_rpn_loc: 0.1599  time: 0.9482  data_time: 0.3141  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:46:17 d2.utils.events]: \u001b[0m eta: 0:23:32  iter: 39  total_loss: 2.58  loss_cls: 0.9471  loss_box_reg: 0.8659  loss_mask: 0.5198  loss_rpn_cls: 0.09389  loss_rpn_loc: 0.1409  time: 0.9699  data_time: 0.3094  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:46:36 d2.utils.events]: \u001b[0m eta: 0:23:07  iter: 59  total_loss: 2.135  loss_cls: 0.7597  loss_box_reg: 0.7787  loss_mask: 0.407  loss_rpn_cls: 0.06784  loss_rpn_loc: 0.1291  time: 0.9652  data_time: 0.2870  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:46:55 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 79  total_loss: 2.01  loss_cls: 0.6154  loss_box_reg: 0.7545  loss_mask: 0.3406  loss_rpn_cls: 0.07828  loss_rpn_loc: 0.1393  time: 0.9707  data_time: 0.3033  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:47:15 d2.utils.events]: \u001b[0m eta: 0:22:28  iter: 99  total_loss: 1.89  loss_cls: 0.6041  loss_box_reg: 0.7095  loss_mask: 0.3087  loss_rpn_cls: 0.06061  loss_rpn_loc: 0.1224  time: 0.9710  data_time: 0.2886  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:47:34 d2.utils.events]: \u001b[0m eta: 0:22:07  iter: 119  total_loss: 1.663  loss_cls: 0.4938  loss_box_reg: 0.6351  loss_mask: 0.2567  loss_rpn_cls: 0.06647  loss_rpn_loc: 0.1529  time: 0.9662  data_time: 0.2770  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:47:53 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 139  total_loss: 1.456  loss_cls: 0.4515  loss_box_reg: 0.5396  loss_mask: 0.2599  loss_rpn_cls: 0.05053  loss_rpn_loc: 0.1416  time: 0.9652  data_time: 0.2762  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:48:12 d2.utils.events]: \u001b[0m eta: 0:21:29  iter: 159  total_loss: 1.472  loss_cls: 0.4607  loss_box_reg: 0.5569  loss_mask: 0.2436  loss_rpn_cls: 0.0504  loss_rpn_loc: 0.1368  time: 0.9640  data_time: 0.2766  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:48:31 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 179  total_loss: 1.286  loss_cls: 0.3817  loss_box_reg: 0.5404  loss_mask: 0.2382  loss_rpn_cls: 0.0455  loss_rpn_loc: 0.1105  time: 0.9616  data_time: 0.2913  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:48:51 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 199  total_loss: 1.414  loss_cls: 0.4147  loss_box_reg: 0.5719  loss_mask: 0.2308  loss_rpn_cls: 0.05585  loss_rpn_loc: 0.1149  time: 0.9657  data_time: 0.3211  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:49:10 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 219  total_loss: 1.415  loss_cls: 0.3986  loss_box_reg: 0.559  loss_mask: 0.2351  loss_rpn_cls: 0.04963  loss_rpn_loc: 0.1182  time: 0.9660  data_time: 0.2880  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:49:30 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 239  total_loss: 1.332  loss_cls: 0.4711  loss_box_reg: 0.5197  loss_mask: 0.2211  loss_rpn_cls: 0.04482  loss_rpn_loc: 0.1147  time: 0.9688  data_time: 0.3044  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:49:50 d2.utils.events]: \u001b[0m eta: 0:19:54  iter: 259  total_loss: 1.296  loss_cls: 0.3932  loss_box_reg: 0.4878  loss_mask: 0.2187  loss_rpn_cls: 0.03939  loss_rpn_loc: 0.1156  time: 0.9680  data_time: 0.2679  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:50:09 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 279  total_loss: 1.262  loss_cls: 0.3377  loss_box_reg: 0.4749  loss_mask: 0.2244  loss_rpn_cls: 0.04428  loss_rpn_loc: 0.1193  time: 0.9699  data_time: 0.2990  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:50:30 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 299  total_loss: 1.155  loss_cls: 0.3169  loss_box_reg: 0.4703  loss_mask: 0.2131  loss_rpn_cls: 0.04043  loss_rpn_loc: 0.09484  time: 0.9744  data_time: 0.3187  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:50:49 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 319  total_loss: 1.247  loss_cls: 0.3589  loss_box_reg: 0.4973  loss_mask: 0.221  loss_rpn_cls: 0.04522  loss_rpn_loc: 0.1287  time: 0.9707  data_time: 0.2857  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:51:09 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 339  total_loss: 1.298  loss_cls: 0.3812  loss_box_reg: 0.4543  loss_mask: 0.2142  loss_rpn_cls: 0.04469  loss_rpn_loc: 0.1214  time: 0.9740  data_time: 0.3247  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:51:28 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 359  total_loss: 1.179  loss_cls: 0.3473  loss_box_reg: 0.435  loss_mask: 0.2052  loss_rpn_cls: 0.04398  loss_rpn_loc: 0.1401  time: 0.9724  data_time: 0.2888  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:51:48 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 379  total_loss: 1.097  loss_cls: 0.2941  loss_box_reg: 0.4392  loss_mask: 0.2121  loss_rpn_cls: 0.03305  loss_rpn_loc: 0.1186  time: 0.9733  data_time: 0.3120  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:52:07 d2.utils.events]: \u001b[0m eta: 0:17:52  iter: 399  total_loss: 1.273  loss_cls: 0.3331  loss_box_reg: 0.4772  loss_mask: 0.2308  loss_rpn_cls: 0.04168  loss_rpn_loc: 0.1587  time: 0.9723  data_time: 0.2710  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:52:27 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 419  total_loss: 1.156  loss_cls: 0.318  loss_box_reg: 0.4585  loss_mask: 0.193  loss_rpn_cls: 0.04116  loss_rpn_loc: 0.1145  time: 0.9745  data_time: 0.3113  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:52:47 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 439  total_loss: 1.107  loss_cls: 0.3125  loss_box_reg: 0.4507  loss_mask: 0.2092  loss_rpn_cls: 0.03161  loss_rpn_loc: 0.1075  time: 0.9743  data_time: 0.2692  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:53:06 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 459  total_loss: 1.15  loss_cls: 0.3112  loss_box_reg: 0.4351  loss_mask: 0.2104  loss_rpn_cls: 0.03813  loss_rpn_loc: 0.1052  time: 0.9730  data_time: 0.2702  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:53:26 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 479  total_loss: 1.003  loss_cls: 0.2881  loss_box_reg: 0.3884  loss_mask: 0.1941  loss_rpn_cls: 0.03589  loss_rpn_loc: 0.0975  time: 0.9741  data_time: 0.3068  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:53:45 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 499  total_loss: 1.07  loss_cls: 0.3157  loss_box_reg: 0.4178  loss_mask: 0.1955  loss_rpn_cls: 0.03263  loss_rpn_loc: 0.1192  time: 0.9738  data_time: 0.2754  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:54:04 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 519  total_loss: 1.009  loss_cls: 0.2805  loss_box_reg: 0.388  loss_mask: 0.1949  loss_rpn_cls: 0.03512  loss_rpn_loc: 0.07907  time: 0.9729  data_time: 0.2909  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:54:23 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 539  total_loss: 1.159  loss_cls: 0.3329  loss_box_reg: 0.4566  loss_mask: 0.2064  loss_rpn_cls: 0.03651  loss_rpn_loc: 0.1429  time: 0.9721  data_time: 0.2811  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:54:42 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 559  total_loss: 1.081  loss_cls: 0.2836  loss_box_reg: 0.4121  loss_mask: 0.201  loss_rpn_cls: 0.03492  loss_rpn_loc: 0.101  time: 0.9705  data_time: 0.2827  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:55:01 d2.utils.events]: \u001b[0m eta: 0:14:56  iter: 579  total_loss: 0.9606  loss_cls: 0.2404  loss_box_reg: 0.3929  loss_mask: 0.1988  loss_rpn_cls: 0.02924  loss_rpn_loc: 0.09725  time: 0.9712  data_time: 0.2947  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:55:20 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 599  total_loss: 0.9883  loss_cls: 0.2709  loss_box_reg: 0.4117  loss_mask: 0.1833  loss_rpn_cls: 0.03212  loss_rpn_loc: 0.09766  time: 0.9705  data_time: 0.2628  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:55:40 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 619  total_loss: 1.063  loss_cls: 0.2552  loss_box_reg: 0.4204  loss_mask: 0.2034  loss_rpn_cls: 0.0274  loss_rpn_loc: 0.0922  time: 0.9703  data_time: 0.2992  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:56:00 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 639  total_loss: 1.121  loss_cls: 0.325  loss_box_reg: 0.3993  loss_mask: 0.1829  loss_rpn_cls: 0.02895  loss_rpn_loc: 0.1404  time: 0.9711  data_time: 0.3049  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:56:19 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 659  total_loss: 0.9925  loss_cls: 0.2442  loss_box_reg: 0.4213  loss_mask: 0.1752  loss_rpn_cls: 0.02717  loss_rpn_loc: 0.09427  time: 0.9703  data_time: 0.2799  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 19:56:38 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 679  total_loss: 1.035  loss_cls: 0.3086  loss_box_reg: 0.4083  loss_mask: 0.1868  loss_rpn_cls: 0.03187  loss_rpn_loc: 0.09216  time: 0.9706  data_time: 0.2991  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:56:57 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 699  total_loss: 1.004  loss_cls: 0.2767  loss_box_reg: 0.3843  loss_mask: 0.1897  loss_rpn_cls: 0.02965  loss_rpn_loc: 0.1021  time: 0.9703  data_time: 0.2872  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:57:17 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 719  total_loss: 0.949  loss_cls: 0.2794  loss_box_reg: 0.3746  loss_mask: 0.1668  loss_rpn_cls: 0.03142  loss_rpn_loc: 0.1189  time: 0.9702  data_time: 0.2851  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:57:37 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 739  total_loss: 1.004  loss_cls: 0.2796  loss_box_reg: 0.4056  loss_mask: 0.1682  loss_rpn_cls: 0.02803  loss_rpn_loc: 0.09669  time: 0.9707  data_time: 0.2972  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:57:56 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 759  total_loss: 0.9691  loss_cls: 0.2754  loss_box_reg: 0.4003  loss_mask: 0.1717  loss_rpn_cls: 0.02876  loss_rpn_loc: 0.08023  time: 0.9711  data_time: 0.2950  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:58:16 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 779  total_loss: 0.9971  loss_cls: 0.2879  loss_box_reg: 0.3828  loss_mask: 0.1731  loss_rpn_cls: 0.03215  loss_rpn_loc: 0.08121  time: 0.9713  data_time: 0.2969  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:58:35 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 799  total_loss: 1.033  loss_cls: 0.2822  loss_box_reg: 0.3937  loss_mask: 0.1967  loss_rpn_cls: 0.02744  loss_rpn_loc: 0.1079  time: 0.9715  data_time: 0.2859  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:58:54 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 819  total_loss: 1.017  loss_cls: 0.2879  loss_box_reg: 0.4007  loss_mask: 0.1724  loss_rpn_cls: 0.03402  loss_rpn_loc: 0.1052  time: 0.9702  data_time: 0.2789  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:59:13 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 839  total_loss: 0.9644  loss_cls: 0.252  loss_box_reg: 0.3814  loss_mask: 0.1726  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.09589  time: 0.9706  data_time: 0.2770  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:59:34 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 859  total_loss: 0.9217  loss_cls: 0.2692  loss_box_reg: 0.3636  loss_mask: 0.1857  loss_rpn_cls: 0.03079  loss_rpn_loc: 0.106  time: 0.9718  data_time: 0.3223  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 19:59:53 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 879  total_loss: 0.9343  loss_cls: 0.2326  loss_box_reg: 0.3855  loss_mask: 0.1993  loss_rpn_cls: 0.02395  loss_rpn_loc: 0.09873  time: 0.9717  data_time: 0.2874  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:00:12 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 899  total_loss: 0.9337  loss_cls: 0.265  loss_box_reg: 0.3899  loss_mask: 0.1716  loss_rpn_cls: 0.02378  loss_rpn_loc: 0.09122  time: 0.9713  data_time: 0.2715  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:00:31 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 919  total_loss: 1.022  loss_cls: 0.3083  loss_box_reg: 0.3725  loss_mask: 0.1693  loss_rpn_cls: 0.03179  loss_rpn_loc: 0.08938  time: 0.9707  data_time: 0.2897  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:00:51 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 939  total_loss: 1.086  loss_cls: 0.2966  loss_box_reg: 0.3988  loss_mask: 0.1851  loss_rpn_cls: 0.02733  loss_rpn_loc: 0.1097  time: 0.9711  data_time: 0.2752  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:01:12 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 959  total_loss: 0.9296  loss_cls: 0.2664  loss_box_reg: 0.3711  loss_mask: 0.1779  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.08974  time: 0.9722  data_time: 0.3176  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:01:32 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 979  total_loss: 0.9724  loss_cls: 0.2693  loss_box_reg: 0.3649  loss_mask: 0.1806  loss_rpn_cls: 0.02545  loss_rpn_loc: 0.09722  time: 0.9728  data_time: 0.3240  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:01:51 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 999  total_loss: 0.9428  loss_cls: 0.2487  loss_box_reg: 0.3832  loss_mask: 0.1656  loss_rpn_cls: 0.02705  loss_rpn_loc: 0.0901  time: 0.9726  data_time: 0.2706  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:02:11 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 1019  total_loss: 0.977  loss_cls: 0.2707  loss_box_reg: 0.3755  loss_mask: 0.1703  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.1238  time: 0.9730  data_time: 0.2914  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:02:30 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 1039  total_loss: 0.9108  loss_cls: 0.2365  loss_box_reg: 0.357  loss_mask: 0.1689  loss_rpn_cls: 0.02864  loss_rpn_loc: 0.08507  time: 0.9725  data_time: 0.2867  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:02:49 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 1059  total_loss: 0.9117  loss_cls: 0.2891  loss_box_reg: 0.3695  loss_mask: 0.1761  loss_rpn_cls: 0.02926  loss_rpn_loc: 0.08148  time: 0.9719  data_time: 0.3053  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:03:08 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 1079  total_loss: 0.9192  loss_cls: 0.2457  loss_box_reg: 0.3569  loss_mask: 0.1503  loss_rpn_cls: 0.02814  loss_rpn_loc: 0.09151  time: 0.9717  data_time: 0.2923  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:03:28 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 1099  total_loss: 0.9662  loss_cls: 0.2662  loss_box_reg: 0.3878  loss_mask: 0.187  loss_rpn_cls: 0.022  loss_rpn_loc: 0.08112  time: 0.9728  data_time: 0.3432  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:03:49 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 1119  total_loss: 0.8748  loss_cls: 0.2432  loss_box_reg: 0.3468  loss_mask: 0.1759  loss_rpn_cls: 0.02323  loss_rpn_loc: 0.08313  time: 0.9735  data_time: 0.3080  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:04:08 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 1139  total_loss: 0.9754  loss_cls: 0.2636  loss_box_reg: 0.3812  loss_mask: 0.1872  loss_rpn_cls: 0.0244  loss_rpn_loc: 0.08062  time: 0.9736  data_time: 0.2703  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:04:27 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1159  total_loss: 0.9466  loss_cls: 0.2778  loss_box_reg: 0.3655  loss_mask: 0.1805  loss_rpn_cls: 0.02792  loss_rpn_loc: 0.113  time: 0.9729  data_time: 0.2594  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:04:47 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 1179  total_loss: 0.8241  loss_cls: 0.223  loss_box_reg: 0.3276  loss_mask: 0.164  loss_rpn_cls: 0.01776  loss_rpn_loc: 0.09339  time: 0.9730  data_time: 0.3075  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:05:06 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 1199  total_loss: 0.9001  loss_cls: 0.24  loss_box_reg: 0.3393  loss_mask: 0.1783  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.08693  time: 0.9730  data_time: 0.2927  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:05:25 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1219  total_loss: 0.8357  loss_cls: 0.2485  loss_box_reg: 0.3187  loss_mask: 0.1657  loss_rpn_cls: 0.02194  loss_rpn_loc: 0.077  time: 0.9726  data_time: 0.3016  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:05:45 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 1239  total_loss: 0.8853  loss_cls: 0.2379  loss_box_reg: 0.331  loss_mask: 0.1658  loss_rpn_cls: 0.02928  loss_rpn_loc: 0.09393  time: 0.9730  data_time: 0.2903  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:06:04 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 1259  total_loss: 0.9104  loss_cls: 0.2614  loss_box_reg: 0.3583  loss_mask: 0.1726  loss_rpn_cls: 0.02418  loss_rpn_loc: 0.1025  time: 0.9730  data_time: 0.2865  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:06:24 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 1279  total_loss: 0.861  loss_cls: 0.2353  loss_box_reg: 0.3216  loss_mask: 0.1739  loss_rpn_cls: 0.02212  loss_rpn_loc: 0.1011  time: 0.9732  data_time: 0.3152  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:06:43 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1299  total_loss: 0.921  loss_cls: 0.2187  loss_box_reg: 0.3456  loss_mask: 0.1714  loss_rpn_cls: 0.02567  loss_rpn_loc: 0.0887  time: 0.9725  data_time: 0.2770  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:07:02 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 1319  total_loss: 0.8344  loss_cls: 0.2281  loss_box_reg: 0.3489  loss_mask: 0.1584  loss_rpn_cls: 0.02142  loss_rpn_loc: 0.0846  time: 0.9726  data_time: 0.3122  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 20:07:22 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1339  total_loss: 0.8611  loss_cls: 0.2614  loss_box_reg: 0.3314  loss_mask: 0.1707  loss_rpn_cls: 0.02157  loss_rpn_loc: 0.07527  time: 0.9724  data_time: 0.2896  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:07:41 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1359  total_loss: 0.8824  loss_cls: 0.2571  loss_box_reg: 0.3473  loss_mask: 0.1788  loss_rpn_cls: 0.01979  loss_rpn_loc: 0.09002  time: 0.9723  data_time: 0.2849  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:08:00 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1379  total_loss: 0.8425  loss_cls: 0.2523  loss_box_reg: 0.3044  loss_mask: 0.1525  loss_rpn_cls: 0.0209  loss_rpn_loc: 0.07804  time: 0.9718  data_time: 0.2791  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:08:19 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1399  total_loss: 0.8917  loss_cls: 0.2476  loss_box_reg: 0.3362  loss_mask: 0.1756  loss_rpn_cls: 0.03002  loss_rpn_loc: 0.103  time: 0.9719  data_time: 0.2780  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:08:38 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.8745  loss_cls: 0.2713  loss_box_reg: 0.3249  loss_mask: 0.1769  loss_rpn_cls: 0.02402  loss_rpn_loc: 0.1118  time: 0.9716  data_time: 0.2753  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:08:57 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.8229  loss_cls: 0.1994  loss_box_reg: 0.3379  loss_mask: 0.1601  loss_rpn_cls: 0.02055  loss_rpn_loc: 0.07238  time: 0.9713  data_time: 0.2992  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:09:17 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.8972  loss_cls: 0.2646  loss_box_reg: 0.2982  loss_mask: 0.1536  loss_rpn_cls: 0.02607  loss_rpn_loc: 0.1038  time: 0.9714  data_time: 0.2902  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:09:37 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.8359  loss_cls: 0.2449  loss_box_reg: 0.3215  loss_mask: 0.1805  loss_rpn_cls: 0.02269  loss_rpn_loc: 0.08628  time: 0.9720  data_time: 0.3094  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:09:57 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.8928  loss_cls: 0.2093  loss_box_reg: 0.3317  loss_mask: 0.1805  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.09448  time: 0.9715  data_time: 0.2699  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:09:57 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:15 (0.9715 s / it)\n",
      "\u001b[32m[03/04 20:09:57 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:17 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 20:09:58 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 20:09:58 d2.data.datasets.coco]: \u001b[0mLoaded 155 images in COCO format from /host/mic21-framework/server/uploads/police_helicopter_gt.json\n",
      "police_helicopter\n",
      "\u001b[32m[03/04 20:09:59 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 20:09:59 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 20:09:59 d2.data.datasets.coco]: \u001b[0mLoaded 155 images in COCO format from /host/mic21-framework/server/uploads/police_helicopter_gt.json\n",
      "\u001b[32m[03/04 20:09:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 155 images left.\n",
      "\u001b[32m[03/04 20:09:59 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|   category    | #instances   |   category   | #instances   |   category   | #instances   |\n",
      "|:-------------:|:-------------|:------------:|:-------------|:------------:|:-------------|\n",
      "|    person     | 57           | landing gear | 101          | rotor system | 115          |\n",
      "| police heli.. | 160          |              |              |              |              |\n",
      "|     total     | 433          |              |              |              |              |\u001b[0m\n",
      "\u001b[32m[03/04 20:09:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 20:09:59 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 20:09:59 d2.data.common]: \u001b[0mSerializing 155 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 20:09:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.82 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 20:09:59 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[03/04 20:10:00 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"/detectron2/detectron2/engine/train_loop.py\", line 149, in train\n",
      "    self.run_step()\n",
      "  File \"/detectron2/detectron2/engine/defaults.py\", line 494, in run_step\n",
      "    self._trainer.run_step()\n",
      "  File \"/detectron2/detectron2/engine/train_loop.py\", line 267, in run_step\n",
      "    data = next(self._data_loader_iter)\n",
      "  File \"/detectron2/detectron2/data/common.py\", line 234, in __iter__\n",
      "    for d in self.dataset:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 32, in fetch\n",
      "    data.append(next(self.dataset_iter))\n",
      "  File \"/detectron2/detectron2/data/common.py\", line 201, in __iter__\n",
      "    yield self.dataset[idx]\n",
      "  File \"/detectron2/detectron2/data/common.py\", line 90, in __getitem__\n",
      "    data = self._map_func(self._dataset[cur_idx])\n",
      "  File \"/detectron2/detectron2/utils/serialize.py\", line 26, in __call__\n",
      "    return self._obj(*args, **kwargs)\n",
      "  File \"/detectron2/detectron2/data/dataset_mapper.py\", line 154, in __call__\n",
      "    image = utils.read_image(dataset_dict[\"file_name\"], format=self.image_format)\n",
      "  File \"/detectron2/detectron2/data/detection_utils.py\", line 180, in read_image\n",
      "    with PathManager.open(file_name, \"rb\") as f:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/iopath/common/file_io.py\", line 1012, in open\n",
      "    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/iopath/common/file_io.py\", line 612, in _open\n",
      "    opener=opener,\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/host/mic21-framework/server/uploads/police_helicopter/CC_API_flickr_6118022c-d34c-48c9-8018-5da63396bd5f.jpg'\n",
      "\n",
      "\u001b[32m[03/04 20:10:00 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n",
      "\u001b[32m[03/04 20:10:00 d2.utils.events]: \u001b[0m iter: 0    lr: N/A  max_mem: 0M\n",
      "New dataset\n",
      "\u001b[32m[03/04 20:10:05 d2.data.datasets.coco]: \u001b[0mLoading /host/mic21-framework/server/uploads/mounted_police_gt.json takes 5.08 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 20:10:05 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 20:10:05 d2.data.datasets.coco]: \u001b[0mLoaded 148 images in COCO format from /host/mic21-framework/server/uploads/mounted_police_gt.json\n",
      "mounted_police\n",
      "\u001b[32m[03/04 20:10:05 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=12, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 20:10:06 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 20:10:06 d2.data.datasets.coco]: \u001b[0mLoaded 148 images in COCO format from /host/mic21-framework/server/uploads/mounted_police_gt.json\n",
      "\u001b[32m[03/04 20:10:06 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 148 images left.\n",
      "\u001b[32m[03/04 20:10:06 d2.data.build]: \u001b[0mDistribution of instances among all 11 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      man      | 130          |     woman     | 109          |      car      | 116          |\n",
      "|     horse     | 320          |   duty belt   | 53           | reflective .. | 90           |\n",
      "| uniform shirt | 126          | uniform pants | 131          | police helmet | 245          |\n",
      "|  police boot  | 284          | mounted pol.. | 310          |               |              |\n",
      "|     total     | 1914         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 20:10:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 20:10:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 20:10:06 d2.data.common]: \u001b[0mSerializing 148 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 20:10:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.28 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (44, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (44,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (11, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 20:10:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 20:10:23 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 19  total_loss: 2.903  loss_cls: 1.192  loss_box_reg: 0.8496  loss_mask: 0.652  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.08854  time: 0.8279  data_time: 0.2026  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:10:40 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 39  total_loss: 2.398  loss_cls: 0.8217  loss_box_reg: 0.839  loss_mask: 0.5691  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.0642  time: 0.8364  data_time: 0.1757  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:10:55 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 59  total_loss: 2.213  loss_cls: 0.6878  loss_box_reg: 0.8063  loss_mask: 0.4931  loss_rpn_cls: 0.04986  loss_rpn_loc: 0.07352  time: 0.8198  data_time: 0.1514  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:11:12 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 79  total_loss: 2.056  loss_cls: 0.6545  loss_box_reg: 0.7597  loss_mask: 0.4198  loss_rpn_cls: 0.05855  loss_rpn_loc: 0.0888  time: 0.8234  data_time: 0.1834  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:11:28 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 99  total_loss: 1.897  loss_cls: 0.627  loss_box_reg: 0.7538  loss_mask: 0.3806  loss_rpn_cls: 0.04869  loss_rpn_loc: 0.06388  time: 0.8161  data_time: 0.1405  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:11:43 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 119  total_loss: 1.531  loss_cls: 0.4229  loss_box_reg: 0.668  loss_mask: 0.3195  loss_rpn_cls: 0.0454  loss_rpn_loc: 0.0565  time: 0.8094  data_time: 0.1636  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:11:59 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 139  total_loss: 1.61  loss_cls: 0.4525  loss_box_reg: 0.6438  loss_mask: 0.3147  loss_rpn_cls: 0.04882  loss_rpn_loc: 0.09636  time: 0.8069  data_time: 0.1516  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:12:14 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 159  total_loss: 1.561  loss_cls: 0.4464  loss_box_reg: 0.6541  loss_mask: 0.303  loss_rpn_cls: 0.04304  loss_rpn_loc: 0.06347  time: 0.8009  data_time: 0.1369  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:12:31 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 179  total_loss: 1.515  loss_cls: 0.4614  loss_box_reg: 0.6265  loss_mask: 0.3157  loss_rpn_cls: 0.04257  loss_rpn_loc: 0.07685  time: 0.8026  data_time: 0.1879  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:12:46 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 199  total_loss: 1.46  loss_cls: 0.3943  loss_box_reg: 0.6339  loss_mask: 0.2946  loss_rpn_cls: 0.04366  loss_rpn_loc: 0.07585  time: 0.8009  data_time: 0.1514  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:13:02 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 219  total_loss: 1.415  loss_cls: 0.3981  loss_box_reg: 0.5895  loss_mask: 0.2653  loss_rpn_cls: 0.03271  loss_rpn_loc: 0.06286  time: 0.7993  data_time: 0.1490  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:13:19 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 239  total_loss: 1.379  loss_cls: 0.384  loss_box_reg: 0.583  loss_mask: 0.2702  loss_rpn_cls: 0.0384  loss_rpn_loc: 0.06497  time: 0.8015  data_time: 0.1748  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:13:35 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 259  total_loss: 1.341  loss_cls: 0.399  loss_box_reg: 0.5454  loss_mask: 0.2711  loss_rpn_cls: 0.03245  loss_rpn_loc: 0.08022  time: 0.8025  data_time: 0.1500  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:13:51 d2.utils.events]: \u001b[0m eta: 0:16:15  iter: 279  total_loss: 1.31  loss_cls: 0.3843  loss_box_reg: 0.5738  loss_mask: 0.2686  loss_rpn_cls: 0.0285  loss_rpn_loc: 0.07544  time: 0.8024  data_time: 0.1470  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:14:07 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 299  total_loss: 1.379  loss_cls: 0.3867  loss_box_reg: 0.5965  loss_mask: 0.2652  loss_rpn_cls: 0.02884  loss_rpn_loc: 0.06184  time: 0.8032  data_time: 0.1607  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:14:24 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 319  total_loss: 1.374  loss_cls: 0.4007  loss_box_reg: 0.5565  loss_mask: 0.2802  loss_rpn_cls: 0.02893  loss_rpn_loc: 0.07219  time: 0.8062  data_time: 0.1899  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:14:40 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 339  total_loss: 1.371  loss_cls: 0.3954  loss_box_reg: 0.5754  loss_mask: 0.2834  loss_rpn_cls: 0.02563  loss_rpn_loc: 0.06491  time: 0.8038  data_time: 0.1325  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:14:57 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 359  total_loss: 1.305  loss_cls: 0.3619  loss_box_reg: 0.5888  loss_mask: 0.2465  loss_rpn_cls: 0.03104  loss_rpn_loc: 0.06213  time: 0.8069  data_time: 0.1923  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:15:13 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 379  total_loss: 1.235  loss_cls: 0.3579  loss_box_reg: 0.5181  loss_mask: 0.2588  loss_rpn_cls: 0.03102  loss_rpn_loc: 0.05166  time: 0.8058  data_time: 0.1364  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:15:29 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 399  total_loss: 1.224  loss_cls: 0.3433  loss_box_reg: 0.4849  loss_mask: 0.2611  loss_rpn_cls: 0.02501  loss_rpn_loc: 0.06288  time: 0.8066  data_time: 0.1728  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:15:45 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 419  total_loss: 1.19  loss_cls: 0.3316  loss_box_reg: 0.5033  loss_mask: 0.2452  loss_rpn_cls: 0.02892  loss_rpn_loc: 0.074  time: 0.8060  data_time: 0.1700  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:16:01 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 439  total_loss: 1.264  loss_cls: 0.3501  loss_box_reg: 0.5002  loss_mask: 0.2479  loss_rpn_cls: 0.02557  loss_rpn_loc: 0.06248  time: 0.8063  data_time: 0.1763  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:16:17 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 459  total_loss: 1.198  loss_cls: 0.3589  loss_box_reg: 0.5245  loss_mask: 0.2388  loss_rpn_cls: 0.02686  loss_rpn_loc: 0.06721  time: 0.8060  data_time: 0.1630  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:16:34 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 479  total_loss: 1.189  loss_cls: 0.3544  loss_box_reg: 0.5215  loss_mask: 0.2447  loss_rpn_cls: 0.02354  loss_rpn_loc: 0.06341  time: 0.8064  data_time: 0.1446  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:16:50 d2.utils.events]: \u001b[0m eta: 0:13:23  iter: 499  total_loss: 1.148  loss_cls: 0.3341  loss_box_reg: 0.5152  loss_mask: 0.2335  loss_rpn_cls: 0.02687  loss_rpn_loc: 0.07356  time: 0.8061  data_time: 0.1791  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:17:06 d2.utils.events]: \u001b[0m eta: 0:13:05  iter: 519  total_loss: 1.254  loss_cls: 0.3148  loss_box_reg: 0.5489  loss_mask: 0.2577  loss_rpn_cls: 0.02802  loss_rpn_loc: 0.06432  time: 0.8065  data_time: 0.1632  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:17:22 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 539  total_loss: 1.162  loss_cls: 0.3226  loss_box_reg: 0.5131  loss_mask: 0.2257  loss_rpn_cls: 0.01998  loss_rpn_loc: 0.0623  time: 0.8065  data_time: 0.1691  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:17:38 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 559  total_loss: 1.197  loss_cls: 0.3588  loss_box_reg: 0.4956  loss_mask: 0.2479  loss_rpn_cls: 0.02082  loss_rpn_loc: 0.07182  time: 0.8061  data_time: 0.1428  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:17:55 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 579  total_loss: 1.118  loss_cls: 0.3398  loss_box_reg: 0.4692  loss_mask: 0.2342  loss_rpn_cls: 0.02319  loss_rpn_loc: 0.06352  time: 0.8069  data_time: 0.1663  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:18:11 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 599  total_loss: 1.087  loss_cls: 0.3009  loss_box_reg: 0.4535  loss_mask: 0.2392  loss_rpn_cls: 0.02303  loss_rpn_loc: 0.05806  time: 0.8078  data_time: 0.1555  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:18:27 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 619  total_loss: 1.126  loss_cls: 0.316  loss_box_reg: 0.4369  loss_mask: 0.2652  loss_rpn_cls: 0.02323  loss_rpn_loc: 0.06534  time: 0.8071  data_time: 0.1454  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:18:42 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 639  total_loss: 1.114  loss_cls: 0.3303  loss_box_reg: 0.4705  loss_mask: 0.2465  loss_rpn_cls: 0.0204  loss_rpn_loc: 0.06522  time: 0.8061  data_time: 0.1611  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:18:59 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 659  total_loss: 1.075  loss_cls: 0.3344  loss_box_reg: 0.4693  loss_mask: 0.2404  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.06138  time: 0.8066  data_time: 0.1912  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 20:19:15 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 679  total_loss: 1.136  loss_cls: 0.3228  loss_box_reg: 0.4909  loss_mask: 0.2453  loss_rpn_cls: 0.01579  loss_rpn_loc: 0.0569  time: 0.8061  data_time: 0.1643  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:19:31 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 699  total_loss: 1.172  loss_cls: 0.3154  loss_box_reg: 0.4886  loss_mask: 0.2498  loss_rpn_cls: 0.01788  loss_rpn_loc: 0.06007  time: 0.8065  data_time: 0.1505  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:19:47 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 719  total_loss: 1.128  loss_cls: 0.3008  loss_box_reg: 0.4492  loss_mask: 0.2394  loss_rpn_cls: 0.01877  loss_rpn_loc: 0.06794  time: 0.8066  data_time: 0.1731  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:20:03 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 739  total_loss: 1.099  loss_cls: 0.2845  loss_box_reg: 0.4916  loss_mask: 0.225  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.0624  time: 0.8056  data_time: 0.1475  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:20:18 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 759  total_loss: 1.129  loss_cls: 0.3317  loss_box_reg: 0.4756  loss_mask: 0.24  loss_rpn_cls: 0.01861  loss_rpn_loc: 0.06684  time: 0.8050  data_time: 0.1669  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:20:34 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 779  total_loss: 1.076  loss_cls: 0.3227  loss_box_reg: 0.4617  loss_mask: 0.2146  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.06033  time: 0.8049  data_time: 0.1689  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:20:50 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 799  total_loss: 1.109  loss_cls: 0.3123  loss_box_reg: 0.4823  loss_mask: 0.2208  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.06284  time: 0.8045  data_time: 0.1665  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:21:06 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 819  total_loss: 0.9843  loss_cls: 0.27  loss_box_reg: 0.4256  loss_mask: 0.2245  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.04803  time: 0.8043  data_time: 0.1473  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:21:22 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 839  total_loss: 1.054  loss_cls: 0.2748  loss_box_reg: 0.4451  loss_mask: 0.251  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.05015  time: 0.8037  data_time: 0.1665  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:21:38 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 859  total_loss: 1.092  loss_cls: 0.298  loss_box_reg: 0.4445  loss_mask: 0.2411  loss_rpn_cls: 0.01781  loss_rpn_loc: 0.0629  time: 0.8037  data_time: 0.1735  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:21:54 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 879  total_loss: 0.9903  loss_cls: 0.2573  loss_box_reg: 0.4212  loss_mask: 0.2252  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.06811  time: 0.8035  data_time: 0.1498  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:22:10 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 899  total_loss: 1.2  loss_cls: 0.3735  loss_box_reg: 0.4837  loss_mask: 0.2342  loss_rpn_cls: 0.02147  loss_rpn_loc: 0.0673  time: 0.8037  data_time: 0.1753  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:22:25 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 919  total_loss: 1.058  loss_cls: 0.2729  loss_box_reg: 0.4637  loss_mask: 0.2294  loss_rpn_cls: 0.01799  loss_rpn_loc: 0.05907  time: 0.8026  data_time: 0.1530  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:22:41 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 939  total_loss: 1.136  loss_cls: 0.3398  loss_box_reg: 0.4593  loss_mask: 0.2287  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.05488  time: 0.8028  data_time: 0.1607  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:22:58 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 959  total_loss: 1.065  loss_cls: 0.2685  loss_box_reg: 0.4362  loss_mask: 0.2191  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.06354  time: 0.8032  data_time: 0.1621  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:23:14 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 979  total_loss: 0.9825  loss_cls: 0.2377  loss_box_reg: 0.4128  loss_mask: 0.2113  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.05501  time: 0.8030  data_time: 0.1625  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:23:29 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 999  total_loss: 1.035  loss_cls: 0.2961  loss_box_reg: 0.4188  loss_mask: 0.2367  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.05631  time: 0.8024  data_time: 0.1603  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:23:46 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 1019  total_loss: 0.9717  loss_cls: 0.2722  loss_box_reg: 0.3997  loss_mask: 0.2225  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.0587  time: 0.8028  data_time: 0.1702  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:24:01 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1039  total_loss: 0.9549  loss_cls: 0.236  loss_box_reg: 0.4232  loss_mask: 0.2263  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.05312  time: 0.8022  data_time: 0.1521  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:24:17 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1059  total_loss: 0.9661  loss_cls: 0.2257  loss_box_reg: 0.4198  loss_mask: 0.2224  loss_rpn_cls: 0.01636  loss_rpn_loc: 0.0596  time: 0.8017  data_time: 0.1620  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:24:33 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 1079  total_loss: 0.9912  loss_cls: 0.2691  loss_box_reg: 0.3894  loss_mask: 0.2382  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.06035  time: 0.8016  data_time: 0.1773  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:24:48 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 1099  total_loss: 0.9935  loss_cls: 0.2739  loss_box_reg: 0.4199  loss_mask: 0.2225  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.06893  time: 0.8011  data_time: 0.1664  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:25:05 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 1119  total_loss: 0.879  loss_cls: 0.2361  loss_box_reg: 0.3853  loss_mask: 0.1996  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.04937  time: 0.8016  data_time: 0.1686  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:25:22 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 1139  total_loss: 0.9049  loss_cls: 0.2744  loss_box_reg: 0.3879  loss_mask: 0.2063  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.05417  time: 0.8023  data_time: 0.1804  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:25:38 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 1159  total_loss: 0.9686  loss_cls: 0.2755  loss_box_reg: 0.4098  loss_mask: 0.2104  loss_rpn_cls: 0.01445  loss_rpn_loc: 0.05763  time: 0.8026  data_time: 0.1622  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:25:54 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 1179  total_loss: 0.9404  loss_cls: 0.2721  loss_box_reg: 0.3771  loss_mask: 0.2231  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.0618  time: 0.8025  data_time: 0.1747  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:26:10 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 1199  total_loss: 0.9604  loss_cls: 0.2462  loss_box_reg: 0.3877  loss_mask: 0.217  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.05411  time: 0.8023  data_time: 0.1522  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:26:25 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 1219  total_loss: 0.9952  loss_cls: 0.2522  loss_box_reg: 0.4221  loss_mask: 0.2157  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.05328  time: 0.8021  data_time: 0.1495  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:26:41 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 1239  total_loss: 0.9094  loss_cls: 0.2328  loss_box_reg: 0.356  loss_mask: 0.2374  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.05348  time: 0.8016  data_time: 0.1536  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:26:56 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 1259  total_loss: 0.9656  loss_cls: 0.2749  loss_box_reg: 0.4012  loss_mask: 0.2188  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.06672  time: 0.8010  data_time: 0.1436  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:27:12 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 1279  total_loss: 0.9663  loss_cls: 0.2415  loss_box_reg: 0.3855  loss_mask: 0.2345  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.05301  time: 0.8010  data_time: 0.1603  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:27:28 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 1299  total_loss: 0.9406  loss_cls: 0.2413  loss_box_reg: 0.3568  loss_mask: 0.2038  loss_rpn_cls: 0.0143  loss_rpn_loc: 0.05441  time: 0.8009  data_time: 0.1683  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:27:44 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 1319  total_loss: 0.9568  loss_cls: 0.2777  loss_box_reg: 0.4246  loss_mask: 0.2242  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.05056  time: 0.8010  data_time: 0.1680  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 20:28:00 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 1339  total_loss: 0.8574  loss_cls: 0.2198  loss_box_reg: 0.3628  loss_mask: 0.2162  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.05226  time: 0.8010  data_time: 0.1601  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:28:17 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 1359  total_loss: 0.9416  loss_cls: 0.2675  loss_box_reg: 0.3769  loss_mask: 0.2087  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.06007  time: 0.8014  data_time: 0.1626  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:28:33 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 1379  total_loss: 0.8949  loss_cls: 0.2218  loss_box_reg: 0.3652  loss_mask: 0.2126  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.05482  time: 0.8014  data_time: 0.1695  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:28:50 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 1399  total_loss: 0.8827  loss_cls: 0.2425  loss_box_reg: 0.374  loss_mask: 0.2089  loss_rpn_cls: 0.01398  loss_rpn_loc: 0.05115  time: 0.8022  data_time: 0.1956  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:29:07 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 1419  total_loss: 1.004  loss_cls: 0.2824  loss_box_reg: 0.3864  loss_mask: 0.2256  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.05902  time: 0.8024  data_time: 0.1809  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:29:23 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 1439  total_loss: 0.9454  loss_cls: 0.262  loss_box_reg: 0.3688  loss_mask: 0.2432  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.06805  time: 0.8027  data_time: 0.1674  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:29:39 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 1459  total_loss: 0.9938  loss_cls: 0.2689  loss_box_reg: 0.3929  loss_mask: 0.2172  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.04933  time: 0.8028  data_time: 0.1577  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:29:55 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 1479  total_loss: 0.964  loss_cls: 0.2458  loss_box_reg: 0.3937  loss_mask: 0.2348  loss_rpn_cls: 0.01376  loss_rpn_loc: 0.05345  time: 0.8028  data_time: 0.1599  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:30:13 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.8829  loss_cls: 0.2277  loss_box_reg: 0.3795  loss_mask: 0.2248  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.05755  time: 0.8031  data_time: 0.1812  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:30:13 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:20:03 (0.8031 s / it)\n",
      "\u001b[32m[03/04 20:30:13 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:05 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 20:30:14 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 20:30:14 d2.data.datasets.coco]: \u001b[0mLoaded 186 images in COCO format from /host/mic21-framework/server/uploads/policeman_gt.json\n",
      "policeman\n",
      "\u001b[32m[03/04 20:30:15 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=15, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=56, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 20:30:15 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 20:30:15 d2.data.datasets.coco]: \u001b[0mLoaded 186 images in COCO format from /host/mic21-framework/server/uploads/policeman_gt.json\n",
      "\u001b[32m[03/04 20:30:15 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 185 images left.\n",
      "\u001b[32m[03/04 20:30:15 d2.data.build]: \u001b[0mDistribution of instances among all 14 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      man      | 130          |     woman     | 91           |      car      | 57           |\n",
      "|   duty belt   | 129          |   duty boot   | 102          | reflective .. | 51           |\n",
      "| uniform shirt | 129          | uniform pants | 112          | police helmet | 100          |\n",
      "| full-dress .. | 73           |  peaked cap   | 168          |   policeman   | 475          |\n",
      "| bulletproof.. | 107          | police badge  | 52           |               |              |\n",
      "|     total     | 1776         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 20:30:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 20:30:15 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 20:30:15 d2.data.common]: \u001b[0mSerializing 185 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 20:30:15 d2.data.common]: \u001b[0mSerialized dataset takes 2.06 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (15, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (15,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (56, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (56,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (14, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 20:30:15 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 20:30:35 d2.utils.events]: \u001b[0m eta: 0:23:03  iter: 19  total_loss: 2.893  loss_cls: 1.228  loss_box_reg: 0.8597  loss_mask: 0.663  loss_rpn_cls: 0.08421  loss_rpn_loc: 0.05922  time: 0.9526  data_time: 0.3361  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:30:55 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 39  total_loss: 2.397  loss_cls: 0.8958  loss_box_reg: 0.7933  loss_mask: 0.5724  loss_rpn_cls: 0.05782  loss_rpn_loc: 0.06496  time: 0.9875  data_time: 0.3146  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:31:13 d2.utils.events]: \u001b[0m eta: 0:22:53  iter: 59  total_loss: 2.221  loss_cls: 0.8234  loss_box_reg: 0.8192  loss_mask: 0.4748  loss_rpn_cls: 0.04422  loss_rpn_loc: 0.05811  time: 0.9584  data_time: 0.2722  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:31:33 d2.utils.events]: \u001b[0m eta: 0:23:07  iter: 79  total_loss: 1.999  loss_cls: 0.7304  loss_box_reg: 0.7968  loss_mask: 0.3844  loss_rpn_cls: 0.03516  loss_rpn_loc: 0.05779  time: 0.9710  data_time: 0.3370  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:31:52 d2.utils.events]: \u001b[0m eta: 0:22:38  iter: 99  total_loss: 1.741  loss_cls: 0.6482  loss_box_reg: 0.684  loss_mask: 0.3276  loss_rpn_cls: 0.03773  loss_rpn_loc: 0.06516  time: 0.9642  data_time: 0.2735  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:32:11 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 119  total_loss: 1.701  loss_cls: 0.6324  loss_box_reg: 0.65  loss_mask: 0.3276  loss_rpn_cls: 0.02808  loss_rpn_loc: 0.04686  time: 0.9627  data_time: 0.2847  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:32:30 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 139  total_loss: 1.481  loss_cls: 0.5132  loss_box_reg: 0.6217  loss_mask: 0.2715  loss_rpn_cls: 0.02838  loss_rpn_loc: 0.05071  time: 0.9603  data_time: 0.3013  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:32:49 d2.utils.events]: \u001b[0m eta: 0:21:03  iter: 159  total_loss: 1.465  loss_cls: 0.4885  loss_box_reg: 0.5632  loss_mask: 0.2681  loss_rpn_cls: 0.0241  loss_rpn_loc: 0.04419  time: 0.9575  data_time: 0.2581  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:33:08 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 179  total_loss: 1.416  loss_cls: 0.5223  loss_box_reg: 0.5731  loss_mask: 0.2492  loss_rpn_cls: 0.02515  loss_rpn_loc: 0.05865  time: 0.9544  data_time: 0.2957  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:33:26 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 199  total_loss: 1.482  loss_cls: 0.5105  loss_box_reg: 0.6296  loss_mask: 0.3041  loss_rpn_cls: 0.03403  loss_rpn_loc: 0.06751  time: 0.9530  data_time: 0.2826  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:33:45 d2.utils.events]: \u001b[0m eta: 0:20:19  iter: 219  total_loss: 1.284  loss_cls: 0.4481  loss_box_reg: 0.5211  loss_mask: 0.2368  loss_rpn_cls: 0.02253  loss_rpn_loc: 0.04649  time: 0.9524  data_time: 0.2671  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:34:04 d2.utils.events]: \u001b[0m eta: 0:20:01  iter: 239  total_loss: 1.297  loss_cls: 0.387  loss_box_reg: 0.5196  loss_mask: 0.2483  loss_rpn_cls: 0.02214  loss_rpn_loc: 0.04738  time: 0.9522  data_time: 0.2842  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:34:24 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 259  total_loss: 1.198  loss_cls: 0.4372  loss_box_reg: 0.5253  loss_mask: 0.207  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.06065  time: 0.9531  data_time: 0.2897  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:34:44 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 279  total_loss: 1.245  loss_cls: 0.4397  loss_box_reg: 0.5011  loss_mask: 0.2429  loss_rpn_cls: 0.03016  loss_rpn_loc: 0.05615  time: 0.9576  data_time: 0.3440  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:35:04 d2.utils.events]: \u001b[0m eta: 0:19:03  iter: 299  total_loss: 1.197  loss_cls: 0.4032  loss_box_reg: 0.4713  loss_mask: 0.2176  loss_rpn_cls: 0.01584  loss_rpn_loc: 0.03549  time: 0.9597  data_time: 0.3142  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:35:23 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 319  total_loss: 1.201  loss_cls: 0.3961  loss_box_reg: 0.4802  loss_mask: 0.2135  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.05634  time: 0.9600  data_time: 0.3040  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:35:42 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 339  total_loss: 1.17  loss_cls: 0.3666  loss_box_reg: 0.4778  loss_mask: 0.2326  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.0488  time: 0.9584  data_time: 0.2528  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:36:02 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 359  total_loss: 1.191  loss_cls: 0.3689  loss_box_reg: 0.501  loss_mask: 0.2021  loss_rpn_cls: 0.01678  loss_rpn_loc: 0.04452  time: 0.9611  data_time: 0.3341  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:36:21 d2.utils.events]: \u001b[0m eta: 0:17:51  iter: 379  total_loss: 1.145  loss_cls: 0.3705  loss_box_reg: 0.4919  loss_mask: 0.2083  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.0445  time: 0.9604  data_time: 0.3204  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:36:39 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 399  total_loss: 1.134  loss_cls: 0.3877  loss_box_reg: 0.4765  loss_mask: 0.2095  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.04646  time: 0.9579  data_time: 0.2694  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:36:59 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 419  total_loss: 1.113  loss_cls: 0.4217  loss_box_reg: 0.4353  loss_mask: 0.223  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.04768  time: 0.9588  data_time: 0.3096  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:37:17 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 439  total_loss: 0.9762  loss_cls: 0.3126  loss_box_reg: 0.416  loss_mask: 0.1886  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.05657  time: 0.9569  data_time: 0.2816  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:37:36 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 459  total_loss: 1.12  loss_cls: 0.3426  loss_box_reg: 0.4638  loss_mask: 0.2239  loss_rpn_cls: 0.01569  loss_rpn_loc: 0.04999  time: 0.9574  data_time: 0.2889  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:37:56 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 479  total_loss: 1.156  loss_cls: 0.3516  loss_box_reg: 0.4625  loss_mask: 0.216  loss_rpn_cls: 0.01808  loss_rpn_loc: 0.05136  time: 0.9591  data_time: 0.3110  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:38:16 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 499  total_loss: 1.082  loss_cls: 0.3468  loss_box_reg: 0.4081  loss_mask: 0.2158  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.04574  time: 0.9591  data_time: 0.2934  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:38:36 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 519  total_loss: 0.9634  loss_cls: 0.304  loss_box_reg: 0.4114  loss_mask: 0.1844  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.04468  time: 0.9618  data_time: 0.3478  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:38:56 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 539  total_loss: 1.038  loss_cls: 0.3705  loss_box_reg: 0.398  loss_mask: 0.1899  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.04963  time: 0.9626  data_time: 0.3219  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:39:15 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 559  total_loss: 1.02  loss_cls: 0.3092  loss_box_reg: 0.403  loss_mask: 0.193  loss_rpn_cls: 0.01727  loss_rpn_loc: 0.04036  time: 0.9626  data_time: 0.3020  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:39:34 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 579  total_loss: 0.9937  loss_cls: 0.2939  loss_box_reg: 0.4029  loss_mask: 0.187  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.04933  time: 0.9618  data_time: 0.2895  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:39:53 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 599  total_loss: 1.039  loss_cls: 0.3747  loss_box_reg: 0.4172  loss_mask: 0.1821  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.03928  time: 0.9616  data_time: 0.2918  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:40:13 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 619  total_loss: 0.9294  loss_cls: 0.3156  loss_box_reg: 0.3903  loss_mask: 0.2007  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.03979  time: 0.9626  data_time: 0.2952  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:40:32 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 639  total_loss: 1.006  loss_cls: 0.3546  loss_box_reg: 0.429  loss_mask: 0.218  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.05146  time: 0.9621  data_time: 0.2951  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:40:51 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 659  total_loss: 0.9526  loss_cls: 0.291  loss_box_reg: 0.4045  loss_mask: 0.1936  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.04543  time: 0.9627  data_time: 0.3256  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 20:41:11 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 679  total_loss: 0.9593  loss_cls: 0.2821  loss_box_reg: 0.3832  loss_mask: 0.1735  loss_rpn_cls: 0.0155  loss_rpn_loc: 0.04674  time: 0.9635  data_time: 0.3233  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:41:30 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 699  total_loss: 0.8718  loss_cls: 0.2481  loss_box_reg: 0.3843  loss_mask: 0.1735  loss_rpn_cls: 0.01131  loss_rpn_loc: 0.05079  time: 0.9631  data_time: 0.2861  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:41:50 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 719  total_loss: 0.883  loss_cls: 0.2794  loss_box_reg: 0.3664  loss_mask: 0.1885  loss_rpn_cls: 0.01389  loss_rpn_loc: 0.04409  time: 0.9632  data_time: 0.2965  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:42:09 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 739  total_loss: 0.9753  loss_cls: 0.3122  loss_box_reg: 0.3991  loss_mask: 0.1941  loss_rpn_cls: 0.01014  loss_rpn_loc: 0.04302  time: 0.9636  data_time: 0.3161  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:42:29 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 759  total_loss: 0.8883  loss_cls: 0.2693  loss_box_reg: 0.3424  loss_mask: 0.1876  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.04222  time: 0.9644  data_time: 0.3050  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:42:49 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 779  total_loss: 0.8602  loss_cls: 0.2489  loss_box_reg: 0.3873  loss_mask: 0.1765  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.05126  time: 0.9651  data_time: 0.3141  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:43:09 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 799  total_loss: 0.8824  loss_cls: 0.2738  loss_box_reg: 0.3695  loss_mask: 0.1826  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.04169  time: 0.9659  data_time: 0.3243  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:43:29 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 819  total_loss: 0.8976  loss_cls: 0.3093  loss_box_reg: 0.3618  loss_mask: 0.1899  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.05047  time: 0.9663  data_time: 0.2981  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:43:48 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 839  total_loss: 0.8442  loss_cls: 0.2482  loss_box_reg: 0.3521  loss_mask: 0.1801  loss_rpn_cls: 0.01042  loss_rpn_loc: 0.04769  time: 0.9658  data_time: 0.2994  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:44:07 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 859  total_loss: 0.8184  loss_cls: 0.2381  loss_box_reg: 0.3618  loss_mask: 0.17  loss_rpn_cls: 0.009175  loss_rpn_loc: 0.04189  time: 0.9658  data_time: 0.2941  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:44:26 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 879  total_loss: 0.9762  loss_cls: 0.2975  loss_box_reg: 0.3748  loss_mask: 0.2105  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.04549  time: 0.9661  data_time: 0.3051  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:44:46 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 899  total_loss: 0.9287  loss_cls: 0.2754  loss_box_reg: 0.3828  loss_mask: 0.2034  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.04552  time: 0.9667  data_time: 0.3436  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:45:06 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 919  total_loss: 0.8599  loss_cls: 0.2705  loss_box_reg: 0.3627  loss_mask: 0.1872  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.03855  time: 0.9675  data_time: 0.3316  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:45:26 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 939  total_loss: 0.9103  loss_cls: 0.2793  loss_box_reg: 0.3929  loss_mask: 0.1747  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.03478  time: 0.9675  data_time: 0.2857  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:45:46 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 959  total_loss: 0.8453  loss_cls: 0.2494  loss_box_reg: 0.338  loss_mask: 0.1728  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.03941  time: 0.9680  data_time: 0.3037  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:46:05 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 979  total_loss: 0.9437  loss_cls: 0.2612  loss_box_reg: 0.3801  loss_mask: 0.1887  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.04329  time: 0.9679  data_time: 0.2916  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:46:24 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 999  total_loss: 0.8477  loss_cls: 0.2484  loss_box_reg: 0.3563  loss_mask: 0.1691  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.03691  time: 0.9681  data_time: 0.3168  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:46:43 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 1019  total_loss: 0.8623  loss_cls: 0.2645  loss_box_reg: 0.3736  loss_mask: 0.1815  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.05113  time: 0.9674  data_time: 0.2659  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:47:03 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 1039  total_loss: 0.8154  loss_cls: 0.2442  loss_box_reg: 0.331  loss_mask: 0.1801  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.04881  time: 0.9683  data_time: 0.3556  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:47:23 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 1059  total_loss: 0.8287  loss_cls: 0.2481  loss_box_reg: 0.3273  loss_mask: 0.183  loss_rpn_cls: 0.009855  loss_rpn_loc: 0.03364  time: 0.9688  data_time: 0.3054  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:47:43 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 1079  total_loss: 0.8495  loss_cls: 0.2767  loss_box_reg: 0.3267  loss_mask: 0.1823  loss_rpn_cls: 0.01012  loss_rpn_loc: 0.04743  time: 0.9691  data_time: 0.3169  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:48:03 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 1099  total_loss: 0.84  loss_cls: 0.2846  loss_box_reg: 0.3205  loss_mask: 0.1698  loss_rpn_cls: 0.007583  loss_rpn_loc: 0.04565  time: 0.9699  data_time: 0.3304  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:48:23 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 1119  total_loss: 0.7549  loss_cls: 0.2366  loss_box_reg: 0.2982  loss_mask: 0.1767  loss_rpn_cls: 0.009157  loss_rpn_loc: 0.04377  time: 0.9698  data_time: 0.3221  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:48:43 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 1139  total_loss: 0.8371  loss_cls: 0.2347  loss_box_reg: 0.3341  loss_mask: 0.1877  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.05  time: 0.9706  data_time: 0.3284  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:49:02 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1159  total_loss: 0.7995  loss_cls: 0.2448  loss_box_reg: 0.3298  loss_mask: 0.1695  loss_rpn_cls: 0.008527  loss_rpn_loc: 0.03659  time: 0.9704  data_time: 0.3277  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:49:21 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1179  total_loss: 0.7702  loss_cls: 0.244  loss_box_reg: 0.2896  loss_mask: 0.1691  loss_rpn_cls: 0.008025  loss_rpn_loc: 0.04321  time: 0.9701  data_time: 0.2808  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:49:40 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 1199  total_loss: 0.756  loss_cls: 0.2226  loss_box_reg: 0.28  loss_mask: 0.1722  loss_rpn_cls: 0.008178  loss_rpn_loc: 0.0388  time: 0.9699  data_time: 0.2729  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:50:00 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1219  total_loss: 0.7675  loss_cls: 0.2509  loss_box_reg: 0.3029  loss_mask: 0.1459  loss_rpn_cls: 0.008549  loss_rpn_loc: 0.04053  time: 0.9703  data_time: 0.3137  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:50:19 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 1239  total_loss: 0.7113  loss_cls: 0.2022  loss_box_reg: 0.2871  loss_mask: 0.1607  loss_rpn_cls: 0.009399  loss_rpn_loc: 0.0427  time: 0.9700  data_time: 0.2831  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:50:39 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 1259  total_loss: 0.6813  loss_cls: 0.186  loss_box_reg: 0.2801  loss_mask: 0.1567  loss_rpn_cls: 0.009341  loss_rpn_loc: 0.03861  time: 0.9701  data_time: 0.3172  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:50:59 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 1279  total_loss: 0.7348  loss_cls: 0.2547  loss_box_reg: 0.2665  loss_mask: 0.1728  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.03205  time: 0.9705  data_time: 0.3147  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:51:18 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1299  total_loss: 0.7304  loss_cls: 0.2176  loss_box_reg: 0.2768  loss_mask: 0.1658  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.0451  time: 0.9703  data_time: 0.2798  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:51:37 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 1319  total_loss: 0.7932  loss_cls: 0.2634  loss_box_reg: 0.3004  loss_mask: 0.1739  loss_rpn_cls: 0.009716  loss_rpn_loc: 0.04711  time: 0.9704  data_time: 0.3150  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 20:51:57 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1339  total_loss: 0.7229  loss_cls: 0.235  loss_box_reg: 0.2942  loss_mask: 0.1516  loss_rpn_cls: 0.006622  loss_rpn_loc: 0.03459  time: 0.9708  data_time: 0.3096  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:52:17 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1359  total_loss: 0.779  loss_cls: 0.2549  loss_box_reg: 0.2932  loss_mask: 0.1726  loss_rpn_cls: 0.008117  loss_rpn_loc: 0.04553  time: 0.9710  data_time: 0.3198  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:52:36 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1379  total_loss: 0.6549  loss_cls: 0.1935  loss_box_reg: 0.265  loss_mask: 0.1401  loss_rpn_cls: 0.007078  loss_rpn_loc: 0.02904  time: 0.9705  data_time: 0.2801  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:52:56 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1399  total_loss: 0.704  loss_cls: 0.2033  loss_box_reg: 0.278  loss_mask: 0.1665  loss_rpn_cls: 0.007666  loss_rpn_loc: 0.0342  time: 0.9709  data_time: 0.3098  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 20:53:15 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.7133  loss_cls: 0.2109  loss_box_reg: 0.2753  loss_mask: 0.1714  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.04103  time: 0.9710  data_time: 0.3004  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:53:35 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.7736  loss_cls: 0.2327  loss_box_reg: 0.3201  loss_mask: 0.172  loss_rpn_cls: 0.009847  loss_rpn_loc: 0.04835  time: 0.9712  data_time: 0.3173  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:53:54 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.8072  loss_cls: 0.23  loss_box_reg: 0.3145  loss_mask: 0.181  loss_rpn_cls: 0.009449  loss_rpn_loc: 0.0465  time: 0.9711  data_time: 0.2949  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:54:13 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.6763  loss_cls: 0.2257  loss_box_reg: 0.2682  loss_mask: 0.1557  loss_rpn_cls: 0.009982  loss_rpn_loc: 0.03879  time: 0.9709  data_time: 0.2927  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:54:35 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7336  loss_cls: 0.2513  loss_box_reg: 0.2805  loss_mask: 0.1578  loss_rpn_cls: 0.009692  loss_rpn_loc: 0.03341  time: 0.9715  data_time: 0.3326  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 20:54:35 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:15 (0.9715 s / it)\n",
      "\u001b[32m[03/04 20:54:35 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:17 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 20:54:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 20:54:36 d2.data.datasets.coco]: \u001b[0mLoaded 166 images in COCO format from /host/mic21-framework/server/uploads/wheelchair_gt.json\n",
      "wheelchair\n",
      "\u001b[32m[03/04 20:54:37 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 20:54:37 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 20:54:37 d2.data.datasets.coco]: \u001b[0mLoaded 166 images in COCO format from /host/mic21-framework/server/uploads/wheelchair_gt.json\n",
      "\u001b[32m[03/04 20:54:37 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 166 images left.\n",
      "\u001b[32m[03/04 20:54:37 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    man     | 62           |  cripple   | 176          | wheelchair | 183          |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 421          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 20:54:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 20:54:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 20:54:37 d2.data.common]: \u001b[0mSerializing 166 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 20:54:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.17 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 20:54:37 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 20:54:57 d2.utils.events]: \u001b[0m eta: 0:21:17  iter: 19  total_loss: 2.149  loss_cls: 0.5951  loss_box_reg: 0.9374  loss_mask: 0.5915  loss_rpn_cls: 0.01824  loss_rpn_loc: 0.01208  time: 0.9613  data_time: 0.3223  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:55:17 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 39  total_loss: 1.529  loss_cls: 0.3095  loss_box_reg: 0.8302  loss_mask: 0.3726  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.01342  time: 0.9790  data_time: 0.3211  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:55:35 d2.utils.events]: \u001b[0m eta: 0:21:50  iter: 59  total_loss: 0.9922  loss_cls: 0.158  loss_box_reg: 0.528  loss_mask: 0.2545  loss_rpn_cls: 0.005523  loss_rpn_loc: 0.01218  time: 0.9617  data_time: 0.2841  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:55:55 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 79  total_loss: 0.9862  loss_cls: 0.2293  loss_box_reg: 0.4881  loss_mask: 0.2371  loss_rpn_cls: 0.006138  loss_rpn_loc: 0.01199  time: 0.9645  data_time: 0.2751  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:56:14 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 99  total_loss: 0.8799  loss_cls: 0.1487  loss_box_reg: 0.4616  loss_mask: 0.2232  loss_rpn_cls: 0.006117  loss_rpn_loc: 0.01215  time: 0.9612  data_time: 0.2907  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:56:34 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 119  total_loss: 0.9281  loss_cls: 0.1851  loss_box_reg: 0.4502  loss_mask: 0.2423  loss_rpn_cls: 0.004501  loss_rpn_loc: 0.01294  time: 0.9647  data_time: 0.2992  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:56:53 d2.utils.events]: \u001b[0m eta: 0:21:39  iter: 139  total_loss: 0.8202  loss_cls: 0.1911  loss_box_reg: 0.421  loss_mask: 0.1929  loss_rpn_cls: 0.004741  loss_rpn_loc: 0.01072  time: 0.9647  data_time: 0.2827  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:57:12 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 159  total_loss: 0.8562  loss_cls: 0.1945  loss_box_reg: 0.3897  loss_mask: 0.2184  loss_rpn_cls: 0.00496  loss_rpn_loc: 0.01196  time: 0.9646  data_time: 0.3172  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:57:31 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 179  total_loss: 0.7424  loss_cls: 0.1531  loss_box_reg: 0.3664  loss_mask: 0.1932  loss_rpn_cls: 0.004798  loss_rpn_loc: 0.01162  time: 0.9624  data_time: 0.2963  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:57:51 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 199  total_loss: 0.7946  loss_cls: 0.1583  loss_box_reg: 0.3605  loss_mask: 0.2015  loss_rpn_cls: 0.001965  loss_rpn_loc: 0.009215  time: 0.9639  data_time: 0.2955  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:58:09 d2.utils.events]: \u001b[0m eta: 0:20:19  iter: 219  total_loss: 0.7157  loss_cls: 0.1613  loss_box_reg: 0.3465  loss_mask: 0.178  loss_rpn_cls: 0.003305  loss_rpn_loc: 0.009544  time: 0.9611  data_time: 0.2863  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:58:29 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 239  total_loss: 0.7691  loss_cls: 0.1718  loss_box_reg: 0.3763  loss_mask: 0.1997  loss_rpn_cls: 0.003426  loss_rpn_loc: 0.009562  time: 0.9638  data_time: 0.2960  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:58:49 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 259  total_loss: 0.7485  loss_cls: 0.1522  loss_box_reg: 0.3275  loss_mask: 0.1982  loss_rpn_cls: 0.00292  loss_rpn_loc: 0.01058  time: 0.9658  data_time: 0.3343  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:59:08 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 279  total_loss: 0.6759  loss_cls: 0.126  loss_box_reg: 0.3459  loss_mask: 0.1804  loss_rpn_cls: 0.003975  loss_rpn_loc: 0.00943  time: 0.9657  data_time: 0.3050  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:59:27 d2.utils.events]: \u001b[0m eta: 0:19:03  iter: 299  total_loss: 0.6714  loss_cls: 0.1519  loss_box_reg: 0.3493  loss_mask: 0.1805  loss_rpn_cls: 0.002533  loss_rpn_loc: 0.01005  time: 0.9651  data_time: 0.3067  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 20:59:47 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 319  total_loss: 0.6691  loss_cls: 0.1481  loss_box_reg: 0.348  loss_mask: 0.1757  loss_rpn_cls: 0.001911  loss_rpn_loc: 0.01052  time: 0.9653  data_time: 0.3022  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:00:06 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 339  total_loss: 0.6599  loss_cls: 0.1418  loss_box_reg: 0.2944  loss_mask: 0.167  loss_rpn_cls: 0.002836  loss_rpn_loc: 0.01106  time: 0.9662  data_time: 0.3156  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:00:25 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 359  total_loss: 0.6508  loss_cls: 0.1182  loss_box_reg: 0.3157  loss_mask: 0.1782  loss_rpn_cls: 0.00169  loss_rpn_loc: 0.008723  time: 0.9645  data_time: 0.2817  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:00:44 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 379  total_loss: 0.681  loss_cls: 0.1427  loss_box_reg: 0.3642  loss_mask: 0.1625  loss_rpn_cls: 0.00292  loss_rpn_loc: 0.00928  time: 0.9634  data_time: 0.2969  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:01:03 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 399  total_loss: 0.6297  loss_cls: 0.1414  loss_box_reg: 0.3271  loss_mask: 0.166  loss_rpn_cls: 0.001972  loss_rpn_loc: 0.008251  time: 0.9625  data_time: 0.2826  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:01:22 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 419  total_loss: 0.6001  loss_cls: 0.1252  loss_box_reg: 0.3101  loss_mask: 0.1695  loss_rpn_cls: 0.001476  loss_rpn_loc: 0.009597  time: 0.9617  data_time: 0.2792  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:01:42 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 439  total_loss: 0.576  loss_cls: 0.131  loss_box_reg: 0.3064  loss_mask: 0.1602  loss_rpn_cls: 0.001601  loss_rpn_loc: 0.00826  time: 0.9632  data_time: 0.3174  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:02:02 d2.utils.events]: \u001b[0m eta: 0:16:32  iter: 459  total_loss: 0.6236  loss_cls: 0.1352  loss_box_reg: 0.2913  loss_mask: 0.1733  loss_rpn_cls: 0.001871  loss_rpn_loc: 0.01109  time: 0.9651  data_time: 0.3378  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:02:22 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 479  total_loss: 0.5907  loss_cls: 0.13  loss_box_reg: 0.3032  loss_mask: 0.1495  loss_rpn_cls: 0.002715  loss_rpn_loc: 0.00952  time: 0.9668  data_time: 0.3272  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:02:42 d2.utils.events]: \u001b[0m eta: 0:15:56  iter: 499  total_loss: 0.5635  loss_cls: 0.1105  loss_box_reg: 0.2685  loss_mask: 0.155  loss_rpn_cls: 0.002471  loss_rpn_loc: 0.008262  time: 0.9674  data_time: 0.3064  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:03:01 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 519  total_loss: 0.5753  loss_cls: 0.1078  loss_box_reg: 0.2892  loss_mask: 0.1541  loss_rpn_cls: 0.002631  loss_rpn_loc: 0.01162  time: 0.9667  data_time: 0.2987  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:03:20 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 539  total_loss: 0.5251  loss_cls: 0.1088  loss_box_reg: 0.2698  loss_mask: 0.1544  loss_rpn_cls: 0.00253  loss_rpn_loc: 0.008717  time: 0.9674  data_time: 0.3166  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:03:39 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 559  total_loss: 0.5595  loss_cls: 0.1211  loss_box_reg: 0.2579  loss_mask: 0.1609  loss_rpn_cls: 0.001031  loss_rpn_loc: 0.009676  time: 0.9664  data_time: 0.3045  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:03:58 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 579  total_loss: 0.4921  loss_cls: 0.07775  loss_box_reg: 0.2549  loss_mask: 0.1495  loss_rpn_cls: 0.002192  loss_rpn_loc: 0.009647  time: 0.9652  data_time: 0.2882  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:04:18 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 599  total_loss: 0.5466  loss_cls: 0.09576  loss_box_reg: 0.2853  loss_mask: 0.1437  loss_rpn_cls: 0.001126  loss_rpn_loc: 0.009212  time: 0.9658  data_time: 0.3177  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:04:37 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 619  total_loss: 0.541  loss_cls: 0.1184  loss_box_reg: 0.2567  loss_mask: 0.1479  loss_rpn_cls: 0.001981  loss_rpn_loc: 0.009754  time: 0.9661  data_time: 0.3105  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:04:56 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 639  total_loss: 0.5523  loss_cls: 0.1025  loss_box_reg: 0.2728  loss_mask: 0.1553  loss_rpn_cls: 0.000946  loss_rpn_loc: 0.009542  time: 0.9658  data_time: 0.3077  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:05:16 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 659  total_loss: 0.5317  loss_cls: 0.1219  loss_box_reg: 0.2552  loss_mask: 0.1445  loss_rpn_cls: 0.001203  loss_rpn_loc: 0.007745  time: 0.9666  data_time: 0.3246  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 21:05:35 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 679  total_loss: 0.5359  loss_cls: 0.1013  loss_box_reg: 0.2718  loss_mask: 0.1382  loss_rpn_cls: 0.001214  loss_rpn_loc: 0.007641  time: 0.9663  data_time: 0.2972  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:05:55 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 699  total_loss: 0.504  loss_cls: 0.1042  loss_box_reg: 0.2524  loss_mask: 0.1489  loss_rpn_cls: 0.00125  loss_rpn_loc: 0.009467  time: 0.9668  data_time: 0.3103  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:06:14 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 719  total_loss: 0.5386  loss_cls: 0.09308  loss_box_reg: 0.2672  loss_mask: 0.1418  loss_rpn_cls: 0.001236  loss_rpn_loc: 0.009128  time: 0.9664  data_time: 0.2900  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:06:33 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 739  total_loss: 0.5284  loss_cls: 0.09065  loss_box_reg: 0.2641  loss_mask: 0.1527  loss_rpn_cls: 0.00163  loss_rpn_loc: 0.008797  time: 0.9663  data_time: 0.2938  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:06:52 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 759  total_loss: 0.5138  loss_cls: 0.1052  loss_box_reg: 0.2586  loss_mask: 0.1351  loss_rpn_cls: 0.00106  loss_rpn_loc: 0.007229  time: 0.9662  data_time: 0.3352  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:07:11 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 779  total_loss: 0.4923  loss_cls: 0.07912  loss_box_reg: 0.2347  loss_mask: 0.1375  loss_rpn_cls: 0.001098  loss_rpn_loc: 0.009114  time: 0.9655  data_time: 0.2843  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:07:31 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 799  total_loss: 0.5133  loss_cls: 0.108  loss_box_reg: 0.2354  loss_mask: 0.1272  loss_rpn_cls: 0.00135  loss_rpn_loc: 0.009708  time: 0.9658  data_time: 0.3106  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:07:50 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 819  total_loss: 0.46  loss_cls: 0.07834  loss_box_reg: 0.2192  loss_mask: 0.1387  loss_rpn_cls: 0.001446  loss_rpn_loc: 0.0103  time: 0.9655  data_time: 0.3082  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:08:09 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 839  total_loss: 0.5354  loss_cls: 0.09235  loss_box_reg: 0.2651  loss_mask: 0.1374  loss_rpn_cls: 0.001369  loss_rpn_loc: 0.008704  time: 0.9651  data_time: 0.2920  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:08:29 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 859  total_loss: 0.5092  loss_cls: 0.0923  loss_box_reg: 0.2682  loss_mask: 0.1475  loss_rpn_cls: 0.00168  loss_rpn_loc: 0.00899  time: 0.9661  data_time: 0.3327  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:08:48 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 879  total_loss: 0.4859  loss_cls: 0.09115  loss_box_reg: 0.2425  loss_mask: 0.1318  loss_rpn_cls: 0.001069  loss_rpn_loc: 0.008753  time: 0.9660  data_time: 0.3135  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:09:08 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 899  total_loss: 0.5051  loss_cls: 0.1195  loss_box_reg: 0.2227  loss_mask: 0.1306  loss_rpn_cls: 0.001144  loss_rpn_loc: 0.00846  time: 0.9659  data_time: 0.2996  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:09:27 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 919  total_loss: 0.4896  loss_cls: 0.07555  loss_box_reg: 0.2449  loss_mask: 0.1468  loss_rpn_cls: 0.0008849  loss_rpn_loc: 0.01009  time: 0.9657  data_time: 0.3158  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:09:46 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 939  total_loss: 0.4638  loss_cls: 0.08796  loss_box_reg: 0.2354  loss_mask: 0.1344  loss_rpn_cls: 0.001494  loss_rpn_loc: 0.009155  time: 0.9660  data_time: 0.2945  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:10:06 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 959  total_loss: 0.4404  loss_cls: 0.07736  loss_box_reg: 0.2283  loss_mask: 0.1332  loss_rpn_cls: 0.001003  loss_rpn_loc: 0.009787  time: 0.9665  data_time: 0.3304  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:10:25 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 979  total_loss: 0.4671  loss_cls: 0.09082  loss_box_reg: 0.2214  loss_mask: 0.1404  loss_rpn_cls: 0.001457  loss_rpn_loc: 0.007908  time: 0.9663  data_time: 0.2958  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:10:45 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 999  total_loss: 0.4585  loss_cls: 0.08498  loss_box_reg: 0.2392  loss_mask: 0.1265  loss_rpn_cls: 0.001095  loss_rpn_loc: 0.009011  time: 0.9669  data_time: 0.3270  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:11:05 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 1019  total_loss: 0.4457  loss_cls: 0.0754  loss_box_reg: 0.2272  loss_mask: 0.1268  loss_rpn_cls: 0.001143  loss_rpn_loc: 0.006913  time: 0.9671  data_time: 0.3277  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:11:24 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 1039  total_loss: 0.4132  loss_cls: 0.08021  loss_box_reg: 0.1844  loss_mask: 0.1345  loss_rpn_cls: 0.001373  loss_rpn_loc: 0.008548  time: 0.9670  data_time: 0.2982  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:11:43 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 1059  total_loss: 0.4424  loss_cls: 0.07935  loss_box_reg: 0.2014  loss_mask: 0.1238  loss_rpn_cls: 0.0008647  loss_rpn_loc: 0.008055  time: 0.9667  data_time: 0.2943  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:12:03 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 1079  total_loss: 0.4386  loss_cls: 0.08418  loss_box_reg: 0.1954  loss_mask: 0.1368  loss_rpn_cls: 0.00212  loss_rpn_loc: 0.009245  time: 0.9671  data_time: 0.3336  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:12:21 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 1099  total_loss: 0.4282  loss_cls: 0.09162  loss_box_reg: 0.194  loss_mask: 0.1277  loss_rpn_cls: 0.001326  loss_rpn_loc: 0.006631  time: 0.9663  data_time: 0.2662  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:12:41 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 1119  total_loss: 0.4299  loss_cls: 0.1042  loss_box_reg: 0.1951  loss_mask: 0.1252  loss_rpn_cls: 0.001122  loss_rpn_loc: 0.00858  time: 0.9670  data_time: 0.3346  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:13:00 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 1139  total_loss: 0.4144  loss_cls: 0.0678  loss_box_reg: 0.1984  loss_mask: 0.1269  loss_rpn_cls: 0.001177  loss_rpn_loc: 0.00783  time: 0.9666  data_time: 0.3108  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:13:20 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 1159  total_loss: 0.4003  loss_cls: 0.06878  loss_box_reg: 0.1993  loss_mask: 0.1261  loss_rpn_cls: 0.001537  loss_rpn_loc: 0.00773  time: 0.9668  data_time: 0.3073  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:13:39 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 1179  total_loss: 0.4098  loss_cls: 0.07252  loss_box_reg: 0.1853  loss_mask: 0.1402  loss_rpn_cls: 0.0007829  loss_rpn_loc: 0.007878  time: 0.9669  data_time: 0.2942  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:13:58 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 1199  total_loss: 0.4012  loss_cls: 0.09066  loss_box_reg: 0.1684  loss_mask: 0.1219  loss_rpn_cls: 0.001455  loss_rpn_loc: 0.008171  time: 0.9663  data_time: 0.2874  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:14:18 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 1219  total_loss: 0.3951  loss_cls: 0.07457  loss_box_reg: 0.1843  loss_mask: 0.1258  loss_rpn_cls: 0.001059  loss_rpn_loc: 0.00692  time: 0.9667  data_time: 0.3193  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:14:37 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 1239  total_loss: 0.3784  loss_cls: 0.09551  loss_box_reg: 0.1664  loss_mask: 0.1234  loss_rpn_cls: 0.001185  loss_rpn_loc: 0.007678  time: 0.9665  data_time: 0.3138  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:14:56 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 1259  total_loss: 0.4188  loss_cls: 0.08279  loss_box_reg: 0.1846  loss_mask: 0.1368  loss_rpn_cls: 0.00119  loss_rpn_loc: 0.00817  time: 0.9665  data_time: 0.3200  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:15:15 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 1279  total_loss: 0.3832  loss_cls: 0.09571  loss_box_reg: 0.1822  loss_mask: 0.1189  loss_rpn_cls: 0.001618  loss_rpn_loc: 0.008469  time: 0.9663  data_time: 0.2950  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:15:34 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 1299  total_loss: 0.4093  loss_cls: 0.07891  loss_box_reg: 0.1823  loss_mask: 0.1234  loss_rpn_cls: 0.0007323  loss_rpn_loc: 0.007215  time: 0.9661  data_time: 0.3067  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:15:55 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 1319  total_loss: 0.4318  loss_cls: 0.08584  loss_box_reg: 0.1894  loss_mask: 0.144  loss_rpn_cls: 0.00101  loss_rpn_loc: 0.007907  time: 0.9667  data_time: 0.3146  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 21:16:14 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 1339  total_loss: 0.3771  loss_cls: 0.07907  loss_box_reg: 0.1769  loss_mask: 0.1265  loss_rpn_cls: 0.000937  loss_rpn_loc: 0.007839  time: 0.9668  data_time: 0.3175  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:16:34 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1359  total_loss: 0.3972  loss_cls: 0.06846  loss_box_reg: 0.1706  loss_mask: 0.135  loss_rpn_cls: 0.001355  loss_rpn_loc: 0.007292  time: 0.9669  data_time: 0.3119  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:16:53 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 1379  total_loss: 0.37  loss_cls: 0.05845  loss_box_reg: 0.1613  loss_mask: 0.1203  loss_rpn_cls: 0.001286  loss_rpn_loc: 0.007302  time: 0.9668  data_time: 0.3281  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:17:12 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1399  total_loss: 0.4016  loss_cls: 0.06194  loss_box_reg: 0.1756  loss_mask: 0.1257  loss_rpn_cls: 0.0009133  loss_rpn_loc: 0.007594  time: 0.9668  data_time: 0.3028  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:17:31 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.3807  loss_cls: 0.06776  loss_box_reg: 0.1587  loss_mask: 0.1283  loss_rpn_cls: 0.0008955  loss_rpn_loc: 0.007117  time: 0.9666  data_time: 0.2999  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:17:51 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.3543  loss_cls: 0.05666  loss_box_reg: 0.1606  loss_mask: 0.1229  loss_rpn_cls: 0.001481  loss_rpn_loc: 0.008512  time: 0.9669  data_time: 0.3223  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:18:10 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.3817  loss_cls: 0.06404  loss_box_reg: 0.1718  loss_mask: 0.1246  loss_rpn_cls: 0.001056  loss_rpn_loc: 0.006766  time: 0.9670  data_time: 0.3179  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:18:31 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.4047  loss_cls: 0.08239  loss_box_reg: 0.1729  loss_mask: 0.1218  loss_rpn_cls: 0.001155  loss_rpn_loc: 0.008203  time: 0.9676  data_time: 0.3430  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:18:51 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.3675  loss_cls: 0.07429  loss_box_reg: 0.154  loss_mask: 0.1233  loss_rpn_cls: 0.001075  loss_rpn_loc: 0.007741  time: 0.9675  data_time: 0.3015  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:18:52 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:09 (0.9676 s / it)\n",
      "\u001b[32m[03/04 21:18:52 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:11 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 21:18:52 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 21:18:52 d2.data.datasets.coco]: \u001b[0mLoaded 176 images in COCO format from /host/mic21-framework/server/uploads/fishing_gt.json\n",
      "fishing\n",
      "\u001b[32m[03/04 21:18:53 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 21:18:53 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 21:18:53 d2.data.datasets.coco]: \u001b[0mLoaded 176 images in COCO format from /host/mic21-framework/server/uploads/fishing_gt.json\n",
      "\u001b[32m[03/04 21:18:53 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 176 images left.\n",
      "\u001b[32m[03/04 21:18:53 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|   category    | #instances   |   category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n",
      "| body of water | 156          | fishing pole | 162          |    fish    | 75           |\n",
      "|   fisherman   | 187          |              |              |            |              |\n",
      "|     total     | 580          |              |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 21:18:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 21:18:53 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 21:18:53 d2.data.common]: \u001b[0mSerializing 176 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 21:18:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.50 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 21:18:53 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 21:19:11 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 19  total_loss: 2.526  loss_cls: 0.8343  loss_box_reg: 0.9692  loss_mask: 0.5775  loss_rpn_cls: 0.03825  loss_rpn_loc: 0.06666  time: 0.8697  data_time: 0.2587  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:19:29 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 39  total_loss: 1.834  loss_cls: 0.5384  loss_box_reg: 0.8605  loss_mask: 0.3102  loss_rpn_cls: 0.04061  loss_rpn_loc: 0.08063  time: 0.8879  data_time: 0.2182  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:19:47 d2.utils.events]: \u001b[0m eta: 0:20:45  iter: 59  total_loss: 1.532  loss_cls: 0.3716  loss_box_reg: 0.7378  loss_mask: 0.2497  loss_rpn_cls: 0.027  loss_rpn_loc: 0.07992  time: 0.8826  data_time: 0.2215  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:20:04 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 79  total_loss: 1.238  loss_cls: 0.2663  loss_box_reg: 0.6385  loss_mask: 0.1972  loss_rpn_cls: 0.02392  loss_rpn_loc: 0.06123  time: 0.8832  data_time: 0.2315  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:20:22 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 99  total_loss: 1.067  loss_cls: 0.2209  loss_box_reg: 0.5495  loss_mask: 0.1811  loss_rpn_cls: 0.02094  loss_rpn_loc: 0.06543  time: 0.8844  data_time: 0.2445  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:20:40 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 119  total_loss: 1.217  loss_cls: 0.2858  loss_box_reg: 0.6007  loss_mask: 0.2174  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.05609  time: 0.8868  data_time: 0.2334  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:20:57 d2.utils.events]: \u001b[0m eta: 0:19:41  iter: 139  total_loss: 1.043  loss_cls: 0.245  loss_box_reg: 0.5305  loss_mask: 0.1823  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.07639  time: 0.8831  data_time: 0.2182  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:21:15 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 159  total_loss: 1.037  loss_cls: 0.2235  loss_box_reg: 0.4914  loss_mask: 0.1765  loss_rpn_cls: 0.01849  loss_rpn_loc: 0.06068  time: 0.8811  data_time: 0.2231  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:21:31 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 179  total_loss: 0.9852  loss_cls: 0.2325  loss_box_reg: 0.461  loss_mask: 0.1916  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.07081  time: 0.8757  data_time: 0.1856  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:21:49 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 199  total_loss: 0.9108  loss_cls: 0.2032  loss_box_reg: 0.4498  loss_mask: 0.1551  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.06755  time: 0.8775  data_time: 0.2513  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:22:07 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 219  total_loss: 0.9762  loss_cls: 0.2338  loss_box_reg: 0.4926  loss_mask: 0.1497  loss_rpn_cls: 0.007345  loss_rpn_loc: 0.06474  time: 0.8778  data_time: 0.2120  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:22:24 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 239  total_loss: 0.9063  loss_cls: 0.1801  loss_box_reg: 0.4257  loss_mask: 0.1472  loss_rpn_cls: 0.008892  loss_rpn_loc: 0.05077  time: 0.8745  data_time: 0.2040  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:22:41 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 259  total_loss: 0.9287  loss_cls: 0.1847  loss_box_reg: 0.436  loss_mask: 0.1496  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.0865  time: 0.8749  data_time: 0.2220  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:22:58 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 279  total_loss: 0.8668  loss_cls: 0.1903  loss_box_reg: 0.4291  loss_mask: 0.1198  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.07643  time: 0.8735  data_time: 0.2019  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:23:17 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 299  total_loss: 0.773  loss_cls: 0.1646  loss_box_reg: 0.3854  loss_mask: 0.1356  loss_rpn_cls: 0.008958  loss_rpn_loc: 0.04197  time: 0.8763  data_time: 0.2588  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:23:34 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 319  total_loss: 0.7817  loss_cls: 0.152  loss_box_reg: 0.365  loss_mask: 0.1418  loss_rpn_cls: 0.01215  loss_rpn_loc: 0.06605  time: 0.8748  data_time: 0.1873  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:23:51 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 339  total_loss: 0.824  loss_cls: 0.147  loss_box_reg: 0.4248  loss_mask: 0.117  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.06411  time: 0.8725  data_time: 0.2120  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:24:08 d2.utils.events]: \u001b[0m eta: 0:16:32  iter: 359  total_loss: 0.8487  loss_cls: 0.1704  loss_box_reg: 0.4283  loss_mask: 0.1294  loss_rpn_cls: 0.009529  loss_rpn_loc: 0.056  time: 0.8732  data_time: 0.2358  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:24:26 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 379  total_loss: 0.8035  loss_cls: 0.1565  loss_box_reg: 0.3859  loss_mask: 0.1349  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.07599  time: 0.8734  data_time: 0.2284  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:24:43 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 399  total_loss: 0.7054  loss_cls: 0.149  loss_box_reg: 0.3868  loss_mask: 0.125  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.05654  time: 0.8729  data_time: 0.2251  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:25:00 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 419  total_loss: 0.7236  loss_cls: 0.159  loss_box_reg: 0.3802  loss_mask: 0.1194  loss_rpn_cls: 0.008647  loss_rpn_loc: 0.04859  time: 0.8726  data_time: 0.1951  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:25:18 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 439  total_loss: 0.8687  loss_cls: 0.1981  loss_box_reg: 0.4565  loss_mask: 0.162  loss_rpn_cls: 0.007365  loss_rpn_loc: 0.06566  time: 0.8723  data_time: 0.2008  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:25:35 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 459  total_loss: 0.76  loss_cls: 0.1454  loss_box_reg: 0.3569  loss_mask: 0.1275  loss_rpn_cls: 0.009766  loss_rpn_loc: 0.06883  time: 0.8728  data_time: 0.2409  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:25:53 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 479  total_loss: 0.7335  loss_cls: 0.1328  loss_box_reg: 0.3681  loss_mask: 0.1263  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.06173  time: 0.8724  data_time: 0.2369  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:26:10 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 499  total_loss: 0.7368  loss_cls: 0.1578  loss_box_reg: 0.3535  loss_mask: 0.1348  loss_rpn_cls: 0.008518  loss_rpn_loc: 0.04897  time: 0.8724  data_time: 0.2262  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:26:27 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 519  total_loss: 0.7061  loss_cls: 0.1363  loss_box_reg: 0.3637  loss_mask: 0.1109  loss_rpn_cls: 0.007794  loss_rpn_loc: 0.05627  time: 0.8721  data_time: 0.2180  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:26:45 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 539  total_loss: 0.6677  loss_cls: 0.1297  loss_box_reg: 0.3558  loss_mask: 0.1121  loss_rpn_cls: 0.007259  loss_rpn_loc: 0.05952  time: 0.8730  data_time: 0.2494  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:27:02 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 559  total_loss: 0.7083  loss_cls: 0.157  loss_box_reg: 0.375  loss_mask: 0.1285  loss_rpn_cls: 0.00764  loss_rpn_loc: 0.07275  time: 0.8716  data_time: 0.2052  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:27:19 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 579  total_loss: 0.7686  loss_cls: 0.147  loss_box_reg: 0.3882  loss_mask: 0.1401  loss_rpn_cls: 0.008382  loss_rpn_loc: 0.05297  time: 0.8713  data_time: 0.2190  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:27:38 d2.utils.events]: \u001b[0m eta: 0:13:05  iter: 599  total_loss: 0.6845  loss_cls: 0.1361  loss_box_reg: 0.3443  loss_mask: 0.1222  loss_rpn_cls: 0.00892  loss_rpn_loc: 0.05683  time: 0.8726  data_time: 0.2387  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:27:55 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 619  total_loss: 0.627  loss_cls: 0.1104  loss_box_reg: 0.3343  loss_mask: 0.104  loss_rpn_cls: 0.006255  loss_rpn_loc: 0.04543  time: 0.8719  data_time: 0.2189  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:28:12 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 639  total_loss: 0.6137  loss_cls: 0.1199  loss_box_reg: 0.3332  loss_mask: 0.1072  loss_rpn_cls: 0.006904  loss_rpn_loc: 0.06901  time: 0.8720  data_time: 0.1859  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:28:30 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 659  total_loss: 0.6591  loss_cls: 0.1134  loss_box_reg: 0.3352  loss_mask: 0.1109  loss_rpn_cls: 0.007712  loss_rpn_loc: 0.07376  time: 0.8722  data_time: 0.2236  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 21:28:48 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 679  total_loss: 0.6807  loss_cls: 0.1401  loss_box_reg: 0.3121  loss_mask: 0.1356  loss_rpn_cls: 0.006379  loss_rpn_loc: 0.05066  time: 0.8729  data_time: 0.2403  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:29:05 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 699  total_loss: 0.6307  loss_cls: 0.1089  loss_box_reg: 0.3436  loss_mask: 0.1204  loss_rpn_cls: 0.007328  loss_rpn_loc: 0.04421  time: 0.8730  data_time: 0.2018  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:29:23 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 719  total_loss: 0.669  loss_cls: 0.1261  loss_box_reg: 0.3151  loss_mask: 0.1161  loss_rpn_cls: 0.008183  loss_rpn_loc: 0.06273  time: 0.8732  data_time: 0.2230  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:29:40 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 739  total_loss: 0.6849  loss_cls: 0.1514  loss_box_reg: 0.3224  loss_mask: 0.1201  loss_rpn_cls: 0.005887  loss_rpn_loc: 0.06223  time: 0.8733  data_time: 0.2093  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:29:58 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 759  total_loss: 0.719  loss_cls: 0.1415  loss_box_reg: 0.3295  loss_mask: 0.1081  loss_rpn_cls: 0.007065  loss_rpn_loc: 0.07996  time: 0.8736  data_time: 0.2215  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:30:15 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 779  total_loss: 0.637  loss_cls: 0.1268  loss_box_reg: 0.3381  loss_mask: 0.1182  loss_rpn_cls: 0.006631  loss_rpn_loc: 0.04266  time: 0.8731  data_time: 0.2294  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:30:32 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 799  total_loss: 0.6862  loss_cls: 0.1208  loss_box_reg: 0.3331  loss_mask: 0.1186  loss_rpn_cls: 0.008142  loss_rpn_loc: 0.0654  time: 0.8723  data_time: 0.1979  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:30:50 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 819  total_loss: 0.6236  loss_cls: 0.1307  loss_box_reg: 0.3392  loss_mask: 0.1135  loss_rpn_cls: 0.005726  loss_rpn_loc: 0.0581  time: 0.8730  data_time: 0.2292  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:31:07 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 839  total_loss: 0.5861  loss_cls: 0.1286  loss_box_reg: 0.3172  loss_mask: 0.108  loss_rpn_cls: 0.007703  loss_rpn_loc: 0.05375  time: 0.8729  data_time: 0.2165  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:31:24 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 859  total_loss: 0.585  loss_cls: 0.09531  loss_box_reg: 0.3144  loss_mask: 0.1029  loss_rpn_cls: 0.006447  loss_rpn_loc: 0.05516  time: 0.8718  data_time: 0.1817  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:31:42 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 879  total_loss: 0.5867  loss_cls: 0.1024  loss_box_reg: 0.2891  loss_mask: 0.1132  loss_rpn_cls: 0.005054  loss_rpn_loc: 0.06501  time: 0.8719  data_time: 0.2056  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:31:58 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 899  total_loss: 0.6641  loss_cls: 0.1422  loss_box_reg: 0.3576  loss_mask: 0.1055  loss_rpn_cls: 0.005937  loss_rpn_loc: 0.04644  time: 0.8712  data_time: 0.2092  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:32:16 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 919  total_loss: 0.6106  loss_cls: 0.09758  loss_box_reg: 0.3052  loss_mask: 0.1132  loss_rpn_cls: 0.006497  loss_rpn_loc: 0.04667  time: 0.8711  data_time: 0.2438  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:32:33 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 939  total_loss: 0.6206  loss_cls: 0.1214  loss_box_reg: 0.3012  loss_mask: 0.1103  loss_rpn_cls: 0.006901  loss_rpn_loc: 0.05054  time: 0.8713  data_time: 0.2159  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:32:51 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 959  total_loss: 0.5824  loss_cls: 0.1012  loss_box_reg: 0.3001  loss_mask: 0.09799  loss_rpn_cls: 0.005307  loss_rpn_loc: 0.04817  time: 0.8714  data_time: 0.2128  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:33:09 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 979  total_loss: 0.6838  loss_cls: 0.1347  loss_box_reg: 0.3384  loss_mask: 0.1095  loss_rpn_cls: 0.007819  loss_rpn_loc: 0.05394  time: 0.8717  data_time: 0.2415  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:33:26 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 999  total_loss: 0.6123  loss_cls: 0.09565  loss_box_reg: 0.3161  loss_mask: 0.1356  loss_rpn_cls: 0.00525  loss_rpn_loc: 0.04953  time: 0.8718  data_time: 0.2042  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:33:44 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1019  total_loss: 0.5473  loss_cls: 0.1062  loss_box_reg: 0.2919  loss_mask: 0.09684  loss_rpn_cls: 0.005055  loss_rpn_loc: 0.06078  time: 0.8721  data_time: 0.2342  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:34:01 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 1039  total_loss: 0.5986  loss_cls: 0.1086  loss_box_reg: 0.3021  loss_mask: 0.1151  loss_rpn_cls: 0.007421  loss_rpn_loc: 0.05423  time: 0.8716  data_time: 0.2079  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:34:18 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 1059  total_loss: 0.5677  loss_cls: 0.09964  loss_box_reg: 0.27  loss_mask: 0.1116  loss_rpn_cls: 0.004353  loss_rpn_loc: 0.04394  time: 0.8718  data_time: 0.2282  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:34:35 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 1079  total_loss: 0.5942  loss_cls: 0.108  loss_box_reg: 0.2925  loss_mask: 0.1095  loss_rpn_cls: 0.006772  loss_rpn_loc: 0.05354  time: 0.8711  data_time: 0.2002  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:34:53 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 1099  total_loss: 0.5669  loss_cls: 0.1279  loss_box_reg: 0.244  loss_mask: 0.119  loss_rpn_cls: 0.007004  loss_rpn_loc: 0.04453  time: 0.8718  data_time: 0.2459  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:35:11 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1119  total_loss: 0.6288  loss_cls: 0.08793  loss_box_reg: 0.3015  loss_mask: 0.1085  loss_rpn_cls: 0.004394  loss_rpn_loc: 0.05312  time: 0.8722  data_time: 0.2268  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:35:29 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 1139  total_loss: 0.5216  loss_cls: 0.1044  loss_box_reg: 0.2708  loss_mask: 0.1014  loss_rpn_cls: 0.00603  loss_rpn_loc: 0.04983  time: 0.8724  data_time: 0.2345  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:35:47 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 1159  total_loss: 0.5332  loss_cls: 0.06534  loss_box_reg: 0.2644  loss_mask: 0.1003  loss_rpn_cls: 0.005626  loss_rpn_loc: 0.03856  time: 0.8726  data_time: 0.2238  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:36:04 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 1179  total_loss: 0.5425  loss_cls: 0.1034  loss_box_reg: 0.2767  loss_mask: 0.1037  loss_rpn_cls: 0.003388  loss_rpn_loc: 0.04859  time: 0.8727  data_time: 0.2341  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:36:22 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 1199  total_loss: 0.5489  loss_cls: 0.108  loss_box_reg: 0.2751  loss_mask: 0.09237  loss_rpn_cls: 0.004289  loss_rpn_loc: 0.05665  time: 0.8732  data_time: 0.2518  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:36:40 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 1219  total_loss: 0.512  loss_cls: 0.09765  loss_box_reg: 0.2562  loss_mask: 0.1095  loss_rpn_cls: 0.005666  loss_rpn_loc: 0.04358  time: 0.8732  data_time: 0.2302  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:36:57 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 1239  total_loss: 0.4775  loss_cls: 0.09728  loss_box_reg: 0.2348  loss_mask: 0.1004  loss_rpn_cls: 0.005079  loss_rpn_loc: 0.04302  time: 0.8732  data_time: 0.2227  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:37:16 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 1259  total_loss: 0.5043  loss_cls: 0.08146  loss_box_reg: 0.2476  loss_mask: 0.09251  loss_rpn_cls: 0.004638  loss_rpn_loc: 0.04824  time: 0.8741  data_time: 0.2449  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:37:34 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 1279  total_loss: 0.5385  loss_cls: 0.09552  loss_box_reg: 0.255  loss_mask: 0.1112  loss_rpn_cls: 0.00581  loss_rpn_loc: 0.03762  time: 0.8744  data_time: 0.2544  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:37:52 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 1299  total_loss: 0.5243  loss_cls: 0.1114  loss_box_reg: 0.2397  loss_mask: 0.1087  loss_rpn_cls: 0.004159  loss_rpn_loc: 0.04876  time: 0.8750  data_time: 0.2578  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:38:10 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 1319  total_loss: 0.5084  loss_cls: 0.09044  loss_box_reg: 0.2132  loss_mask: 0.1023  loss_rpn_cls: 0.004968  loss_rpn_loc: 0.04881  time: 0.8753  data_time: 0.2179  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 21:38:29 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 1339  total_loss: 0.4909  loss_cls: 0.104  loss_box_reg: 0.2318  loss_mask: 0.09173  loss_rpn_cls: 0.004773  loss_rpn_loc: 0.04699  time: 0.8763  data_time: 0.2743  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:38:48 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 1359  total_loss: 0.5703  loss_cls: 0.1178  loss_box_reg: 0.2742  loss_mask: 0.1066  loss_rpn_cls: 0.005984  loss_rpn_loc: 0.05117  time: 0.8772  data_time: 0.2631  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:39:06 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 1379  total_loss: 0.5558  loss_cls: 0.1162  loss_box_reg: 0.2693  loss_mask: 0.1052  loss_rpn_cls: 0.004547  loss_rpn_loc: 0.0585  time: 0.8775  data_time: 0.2346  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:39:24 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 1399  total_loss: 0.5214  loss_cls: 0.096  loss_box_reg: 0.2654  loss_mask: 0.09747  loss_rpn_cls: 0.005165  loss_rpn_loc: 0.04039  time: 0.8780  data_time: 0.2552  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:39:42 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 1419  total_loss: 0.4777  loss_cls: 0.08005  loss_box_reg: 0.2231  loss_mask: 0.09884  loss_rpn_cls: 0.005828  loss_rpn_loc: 0.04596  time: 0.8783  data_time: 0.2415  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:40:00 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 1439  total_loss: 0.5406  loss_cls: 0.09447  loss_box_reg: 0.2447  loss_mask: 0.1047  loss_rpn_cls: 0.00377  loss_rpn_loc: 0.04264  time: 0.8784  data_time: 0.2406  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:40:18 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 1459  total_loss: 0.5012  loss_cls: 0.0894  loss_box_reg: 0.259  loss_mask: 0.09922  loss_rpn_cls: 0.00539  loss_rpn_loc: 0.05338  time: 0.8790  data_time: 0.2715  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:40:36 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.5448  loss_cls: 0.123  loss_box_reg: 0.2457  loss_mask: 0.1057  loss_rpn_cls: 0.006829  loss_rpn_loc: 0.05113  time: 0.8793  data_time: 0.2465  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:40:55 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4563  loss_cls: 0.07912  loss_box_reg: 0.2221  loss_mask: 0.1012  loss_rpn_cls: 0.00501  loss_rpn_loc: 0.03869  time: 0.8794  data_time: 0.2293  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 21:40:55 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:57 (0.8794 s / it)\n",
      "\u001b[32m[03/04 21:40:55 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:59 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 21:40:56 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 21:40:56 d2.data.datasets.coco]: \u001b[0mLoaded 119 images in COCO format from /host/mic21-framework/server/uploads/hunting_gt.json\n",
      "hunting\n",
      "\u001b[32m[03/04 21:40:57 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 21:40:57 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 21:40:57 d2.data.datasets.coco]: \u001b[0mLoaded 119 images in COCO format from /host/mic21-framework/server/uploads/hunting_gt.json\n",
      "\u001b[32m[03/04 21:40:57 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 119 images left.\n",
      "\u001b[32m[03/04 21:40:57 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|   category   | #instances   |   category   | #instances   |   category    | #instances   |\n",
      "|:------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
      "|    rifle     | 106          | hunting boot | 75           | camouflage .. | 78           |\n",
      "| hunting vest | 70           |    hunter    | 194          |               |              |\n",
      "|    total     | 523          |              |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 21:40:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 21:40:57 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 21:40:57 d2.data.common]: \u001b[0mSerializing 119 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 21:40:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.61 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 21:40:57 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 21:41:14 d2.utils.events]: \u001b[0m eta: 0:21:25  iter: 19  total_loss: 2.411  loss_cls: 0.8438  loss_box_reg: 0.8845  loss_mask: 0.62  loss_rpn_cls: 0.03013  loss_rpn_loc: 0.02661  time: 0.8571  data_time: 0.2208  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:41:32 d2.utils.events]: \u001b[0m eta: 0:20:59  iter: 39  total_loss: 1.962  loss_cls: 0.5869  loss_box_reg: 0.8943  loss_mask: 0.4566  loss_rpn_cls: 0.02805  loss_rpn_loc: 0.0278  time: 0.8600  data_time: 0.1875  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:41:49 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 59  total_loss: 1.537  loss_cls: 0.4386  loss_box_reg: 0.7601  loss_mask: 0.3145  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.04839  time: 0.8664  data_time: 0.2037  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:42:07 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 79  total_loss: 1.359  loss_cls: 0.3465  loss_box_reg: 0.6521  loss_mask: 0.2786  loss_rpn_cls: 0.01674  loss_rpn_loc: 0.03918  time: 0.8722  data_time: 0.2251  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:42:24 d2.utils.events]: \u001b[0m eta: 0:20:29  iter: 99  total_loss: 1.28  loss_cls: 0.3511  loss_box_reg: 0.6085  loss_mask: 0.2795  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.01961  time: 0.8714  data_time: 0.1951  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:42:41 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 119  total_loss: 1.276  loss_cls: 0.3382  loss_box_reg: 0.549  loss_mask: 0.2847  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.04054  time: 0.8672  data_time: 0.1762  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:42:59 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 139  total_loss: 1.137  loss_cls: 0.271  loss_box_reg: 0.52  loss_mask: 0.237  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.03042  time: 0.8679  data_time: 0.2069  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:43:16 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 159  total_loss: 1.127  loss_cls: 0.3082  loss_box_reg: 0.507  loss_mask: 0.2354  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.0297  time: 0.8700  data_time: 0.2122  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:43:33 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 179  total_loss: 1.071  loss_cls: 0.2913  loss_box_reg: 0.4768  loss_mask: 0.2372  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.02773  time: 0.8653  data_time: 0.1804  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:43:51 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 199  total_loss: 1.069  loss_cls: 0.2769  loss_box_reg: 0.4861  loss_mask: 0.2247  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.03486  time: 0.8679  data_time: 0.2140  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:44:08 d2.utils.events]: \u001b[0m eta: 0:18:28  iter: 219  total_loss: 1.009  loss_cls: 0.2338  loss_box_reg: 0.4885  loss_mask: 0.2266  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.03186  time: 0.8683  data_time: 0.2031  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:44:25 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 239  total_loss: 1.028  loss_cls: 0.2482  loss_box_reg: 0.482  loss_mask: 0.2472  loss_rpn_cls: 0.008949  loss_rpn_loc: 0.02844  time: 0.8668  data_time: 0.2026  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:44:42 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 259  total_loss: 1.034  loss_cls: 0.2822  loss_box_reg: 0.4597  loss_mask: 0.2351  loss_rpn_cls: 0.006827  loss_rpn_loc: 0.02478  time: 0.8647  data_time: 0.1907  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:45:00 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 279  total_loss: 0.8815  loss_cls: 0.2417  loss_box_reg: 0.3991  loss_mask: 0.1982  loss_rpn_cls: 0.009767  loss_rpn_loc: 0.02801  time: 0.8650  data_time: 0.2094  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:45:17 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 299  total_loss: 0.8883  loss_cls: 0.2519  loss_box_reg: 0.4177  loss_mask: 0.1965  loss_rpn_cls: 0.006948  loss_rpn_loc: 0.03139  time: 0.8658  data_time: 0.2041  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:45:35 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 319  total_loss: 0.9144  loss_cls: 0.2508  loss_box_reg: 0.4284  loss_mask: 0.2062  loss_rpn_cls: 0.007038  loss_rpn_loc: 0.02669  time: 0.8666  data_time: 0.2080  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:45:52 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 339  total_loss: 0.9163  loss_cls: 0.2618  loss_box_reg: 0.4076  loss_mask: 0.2088  loss_rpn_cls: 0.006269  loss_rpn_loc: 0.01881  time: 0.8677  data_time: 0.2135  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:46:10 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 359  total_loss: 0.8828  loss_cls: 0.2245  loss_box_reg: 0.4361  loss_mask: 0.2226  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.02404  time: 0.8690  data_time: 0.2248  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:46:28 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 379  total_loss: 0.9326  loss_cls: 0.2589  loss_box_reg: 0.4312  loss_mask: 0.197  loss_rpn_cls: 0.006633  loss_rpn_loc: 0.02618  time: 0.8692  data_time: 0.2122  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:46:45 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 399  total_loss: 0.8919  loss_cls: 0.2498  loss_box_reg: 0.3842  loss_mask: 0.209  loss_rpn_cls: 0.006692  loss_rpn_loc: 0.02714  time: 0.8685  data_time: 0.2120  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:47:01 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 419  total_loss: 0.884  loss_cls: 0.2377  loss_box_reg: 0.3979  loss_mask: 0.224  loss_rpn_cls: 0.006335  loss_rpn_loc: 0.02832  time: 0.8665  data_time: 0.1772  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:47:18 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 439  total_loss: 0.7323  loss_cls: 0.2001  loss_box_reg: 0.3412  loss_mask: 0.1642  loss_rpn_cls: 0.006179  loss_rpn_loc: 0.02746  time: 0.8659  data_time: 0.1754  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:47:36 d2.utils.events]: \u001b[0m eta: 0:14:56  iter: 459  total_loss: 0.8441  loss_cls: 0.2271  loss_box_reg: 0.3513  loss_mask: 0.2008  loss_rpn_cls: 0.006656  loss_rpn_loc: 0.04114  time: 0.8668  data_time: 0.2070  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:47:53 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 479  total_loss: 0.8072  loss_cls: 0.1916  loss_box_reg: 0.3533  loss_mask: 0.1884  loss_rpn_cls: 0.005485  loss_rpn_loc: 0.02681  time: 0.8658  data_time: 0.1888  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:48:10 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 499  total_loss: 0.7892  loss_cls: 0.201  loss_box_reg: 0.3505  loss_mask: 0.1747  loss_rpn_cls: 0.007151  loss_rpn_loc: 0.02806  time: 0.8646  data_time: 0.1841  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:48:28 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 519  total_loss: 0.7276  loss_cls: 0.1779  loss_box_reg: 0.3284  loss_mask: 0.1613  loss_rpn_cls: 0.005133  loss_rpn_loc: 0.02532  time: 0.8658  data_time: 0.2029  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:48:46 d2.utils.events]: \u001b[0m eta: 0:13:46  iter: 539  total_loss: 0.8317  loss_cls: 0.2209  loss_box_reg: 0.3724  loss_mask: 0.177  loss_rpn_cls: 0.007565  loss_rpn_loc: 0.03386  time: 0.8677  data_time: 0.2453  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:49:04 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 559  total_loss: 0.8008  loss_cls: 0.2138  loss_box_reg: 0.3737  loss_mask: 0.1961  loss_rpn_cls: 0.00636  loss_rpn_loc: 0.02425  time: 0.8685  data_time: 0.2285  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:49:21 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 579  total_loss: 0.7714  loss_cls: 0.2111  loss_box_reg: 0.3459  loss_mask: 0.1698  loss_rpn_cls: 0.005341  loss_rpn_loc: 0.02469  time: 0.8673  data_time: 0.1873  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:49:37 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 599  total_loss: 0.7674  loss_cls: 0.1975  loss_box_reg: 0.3613  loss_mask: 0.1697  loss_rpn_cls: 0.006927  loss_rpn_loc: 0.02151  time: 0.8664  data_time: 0.1932  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:49:55 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 619  total_loss: 0.7201  loss_cls: 0.1883  loss_box_reg: 0.3386  loss_mask: 0.1799  loss_rpn_cls: 0.007024  loss_rpn_loc: 0.02659  time: 0.8662  data_time: 0.2030  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:50:13 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 639  total_loss: 0.7023  loss_cls: 0.1629  loss_box_reg: 0.3526  loss_mask: 0.153  loss_rpn_cls: 0.005214  loss_rpn_loc: 0.02153  time: 0.8679  data_time: 0.2265  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:50:30 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 659  total_loss: 0.7361  loss_cls: 0.1942  loss_box_reg: 0.3551  loss_mask: 0.1656  loss_rpn_cls: 0.003605  loss_rpn_loc: 0.02677  time: 0.8675  data_time: 0.1987  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 21:50:48 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 679  total_loss: 0.6284  loss_cls: 0.1379  loss_box_reg: 0.3046  loss_mask: 0.1533  loss_rpn_cls: 0.004408  loss_rpn_loc: 0.01929  time: 0.8680  data_time: 0.2202  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:51:06 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 699  total_loss: 0.6574  loss_cls: 0.1415  loss_box_reg: 0.3195  loss_mask: 0.159  loss_rpn_cls: 0.004324  loss_rpn_loc: 0.02642  time: 0.8692  data_time: 0.2365  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:51:24 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 719  total_loss: 0.7127  loss_cls: 0.1665  loss_box_reg: 0.3314  loss_mask: 0.1589  loss_rpn_cls: 0.006229  loss_rpn_loc: 0.02218  time: 0.8697  data_time: 0.2294  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:51:40 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 739  total_loss: 0.6519  loss_cls: 0.1759  loss_box_reg: 0.2926  loss_mask: 0.1575  loss_rpn_cls: 0.004435  loss_rpn_loc: 0.0206  time: 0.8687  data_time: 0.1780  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:51:58 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 759  total_loss: 0.6315  loss_cls: 0.1528  loss_box_reg: 0.3261  loss_mask: 0.1538  loss_rpn_cls: 0.004097  loss_rpn_loc: 0.02395  time: 0.8683  data_time: 0.1954  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:52:15 d2.utils.events]: \u001b[0m eta: 0:10:20  iter: 779  total_loss: 0.6208  loss_cls: 0.1696  loss_box_reg: 0.3001  loss_mask: 0.1417  loss_rpn_cls: 0.00389  loss_rpn_loc: 0.02121  time: 0.8686  data_time: 0.1795  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:52:32 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 799  total_loss: 0.7105  loss_cls: 0.1754  loss_box_reg: 0.3377  loss_mask: 0.1757  loss_rpn_cls: 0.004672  loss_rpn_loc: 0.02976  time: 0.8685  data_time: 0.1978  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:52:50 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 819  total_loss: 0.6934  loss_cls: 0.1632  loss_box_reg: 0.3133  loss_mask: 0.1667  loss_rpn_cls: 0.004124  loss_rpn_loc: 0.02169  time: 0.8686  data_time: 0.2101  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:53:07 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 839  total_loss: 0.6247  loss_cls: 0.1563  loss_box_reg: 0.3095  loss_mask: 0.1588  loss_rpn_cls: 0.005968  loss_rpn_loc: 0.02815  time: 0.8681  data_time: 0.1905  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:53:24 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 859  total_loss: 0.6794  loss_cls: 0.1637  loss_box_reg: 0.3116  loss_mask: 0.1582  loss_rpn_cls: 0.003034  loss_rpn_loc: 0.02389  time: 0.8675  data_time: 0.1703  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:53:42 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 879  total_loss: 0.6952  loss_cls: 0.1634  loss_box_reg: 0.3125  loss_mask: 0.1458  loss_rpn_cls: 0.00444  loss_rpn_loc: 0.0261  time: 0.8681  data_time: 0.2159  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:53:58 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 899  total_loss: 0.6814  loss_cls: 0.1682  loss_box_reg: 0.3448  loss_mask: 0.1707  loss_rpn_cls: 0.005682  loss_rpn_loc: 0.01673  time: 0.8666  data_time: 0.1745  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:54:15 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 919  total_loss: 0.6627  loss_cls: 0.1373  loss_box_reg: 0.2887  loss_mask: 0.1685  loss_rpn_cls: 0.00462  loss_rpn_loc: 0.03035  time: 0.8667  data_time: 0.1990  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:54:32 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 939  total_loss: 0.6203  loss_cls: 0.1511  loss_box_reg: 0.2835  loss_mask: 0.1298  loss_rpn_cls: 0.00355  loss_rpn_loc: 0.02239  time: 0.8667  data_time: 0.1904  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:54:49 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 959  total_loss: 0.7252  loss_cls: 0.1619  loss_box_reg: 0.3196  loss_mask: 0.1759  loss_rpn_cls: 0.002461  loss_rpn_loc: 0.02697  time: 0.8658  data_time: 0.1867  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:55:06 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 979  total_loss: 0.5747  loss_cls: 0.115  loss_box_reg: 0.2881  loss_mask: 0.1333  loss_rpn_cls: 0.002801  loss_rpn_loc: 0.02252  time: 0.8652  data_time: 0.1824  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:55:23 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 999  total_loss: 0.6097  loss_cls: 0.1365  loss_box_reg: 0.2993  loss_mask: 0.1437  loss_rpn_cls: 0.003461  loss_rpn_loc: 0.02299  time: 0.8654  data_time: 0.2234  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 21:55:41 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 1019  total_loss: 0.5502  loss_cls: 0.09971  loss_box_reg: 0.2788  loss_mask: 0.1426  loss_rpn_cls: 0.002218  loss_rpn_loc: 0.01917  time: 0.8656  data_time: 0.2128  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:55:57 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 1039  total_loss: 0.5881  loss_cls: 0.1533  loss_box_reg: 0.2795  loss_mask: 0.1321  loss_rpn_cls: 0.003973  loss_rpn_loc: 0.02736  time: 0.8650  data_time: 0.1875  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:56:15 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 1059  total_loss: 0.5706  loss_cls: 0.1243  loss_box_reg: 0.2645  loss_mask: 0.1507  loss_rpn_cls: 0.002414  loss_rpn_loc: 0.02298  time: 0.8655  data_time: 0.2280  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:56:33 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1079  total_loss: 0.5421  loss_cls: 0.1303  loss_box_reg: 0.2577  loss_mask: 0.1321  loss_rpn_cls: 0.00316  loss_rpn_loc: 0.01955  time: 0.8658  data_time: 0.1952  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:56:51 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 1099  total_loss: 0.5933  loss_cls: 0.1562  loss_box_reg: 0.2297  loss_mask: 0.1393  loss_rpn_cls: 0.004179  loss_rpn_loc: 0.02146  time: 0.8663  data_time: 0.2114  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:57:08 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 1119  total_loss: 0.5162  loss_cls: 0.1017  loss_box_reg: 0.2375  loss_mask: 0.1382  loss_rpn_cls: 0.002425  loss_rpn_loc: 0.01519  time: 0.8660  data_time: 0.2063  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:57:26 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 1139  total_loss: 0.5753  loss_cls: 0.1367  loss_box_reg: 0.2595  loss_mask: 0.1394  loss_rpn_cls: 0.003879  loss_rpn_loc: 0.02664  time: 0.8666  data_time: 0.2403  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:57:43 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 1159  total_loss: 0.5116  loss_cls: 0.1178  loss_box_reg: 0.2335  loss_mask: 0.1284  loss_rpn_cls: 0.002696  loss_rpn_loc: 0.0224  time: 0.8663  data_time: 0.1992  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:58:00 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 1179  total_loss: 0.5057  loss_cls: 0.1204  loss_box_reg: 0.2386  loss_mask: 0.1345  loss_rpn_cls: 0.003661  loss_rpn_loc: 0.01981  time: 0.8663  data_time: 0.2035  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:58:17 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 1199  total_loss: 0.552  loss_cls: 0.1216  loss_box_reg: 0.2736  loss_mask: 0.134  loss_rpn_cls: 0.003244  loss_rpn_loc: 0.02118  time: 0.8660  data_time: 0.1844  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:58:34 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 1219  total_loss: 0.5524  loss_cls: 0.1372  loss_box_reg: 0.2384  loss_mask: 0.1339  loss_rpn_cls: 0.002186  loss_rpn_loc: 0.02213  time: 0.8657  data_time: 0.1878  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:58:52 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 1239  total_loss: 0.5564  loss_cls: 0.1164  loss_box_reg: 0.2489  loss_mask: 0.1506  loss_rpn_cls: 0.00361  loss_rpn_loc: 0.02432  time: 0.8658  data_time: 0.2158  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:59:09 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 1259  total_loss: 0.5366  loss_cls: 0.13  loss_box_reg: 0.2319  loss_mask: 0.1316  loss_rpn_cls: 0.002009  loss_rpn_loc: 0.02095  time: 0.8656  data_time: 0.1971  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:59:26 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 1279  total_loss: 0.5964  loss_cls: 0.1629  loss_box_reg: 0.2483  loss_mask: 0.1407  loss_rpn_cls: 0.004065  loss_rpn_loc: 0.02626  time: 0.8659  data_time: 0.2104  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 21:59:44 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 1299  total_loss: 0.5595  loss_cls: 0.1302  loss_box_reg: 0.2573  loss_mask: 0.1402  loss_rpn_cls: 0.003003  loss_rpn_loc: 0.02526  time: 0.8658  data_time: 0.1976  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:00:01 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 1319  total_loss: 0.5336  loss_cls: 0.121  loss_box_reg: 0.245  loss_mask: 0.1428  loss_rpn_cls: 0.003497  loss_rpn_loc: 0.01935  time: 0.8661  data_time: 0.2144  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 22:00:19 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1339  total_loss: 0.5393  loss_cls: 0.1275  loss_box_reg: 0.2389  loss_mask: 0.1419  loss_rpn_cls: 0.002823  loss_rpn_loc: 0.02072  time: 0.8666  data_time: 0.2254  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:00:36 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 1359  total_loss: 0.5504  loss_cls: 0.1285  loss_box_reg: 0.2444  loss_mask: 0.1501  loss_rpn_cls: 0.002694  loss_rpn_loc: 0.01849  time: 0.8661  data_time: 0.1961  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:00:54 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 1379  total_loss: 0.5613  loss_cls: 0.1252  loss_box_reg: 0.2351  loss_mask: 0.1389  loss_rpn_cls: 0.002606  loss_rpn_loc: 0.02334  time: 0.8666  data_time: 0.2263  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:01:12 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 1399  total_loss: 0.4606  loss_cls: 0.09947  loss_box_reg: 0.2074  loss_mask: 0.1272  loss_rpn_cls: 0.002876  loss_rpn_loc: 0.01692  time: 0.8672  data_time: 0.2485  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:01:28 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 1419  total_loss: 0.5733  loss_cls: 0.1355  loss_box_reg: 0.2791  loss_mask: 0.138  loss_rpn_cls: 0.004673  loss_rpn_loc: 0.02545  time: 0.8664  data_time: 0.1561  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:01:47 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 1439  total_loss: 0.5121  loss_cls: 0.1324  loss_box_reg: 0.2271  loss_mask: 0.1365  loss_rpn_cls: 0.002224  loss_rpn_loc: 0.01994  time: 0.8672  data_time: 0.2350  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:02:04 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 1459  total_loss: 0.4933  loss_cls: 0.1171  loss_box_reg: 0.2187  loss_mask: 0.1206  loss_rpn_cls: 0.002914  loss_rpn_loc: 0.02398  time: 0.8671  data_time: 0.2108  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:02:21 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.5611  loss_cls: 0.1157  loss_box_reg: 0.2579  loss_mask: 0.1319  loss_rpn_cls: 0.002033  loss_rpn_loc: 0.0194  time: 0.8669  data_time: 0.1995  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:02:39 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.527  loss_cls: 0.1248  loss_box_reg: 0.2398  loss_mask: 0.1419  loss_rpn_cls: 0.002111  loss_rpn_loc: 0.01507  time: 0.8666  data_time: 0.1877  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:02:40 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:38 (0.8667 s / it)\n",
      "\u001b[32m[03/04 22:02:40 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:40 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 22:02:40 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 22:02:40 d2.data.datasets.coco]: \u001b[0mLoaded 101 images in COCO format from /host/mic21-framework/server/uploads/tank_gt.json\n",
      "tank\n",
      "\u001b[32m[03/04 22:02:41 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 22:02:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 22:02:41 d2.data.datasets.coco]: \u001b[0mLoaded 101 images in COCO format from /host/mic21-framework/server/uploads/tank_gt.json\n",
      "\u001b[32m[03/04 22:02:41 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 101 images left.\n",
      "\u001b[32m[03/04 22:02:41 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|  soldier   | 136          | gun turret | 110          |    tank    | 115          |\n",
      "|   cannon   | 98           |            |              |            |              |\n",
      "|   total    | 459          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 22:02:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 22:02:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 22:02:41 d2.data.common]: \u001b[0mSerializing 101 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 22:02:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.60 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 22:02:41 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 22:02:59 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 19  total_loss: 2.455  loss_cls: 0.7711  loss_box_reg: 0.9741  loss_mask: 0.577  loss_rpn_cls: 0.04233  loss_rpn_loc: 0.0486  time: 0.8544  data_time: 0.2148  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:03:17 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 39  total_loss: 1.853  loss_cls: 0.503  loss_box_reg: 0.8855  loss_mask: 0.3597  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.04493  time: 0.8654  data_time: 0.1994  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:03:35 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 59  total_loss: 1.379  loss_cls: 0.3265  loss_box_reg: 0.752  loss_mask: 0.2308  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.05437  time: 0.8843  data_time: 0.2364  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:03:53 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 79  total_loss: 1.213  loss_cls: 0.2665  loss_box_reg: 0.6559  loss_mask: 0.2024  loss_rpn_cls: 0.01913  loss_rpn_loc: 0.04993  time: 0.8835  data_time: 0.2079  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:04:09 d2.utils.events]: \u001b[0m eta: 0:20:06  iter: 99  total_loss: 0.9955  loss_cls: 0.2019  loss_box_reg: 0.542  loss_mask: 0.162  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.04244  time: 0.8748  data_time: 0.1842  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:04:27 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 119  total_loss: 1.06  loss_cls: 0.2273  loss_box_reg: 0.5471  loss_mask: 0.1968  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.04183  time: 0.8748  data_time: 0.2064  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:04:45 d2.utils.events]: \u001b[0m eta: 0:19:32  iter: 139  total_loss: 0.9852  loss_cls: 0.1809  loss_box_reg: 0.5062  loss_mask: 0.1806  loss_rpn_cls: 0.01258  loss_rpn_loc: 0.04608  time: 0.8768  data_time: 0.2028  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:05:02 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 159  total_loss: 0.9337  loss_cls: 0.2195  loss_box_reg: 0.4625  loss_mask: 0.164  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.04426  time: 0.8753  data_time: 0.2007  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:05:21 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 179  total_loss: 0.8638  loss_cls: 0.1886  loss_box_reg: 0.4407  loss_mask: 0.1663  loss_rpn_cls: 0.005942  loss_rpn_loc: 0.04081  time: 0.8809  data_time: 0.2368  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:05:38 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 199  total_loss: 0.806  loss_cls: 0.1721  loss_box_reg: 0.4115  loss_mask: 0.163  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.05381  time: 0.8805  data_time: 0.1978  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:05:55 d2.utils.events]: \u001b[0m eta: 0:18:28  iter: 219  total_loss: 0.7916  loss_cls: 0.1736  loss_box_reg: 0.4067  loss_mask: 0.1608  loss_rpn_cls: 0.007211  loss_rpn_loc: 0.04073  time: 0.8785  data_time: 0.2014  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:06:13 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 239  total_loss: 0.7838  loss_cls: 0.1704  loss_box_reg: 0.4283  loss_mask: 0.1652  loss_rpn_cls: 0.006592  loss_rpn_loc: 0.03665  time: 0.8807  data_time: 0.1929  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:06:31 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 259  total_loss: 0.7973  loss_cls: 0.1649  loss_box_reg: 0.4252  loss_mask: 0.1673  loss_rpn_cls: 0.008792  loss_rpn_loc: 0.04525  time: 0.8790  data_time: 0.1975  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:06:48 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 279  total_loss: 0.7718  loss_cls: 0.1518  loss_box_reg: 0.3957  loss_mask: 0.1374  loss_rpn_cls: 0.005014  loss_rpn_loc: 0.03779  time: 0.8799  data_time: 0.1929  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:07:06 d2.utils.events]: \u001b[0m eta: 0:17:23  iter: 299  total_loss: 0.7137  loss_cls: 0.1455  loss_box_reg: 0.3746  loss_mask: 0.1369  loss_rpn_cls: 0.005524  loss_rpn_loc: 0.04645  time: 0.8796  data_time: 0.1896  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:07:24 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 319  total_loss: 0.6927  loss_cls: 0.1368  loss_box_reg: 0.3497  loss_mask: 0.1376  loss_rpn_cls: 0.004597  loss_rpn_loc: 0.03586  time: 0.8797  data_time: 0.1881  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:07:41 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 339  total_loss: 0.7147  loss_cls: 0.1358  loss_box_reg: 0.3701  loss_mask: 0.1398  loss_rpn_cls: 0.004673  loss_rpn_loc: 0.03145  time: 0.8798  data_time: 0.2169  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:07:59 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 359  total_loss: 0.7205  loss_cls: 0.1594  loss_box_reg: 0.3402  loss_mask: 0.1433  loss_rpn_cls: 0.006438  loss_rpn_loc: 0.03001  time: 0.8796  data_time: 0.1937  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:08:17 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 379  total_loss: 0.7134  loss_cls: 0.1202  loss_box_reg: 0.3727  loss_mask: 0.1406  loss_rpn_cls: 0.005835  loss_rpn_loc: 0.04287  time: 0.8804  data_time: 0.2147  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:08:34 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 399  total_loss: 0.6926  loss_cls: 0.138  loss_box_reg: 0.3426  loss_mask: 0.1306  loss_rpn_cls: 0.005439  loss_rpn_loc: 0.03837  time: 0.8796  data_time: 0.1818  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:08:51 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 419  total_loss: 0.6565  loss_cls: 0.1432  loss_box_reg: 0.3235  loss_mask: 0.1478  loss_rpn_cls: 0.005784  loss_rpn_loc: 0.03282  time: 0.8787  data_time: 0.2014  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:09:09 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 439  total_loss: 0.7273  loss_cls: 0.1581  loss_box_reg: 0.356  loss_mask: 0.1456  loss_rpn_cls: 0.009288  loss_rpn_loc: 0.04811  time: 0.8796  data_time: 0.2187  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:09:27 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 459  total_loss: 0.6303  loss_cls: 0.1087  loss_box_reg: 0.3436  loss_mask: 0.131  loss_rpn_cls: 0.003065  loss_rpn_loc: 0.03043  time: 0.8792  data_time: 0.2104  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:09:45 d2.utils.events]: \u001b[0m eta: 0:14:49  iter: 479  total_loss: 0.6502  loss_cls: 0.1212  loss_box_reg: 0.3153  loss_mask: 0.1329  loss_rpn_cls: 0.006323  loss_rpn_loc: 0.03485  time: 0.8799  data_time: 0.2159  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:10:01 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 499  total_loss: 0.5961  loss_cls: 0.1167  loss_box_reg: 0.3151  loss_mask: 0.124  loss_rpn_cls: 0.005345  loss_rpn_loc: 0.03291  time: 0.8783  data_time: 0.1829  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:10:18 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 519  total_loss: 0.6131  loss_cls: 0.137  loss_box_reg: 0.3037  loss_mask: 0.127  loss_rpn_cls: 0.003802  loss_rpn_loc: 0.03754  time: 0.8774  data_time: 0.1762  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:10:36 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 539  total_loss: 0.6333  loss_cls: 0.1301  loss_box_reg: 0.302  loss_mask: 0.1352  loss_rpn_cls: 0.003518  loss_rpn_loc: 0.03417  time: 0.8771  data_time: 0.2008  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:10:54 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 559  total_loss: 0.6264  loss_cls: 0.09677  loss_box_reg: 0.3219  loss_mask: 0.1288  loss_rpn_cls: 0.004969  loss_rpn_loc: 0.04109  time: 0.8788  data_time: 0.2193  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:11:12 d2.utils.events]: \u001b[0m eta: 0:13:23  iter: 579  total_loss: 0.5999  loss_cls: 0.09751  loss_box_reg: 0.3071  loss_mask: 0.1377  loss_rpn_cls: 0.00284  loss_rpn_loc: 0.03409  time: 0.8790  data_time: 0.2077  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:11:29 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 599  total_loss: 0.587  loss_cls: 0.1168  loss_box_reg: 0.3093  loss_mask: 0.1229  loss_rpn_cls: 0.004606  loss_rpn_loc: 0.0336  time: 0.8775  data_time: 0.1689  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:11:46 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 619  total_loss: 0.5739  loss_cls: 0.1096  loss_box_reg: 0.3084  loss_mask: 0.1278  loss_rpn_cls: 0.002984  loss_rpn_loc: 0.0303  time: 0.8767  data_time: 0.1872  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:12:04 d2.utils.events]: \u001b[0m eta: 0:12:29  iter: 639  total_loss: 0.5461  loss_cls: 0.1001  loss_box_reg: 0.2955  loss_mask: 0.1144  loss_rpn_cls: 0.002919  loss_rpn_loc: 0.03143  time: 0.8771  data_time: 0.2321  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:12:21 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 659  total_loss: 0.5699  loss_cls: 0.1179  loss_box_reg: 0.2977  loss_mask: 0.1353  loss_rpn_cls: 0.004283  loss_rpn_loc: 0.03215  time: 0.8768  data_time: 0.1857  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 22:12:38 d2.utils.events]: \u001b[0m eta: 0:11:51  iter: 679  total_loss: 0.5376  loss_cls: 0.09113  loss_box_reg: 0.2751  loss_mask: 0.1367  loss_rpn_cls: 0.00334  loss_rpn_loc: 0.03259  time: 0.8761  data_time: 0.1938  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:12:56 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 699  total_loss: 0.5564  loss_cls: 0.1109  loss_box_reg: 0.2813  loss_mask: 0.1264  loss_rpn_cls: 0.005086  loss_rpn_loc: 0.03393  time: 0.8764  data_time: 0.2067  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:13:14 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 719  total_loss: 0.5958  loss_cls: 0.1263  loss_box_reg: 0.2888  loss_mask: 0.1231  loss_rpn_cls: 0.005775  loss_rpn_loc: 0.03657  time: 0.8768  data_time: 0.1946  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:13:31 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 739  total_loss: 0.5952  loss_cls: 0.09356  loss_box_reg: 0.3112  loss_mask: 0.1381  loss_rpn_cls: 0.003154  loss_rpn_loc: 0.03112  time: 0.8771  data_time: 0.2055  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:13:49 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 759  total_loss: 0.5441  loss_cls: 0.1034  loss_box_reg: 0.2612  loss_mask: 0.122  loss_rpn_cls: 0.003936  loss_rpn_loc: 0.02876  time: 0.8770  data_time: 0.1957  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:14:06 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 779  total_loss: 0.5781  loss_cls: 0.1159  loss_box_reg: 0.3044  loss_mask: 0.125  loss_rpn_cls: 0.004098  loss_rpn_loc: 0.03039  time: 0.8766  data_time: 0.1836  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:14:23 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 799  total_loss: 0.5337  loss_cls: 0.1135  loss_box_reg: 0.2596  loss_mask: 0.122  loss_rpn_cls: 0.002838  loss_rpn_loc: 0.03069  time: 0.8757  data_time: 0.1842  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:14:40 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 819  total_loss: 0.5596  loss_cls: 0.1208  loss_box_reg: 0.2731  loss_mask: 0.1041  loss_rpn_cls: 0.003962  loss_rpn_loc: 0.03613  time: 0.8751  data_time: 0.1911  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:14:57 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 839  total_loss: 0.5191  loss_cls: 0.08697  loss_box_reg: 0.2609  loss_mask: 0.1246  loss_rpn_cls: 0.003969  loss_rpn_loc: 0.03074  time: 0.8751  data_time: 0.2106  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:15:14 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 859  total_loss: 0.5495  loss_cls: 0.09293  loss_box_reg: 0.2821  loss_mask: 0.132  loss_rpn_cls: 0.002644  loss_rpn_loc: 0.03021  time: 0.8739  data_time: 0.1726  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:15:32 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 879  total_loss: 0.5079  loss_cls: 0.08834  loss_box_reg: 0.2665  loss_mask: 0.1258  loss_rpn_cls: 0.003952  loss_rpn_loc: 0.03535  time: 0.8746  data_time: 0.2129  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:15:50 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 899  total_loss: 0.523  loss_cls: 0.08987  loss_box_reg: 0.2548  loss_mask: 0.1146  loss_rpn_cls: 0.002339  loss_rpn_loc: 0.03866  time: 0.8753  data_time: 0.2065  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:16:08 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 919  total_loss: 0.5217  loss_cls: 0.08939  loss_box_reg: 0.2847  loss_mask: 0.1239  loss_rpn_cls: 0.003928  loss_rpn_loc: 0.03223  time: 0.8756  data_time: 0.2142  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:16:25 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 939  total_loss: 0.4619  loss_cls: 0.08716  loss_box_reg: 0.2446  loss_mask: 0.1068  loss_rpn_cls: 0.003405  loss_rpn_loc: 0.03071  time: 0.8753  data_time: 0.1960  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:16:42 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 959  total_loss: 0.5035  loss_cls: 0.1058  loss_box_reg: 0.2655  loss_mask: 0.1138  loss_rpn_cls: 0.004491  loss_rpn_loc: 0.027  time: 0.8746  data_time: 0.1885  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:17:00 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 979  total_loss: 0.5262  loss_cls: 0.08696  loss_box_reg: 0.2589  loss_mask: 0.1243  loss_rpn_cls: 0.004233  loss_rpn_loc: 0.02873  time: 0.8746  data_time: 0.1993  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:17:17 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 999  total_loss: 0.5139  loss_cls: 0.1049  loss_box_reg: 0.2445  loss_mask: 0.1143  loss_rpn_cls: 0.002594  loss_rpn_loc: 0.03226  time: 0.8745  data_time: 0.1957  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:17:35 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 1019  total_loss: 0.5106  loss_cls: 0.1034  loss_box_reg: 0.2418  loss_mask: 0.114  loss_rpn_cls: 0.002709  loss_rpn_loc: 0.03007  time: 0.8745  data_time: 0.2046  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:17:52 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 1039  total_loss: 0.4834  loss_cls: 0.09417  loss_box_reg: 0.2406  loss_mask: 0.1167  loss_rpn_cls: 0.001696  loss_rpn_loc: 0.02904  time: 0.8742  data_time: 0.1971  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:18:09 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 1059  total_loss: 0.4678  loss_cls: 0.0888  loss_box_reg: 0.2207  loss_mask: 0.1168  loss_rpn_cls: 0.003075  loss_rpn_loc: 0.02712  time: 0.8742  data_time: 0.2015  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:18:26 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1079  total_loss: 0.474  loss_cls: 0.08954  loss_box_reg: 0.2323  loss_mask: 0.1102  loss_rpn_cls: 0.003259  loss_rpn_loc: 0.03095  time: 0.8737  data_time: 0.1879  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:18:44 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1099  total_loss: 0.4657  loss_cls: 0.07797  loss_box_reg: 0.2182  loss_mask: 0.1187  loss_rpn_cls: 0.001925  loss_rpn_loc: 0.02576  time: 0.8742  data_time: 0.2419  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:19:01 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1119  total_loss: 0.4556  loss_cls: 0.06844  loss_box_reg: 0.2123  loss_mask: 0.1164  loss_rpn_cls: 0.003745  loss_rpn_loc: 0.03512  time: 0.8739  data_time: 0.2004  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:19:19 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 1139  total_loss: 0.4841  loss_cls: 0.08474  loss_box_reg: 0.2376  loss_mask: 0.1152  loss_rpn_cls: 0.002301  loss_rpn_loc: 0.02502  time: 0.8741  data_time: 0.2119  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:19:37 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 1159  total_loss: 0.4456  loss_cls: 0.08291  loss_box_reg: 0.216  loss_mask: 0.1171  loss_rpn_cls: 0.002131  loss_rpn_loc: 0.02829  time: 0.8741  data_time: 0.1977  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:19:54 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 1179  total_loss: 0.449  loss_cls: 0.06877  loss_box_reg: 0.2414  loss_mask: 0.1143  loss_rpn_cls: 0.00271  loss_rpn_loc: 0.0259  time: 0.8740  data_time: 0.2039  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:20:12 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 1199  total_loss: 0.445  loss_cls: 0.0856  loss_box_reg: 0.2147  loss_mask: 0.1116  loss_rpn_cls: 0.002164  loss_rpn_loc: 0.02849  time: 0.8743  data_time: 0.2100  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:20:29 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 1219  total_loss: 0.4586  loss_cls: 0.09888  loss_box_reg: 0.2027  loss_mask: 0.1163  loss_rpn_cls: 0.002461  loss_rpn_loc: 0.02636  time: 0.8740  data_time: 0.1910  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:20:46 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 1239  total_loss: 0.4706  loss_cls: 0.1092  loss_box_reg: 0.2061  loss_mask: 0.1129  loss_rpn_cls: 0.003235  loss_rpn_loc: 0.02763  time: 0.8740  data_time: 0.1865  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:21:04 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 1259  total_loss: 0.4547  loss_cls: 0.1005  loss_box_reg: 0.2039  loss_mask: 0.1178  loss_rpn_cls: 0.002614  loss_rpn_loc: 0.02477  time: 0.8738  data_time: 0.1945  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:21:21 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 1279  total_loss: 0.3898  loss_cls: 0.07725  loss_box_reg: 0.1942  loss_mask: 0.1053  loss_rpn_cls: 0.002696  loss_rpn_loc: 0.02806  time: 0.8737  data_time: 0.2119  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:21:38 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 1299  total_loss: 0.4628  loss_cls: 0.08874  loss_box_reg: 0.2075  loss_mask: 0.1121  loss_rpn_cls: 0.002479  loss_rpn_loc: 0.02324  time: 0.8735  data_time: 0.1890  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:21:55 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1319  total_loss: 0.4662  loss_cls: 0.1014  loss_box_reg: 0.2183  loss_mask: 0.127  loss_rpn_cls: 0.003373  loss_rpn_loc: 0.03136  time: 0.8726  data_time: 0.1555  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 22:22:12 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 1339  total_loss: 0.4146  loss_cls: 0.07473  loss_box_reg: 0.1853  loss_mask: 0.1117  loss_rpn_cls: 0.002696  loss_rpn_loc: 0.02901  time: 0.8728  data_time: 0.2013  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:22:29 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 1359  total_loss: 0.4893  loss_cls: 0.09699  loss_box_reg: 0.2005  loss_mask: 0.1099  loss_rpn_cls: 0.002771  loss_rpn_loc: 0.02659  time: 0.8725  data_time: 0.1825  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:22:47 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 1379  total_loss: 0.4614  loss_cls: 0.09144  loss_box_reg: 0.2044  loss_mask: 0.124  loss_rpn_cls: 0.002093  loss_rpn_loc: 0.03012  time: 0.8724  data_time: 0.1918  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:23:05 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 1399  total_loss: 0.3919  loss_cls: 0.07126  loss_box_reg: 0.2046  loss_mask: 0.1099  loss_rpn_cls: 0.004431  loss_rpn_loc: 0.02925  time: 0.8728  data_time: 0.2214  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:23:22 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 1419  total_loss: 0.4603  loss_cls: 0.08803  loss_box_reg: 0.1977  loss_mask: 0.1093  loss_rpn_cls: 0.002339  loss_rpn_loc: 0.0256  time: 0.8723  data_time: 0.1783  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:23:39 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 1439  total_loss: 0.4302  loss_cls: 0.09005  loss_box_reg: 0.1928  loss_mask: 0.1163  loss_rpn_cls: 0.002273  loss_rpn_loc: 0.02783  time: 0.8725  data_time: 0.2268  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:23:57 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 1459  total_loss: 0.4172  loss_cls: 0.09101  loss_box_reg: 0.2002  loss_mask: 0.1115  loss_rpn_cls: 0.003403  loss_rpn_loc: 0.02698  time: 0.8725  data_time: 0.2115  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:24:15 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.4353  loss_cls: 0.07263  loss_box_reg: 0.1971  loss_mask: 0.1159  loss_rpn_cls: 0.00165  loss_rpn_loc: 0.02682  time: 0.8730  data_time: 0.2166  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:24:33 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4232  loss_cls: 0.07123  loss_box_reg: 0.1955  loss_mask: 0.1188  loss_rpn_cls: 0.002296  loss_rpn_loc: 0.02499  time: 0.8729  data_time: 0.1984  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:24:34 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:47 (0.8729 s / it)\n",
      "\u001b[32m[03/04 22:24:34 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:50 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 22:24:34 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 22:24:34 d2.data.datasets.coco]: \u001b[0mLoaded 131 images in COCO format from /host/mic21-framework/server/uploads/hang_gliding_gt.json\n",
      "hang_gliding\n",
      "\u001b[32m[03/04 22:24:35 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 22:24:35 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 22:24:35 d2.data.datasets.coco]: \u001b[0mLoaded 131 images in COCO format from /host/mic21-framework/server/uploads/hang_gliding_gt.json\n",
      "\u001b[32m[03/04 22:24:35 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 131 images left.\n",
      "\u001b[32m[03/04 22:24:35 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category   | #instances   |   category    | #instances   |\n",
      "|:-----------:|:-------------|:-------------:|:-------------|\n",
      "| hang glider | 169          | hang glider.. | 145          |\n",
      "|             |              |               |              |\n",
      "|    total    | 314          |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 22:24:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 22:24:35 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 22:24:35 d2.data.common]: \u001b[0mSerializing 131 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 22:24:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 22:24:35 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 22:24:56 d2.utils.events]: \u001b[0m eta: 0:22:18  iter: 19  total_loss: 1.954  loss_cls: 0.5606  loss_box_reg: 0.8931  loss_mask: 0.485  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.01488  time: 1.0217  data_time: 0.3737  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:25:18 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 39  total_loss: 1.425  loss_cls: 0.2818  loss_box_reg: 0.8127  loss_mask: 0.2894  loss_rpn_cls: 0.00529  loss_rpn_loc: 0.01406  time: 1.0663  data_time: 0.4492  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:25:40 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 59  total_loss: 0.944  loss_cls: 0.1677  loss_box_reg: 0.4963  loss_mask: 0.2201  loss_rpn_cls: 0.004127  loss_rpn_loc: 0.01303  time: 1.0725  data_time: 0.4250  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:26:04 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 79  total_loss: 0.8014  loss_cls: 0.1503  loss_box_reg: 0.426  loss_mask: 0.2224  loss_rpn_cls: 0.00349  loss_rpn_loc: 0.01268  time: 1.1143  data_time: 0.5773  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:26:24 d2.utils.events]: \u001b[0m eta: 0:21:49  iter: 99  total_loss: 0.733  loss_cls: 0.1246  loss_box_reg: 0.3748  loss_mask: 0.203  loss_rpn_cls: 0.003745  loss_rpn_loc: 0.01006  time: 1.0886  data_time: 0.3140  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:26:48 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 119  total_loss: 0.7101  loss_cls: 0.1145  loss_box_reg: 0.3444  loss_mask: 0.2015  loss_rpn_cls: 0.003886  loss_rpn_loc: 0.0123  time: 1.1080  data_time: 0.5190  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:27:10 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 139  total_loss: 0.7126  loss_cls: 0.1253  loss_box_reg: 0.3451  loss_mask: 0.2075  loss_rpn_cls: 0.004767  loss_rpn_loc: 0.01372  time: 1.1013  data_time: 0.3727  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:27:31 d2.utils.events]: \u001b[0m eta: 0:21:19  iter: 159  total_loss: 0.7002  loss_cls: 0.118  loss_box_reg: 0.3746  loss_mask: 0.1952  loss_rpn_cls: 0.002904  loss_rpn_loc: 0.01085  time: 1.0993  data_time: 0.4089  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:27:51 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 179  total_loss: 0.6953  loss_cls: 0.112  loss_box_reg: 0.3457  loss_mask: 0.2088  loss_rpn_cls: 0.002106  loss_rpn_loc: 0.01317  time: 1.0868  data_time: 0.3320  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:28:14 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 199  total_loss: 0.6357  loss_cls: 0.1034  loss_box_reg: 0.3368  loss_mask: 0.2105  loss_rpn_cls: 0.00296  loss_rpn_loc: 0.009619  time: 1.0921  data_time: 0.4468  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:28:38 d2.utils.events]: \u001b[0m eta: 0:19:58  iter: 219  total_loss: 0.6  loss_cls: 0.1153  loss_box_reg: 0.2903  loss_mask: 0.1856  loss_rpn_cls: 0.002794  loss_rpn_loc: 0.009677  time: 1.1020  data_time: 0.5324  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:28:59 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 239  total_loss: 0.6189  loss_cls: 0.1037  loss_box_reg: 0.3006  loss_mask: 0.1929  loss_rpn_cls: 0.003008  loss_rpn_loc: 0.009978  time: 1.0973  data_time: 0.3688  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:29:20 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 259  total_loss: 0.5967  loss_cls: 0.09733  loss_box_reg: 0.3172  loss_mask: 0.1828  loss_rpn_cls: 0.002675  loss_rpn_loc: 0.009525  time: 1.0933  data_time: 0.3986  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:29:42 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 279  total_loss: 0.595  loss_cls: 0.09881  loss_box_reg: 0.2958  loss_mask: 0.1921  loss_rpn_cls: 0.001313  loss_rpn_loc: 0.0091  time: 1.0945  data_time: 0.4524  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:30:03 d2.utils.events]: \u001b[0m eta: 0:18:47  iter: 299  total_loss: 0.6027  loss_cls: 0.1247  loss_box_reg: 0.282  loss_mask: 0.1839  loss_rpn_cls: 0.001998  loss_rpn_loc: 0.01281  time: 1.0919  data_time: 0.3918  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:30:25 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 319  total_loss: 0.5753  loss_cls: 0.09858  loss_box_reg: 0.269  loss_mask: 0.1958  loss_rpn_cls: 0.002599  loss_rpn_loc: 0.01009  time: 1.0933  data_time: 0.4283  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:30:47 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 339  total_loss: 0.5974  loss_cls: 0.1059  loss_box_reg: 0.2805  loss_mask: 0.19  loss_rpn_cls: 0.001897  loss_rpn_loc: 0.01155  time: 1.0934  data_time: 0.4202  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:31:07 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 359  total_loss: 0.5277  loss_cls: 0.08376  loss_box_reg: 0.257  loss_mask: 0.1794  loss_rpn_cls: 0.001255  loss_rpn_loc: 0.009351  time: 1.0885  data_time: 0.3434  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:31:33 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 379  total_loss: 0.5438  loss_cls: 0.1085  loss_box_reg: 0.2457  loss_mask: 0.1622  loss_rpn_cls: 0.00238  loss_rpn_loc: 0.009503  time: 1.0972  data_time: 0.5787  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:31:53 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 399  total_loss: 0.5576  loss_cls: 0.09043  loss_box_reg: 0.2667  loss_mask: 0.1811  loss_rpn_cls: 0.002297  loss_rpn_loc: 0.007583  time: 1.0928  data_time: 0.3447  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:32:15 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 419  total_loss: 0.561  loss_cls: 0.085  loss_box_reg: 0.2466  loss_mask: 0.1812  loss_rpn_cls: 0.001546  loss_rpn_loc: 0.0102  time: 1.0934  data_time: 0.4130  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:32:35 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 439  total_loss: 0.5488  loss_cls: 0.07583  loss_box_reg: 0.2505  loss_mask: 0.1849  loss_rpn_cls: 0.002987  loss_rpn_loc: 0.01067  time: 1.0890  data_time: 0.3472  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:32:58 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 459  total_loss: 0.5169  loss_cls: 0.09068  loss_box_reg: 0.2623  loss_mask: 0.1622  loss_rpn_cls: 0.001876  loss_rpn_loc: 0.009625  time: 1.0914  data_time: 0.4679  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:33:19 d2.utils.events]: \u001b[0m eta: 0:16:04  iter: 479  total_loss: 0.5377  loss_cls: 0.06758  loss_box_reg: 0.2689  loss_mask: 0.1689  loss_rpn_cls: 0.001547  loss_rpn_loc: 0.009915  time: 1.0910  data_time: 0.4245  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:33:40 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 499  total_loss: 0.5151  loss_cls: 0.07255  loss_box_reg: 0.2505  loss_mask: 0.1685  loss_rpn_cls: 0.001733  loss_rpn_loc: 0.009015  time: 1.0883  data_time: 0.3588  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:34:02 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 519  total_loss: 0.4869  loss_cls: 0.078  loss_box_reg: 0.25  loss_mask: 0.1628  loss_rpn_cls: 0.001703  loss_rpn_loc: 0.00833  time: 1.0899  data_time: 0.4667  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:34:25 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 539  total_loss: 0.5026  loss_cls: 0.07718  loss_box_reg: 0.2459  loss_mask: 0.163  loss_rpn_cls: 0.001246  loss_rpn_loc: 0.009949  time: 1.0907  data_time: 0.4547  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:34:43 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 559  total_loss: 0.4939  loss_cls: 0.0828  loss_box_reg: 0.2301  loss_mask: 0.1653  loss_rpn_cls: 0.001951  loss_rpn_loc: 0.009499  time: 1.0850  data_time: 0.2673  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:35:08 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 579  total_loss: 0.4454  loss_cls: 0.06675  loss_box_reg: 0.2159  loss_mask: 0.1535  loss_rpn_cls: 0.0008447  loss_rpn_loc: 0.00847  time: 1.0903  data_time: 0.5814  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:35:28 d2.utils.events]: \u001b[0m eta: 0:14:09  iter: 599  total_loss: 0.4995  loss_cls: 0.07918  loss_box_reg: 0.2276  loss_mask: 0.1623  loss_rpn_cls: 0.002941  loss_rpn_loc: 0.009022  time: 1.0878  data_time: 0.3791  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:35:51 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 619  total_loss: 0.5217  loss_cls: 0.08075  loss_box_reg: 0.2517  loss_mask: 0.1675  loss_rpn_cls: 0.001705  loss_rpn_loc: 0.009076  time: 1.0890  data_time: 0.4681  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:36:11 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 639  total_loss: 0.4605  loss_cls: 0.06871  loss_box_reg: 0.2351  loss_mask: 0.1493  loss_rpn_cls: 0.001586  loss_rpn_loc: 0.009279  time: 1.0864  data_time: 0.3389  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:36:34 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 659  total_loss: 0.4729  loss_cls: 0.06197  loss_box_reg: 0.216  loss_mask: 0.1454  loss_rpn_cls: 0.001949  loss_rpn_loc: 0.01246  time: 1.0885  data_time: 0.4726  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 22:36:58 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 679  total_loss: 0.4642  loss_cls: 0.07035  loss_box_reg: 0.224  loss_mask: 0.1591  loss_rpn_cls: 0.0008841  loss_rpn_loc: 0.006317  time: 1.0911  data_time: 0.5110  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:37:17 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 699  total_loss: 0.4759  loss_cls: 0.06668  loss_box_reg: 0.2202  loss_mask: 0.1634  loss_rpn_cls: 0.0006405  loss_rpn_loc: 0.009013  time: 1.0875  data_time: 0.3052  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:37:40 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 719  total_loss: 0.4899  loss_cls: 0.06  loss_box_reg: 0.2404  loss_mask: 0.1578  loss_rpn_cls: 0.001245  loss_rpn_loc: 0.009688  time: 1.0896  data_time: 0.5209  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:38:03 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 739  total_loss: 0.4473  loss_cls: 0.05252  loss_box_reg: 0.1997  loss_mask: 0.1531  loss_rpn_cls: 0.001554  loss_rpn_loc: 0.008922  time: 1.0904  data_time: 0.4214  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:38:24 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 759  total_loss: 0.4465  loss_cls: 0.06652  loss_box_reg: 0.2086  loss_mask: 0.1616  loss_rpn_cls: 0.001738  loss_rpn_loc: 0.008518  time: 1.0902  data_time: 0.4077  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:38:44 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 779  total_loss: 0.4135  loss_cls: 0.05699  loss_box_reg: 0.2085  loss_mask: 0.1533  loss_rpn_cls: 0.001397  loss_rpn_loc: 0.00781  time: 1.0878  data_time: 0.3119  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:39:07 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 799  total_loss: 0.4546  loss_cls: 0.05914  loss_box_reg: 0.2158  loss_mask: 0.1535  loss_rpn_cls: 0.0008975  loss_rpn_loc: 0.008506  time: 1.0895  data_time: 0.4914  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:39:30 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 819  total_loss: 0.4669  loss_cls: 0.07431  loss_box_reg: 0.2349  loss_mask: 0.1428  loss_rpn_cls: 0.001682  loss_rpn_loc: 0.008311  time: 1.0907  data_time: 0.4477  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:39:53 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 839  total_loss: 0.4601  loss_cls: 0.06256  loss_box_reg: 0.2099  loss_mask: 0.1491  loss_rpn_cls: 0.001047  loss_rpn_loc: 0.009229  time: 1.0920  data_time: 0.4721  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:40:13 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 859  total_loss: 0.4461  loss_cls: 0.0615  loss_box_reg: 0.2077  loss_mask: 0.1531  loss_rpn_cls: 0.0005898  loss_rpn_loc: 0.007132  time: 1.0899  data_time: 0.3336  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:40:35 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 879  total_loss: 0.4165  loss_cls: 0.05174  loss_box_reg: 0.2163  loss_mask: 0.1382  loss_rpn_cls: 0.001291  loss_rpn_loc: 0.007451  time: 1.0897  data_time: 0.4305  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:40:58 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 899  total_loss: 0.4474  loss_cls: 0.06331  loss_box_reg: 0.2215  loss_mask: 0.1596  loss_rpn_cls: 0.001149  loss_rpn_loc: 0.008582  time: 1.0910  data_time: 0.4569  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:41:18 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 919  total_loss: 0.4119  loss_cls: 0.05417  loss_box_reg: 0.212  loss_mask: 0.1419  loss_rpn_cls: 0.0009956  loss_rpn_loc: 0.007436  time: 1.0891  data_time: 0.3279  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:41:38 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 939  total_loss: 0.4156  loss_cls: 0.06357  loss_box_reg: 0.2112  loss_mask: 0.1431  loss_rpn_cls: 0.0007375  loss_rpn_loc: 0.006778  time: 1.0877  data_time: 0.3507  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:42:03 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 959  total_loss: 0.4176  loss_cls: 0.05424  loss_box_reg: 0.2132  loss_mask: 0.1407  loss_rpn_cls: 0.0006689  loss_rpn_loc: 0.007303  time: 1.0902  data_time: 0.5158  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:42:23 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 979  total_loss: 0.4283  loss_cls: 0.06888  loss_box_reg: 0.1951  loss_mask: 0.1467  loss_rpn_cls: 0.0012  loss_rpn_loc: 0.009214  time: 1.0891  data_time: 0.3720  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:42:43 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 999  total_loss: 0.4284  loss_cls: 0.05602  loss_box_reg: 0.1978  loss_mask: 0.1594  loss_rpn_cls: 0.001503  loss_rpn_loc: 0.008436  time: 1.0873  data_time: 0.3253  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:43:05 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 1019  total_loss: 0.3908  loss_cls: 0.06624  loss_box_reg: 0.1921  loss_mask: 0.1437  loss_rpn_cls: 0.0009026  loss_rpn_loc: 0.009641  time: 1.0877  data_time: 0.4165  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:43:25 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 1039  total_loss: 0.4079  loss_cls: 0.0583  loss_box_reg: 0.1874  loss_mask: 0.1432  loss_rpn_cls: 0.001052  loss_rpn_loc: 0.006921  time: 1.0857  data_time: 0.3182  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:43:49 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 1059  total_loss: 0.4072  loss_cls: 0.06804  loss_box_reg: 0.1717  loss_mask: 0.1504  loss_rpn_cls: 0.0009184  loss_rpn_loc: 0.008158  time: 1.0880  data_time: 0.5284  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:44:08 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 1079  total_loss: 0.3701  loss_cls: 0.04723  loss_box_reg: 0.1663  loss_mask: 0.1301  loss_rpn_cls: 0.001246  loss_rpn_loc: 0.007984  time: 1.0854  data_time: 0.2628  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:44:32 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 1099  total_loss: 0.3689  loss_cls: 0.06392  loss_box_reg: 0.1673  loss_mask: 0.134  loss_rpn_cls: 0.001481  loss_rpn_loc: 0.007555  time: 1.0871  data_time: 0.4796  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:44:54 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 1119  total_loss: 0.3754  loss_cls: 0.06004  loss_box_reg: 0.1708  loss_mask: 0.1398  loss_rpn_cls: 0.0007169  loss_rpn_loc: 0.007405  time: 1.0871  data_time: 0.4053  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:45:15 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 1139  total_loss: 0.3738  loss_cls: 0.05432  loss_box_reg: 0.1607  loss_mask: 0.138  loss_rpn_cls: 0.001272  loss_rpn_loc: 0.008454  time: 1.0871  data_time: 0.3964  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:45:37 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 1159  total_loss: 0.4065  loss_cls: 0.0542  loss_box_reg: 0.1693  loss_mask: 0.1443  loss_rpn_cls: 0.001089  loss_rpn_loc: 0.009913  time: 1.0867  data_time: 0.3842  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:45:58 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 1179  total_loss: 0.3812  loss_cls: 0.04724  loss_box_reg: 0.1543  loss_mask: 0.1486  loss_rpn_cls: 0.001208  loss_rpn_loc: 0.007149  time: 1.0860  data_time: 0.3841  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:46:16 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 1199  total_loss: 0.3687  loss_cls: 0.04535  loss_box_reg: 0.1614  loss_mask: 0.1448  loss_rpn_cls: 0.000859  loss_rpn_loc: 0.006891  time: 1.0835  data_time: 0.2948  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:46:42 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 1219  total_loss: 0.3636  loss_cls: 0.0667  loss_box_reg: 0.1507  loss_mask: 0.1321  loss_rpn_cls: 0.000822  loss_rpn_loc: 0.008244  time: 1.0866  data_time: 0.5679  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:47:04 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 1239  total_loss: 0.3894  loss_cls: 0.06169  loss_box_reg: 0.1724  loss_mask: 0.1515  loss_rpn_cls: 0.0009734  loss_rpn_loc: 0.006927  time: 1.0868  data_time: 0.4162  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:47:27 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 1259  total_loss: 0.3722  loss_cls: 0.04608  loss_box_reg: 0.1519  loss_mask: 0.1437  loss_rpn_cls: 0.001494  loss_rpn_loc: 0.007472  time: 1.0883  data_time: 0.5230  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:47:50 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 1279  total_loss: 0.3952  loss_cls: 0.05523  loss_box_reg: 0.1672  loss_mask: 0.1338  loss_rpn_cls: 0.0007413  loss_rpn_loc: 0.007268  time: 1.0887  data_time: 0.4139  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:48:12 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 1299  total_loss: 0.3597  loss_cls: 0.06095  loss_box_reg: 0.1378  loss_mask: 0.1321  loss_rpn_cls: 0.001061  loss_rpn_loc: 0.006329  time: 1.0892  data_time: 0.4406  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:48:33 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 1319  total_loss: 0.3623  loss_cls: 0.07527  loss_box_reg: 0.145  loss_mask: 0.1319  loss_rpn_cls: 0.0007328  loss_rpn_loc: 0.007361  time: 1.0886  data_time: 0.3819  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 22:48:55 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 1339  total_loss: 0.3981  loss_cls: 0.0495  loss_box_reg: 0.1866  loss_mask: 0.1425  loss_rpn_cls: 0.001463  loss_rpn_loc: 0.007698  time: 1.0884  data_time: 0.4192  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:49:19 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 1359  total_loss: 0.3734  loss_cls: 0.05465  loss_box_reg: 0.1564  loss_mask: 0.1361  loss_rpn_cls: 0.001415  loss_rpn_loc: 0.007141  time: 1.0902  data_time: 0.5204  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:49:38 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 1379  total_loss: 0.3889  loss_cls: 0.06184  loss_box_reg: 0.1621  loss_mask: 0.1465  loss_rpn_cls: 0.0008766  loss_rpn_loc: 0.007443  time: 1.0879  data_time: 0.2712  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:49:59 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 1399  total_loss: 0.3219  loss_cls: 0.05498  loss_box_reg: 0.1468  loss_mask: 0.1257  loss_rpn_cls: 0.0007212  loss_rpn_loc: 0.006291  time: 1.0875  data_time: 0.3776  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 22:50:22 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 1419  total_loss: 0.3464  loss_cls: 0.04282  loss_box_reg: 0.1451  loss_mask: 0.1374  loss_rpn_cls: 0.001304  loss_rpn_loc: 0.006839  time: 1.0882  data_time: 0.4769  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:50:44 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 1439  total_loss: 0.3418  loss_cls: 0.0384  loss_box_reg: 0.1541  loss_mask: 0.1347  loss_rpn_cls: 0.001177  loss_rpn_loc: 0.007259  time: 1.0885  data_time: 0.4295  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:51:08 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 1459  total_loss: 0.367  loss_cls: 0.05077  loss_box_reg: 0.1682  loss_mask: 0.1398  loss_rpn_cls: 0.0005464  loss_rpn_loc: 0.007081  time: 1.0900  data_time: 0.5075  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:51:28 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1479  total_loss: 0.3661  loss_cls: 0.0473  loss_box_reg: 0.1552  loss_mask: 0.147  loss_rpn_cls: 0.001259  loss_rpn_loc: 0.00797  time: 1.0889  data_time: 0.3177  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:51:53 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.362  loss_cls: 0.05275  loss_box_reg: 0.1486  loss_mask: 0.1381  loss_rpn_cls: 0.0005129  loss_rpn_loc: 0.006185  time: 1.0902  data_time: 0.4987  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 22:51:53 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:27:13 (1.0902 s / it)\n",
      "\u001b[32m[03/04 22:51:53 d2.engine.hooks]: \u001b[0mTotal training time: 0:27:15 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 22:51:54 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 22:51:54 d2.data.datasets.coco]: \u001b[0mLoaded 166 images in COCO format from /host/mic21-framework/server/uploads/rhythmic_gymnastics_gt.json\n",
      "rhythmic_gymnastics\n",
      "\u001b[32m[03/04 22:51:54 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 22:51:54 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 22:51:54 d2.data.datasets.coco]: \u001b[0mLoaded 166 images in COCO format from /host/mic21-framework/server/uploads/rhythmic_gymnastics_gt.json\n",
      "\u001b[32m[03/04 22:51:54 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 166 images left.\n",
      "\u001b[32m[03/04 22:51:54 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|   category    | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|      man      | 97           |   woman    | 300          |    ball    | 110          |\n",
      "| rhythmic gy.. | 229          |  leotard   | 226          |            |              |\n",
      "|     total     | 962          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 22:51:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 22:51:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 22:51:54 d2.data.common]: \u001b[0mSerializing 166 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 22:51:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.48 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 22:51:55 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 22:52:15 d2.utils.events]: \u001b[0m eta: 0:24:46  iter: 19  total_loss: 2.272  loss_cls: 0.7729  loss_box_reg: 0.8759  loss_mask: 0.5586  loss_rpn_cls: 0.02085  loss_rpn_loc: 0.02616  time: 0.9729  data_time: 0.3708  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:52:35 d2.utils.events]: \u001b[0m eta: 0:24:57  iter: 39  total_loss: 1.708  loss_cls: 0.5101  loss_box_reg: 0.8464  loss_mask: 0.3662  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.02836  time: 0.9932  data_time: 0.3634  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:52:55 d2.utils.events]: \u001b[0m eta: 0:24:37  iter: 59  total_loss: 1.318  loss_cls: 0.3604  loss_box_reg: 0.7178  loss_mask: 0.2337  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.02998  time: 0.9956  data_time: 0.3408  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:53:15 d2.utils.events]: \u001b[0m eta: 0:24:10  iter: 79  total_loss: 1.138  loss_cls: 0.2807  loss_box_reg: 0.5927  loss_mask: 0.2042  loss_rpn_cls: 0.008871  loss_rpn_loc: 0.02385  time: 0.9877  data_time: 0.3216  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:53:35 d2.utils.events]: \u001b[0m eta: 0:23:50  iter: 99  total_loss: 0.9973  loss_cls: 0.2306  loss_box_reg: 0.535  loss_mask: 0.1772  loss_rpn_cls: 0.007351  loss_rpn_loc: 0.02433  time: 0.9900  data_time: 0.3733  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:53:54 d2.utils.events]: \u001b[0m eta: 0:23:26  iter: 119  total_loss: 0.9692  loss_cls: 0.2211  loss_box_reg: 0.4985  loss_mask: 0.1628  loss_rpn_cls: 0.006529  loss_rpn_loc: 0.02591  time: 0.9865  data_time: 0.3195  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:54:14 d2.utils.events]: \u001b[0m eta: 0:23:04  iter: 139  total_loss: 0.9294  loss_cls: 0.2872  loss_box_reg: 0.4578  loss_mask: 0.159  loss_rpn_cls: 0.007484  loss_rpn_loc: 0.0196  time: 0.9855  data_time: 0.3253  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:54:33 d2.utils.events]: \u001b[0m eta: 0:22:46  iter: 159  total_loss: 0.8732  loss_cls: 0.2252  loss_box_reg: 0.4028  loss_mask: 0.162  loss_rpn_cls: 0.004839  loss_rpn_loc: 0.02441  time: 0.9831  data_time: 0.3260  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:54:53 d2.utils.events]: \u001b[0m eta: 0:22:28  iter: 179  total_loss: 0.8039  loss_cls: 0.224  loss_box_reg: 0.3929  loss_mask: 0.1582  loss_rpn_cls: 0.005285  loss_rpn_loc: 0.01811  time: 0.9830  data_time: 0.3553  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:55:13 d2.utils.events]: \u001b[0m eta: 0:22:07  iter: 199  total_loss: 0.8142  loss_cls: 0.2024  loss_box_reg: 0.3898  loss_mask: 0.1482  loss_rpn_cls: 0.003921  loss_rpn_loc: 0.01852  time: 0.9881  data_time: 0.3690  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:55:33 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 219  total_loss: 0.8109  loss_cls: 0.2348  loss_box_reg: 0.3815  loss_mask: 0.1578  loss_rpn_cls: 0.004808  loss_rpn_loc: 0.02833  time: 0.9881  data_time: 0.3266  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:55:52 d2.utils.events]: \u001b[0m eta: 0:21:30  iter: 239  total_loss: 0.7197  loss_cls: 0.2308  loss_box_reg: 0.3526  loss_mask: 0.1486  loss_rpn_cls: 0.004298  loss_rpn_loc: 0.0246  time: 0.9867  data_time: 0.3334  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:56:13 d2.utils.events]: \u001b[0m eta: 0:21:06  iter: 259  total_loss: 0.6896  loss_cls: 0.1903  loss_box_reg: 0.3288  loss_mask: 0.127  loss_rpn_cls: 0.005342  loss_rpn_loc: 0.02045  time: 0.9895  data_time: 0.3231  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:56:33 d2.utils.events]: \u001b[0m eta: 0:20:46  iter: 279  total_loss: 0.653  loss_cls: 0.175  loss_box_reg: 0.3213  loss_mask: 0.1361  loss_rpn_cls: 0.00355  loss_rpn_loc: 0.02295  time: 0.9891  data_time: 0.3412  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:56:52 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 299  total_loss: 0.7468  loss_cls: 0.1856  loss_box_reg: 0.3979  loss_mask: 0.1576  loss_rpn_cls: 0.004061  loss_rpn_loc: 0.0265  time: 0.9876  data_time: 0.3142  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:57:12 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 319  total_loss: 0.6732  loss_cls: 0.1608  loss_box_reg: 0.3313  loss_mask: 0.1252  loss_rpn_cls: 0.002969  loss_rpn_loc: 0.01863  time: 0.9895  data_time: 0.3538  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:57:31 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 339  total_loss: 0.667  loss_cls: 0.1804  loss_box_reg: 0.3393  loss_mask: 0.1304  loss_rpn_cls: 0.003782  loss_rpn_loc: 0.01657  time: 0.9875  data_time: 0.3209  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:57:51 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 359  total_loss: 0.7073  loss_cls: 0.2218  loss_box_reg: 0.3611  loss_mask: 0.1365  loss_rpn_cls: 0.003597  loss_rpn_loc: 0.02154  time: 0.9882  data_time: 0.3533  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:58:12 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 379  total_loss: 0.6633  loss_cls: 0.1666  loss_box_reg: 0.3432  loss_mask: 0.1232  loss_rpn_cls: 0.002353  loss_rpn_loc: 0.02136  time: 0.9893  data_time: 0.3343  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:58:30 d2.utils.events]: \u001b[0m eta: 0:18:40  iter: 399  total_loss: 0.644  loss_cls: 0.1592  loss_box_reg: 0.3267  loss_mask: 0.1507  loss_rpn_cls: 0.002644  loss_rpn_loc: 0.01719  time: 0.9863  data_time: 0.3093  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:58:50 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 419  total_loss: 0.6367  loss_cls: 0.1673  loss_box_reg: 0.3129  loss_mask: 0.1291  loss_rpn_cls: 0.003071  loss_rpn_loc: 0.02186  time: 0.9862  data_time: 0.3411  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:59:09 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 439  total_loss: 0.628  loss_cls: 0.1871  loss_box_reg: 0.3056  loss_mask: 0.1281  loss_rpn_cls: 0.002906  loss_rpn_loc: 0.02116  time: 0.9854  data_time: 0.3223  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:59:29 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 459  total_loss: 0.6003  loss_cls: 0.1561  loss_box_reg: 0.3026  loss_mask: 0.1462  loss_rpn_cls: 0.002178  loss_rpn_loc: 0.02247  time: 0.9841  data_time: 0.3058  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 22:59:49 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 479  total_loss: 0.578  loss_cls: 0.1405  loss_box_reg: 0.2782  loss_mask: 0.1163  loss_rpn_cls: 0.00349  loss_rpn_loc: 0.02189  time: 0.9850  data_time: 0.3442  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:00:09 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 499  total_loss: 0.6796  loss_cls: 0.1829  loss_box_reg: 0.341  loss_mask: 0.1221  loss_rpn_cls: 0.002326  loss_rpn_loc: 0.02033  time: 0.9854  data_time: 0.3451  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:00:28 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 519  total_loss: 0.6435  loss_cls: 0.1665  loss_box_reg: 0.3118  loss_mask: 0.1218  loss_rpn_cls: 0.003014  loss_rpn_loc: 0.01821  time: 0.9850  data_time: 0.3353  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:00:48 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 539  total_loss: 0.5836  loss_cls: 0.1467  loss_box_reg: 0.3263  loss_mask: 0.1186  loss_rpn_cls: 0.003527  loss_rpn_loc: 0.02094  time: 0.9851  data_time: 0.3221  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:01:08 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 559  total_loss: 0.5791  loss_cls: 0.1426  loss_box_reg: 0.2715  loss_mask: 0.124  loss_rpn_cls: 0.003225  loss_rpn_loc: 0.01827  time: 0.9856  data_time: 0.3524  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:01:27 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 579  total_loss: 0.5571  loss_cls: 0.1458  loss_box_reg: 0.283  loss_mask: 0.1178  loss_rpn_cls: 0.002861  loss_rpn_loc: 0.02224  time: 0.9848  data_time: 0.3252  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:01:46 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 599  total_loss: 0.5825  loss_cls: 0.1486  loss_box_reg: 0.3151  loss_mask: 0.1222  loss_rpn_cls: 0.001672  loss_rpn_loc: 0.01888  time: 0.9843  data_time: 0.3295  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:02:06 d2.utils.events]: \u001b[0m eta: 0:14:47  iter: 619  total_loss: 0.6036  loss_cls: 0.1426  loss_box_reg: 0.2877  loss_mask: 0.1295  loss_rpn_cls: 0.004026  loss_rpn_loc: 0.01919  time: 0.9837  data_time: 0.3247  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:02:25 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 639  total_loss: 0.6054  loss_cls: 0.1516  loss_box_reg: 0.2895  loss_mask: 0.12  loss_rpn_cls: 0.001542  loss_rpn_loc: 0.01755  time: 0.9834  data_time: 0.3362  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:02:45 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 659  total_loss: 0.522  loss_cls: 0.1324  loss_box_reg: 0.2711  loss_mask: 0.1012  loss_rpn_cls: 0.00201  loss_rpn_loc: 0.0171  time: 0.9828  data_time: 0.3132  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 23:03:04 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 679  total_loss: 0.5581  loss_cls: 0.1422  loss_box_reg: 0.2571  loss_mask: 0.1187  loss_rpn_cls: 0.002545  loss_rpn_loc: 0.01859  time: 0.9824  data_time: 0.3366  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:03:23 d2.utils.events]: \u001b[0m eta: 0:13:23  iter: 699  total_loss: 0.563  loss_cls: 0.1489  loss_box_reg: 0.2624  loss_mask: 0.1211  loss_rpn_cls: 0.002468  loss_rpn_loc: 0.01658  time: 0.9817  data_time: 0.3285  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:03:43 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 719  total_loss: 0.5731  loss_cls: 0.1181  loss_box_reg: 0.2833  loss_mask: 0.1227  loss_rpn_cls: 0.001934  loss_rpn_loc: 0.01916  time: 0.9820  data_time: 0.3524  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:04:02 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 739  total_loss: 0.5388  loss_cls: 0.1249  loss_box_reg: 0.2602  loss_mask: 0.1034  loss_rpn_cls: 0.001644  loss_rpn_loc: 0.01486  time: 0.9811  data_time: 0.3197  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:04:21 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 759  total_loss: 0.5576  loss_cls: 0.1542  loss_box_reg: 0.256  loss_mask: 0.1024  loss_rpn_cls: 0.003312  loss_rpn_loc: 0.01712  time: 0.9808  data_time: 0.3227  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:04:41 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 779  total_loss: 0.5084  loss_cls: 0.1006  loss_box_reg: 0.2665  loss_mask: 0.1101  loss_rpn_cls: 0.002267  loss_rpn_loc: 0.01988  time: 0.9806  data_time: 0.3247  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:05:00 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 799  total_loss: 0.4703  loss_cls: 0.1161  loss_box_reg: 0.2572  loss_mask: 0.1013  loss_rpn_cls: 0.001052  loss_rpn_loc: 0.01627  time: 0.9801  data_time: 0.3262  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:05:20 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 819  total_loss: 0.5346  loss_cls: 0.1263  loss_box_reg: 0.2648  loss_mask: 0.1121  loss_rpn_cls: 0.00254  loss_rpn_loc: 0.01793  time: 0.9802  data_time: 0.3354  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:05:39 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 839  total_loss: 0.53  loss_cls: 0.1458  loss_box_reg: 0.2582  loss_mask: 0.1021  loss_rpn_cls: 0.001797  loss_rpn_loc: 0.02121  time: 0.9800  data_time: 0.3250  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:05:59 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 859  total_loss: 0.4786  loss_cls: 0.121  loss_box_reg: 0.2403  loss_mask: 0.09921  loss_rpn_cls: 0.001846  loss_rpn_loc: 0.01699  time: 0.9800  data_time: 0.3294  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:06:18 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 879  total_loss: 0.5317  loss_cls: 0.115  loss_box_reg: 0.2441  loss_mask: 0.1238  loss_rpn_cls: 0.001857  loss_rpn_loc: 0.01801  time: 0.9791  data_time: 0.2997  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:06:37 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 899  total_loss: 0.4938  loss_cls: 0.1106  loss_box_reg: 0.2371  loss_mask: 0.1134  loss_rpn_cls: 0.001292  loss_rpn_loc: 0.01842  time: 0.9790  data_time: 0.3065  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:06:57 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 919  total_loss: 0.4918  loss_cls: 0.1183  loss_box_reg: 0.2354  loss_mask: 0.1101  loss_rpn_cls: 0.001959  loss_rpn_loc: 0.02055  time: 0.9790  data_time: 0.3367  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:07:16 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 939  total_loss: 0.5112  loss_cls: 0.116  loss_box_reg: 0.2643  loss_mask: 0.1023  loss_rpn_cls: 0.001988  loss_rpn_loc: 0.01576  time: 0.9787  data_time: 0.2988  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:07:36 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 959  total_loss: 0.5479  loss_cls: 0.1239  loss_box_reg: 0.2511  loss_mask: 0.1251  loss_rpn_cls: 0.002891  loss_rpn_loc: 0.01759  time: 0.9789  data_time: 0.3582  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:07:56 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 979  total_loss: 0.5139  loss_cls: 0.1087  loss_box_reg: 0.2334  loss_mask: 0.1262  loss_rpn_cls: 0.002343  loss_rpn_loc: 0.01733  time: 0.9793  data_time: 0.3296  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:08:15 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 999  total_loss: 0.4982  loss_cls: 0.1254  loss_box_reg: 0.2654  loss_mask: 0.1031  loss_rpn_cls: 0.00207  loss_rpn_loc: 0.01639  time: 0.9789  data_time: 0.3441  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:08:35 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 1019  total_loss: 0.5359  loss_cls: 0.1226  loss_box_reg: 0.2378  loss_mask: 0.1098  loss_rpn_cls: 0.003287  loss_rpn_loc: 0.02121  time: 0.9787  data_time: 0.3392  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:08:54 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 1039  total_loss: 0.4745  loss_cls: 0.1122  loss_box_reg: 0.221  loss_mask: 0.1135  loss_rpn_cls: 0.001503  loss_rpn_loc: 0.01413  time: 0.9790  data_time: 0.3433  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:09:15 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 1059  total_loss: 0.4561  loss_cls: 0.1351  loss_box_reg: 0.2002  loss_mask: 0.09895  loss_rpn_cls: 0.00129  loss_rpn_loc: 0.01703  time: 0.9796  data_time: 0.3477  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:09:34 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1079  total_loss: 0.4611  loss_cls: 0.1166  loss_box_reg: 0.2027  loss_mask: 0.1074  loss_rpn_cls: 0.002405  loss_rpn_loc: 0.01908  time: 0.9798  data_time: 0.3367  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:09:54 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 1099  total_loss: 0.4353  loss_cls: 0.1135  loss_box_reg: 0.1997  loss_mask: 0.1037  loss_rpn_cls: 0.002035  loss_rpn_loc: 0.01947  time: 0.9801  data_time: 0.3524  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:10:14 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 1119  total_loss: 0.457  loss_cls: 0.1259  loss_box_reg: 0.2068  loss_mask: 0.1108  loss_rpn_cls: 0.001392  loss_rpn_loc: 0.01794  time: 0.9798  data_time: 0.3337  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:10:33 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1139  total_loss: 0.4687  loss_cls: 0.1159  loss_box_reg: 0.216  loss_mask: 0.1061  loss_rpn_cls: 0.0007197  loss_rpn_loc: 0.01356  time: 0.9800  data_time: 0.3584  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:10:53 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 1159  total_loss: 0.4662  loss_cls: 0.1158  loss_box_reg: 0.2121  loss_mask: 0.1108  loss_rpn_cls: 0.001745  loss_rpn_loc: 0.01857  time: 0.9800  data_time: 0.3327  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:11:12 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 1179  total_loss: 0.4302  loss_cls: 0.09642  loss_box_reg: 0.1992  loss_mask: 0.1076  loss_rpn_cls: 0.001073  loss_rpn_loc: 0.01343  time: 0.9797  data_time: 0.3319  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:11:32 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 1199  total_loss: 0.436  loss_cls: 0.09945  loss_box_reg: 0.2121  loss_mask: 0.1114  loss_rpn_cls: 0.001148  loss_rpn_loc: 0.01436  time: 0.9800  data_time: 0.3426  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:11:52 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 1219  total_loss: 0.4515  loss_cls: 0.1128  loss_box_reg: 0.1986  loss_mask: 0.09838  loss_rpn_cls: 0.001847  loss_rpn_loc: 0.01512  time: 0.9799  data_time: 0.3391  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:12:11 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 1239  total_loss: 0.3959  loss_cls: 0.0936  loss_box_reg: 0.1974  loss_mask: 0.0999  loss_rpn_cls: 0.001713  loss_rpn_loc: 0.01807  time: 0.9797  data_time: 0.3174  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:12:31 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 1259  total_loss: 0.3984  loss_cls: 0.09523  loss_box_reg: 0.1868  loss_mask: 0.1066  loss_rpn_cls: 0.001763  loss_rpn_loc: 0.01663  time: 0.9802  data_time: 0.3642  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:12:51 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 1279  total_loss: 0.4632  loss_cls: 0.1098  loss_box_reg: 0.192  loss_mask: 0.1078  loss_rpn_cls: 0.001911  loss_rpn_loc: 0.01911  time: 0.9799  data_time: 0.3048  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:13:10 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 1299  total_loss: 0.4406  loss_cls: 0.09261  loss_box_reg: 0.2109  loss_mask: 0.1076  loss_rpn_cls: 0.001595  loss_rpn_loc: 0.01485  time: 0.9799  data_time: 0.3135  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:13:29 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 1319  total_loss: 0.4213  loss_cls: 0.108  loss_box_reg: 0.1926  loss_mask: 0.09632  loss_rpn_cls: 0.001123  loss_rpn_loc: 0.0176  time: 0.9792  data_time: 0.2900  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 23:13:48 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 1339  total_loss: 0.4604  loss_cls: 0.1298  loss_box_reg: 0.2083  loss_mask: 0.1076  loss_rpn_cls: 0.001642  loss_rpn_loc: 0.01844  time: 0.9790  data_time: 0.3294  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:14:08 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 1359  total_loss: 0.4574  loss_cls: 0.1224  loss_box_reg: 0.1895  loss_mask: 0.1058  loss_rpn_cls: 0.001401  loss_rpn_loc: 0.01652  time: 0.9789  data_time: 0.3342  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:14:27 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1379  total_loss: 0.4402  loss_cls: 0.1083  loss_box_reg: 0.2009  loss_mask: 0.101  loss_rpn_cls: 0.00246  loss_rpn_loc: 0.01829  time: 0.9785  data_time: 0.2935  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:14:46 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 1399  total_loss: 0.4005  loss_cls: 0.09374  loss_box_reg: 0.193  loss_mask: 0.104  loss_rpn_cls: 0.001697  loss_rpn_loc: 0.01472  time: 0.9785  data_time: 0.3247  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:15:06 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 1419  total_loss: 0.452  loss_cls: 0.1263  loss_box_reg: 0.1887  loss_mask: 0.1096  loss_rpn_cls: 0.001447  loss_rpn_loc: 0.0169  time: 0.9785  data_time: 0.3259  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:15:26 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 1439  total_loss: 0.4103  loss_cls: 0.1062  loss_box_reg: 0.1906  loss_mask: 0.0999  loss_rpn_cls: 0.001097  loss_rpn_loc: 0.01707  time: 0.9787  data_time: 0.3438  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:15:45 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.4228  loss_cls: 0.1102  loss_box_reg: 0.1947  loss_mask: 0.108  loss_rpn_cls: 0.001425  loss_rpn_loc: 0.01976  time: 0.9781  data_time: 0.3212  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:16:05 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.4592  loss_cls: 0.1344  loss_box_reg: 0.198  loss_mask: 0.1058  loss_rpn_cls: 0.002222  loss_rpn_loc: 0.01876  time: 0.9789  data_time: 0.3541  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:16:26 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4073  loss_cls: 0.09939  loss_box_reg: 0.1884  loss_mask: 0.09077  loss_rpn_cls: 0.000605  loss_rpn_loc: 0.01302  time: 0.9785  data_time: 0.3199  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:16:26 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:25 (0.9786 s / it)\n",
      "\u001b[32m[03/04 23:16:26 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:28 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 23:16:27 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 23:16:27 d2.data.datasets.coco]: \u001b[0mLoaded 157 images in COCO format from /host/mic21-framework/server/uploads/horse_sleigh_gt.json\n",
      "horse_sleigh\n",
      "\u001b[32m[03/04 23:16:27 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 23:16:27 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 23:16:27 d2.data.datasets.coco]: \u001b[0mLoaded 157 images in COCO format from /host/mic21-framework/server/uploads/horse_sleigh_gt.json\n",
      "\u001b[32m[03/04 23:16:27 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 157 images left.\n",
      "\u001b[32m[03/04 23:16:28 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|  category  | #instances   |   category   | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n",
      "|    man     | 117          |    woman     | 131          |   person   | 93           |\n",
      "|   horse    | 206          | horse sleigh | 193          |            |              |\n",
      "|   total    | 740          |              |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 23:16:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 23:16:28 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 23:16:28 d2.data.common]: \u001b[0mSerializing 157 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 23:16:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.97 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 23:16:28 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 23:16:44 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 19  total_loss: 2.37  loss_cls: 0.7643  loss_box_reg: 0.9394  loss_mask: 0.6125  loss_rpn_cls: 0.009037  loss_rpn_loc: 0.01868  time: 0.7858  data_time: 0.1554  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:16:59 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 39  total_loss: 1.905  loss_cls: 0.5137  loss_box_reg: 0.8872  loss_mask: 0.464  loss_rpn_cls: 0.006995  loss_rpn_loc: 0.01873  time: 0.7751  data_time: 0.1246  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:17:15 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 59  total_loss: 1.438  loss_cls: 0.3694  loss_box_reg: 0.6933  loss_mask: 0.3125  loss_rpn_cls: 0.00553  loss_rpn_loc: 0.0201  time: 0.7768  data_time: 0.1319  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:17:30 d2.utils.events]: \u001b[0m eta: 0:18:33  iter: 79  total_loss: 1.276  loss_cls: 0.3564  loss_box_reg: 0.6542  loss_mask: 0.2539  loss_rpn_cls: 0.00642  loss_rpn_loc: 0.01912  time: 0.7728  data_time: 0.1296  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:17:45 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 99  total_loss: 1.153  loss_cls: 0.3079  loss_box_reg: 0.5822  loss_mask: 0.2419  loss_rpn_cls: 0.002189  loss_rpn_loc: 0.01835  time: 0.7687  data_time: 0.1322  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:18:00 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 119  total_loss: 1.106  loss_cls: 0.3006  loss_box_reg: 0.5321  loss_mask: 0.2039  loss_rpn_cls: 0.003556  loss_rpn_loc: 0.0213  time: 0.7659  data_time: 0.1302  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:18:15 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 139  total_loss: 1.02  loss_cls: 0.242  loss_box_reg: 0.4763  loss_mask: 0.2211  loss_rpn_cls: 0.003233  loss_rpn_loc: 0.0176  time: 0.7668  data_time: 0.1218  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:18:30 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 159  total_loss: 0.9697  loss_cls: 0.2738  loss_box_reg: 0.4524  loss_mask: 0.2127  loss_rpn_cls: 0.003381  loss_rpn_loc: 0.01696  time: 0.7620  data_time: 0.1050  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:18:45 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 179  total_loss: 0.9315  loss_cls: 0.2697  loss_box_reg: 0.4516  loss_mask: 0.2  loss_rpn_cls: 0.003504  loss_rpn_loc: 0.01646  time: 0.7610  data_time: 0.1155  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:19:01 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 199  total_loss: 0.8651  loss_cls: 0.2512  loss_box_reg: 0.3862  loss_mask: 0.189  loss_rpn_cls: 0.004209  loss_rpn_loc: 0.0157  time: 0.7625  data_time: 0.1258  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:19:16 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 219  total_loss: 0.9233  loss_cls: 0.2676  loss_box_reg: 0.4319  loss_mask: 0.1997  loss_rpn_cls: 0.002766  loss_rpn_loc: 0.01492  time: 0.7628  data_time: 0.1233  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:19:31 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 239  total_loss: 1.011  loss_cls: 0.275  loss_box_reg: 0.4544  loss_mask: 0.2029  loss_rpn_cls: 0.002566  loss_rpn_loc: 0.017  time: 0.7627  data_time: 0.1165  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:19:46 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 259  total_loss: 0.8959  loss_cls: 0.2247  loss_box_reg: 0.3862  loss_mask: 0.1922  loss_rpn_cls: 0.001733  loss_rpn_loc: 0.01776  time: 0.7617  data_time: 0.1081  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:20:01 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 279  total_loss: 0.7996  loss_cls: 0.2586  loss_box_reg: 0.3522  loss_mask: 0.1753  loss_rpn_cls: 0.002504  loss_rpn_loc: 0.01683  time: 0.7608  data_time: 0.1165  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:20:17 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 299  total_loss: 0.8181  loss_cls: 0.237  loss_box_reg: 0.3698  loss_mask: 0.1904  loss_rpn_cls: 0.002338  loss_rpn_loc: 0.01491  time: 0.7609  data_time: 0.1165  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:20:31 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 319  total_loss: 0.8112  loss_cls: 0.2467  loss_box_reg: 0.3793  loss_mask: 0.1731  loss_rpn_cls: 0.001634  loss_rpn_loc: 0.01563  time: 0.7582  data_time: 0.1070  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:20:46 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 339  total_loss: 0.7531  loss_cls: 0.2227  loss_box_reg: 0.3611  loss_mask: 0.1661  loss_rpn_cls: 0.001705  loss_rpn_loc: 0.01408  time: 0.7572  data_time: 0.1084  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:21:01 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 359  total_loss: 0.7811  loss_cls: 0.246  loss_box_reg: 0.3411  loss_mask: 0.1743  loss_rpn_cls: 0.002807  loss_rpn_loc: 0.01412  time: 0.7568  data_time: 0.1004  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:21:17 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 379  total_loss: 0.8149  loss_cls: 0.1985  loss_box_reg: 0.3465  loss_mask: 0.1893  loss_rpn_cls: 0.002569  loss_rpn_loc: 0.01367  time: 0.7593  data_time: 0.1405  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:21:32 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 399  total_loss: 0.8101  loss_cls: 0.2339  loss_box_reg: 0.3574  loss_mask: 0.1889  loss_rpn_cls: 0.002614  loss_rpn_loc: 0.01567  time: 0.7584  data_time: 0.1267  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:21:47 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 419  total_loss: 0.7453  loss_cls: 0.2032  loss_box_reg: 0.3361  loss_mask: 0.1716  loss_rpn_cls: 0.002005  loss_rpn_loc: 0.01432  time: 0.7583  data_time: 0.1180  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:22:02 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 439  total_loss: 0.7583  loss_cls: 0.2119  loss_box_reg: 0.3319  loss_mask: 0.1851  loss_rpn_cls: 0.001917  loss_rpn_loc: 0.01527  time: 0.7579  data_time: 0.1080  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:22:17 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 459  total_loss: 0.7329  loss_cls: 0.2533  loss_box_reg: 0.3063  loss_mask: 0.1647  loss_rpn_cls: 0.001825  loss_rpn_loc: 0.01524  time: 0.7585  data_time: 0.1164  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:22:33 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 479  total_loss: 0.7547  loss_cls: 0.2493  loss_box_reg: 0.3269  loss_mask: 0.1651  loss_rpn_cls: 0.00161  loss_rpn_loc: 0.01567  time: 0.7591  data_time: 0.1228  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:22:48 d2.utils.events]: \u001b[0m eta: 0:12:40  iter: 499  total_loss: 0.7439  loss_cls: 0.1946  loss_box_reg: 0.3285  loss_mask: 0.1848  loss_rpn_cls: 0.001355  loss_rpn_loc: 0.01205  time: 0.7591  data_time: 0.1200  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:23:03 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 519  total_loss: 0.8042  loss_cls: 0.2407  loss_box_reg: 0.3493  loss_mask: 0.1747  loss_rpn_cls: 0.002018  loss_rpn_loc: 0.01479  time: 0.7589  data_time: 0.1066  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:23:18 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 539  total_loss: 0.7634  loss_cls: 0.2482  loss_box_reg: 0.3282  loss_mask: 0.1763  loss_rpn_cls: 0.002008  loss_rpn_loc: 0.01257  time: 0.7588  data_time: 0.1181  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:23:33 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 559  total_loss: 0.7599  loss_cls: 0.233  loss_box_reg: 0.3065  loss_mask: 0.1728  loss_rpn_cls: 0.001559  loss_rpn_loc: 0.01438  time: 0.7589  data_time: 0.1260  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:23:49 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 579  total_loss: 0.7358  loss_cls: 0.214  loss_box_reg: 0.3232  loss_mask: 0.1783  loss_rpn_cls: 0.002115  loss_rpn_loc: 0.01528  time: 0.7590  data_time: 0.1163  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:24:04 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 599  total_loss: 0.6488  loss_cls: 0.2012  loss_box_reg: 0.2838  loss_mask: 0.1508  loss_rpn_cls: 0.001682  loss_rpn_loc: 0.01388  time: 0.7596  data_time: 0.1143  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:24:19 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 619  total_loss: 0.7585  loss_cls: 0.2174  loss_box_reg: 0.3362  loss_mask: 0.1789  loss_rpn_cls: 0.001509  loss_rpn_loc: 0.01384  time: 0.7594  data_time: 0.1226  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:24:35 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 639  total_loss: 0.7281  loss_cls: 0.2131  loss_box_reg: 0.3296  loss_mask: 0.1754  loss_rpn_cls: 0.001029  loss_rpn_loc: 0.01542  time: 0.7595  data_time: 0.1093  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:24:50 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 659  total_loss: 0.6921  loss_cls: 0.197  loss_box_reg: 0.3017  loss_mask: 0.163  loss_rpn_cls: 0.001221  loss_rpn_loc: 0.01142  time: 0.7600  data_time: 0.1127  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 23:25:05 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 679  total_loss: 0.7155  loss_cls: 0.204  loss_box_reg: 0.3088  loss_mask: 0.1785  loss_rpn_cls: 0.001141  loss_rpn_loc: 0.01526  time: 0.7598  data_time: 0.1041  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:25:20 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 699  total_loss: 0.6476  loss_cls: 0.1795  loss_box_reg: 0.2807  loss_mask: 0.1528  loss_rpn_cls: 0.001469  loss_rpn_loc: 0.01312  time: 0.7598  data_time: 0.1120  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:25:36 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 719  total_loss: 0.6835  loss_cls: 0.1824  loss_box_reg: 0.3125  loss_mask: 0.1693  loss_rpn_cls: 0.001243  loss_rpn_loc: 0.01407  time: 0.7602  data_time: 0.1151  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:25:51 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 739  total_loss: 0.6295  loss_cls: 0.1839  loss_box_reg: 0.2908  loss_mask: 0.1474  loss_rpn_cls: 0.0007588  loss_rpn_loc: 0.01269  time: 0.7600  data_time: 0.1027  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:26:06 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 759  total_loss: 0.6223  loss_cls: 0.2141  loss_box_reg: 0.2614  loss_mask: 0.1412  loss_rpn_cls: 0.002141  loss_rpn_loc: 0.0139  time: 0.7598  data_time: 0.1122  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:26:21 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 779  total_loss: 0.6603  loss_cls: 0.2138  loss_box_reg: 0.2693  loss_mask: 0.1635  loss_rpn_cls: 0.00195  loss_rpn_loc: 0.01565  time: 0.7595  data_time: 0.1032  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:26:36 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 799  total_loss: 0.6594  loss_cls: 0.1889  loss_box_reg: 0.2978  loss_mask: 0.157  loss_rpn_cls: 0.001604  loss_rpn_loc: 0.01174  time: 0.7586  data_time: 0.1094  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:26:51 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 819  total_loss: 0.7058  loss_cls: 0.2013  loss_box_reg: 0.291  loss_mask: 0.1613  loss_rpn_cls: 0.0009645  loss_rpn_loc: 0.01423  time: 0.7592  data_time: 0.1123  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:27:06 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 839  total_loss: 0.6504  loss_cls: 0.1877  loss_box_reg: 0.2938  loss_mask: 0.1549  loss_rpn_cls: 0.001928  loss_rpn_loc: 0.01293  time: 0.7592  data_time: 0.1074  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:27:21 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 859  total_loss: 0.6151  loss_cls: 0.1617  loss_box_reg: 0.2773  loss_mask: 0.1584  loss_rpn_cls: 0.001715  loss_rpn_loc: 0.01337  time: 0.7581  data_time: 0.1084  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:27:36 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 879  total_loss: 0.6663  loss_cls: 0.2081  loss_box_reg: 0.2731  loss_mask: 0.1576  loss_rpn_cls: 0.001547  loss_rpn_loc: 0.01218  time: 0.7584  data_time: 0.1153  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:27:51 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 899  total_loss: 0.6634  loss_cls: 0.2009  loss_box_reg: 0.2723  loss_mask: 0.1563  loss_rpn_cls: 0.001629  loss_rpn_loc: 0.01305  time: 0.7583  data_time: 0.1120  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:28:06 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 919  total_loss: 0.6337  loss_cls: 0.1857  loss_box_reg: 0.2936  loss_mask: 0.1535  loss_rpn_cls: 0.00129  loss_rpn_loc: 0.01301  time: 0.7579  data_time: 0.1124  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:28:21 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 939  total_loss: 0.6544  loss_cls: 0.1923  loss_box_reg: 0.2718  loss_mask: 0.1718  loss_rpn_cls: 0.001938  loss_rpn_loc: 0.01279  time: 0.7574  data_time: 0.1016  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:28:36 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 959  total_loss: 0.6204  loss_cls: 0.1788  loss_box_reg: 0.2525  loss_mask: 0.156  loss_rpn_cls: 0.001049  loss_rpn_loc: 0.01477  time: 0.7576  data_time: 0.1216  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:28:50 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 979  total_loss: 0.5709  loss_cls: 0.175  loss_box_reg: 0.2595  loss_mask: 0.1445  loss_rpn_cls: 0.0009729  loss_rpn_loc: 0.01269  time: 0.7567  data_time: 0.1040  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:29:05 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 999  total_loss: 0.6529  loss_cls: 0.2002  loss_box_reg: 0.2521  loss_mask: 0.1519  loss_rpn_cls: 0.001114  loss_rpn_loc: 0.0111  time: 0.7566  data_time: 0.1144  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:29:20 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 1019  total_loss: 0.6682  loss_cls: 0.1992  loss_box_reg: 0.2781  loss_mask: 0.1615  loss_rpn_cls: 0.001188  loss_rpn_loc: 0.01409  time: 0.7561  data_time: 0.1034  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:29:35 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 1039  total_loss: 0.5923  loss_cls: 0.1749  loss_box_reg: 0.2637  loss_mask: 0.1463  loss_rpn_cls: 0.001487  loss_rpn_loc: 0.01219  time: 0.7562  data_time: 0.1061  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:29:50 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1059  total_loss: 0.6073  loss_cls: 0.2032  loss_box_reg: 0.2664  loss_mask: 0.1632  loss_rpn_cls: 0.001417  loss_rpn_loc: 0.01367  time: 0.7562  data_time: 0.1066  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:30:05 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 1079  total_loss: 0.5781  loss_cls: 0.1679  loss_box_reg: 0.2418  loss_mask: 0.1603  loss_rpn_cls: 0.001279  loss_rpn_loc: 0.01213  time: 0.7561  data_time: 0.1146  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:30:20 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 1099  total_loss: 0.5641  loss_cls: 0.1724  loss_box_reg: 0.2288  loss_mask: 0.1462  loss_rpn_cls: 0.0006238  loss_rpn_loc: 0.01104  time: 0.7556  data_time: 0.1015  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:30:35 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 1119  total_loss: 0.5642  loss_cls: 0.1671  loss_box_reg: 0.225  loss_mask: 0.1472  loss_rpn_cls: 0.001053  loss_rpn_loc: 0.01174  time: 0.7557  data_time: 0.1070  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:30:50 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 1139  total_loss: 0.6241  loss_cls: 0.1717  loss_box_reg: 0.2386  loss_mask: 0.1608  loss_rpn_cls: 0.001779  loss_rpn_loc: 0.01335  time: 0.7558  data_time: 0.1079  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:31:06 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 1159  total_loss: 0.5434  loss_cls: 0.1625  loss_box_reg: 0.2286  loss_mask: 0.1522  loss_rpn_cls: 0.001306  loss_rpn_loc: 0.0144  time: 0.7557  data_time: 0.1085  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:31:20 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 1179  total_loss: 0.5592  loss_cls: 0.1586  loss_box_reg: 0.228  loss_mask: 0.1437  loss_rpn_cls: 0.001237  loss_rpn_loc: 0.01152  time: 0.7552  data_time: 0.1126  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:31:35 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 1199  total_loss: 0.58  loss_cls: 0.1449  loss_box_reg: 0.2595  loss_mask: 0.1631  loss_rpn_cls: 0.0008473  loss_rpn_loc: 0.01183  time: 0.7548  data_time: 0.1130  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:31:50 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 1219  total_loss: 0.6238  loss_cls: 0.2021  loss_box_reg: 0.2374  loss_mask: 0.154  loss_rpn_cls: 0.001533  loss_rpn_loc: 0.0123  time: 0.7549  data_time: 0.1201  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:32:05 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 1239  total_loss: 0.5727  loss_cls: 0.1833  loss_box_reg: 0.226  loss_mask: 0.1288  loss_rpn_cls: 0.001202  loss_rpn_loc: 0.01185  time: 0.7545  data_time: 0.1133  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:32:19 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 1259  total_loss: 0.5549  loss_cls: 0.1489  loss_box_reg: 0.2248  loss_mask: 0.1505  loss_rpn_cls: 0.001546  loss_rpn_loc: 0.01182  time: 0.7539  data_time: 0.1080  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:32:34 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 1279  total_loss: 0.5731  loss_cls: 0.1708  loss_box_reg: 0.2355  loss_mask: 0.1478  loss_rpn_cls: 0.002689  loss_rpn_loc: 0.01118  time: 0.7540  data_time: 0.1125  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:32:49 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 1299  total_loss: 0.5567  loss_cls: 0.1737  loss_box_reg: 0.2141  loss_mask: 0.1562  loss_rpn_cls: 0.001168  loss_rpn_loc: 0.01214  time: 0.7541  data_time: 0.1071  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:33:05 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 1319  total_loss: 0.5329  loss_cls: 0.1565  loss_box_reg: 0.2174  loss_mask: 0.153  loss_rpn_cls: 0.0008468  loss_rpn_loc: 0.01189  time: 0.7542  data_time: 0.1240  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 23:33:20 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 1339  total_loss: 0.571  loss_cls: 0.1588  loss_box_reg: 0.234  loss_mask: 0.159  loss_rpn_cls: 0.000998  loss_rpn_loc: 0.01214  time: 0.7546  data_time: 0.1334  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:33:36 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 1359  total_loss: 0.575  loss_cls: 0.1662  loss_box_reg: 0.2288  loss_mask: 0.1661  loss_rpn_cls: 0.001728  loss_rpn_loc: 0.01374  time: 0.7550  data_time: 0.1325  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:33:51 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 1379  total_loss: 0.5094  loss_cls: 0.1475  loss_box_reg: 0.1983  loss_mask: 0.1444  loss_rpn_cls: 0.0008864  loss_rpn_loc: 0.01044  time: 0.7549  data_time: 0.1128  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:34:06 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 1399  total_loss: 0.5791  loss_cls: 0.1553  loss_box_reg: 0.2331  loss_mask: 0.1548  loss_rpn_cls: 0.001653  loss_rpn_loc: 0.01226  time: 0.7551  data_time: 0.1122  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:34:21 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 1419  total_loss: 0.5476  loss_cls: 0.1375  loss_box_reg: 0.2271  loss_mask: 0.1489  loss_rpn_cls: 0.001021  loss_rpn_loc: 0.01161  time: 0.7549  data_time: 0.1094  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:34:36 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 1439  total_loss: 0.5567  loss_cls: 0.1869  loss_box_reg: 0.2281  loss_mask: 0.143  loss_rpn_cls: 0.000679  loss_rpn_loc: 0.01241  time: 0.7551  data_time: 0.1376  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:34:51 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 1459  total_loss: 0.5464  loss_cls: 0.1465  loss_box_reg: 0.2394  loss_mask: 0.1663  loss_rpn_cls: 0.001273  loss_rpn_loc: 0.01194  time: 0.7550  data_time: 0.1157  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:35:07 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 1479  total_loss: 0.557  loss_cls: 0.1576  loss_box_reg: 0.2296  loss_mask: 0.1614  loss_rpn_cls: 0.001053  loss_rpn_loc: 0.01231  time: 0.7552  data_time: 0.1142  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:35:23 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.6036  loss_cls: 0.1847  loss_box_reg: 0.2444  loss_mask: 0.1602  loss_rpn_cls: 0.001324  loss_rpn_loc: 0.01182  time: 0.7553  data_time: 0.1114  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:35:24 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:18:51 (0.7553 s / it)\n",
      "\u001b[32m[03/04 23:35:24 d2.engine.hooks]: \u001b[0mTotal training time: 0:18:54 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 23:35:24 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 23:35:24 d2.data.datasets.coco]: \u001b[0mLoaded 191 images in COCO format from /host/mic21-framework/server/uploads/ambulance_gt.json\n",
      "ambulance\n",
      "\u001b[32m[03/04 23:35:25 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 23:35:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 23:35:25 d2.data.datasets.coco]: \u001b[0mLoaded 191 images in COCO format from /host/mic21-framework/server/uploads/ambulance_gt.json\n",
      "\u001b[32m[03/04 23:35:25 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 191 images left.\n",
      "\u001b[32m[03/04 23:35:25 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      car      | 74           | emergency s.. | 630          | ambulance d.. | 433          |\n",
      "| ambulance w.. | 511          | ambulance w.. | 570          | ambulance h.. | 266          |\n",
      "| ambulance w.. | 142          | ambulance r.. | 81           |   ambulance   | 220          |\n",
      "| ambulance m.. | 340          |               |              |               |              |\n",
      "|     total     | 3267         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/04 23:35:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 23:35:25 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 23:35:25 d2.data.common]: \u001b[0mSerializing 191 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 23:35:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.21 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (10, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (10,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 23:35:25 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 23:35:44 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 19  total_loss: 3.042  loss_cls: 1.192  loss_box_reg: 0.8006  loss_mask: 0.6416  loss_rpn_cls: 0.1966  loss_rpn_loc: 0.2288  time: 0.9147  data_time: 0.2431  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:36:02 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 39  total_loss: 2.519  loss_cls: 0.9292  loss_box_reg: 0.8384  loss_mask: 0.5147  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.1775  time: 0.9207  data_time: 0.2392  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:36:21 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 59  total_loss: 2.175  loss_cls: 0.787  loss_box_reg: 0.7085  loss_mask: 0.4002  loss_rpn_cls: 0.08086  loss_rpn_loc: 0.1497  time: 0.9180  data_time: 0.2347  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:36:39 d2.utils.events]: \u001b[0m eta: 0:21:53  iter: 79  total_loss: 2.047  loss_cls: 0.6569  loss_box_reg: 0.8287  loss_mask: 0.3195  loss_rpn_cls: 0.0737  loss_rpn_loc: 0.159  time: 0.9198  data_time: 0.2257  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:36:57 d2.utils.events]: \u001b[0m eta: 0:21:34  iter: 99  total_loss: 1.83  loss_cls: 0.5756  loss_box_reg: 0.6879  loss_mask: 0.2691  loss_rpn_cls: 0.07163  loss_rpn_loc: 0.1763  time: 0.9162  data_time: 0.2180  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:37:15 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 119  total_loss: 1.591  loss_cls: 0.4863  loss_box_reg: 0.6082  loss_mask: 0.2589  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.1592  time: 0.9140  data_time: 0.2078  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:37:33 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 139  total_loss: 1.637  loss_cls: 0.4909  loss_box_reg: 0.5806  loss_mask: 0.2801  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.1611  time: 0.9126  data_time: 0.2361  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:37:52 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 159  total_loss: 1.419  loss_cls: 0.3977  loss_box_reg: 0.535  loss_mask: 0.2482  loss_rpn_cls: 0.05163  loss_rpn_loc: 0.1518  time: 0.9126  data_time: 0.2127  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:38:10 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 179  total_loss: 1.493  loss_cls: 0.4123  loss_box_reg: 0.5963  loss_mask: 0.2405  loss_rpn_cls: 0.05783  loss_rpn_loc: 0.1616  time: 0.9105  data_time: 0.2031  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:38:28 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 199  total_loss: 1.297  loss_cls: 0.38  loss_box_reg: 0.5494  loss_mask: 0.2033  loss_rpn_cls: 0.06037  loss_rpn_loc: 0.1388  time: 0.9099  data_time: 0.2342  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:38:46 d2.utils.events]: \u001b[0m eta: 0:19:30  iter: 219  total_loss: 1.286  loss_cls: 0.3427  loss_box_reg: 0.5351  loss_mask: 0.1917  loss_rpn_cls: 0.05886  loss_rpn_loc: 0.1445  time: 0.9095  data_time: 0.2075  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:39:04 d2.utils.events]: \u001b[0m eta: 0:19:09  iter: 239  total_loss: 1.327  loss_cls: 0.3755  loss_box_reg: 0.4958  loss_mask: 0.2298  loss_rpn_cls: 0.05179  loss_rpn_loc: 0.1587  time: 0.9085  data_time: 0.2055  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:39:22 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 259  total_loss: 1.243  loss_cls: 0.334  loss_box_reg: 0.4813  loss_mask: 0.2254  loss_rpn_cls: 0.04782  loss_rpn_loc: 0.1498  time: 0.9075  data_time: 0.2062  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:39:40 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 279  total_loss: 1.195  loss_cls: 0.3301  loss_box_reg: 0.5092  loss_mask: 0.2171  loss_rpn_cls: 0.04762  loss_rpn_loc: 0.1592  time: 0.9081  data_time: 0.2314  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:39:58 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 299  total_loss: 1.269  loss_cls: 0.3444  loss_box_reg: 0.4849  loss_mask: 0.2292  loss_rpn_cls: 0.04539  loss_rpn_loc: 0.1397  time: 0.9084  data_time: 0.2321  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:40:16 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 319  total_loss: 1.161  loss_cls: 0.2986  loss_box_reg: 0.4715  loss_mask: 0.2058  loss_rpn_cls: 0.0513  loss_rpn_loc: 0.1333  time: 0.9079  data_time: 0.2181  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:40:34 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 339  total_loss: 1.16  loss_cls: 0.3341  loss_box_reg: 0.4612  loss_mask: 0.2174  loss_rpn_cls: 0.04902  loss_rpn_loc: 0.1527  time: 0.9063  data_time: 0.2072  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:40:52 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 359  total_loss: 1.234  loss_cls: 0.3727  loss_box_reg: 0.4532  loss_mask: 0.2307  loss_rpn_cls: 0.04942  loss_rpn_loc: 0.1463  time: 0.9049  data_time: 0.2082  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:41:10 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 379  total_loss: 1.135  loss_cls: 0.3069  loss_box_reg: 0.4496  loss_mask: 0.1875  loss_rpn_cls: 0.03797  loss_rpn_loc: 0.1421  time: 0.9063  data_time: 0.2139  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:41:28 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 399  total_loss: 1.174  loss_cls: 0.2977  loss_box_reg: 0.4481  loss_mask: 0.2252  loss_rpn_cls: 0.04542  loss_rpn_loc: 0.1417  time: 0.9046  data_time: 0.1831  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:41:46 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 419  total_loss: 1.107  loss_cls: 0.2852  loss_box_reg: 0.4172  loss_mask: 0.2103  loss_rpn_cls: 0.03979  loss_rpn_loc: 0.1184  time: 0.9047  data_time: 0.2266  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:42:04 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 439  total_loss: 1.093  loss_cls: 0.3024  loss_box_reg: 0.4128  loss_mask: 0.1994  loss_rpn_cls: 0.03904  loss_rpn_loc: 0.126  time: 0.9041  data_time: 0.2173  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:42:22 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 459  total_loss: 1.062  loss_cls: 0.2847  loss_box_reg: 0.4185  loss_mask: 0.1985  loss_rpn_cls: 0.03968  loss_rpn_loc: 0.1383  time: 0.9042  data_time: 0.2155  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:42:39 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 479  total_loss: 1.108  loss_cls: 0.2892  loss_box_reg: 0.4296  loss_mask: 0.1912  loss_rpn_cls: 0.03871  loss_rpn_loc: 0.1531  time: 0.9030  data_time: 0.2114  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:42:57 d2.utils.events]: \u001b[0m eta: 0:15:07  iter: 499  total_loss: 1.135  loss_cls: 0.276  loss_box_reg: 0.4605  loss_mask: 0.2121  loss_rpn_cls: 0.03471  loss_rpn_loc: 0.1325  time: 0.9030  data_time: 0.2218  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:43:16 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 519  total_loss: 1.065  loss_cls: 0.2509  loss_box_reg: 0.4417  loss_mask: 0.1906  loss_rpn_cls: 0.03017  loss_rpn_loc: 0.1345  time: 0.9038  data_time: 0.2269  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:43:35 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 539  total_loss: 0.9425  loss_cls: 0.2423  loss_box_reg: 0.3662  loss_mask: 0.1636  loss_rpn_cls: 0.03345  loss_rpn_loc: 0.1231  time: 0.9055  data_time: 0.2510  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:43:53 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 559  total_loss: 1.161  loss_cls: 0.2769  loss_box_reg: 0.4416  loss_mask: 0.2061  loss_rpn_cls: 0.03964  loss_rpn_loc: 0.1349  time: 0.9048  data_time: 0.2353  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:44:11 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 579  total_loss: 1.058  loss_cls: 0.2547  loss_box_reg: 0.3835  loss_mask: 0.2004  loss_rpn_cls: 0.03511  loss_rpn_loc: 0.1302  time: 0.9053  data_time: 0.2241  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:44:29 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 599  total_loss: 1.019  loss_cls: 0.303  loss_box_reg: 0.4082  loss_mask: 0.1946  loss_rpn_cls: 0.02762  loss_rpn_loc: 0.1163  time: 0.9053  data_time: 0.2410  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:44:48 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 619  total_loss: 1.034  loss_cls: 0.2451  loss_box_reg: 0.3981  loss_mask: 0.1912  loss_rpn_cls: 0.03033  loss_rpn_loc: 0.1308  time: 0.9070  data_time: 0.2451  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:45:07 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 639  total_loss: 0.998  loss_cls: 0.2565  loss_box_reg: 0.3958  loss_mask: 0.1796  loss_rpn_cls: 0.03011  loss_rpn_loc: 0.1255  time: 0.9079  data_time: 0.2395  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:45:26 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 659  total_loss: 1.022  loss_cls: 0.2396  loss_box_reg: 0.3737  loss_mask: 0.1787  loss_rpn_cls: 0.02858  loss_rpn_loc: 0.1369  time: 0.9095  data_time: 0.2548  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 23:45:44 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 679  total_loss: 1.003  loss_cls: 0.2486  loss_box_reg: 0.4053  loss_mask: 0.1764  loss_rpn_cls: 0.02826  loss_rpn_loc: 0.1292  time: 0.9090  data_time: 0.2190  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:46:03 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 699  total_loss: 1.013  loss_cls: 0.2774  loss_box_reg: 0.4184  loss_mask: 0.1902  loss_rpn_cls: 0.0294  loss_rpn_loc: 0.1209  time: 0.9098  data_time: 0.2460  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:46:21 d2.utils.events]: \u001b[0m eta: 0:11:51  iter: 719  total_loss: 0.9759  loss_cls: 0.2285  loss_box_reg: 0.3939  loss_mask: 0.1906  loss_rpn_cls: 0.02866  loss_rpn_loc: 0.1228  time: 0.9096  data_time: 0.2458  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:46:40 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 739  total_loss: 0.9802  loss_cls: 0.2614  loss_box_reg: 0.372  loss_mask: 0.1896  loss_rpn_cls: 0.03269  loss_rpn_loc: 0.1302  time: 0.9106  data_time: 0.2432  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:46:57 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 759  total_loss: 0.9879  loss_cls: 0.2696  loss_box_reg: 0.3898  loss_mask: 0.1833  loss_rpn_cls: 0.02662  loss_rpn_loc: 0.122  time: 0.9095  data_time: 0.2146  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:47:15 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 779  total_loss: 0.981  loss_cls: 0.2506  loss_box_reg: 0.3792  loss_mask: 0.1794  loss_rpn_cls: 0.02096  loss_rpn_loc: 0.1205  time: 0.9094  data_time: 0.2353  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:47:35 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 799  total_loss: 0.9473  loss_cls: 0.2553  loss_box_reg: 0.3757  loss_mask: 0.1754  loss_rpn_cls: 0.02782  loss_rpn_loc: 0.1198  time: 0.9111  data_time: 0.2857  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:47:54 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 819  total_loss: 0.8806  loss_cls: 0.2124  loss_box_reg: 0.3679  loss_mask: 0.1757  loss_rpn_cls: 0.02746  loss_rpn_loc: 0.122  time: 0.9115  data_time: 0.2537  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:48:12 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 839  total_loss: 0.9186  loss_cls: 0.2175  loss_box_reg: 0.39  loss_mask: 0.1858  loss_rpn_cls: 0.0253  loss_rpn_loc: 0.1252  time: 0.9115  data_time: 0.2409  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:48:30 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 859  total_loss: 1.014  loss_cls: 0.2545  loss_box_reg: 0.3801  loss_mask: 0.1809  loss_rpn_cls: 0.02755  loss_rpn_loc: 0.1231  time: 0.9117  data_time: 0.2500  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:48:49 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 879  total_loss: 0.9544  loss_cls: 0.2373  loss_box_reg: 0.3842  loss_mask: 0.1815  loss_rpn_cls: 0.02563  loss_rpn_loc: 0.1358  time: 0.9124  data_time: 0.2529  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:49:07 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 899  total_loss: 0.9546  loss_cls: 0.2357  loss_box_reg: 0.3721  loss_mask: 0.1823  loss_rpn_cls: 0.02553  loss_rpn_loc: 0.1097  time: 0.9125  data_time: 0.2500  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:49:25 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 919  total_loss: 0.9474  loss_cls: 0.2257  loss_box_reg: 0.3689  loss_mask: 0.1716  loss_rpn_cls: 0.02272  loss_rpn_loc: 0.1139  time: 0.9122  data_time: 0.2276  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:49:44 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 939  total_loss: 0.9381  loss_cls: 0.2261  loss_box_reg: 0.3848  loss_mask: 0.1675  loss_rpn_cls: 0.02248  loss_rpn_loc: 0.1206  time: 0.9122  data_time: 0.2325  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:50:02 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 959  total_loss: 0.9356  loss_cls: 0.2461  loss_box_reg: 0.3852  loss_mask: 0.1877  loss_rpn_cls: 0.02188  loss_rpn_loc: 0.1172  time: 0.9119  data_time: 0.2326  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:50:20 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 979  total_loss: 0.8921  loss_cls: 0.2207  loss_box_reg: 0.3639  loss_mask: 0.1789  loss_rpn_cls: 0.02215  loss_rpn_loc: 0.1271  time: 0.9123  data_time: 0.2350  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:50:39 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 999  total_loss: 0.952  loss_cls: 0.2586  loss_box_reg: 0.3861  loss_mask: 0.1838  loss_rpn_cls: 0.02542  loss_rpn_loc: 0.1106  time: 0.9127  data_time: 0.2488  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:50:58 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 1019  total_loss: 0.9307  loss_cls: 0.2478  loss_box_reg: 0.3534  loss_mask: 0.1638  loss_rpn_cls: 0.02438  loss_rpn_loc: 0.115  time: 0.9132  data_time: 0.2522  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:51:17 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 1039  total_loss: 0.9805  loss_cls: 0.2647  loss_box_reg: 0.3503  loss_mask: 0.1854  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.1055  time: 0.9139  data_time: 0.2626  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:51:35 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 1059  total_loss: 0.8753  loss_cls: 0.2247  loss_box_reg: 0.3547  loss_mask: 0.1731  loss_rpn_cls: 0.02335  loss_rpn_loc: 0.1075  time: 0.9141  data_time: 0.2466  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:51:54 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 1079  total_loss: 0.8986  loss_cls: 0.21  loss_box_reg: 0.3441  loss_mask: 0.1771  loss_rpn_cls: 0.02261  loss_rpn_loc: 0.1162  time: 0.9144  data_time: 0.2196  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:52:13 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 1099  total_loss: 0.9308  loss_cls: 0.2614  loss_box_reg: 0.3529  loss_mask: 0.1756  loss_rpn_cls: 0.01887  loss_rpn_loc: 0.1182  time: 0.9148  data_time: 0.2545  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:52:31 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1119  total_loss: 0.903  loss_cls: 0.2115  loss_box_reg: 0.3471  loss_mask: 0.1898  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.1123  time: 0.9152  data_time: 0.2513  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:52:50 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 1139  total_loss: 0.8401  loss_cls: 0.2094  loss_box_reg: 0.3382  loss_mask: 0.1645  loss_rpn_cls: 0.02132  loss_rpn_loc: 0.1095  time: 0.9153  data_time: 0.2400  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:53:08 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1159  total_loss: 0.8097  loss_cls: 0.2166  loss_box_reg: 0.3207  loss_mask: 0.1641  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.1103  time: 0.9150  data_time: 0.2344  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:53:26 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 1179  total_loss: 0.8979  loss_cls: 0.2477  loss_box_reg: 0.3434  loss_mask: 0.1858  loss_rpn_cls: 0.02263  loss_rpn_loc: 0.1157  time: 0.9149  data_time: 0.2424  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:53:45 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 1199  total_loss: 0.9031  loss_cls: 0.2127  loss_box_reg: 0.3586  loss_mask: 0.1714  loss_rpn_cls: 0.02185  loss_rpn_loc: 0.1063  time: 0.9153  data_time: 0.2457  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:54:03 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 1219  total_loss: 0.8393  loss_cls: 0.2247  loss_box_reg: 0.321  loss_mask: 0.1746  loss_rpn_cls: 0.02105  loss_rpn_loc: 0.1062  time: 0.9150  data_time: 0.2257  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:54:21 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 1239  total_loss: 0.8292  loss_cls: 0.1837  loss_box_reg: 0.3114  loss_mask: 0.1701  loss_rpn_cls: 0.01975  loss_rpn_loc: 0.1147  time: 0.9152  data_time: 0.2644  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:54:40 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 1259  total_loss: 0.8964  loss_cls: 0.213  loss_box_reg: 0.3219  loss_mask: 0.1763  loss_rpn_cls: 0.02143  loss_rpn_loc: 0.1103  time: 0.9154  data_time: 0.2397  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:54:58 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 1279  total_loss: 0.831  loss_cls: 0.1914  loss_box_reg: 0.3182  loss_mask: 0.1629  loss_rpn_cls: 0.02034  loss_rpn_loc: 0.1071  time: 0.9156  data_time: 0.2485  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:55:18 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 1299  total_loss: 0.7956  loss_cls: 0.1931  loss_box_reg: 0.3169  loss_mask: 0.1596  loss_rpn_cls: 0.02193  loss_rpn_loc: 0.1149  time: 0.9165  data_time: 0.2610  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:55:36 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 1319  total_loss: 0.8562  loss_cls: 0.2286  loss_box_reg: 0.3337  loss_mask: 0.1532  loss_rpn_cls: 0.01886  loss_rpn_loc: 0.1092  time: 0.9163  data_time: 0.2371  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 23:55:54 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 1339  total_loss: 0.7879  loss_cls: 0.1749  loss_box_reg: 0.3175  loss_mask: 0.1585  loss_rpn_cls: 0.01849  loss_rpn_loc: 0.1009  time: 0.9161  data_time: 0.2222  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:56:13 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 1359  total_loss: 0.7987  loss_cls: 0.189  loss_box_reg: 0.3165  loss_mask: 0.164  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.1053  time: 0.9165  data_time: 0.2698  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:56:32 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 1379  total_loss: 0.8341  loss_cls: 0.2104  loss_box_reg: 0.3123  loss_mask: 0.1767  loss_rpn_cls: 0.01895  loss_rpn_loc: 0.1216  time: 0.9167  data_time: 0.2478  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:56:50 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 1399  total_loss: 0.7837  loss_cls: 0.2091  loss_box_reg: 0.2806  loss_mask: 0.1669  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.1088  time: 0.9168  data_time: 0.2340  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/04 23:57:09 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 1419  total_loss: 0.8882  loss_cls: 0.2031  loss_box_reg: 0.356  loss_mask: 0.1945  loss_rpn_cls: 0.0215  loss_rpn_loc: 0.1059  time: 0.9171  data_time: 0.2572  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:57:27 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 1439  total_loss: 0.8013  loss_cls: 0.2139  loss_box_reg: 0.3088  loss_mask: 0.1589  loss_rpn_cls: 0.01887  loss_rpn_loc: 0.1013  time: 0.9171  data_time: 0.2336  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:57:46 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 1459  total_loss: 0.8328  loss_cls: 0.2102  loss_box_reg: 0.3265  loss_mask: 0.1635  loss_rpn_cls: 0.02205  loss_rpn_loc: 0.1062  time: 0.9175  data_time: 0.2655  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:58:04 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1479  total_loss: 0.7875  loss_cls: 0.2046  loss_box_reg: 0.3126  loss_mask: 0.1647  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.1089  time: 0.9174  data_time: 0.2277  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:58:24 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7279  loss_cls: 0.1707  loss_box_reg: 0.3009  loss_mask: 0.1514  loss_rpn_cls: 0.02052  loss_rpn_loc: 0.09858  time: 0.9172  data_time: 0.2227  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/04 23:58:24 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:22:53 (0.9172 s / it)\n",
      "\u001b[32m[03/04 23:58:24 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:56 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 23:58:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 23:58:25 d2.data.datasets.coco]: \u001b[0mLoaded 127 images in COCO format from /host/mic21-framework/server/uploads/dog_sleigh_gt.json\n",
      "dog_sleigh\n",
      "\u001b[32m[03/04 23:58:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/04 23:58:26 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/04 23:58:26 d2.data.datasets.coco]: \u001b[0mLoaded 127 images in COCO format from /host/mic21-framework/server/uploads/dog_sleigh_gt.json\n",
      "\u001b[32m[03/04 23:58:26 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 127 images left.\n",
      "\u001b[32m[03/04 23:58:26 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    man     | 93           |   person   | 122          |    dog     | 853          |\n",
      "| dog sleigh | 158          |            |              |            |              |\n",
      "|   total    | 1226         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/04 23:58:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/04 23:58:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/04 23:58:26 d2.data.common]: \u001b[0mSerializing 127 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/04 23:58:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.04 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/04 23:58:26 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/04 23:58:44 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 19  total_loss: 2.347  loss_cls: 0.7125  loss_box_reg: 0.9057  loss_mask: 0.6053  loss_rpn_cls: 0.04008  loss_rpn_loc: 0.07199  time: 0.8644  data_time: 0.2013  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:59:01 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 39  total_loss: 1.829  loss_cls: 0.4869  loss_box_reg: 0.8425  loss_mask: 0.4419  loss_rpn_cls: 0.02368  loss_rpn_loc: 0.05398  time: 0.8664  data_time: 0.1645  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:59:18 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 59  total_loss: 1.56  loss_cls: 0.3987  loss_box_reg: 0.6796  loss_mask: 0.4036  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.05862  time: 0.8679  data_time: 0.1883  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:59:35 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 79  total_loss: 1.486  loss_cls: 0.4175  loss_box_reg: 0.6749  loss_mask: 0.338  loss_rpn_cls: 0.02163  loss_rpn_loc: 0.05512  time: 0.8613  data_time: 0.1685  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/04 23:59:52 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 99  total_loss: 1.486  loss_cls: 0.4019  loss_box_reg: 0.6452  loss_mask: 0.357  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.06466  time: 0.8612  data_time: 0.1890  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:00:10 d2.utils.events]: \u001b[0m eta: 0:20:07  iter: 119  total_loss: 1.51  loss_cls: 0.3645  loss_box_reg: 0.6692  loss_mask: 0.3369  loss_rpn_cls: 0.02037  loss_rpn_loc: 0.05486  time: 0.8600  data_time: 0.1587  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:00:27 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 139  total_loss: 1.328  loss_cls: 0.3533  loss_box_reg: 0.5761  loss_mask: 0.3103  loss_rpn_cls: 0.0222  loss_rpn_loc: 0.05899  time: 0.8587  data_time: 0.1738  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:00:44 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 159  total_loss: 1.436  loss_cls: 0.4067  loss_box_reg: 0.6214  loss_mask: 0.3256  loss_rpn_cls: 0.01757  loss_rpn_loc: 0.06101  time: 0.8612  data_time: 0.1654  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:01:02 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 179  total_loss: 1.23  loss_cls: 0.3031  loss_box_reg: 0.5612  loss_mask: 0.3105  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.06128  time: 0.8625  data_time: 0.1763  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:01:19 d2.utils.events]: \u001b[0m eta: 0:19:03  iter: 199  total_loss: 1.317  loss_cls: 0.3456  loss_box_reg: 0.5989  loss_mask: 0.3037  loss_rpn_cls: 0.01732  loss_rpn_loc: 0.05412  time: 0.8608  data_time: 0.1729  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:01:36 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 219  total_loss: 1.256  loss_cls: 0.3092  loss_box_reg: 0.5682  loss_mask: 0.2983  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.0544  time: 0.8597  data_time: 0.1515  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:01:53 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 239  total_loss: 1.219  loss_cls: 0.2875  loss_box_reg: 0.558  loss_mask: 0.3264  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.0493  time: 0.8592  data_time: 0.1723  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:02:10 d2.utils.events]: \u001b[0m eta: 0:18:03  iter: 259  total_loss: 1.188  loss_cls: 0.2783  loss_box_reg: 0.5383  loss_mask: 0.2842  loss_rpn_cls: 0.01721  loss_rpn_loc: 0.06064  time: 0.8586  data_time: 0.1577  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:02:27 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 279  total_loss: 1.148  loss_cls: 0.2915  loss_box_reg: 0.5108  loss_mask: 0.283  loss_rpn_cls: 0.01581  loss_rpn_loc: 0.05254  time: 0.8600  data_time: 0.1861  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:02:45 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 299  total_loss: 1.212  loss_cls: 0.326  loss_box_reg: 0.5172  loss_mask: 0.2848  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.05287  time: 0.8618  data_time: 0.1700  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:03:03 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 319  total_loss: 1.214  loss_cls: 0.2956  loss_box_reg: 0.5087  loss_mask: 0.2975  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.05304  time: 0.8631  data_time: 0.1785  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:03:20 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 339  total_loss: 1.232  loss_cls: 0.3083  loss_box_reg: 0.5389  loss_mask: 0.2991  loss_rpn_cls: 0.01376  loss_rpn_loc: 0.05881  time: 0.8635  data_time: 0.1737  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:03:37 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 359  total_loss: 1.128  loss_cls: 0.274  loss_box_reg: 0.4806  loss_mask: 0.2739  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.05033  time: 0.8632  data_time: 0.1705  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:03:54 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 379  total_loss: 1.068  loss_cls: 0.2522  loss_box_reg: 0.4708  loss_mask: 0.2978  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.05182  time: 0.8624  data_time: 0.1695  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:04:13 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 399  total_loss: 1.099  loss_cls: 0.3028  loss_box_reg: 0.4524  loss_mask: 0.2577  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.05918  time: 0.8651  data_time: 0.1942  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:04:29 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 419  total_loss: 1.104  loss_cls: 0.282  loss_box_reg: 0.4512  loss_mask: 0.2804  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.05169  time: 0.8637  data_time: 0.1446  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:04:47 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 439  total_loss: 1.118  loss_cls: 0.2614  loss_box_reg: 0.5157  loss_mask: 0.3025  loss_rpn_cls: 0.00939  loss_rpn_loc: 0.04722  time: 0.8640  data_time: 0.1824  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:05:04 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 459  total_loss: 1.101  loss_cls: 0.2905  loss_box_reg: 0.4624  loss_mask: 0.2764  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.05945  time: 0.8633  data_time: 0.1559  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:05:21 d2.utils.events]: \u001b[0m eta: 0:14:49  iter: 479  total_loss: 1.147  loss_cls: 0.2553  loss_box_reg: 0.5025  loss_mask: 0.3001  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.04799  time: 0.8632  data_time: 0.1831  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:05:39 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 499  total_loss: 0.9425  loss_cls: 0.2558  loss_box_reg: 0.3916  loss_mask: 0.2518  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.04437  time: 0.8646  data_time: 0.1936  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:05:56 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 519  total_loss: 1.085  loss_cls: 0.2694  loss_box_reg: 0.4466  loss_mask: 0.2794  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.04395  time: 0.8640  data_time: 0.1778  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:06:14 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 539  total_loss: 1.041  loss_cls: 0.2706  loss_box_reg: 0.4418  loss_mask: 0.2562  loss_rpn_cls: 0.009377  loss_rpn_loc: 0.04896  time: 0.8647  data_time: 0.1836  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:06:31 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 559  total_loss: 1.117  loss_cls: 0.2724  loss_box_reg: 0.4728  loss_mask: 0.2564  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.05397  time: 0.8653  data_time: 0.1832  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:06:49 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 579  total_loss: 0.9577  loss_cls: 0.2299  loss_box_reg: 0.4193  loss_mask: 0.2621  loss_rpn_cls: 0.008231  loss_rpn_loc: 0.0474  time: 0.8653  data_time: 0.1700  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:07:05 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 599  total_loss: 0.9948  loss_cls: 0.2361  loss_box_reg: 0.4158  loss_mask: 0.2656  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.04474  time: 0.8646  data_time: 0.1568  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:07:23 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 619  total_loss: 1.056  loss_cls: 0.2708  loss_box_reg: 0.4422  loss_mask: 0.2666  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.05243  time: 0.8648  data_time: 0.1892  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:07:39 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 639  total_loss: 0.9638  loss_cls: 0.2421  loss_box_reg: 0.3997  loss_mask: 0.2584  loss_rpn_cls: 0.008189  loss_rpn_loc: 0.04148  time: 0.8637  data_time: 0.1664  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:07:57 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 659  total_loss: 1.073  loss_cls: 0.2477  loss_box_reg: 0.4498  loss_mask: 0.2481  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.05857  time: 0.8642  data_time: 0.1731  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 00:08:15 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 679  total_loss: 1.096  loss_cls: 0.2934  loss_box_reg: 0.4441  loss_mask: 0.261  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.04957  time: 0.8647  data_time: 0.1911  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:08:32 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 699  total_loss: 0.961  loss_cls: 0.2389  loss_box_reg: 0.3962  loss_mask: 0.2589  loss_rpn_cls: 0.008052  loss_rpn_loc: 0.04554  time: 0.8646  data_time: 0.1755  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:08:49 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 719  total_loss: 1.022  loss_cls: 0.2184  loss_box_reg: 0.4174  loss_mask: 0.2737  loss_rpn_cls: 0.007259  loss_rpn_loc: 0.04531  time: 0.8643  data_time: 0.1688  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:09:07 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 739  total_loss: 1.019  loss_cls: 0.2702  loss_box_reg: 0.4099  loss_mask: 0.2398  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.04408  time: 0.8652  data_time: 0.1877  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:09:24 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 759  total_loss: 0.9436  loss_cls: 0.2288  loss_box_reg: 0.4066  loss_mask: 0.2419  loss_rpn_cls: 0.008651  loss_rpn_loc: 0.03984  time: 0.8651  data_time: 0.1625  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:09:42 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 779  total_loss: 0.944  loss_cls: 0.2082  loss_box_reg: 0.403  loss_mask: 0.2617  loss_rpn_cls: 0.009094  loss_rpn_loc: 0.04246  time: 0.8654  data_time: 0.1858  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:09:59 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 799  total_loss: 0.9708  loss_cls: 0.2383  loss_box_reg: 0.3843  loss_mask: 0.2668  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.05393  time: 0.8654  data_time: 0.1601  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:10:16 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 819  total_loss: 0.9964  loss_cls: 0.2475  loss_box_reg: 0.4054  loss_mask: 0.2439  loss_rpn_cls: 0.009157  loss_rpn_loc: 0.04035  time: 0.8646  data_time: 0.1579  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:10:33 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 839  total_loss: 0.9611  loss_cls: 0.2047  loss_box_reg: 0.3748  loss_mask: 0.2435  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.04421  time: 0.8642  data_time: 0.1669  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:10:50 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 859  total_loss: 0.9624  loss_cls: 0.2305  loss_box_reg: 0.4425  loss_mask: 0.2514  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.05011  time: 0.8639  data_time: 0.1751  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:11:08 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 879  total_loss: 0.9653  loss_cls: 0.236  loss_box_reg: 0.4273  loss_mask: 0.2503  loss_rpn_cls: 0.006465  loss_rpn_loc: 0.04559  time: 0.8644  data_time: 0.1938  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:11:26 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 899  total_loss: 0.9634  loss_cls: 0.2313  loss_box_reg: 0.3907  loss_mask: 0.2447  loss_rpn_cls: 0.007819  loss_rpn_loc: 0.03869  time: 0.8653  data_time: 0.1817  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:11:42 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 919  total_loss: 0.9501  loss_cls: 0.2145  loss_box_reg: 0.4039  loss_mask: 0.2592  loss_rpn_cls: 0.006263  loss_rpn_loc: 0.04065  time: 0.8646  data_time: 0.1817  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:11:59 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 939  total_loss: 0.9501  loss_cls: 0.2282  loss_box_reg: 0.4026  loss_mask: 0.237  loss_rpn_cls: 0.005334  loss_rpn_loc: 0.03453  time: 0.8640  data_time: 0.1579  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:12:16 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 959  total_loss: 0.9704  loss_cls: 0.2601  loss_box_reg: 0.4034  loss_mask: 0.2691  loss_rpn_cls: 0.008516  loss_rpn_loc: 0.0464  time: 0.8634  data_time: 0.1549  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:12:33 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 979  total_loss: 0.9475  loss_cls: 0.2427  loss_box_reg: 0.39  loss_mask: 0.2395  loss_rpn_cls: 0.009354  loss_rpn_loc: 0.04249  time: 0.8632  data_time: 0.1664  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:12:51 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 999  total_loss: 0.963  loss_cls: 0.2303  loss_box_reg: 0.3872  loss_mask: 0.2584  loss_rpn_cls: 0.005021  loss_rpn_loc: 0.04648  time: 0.8640  data_time: 0.1821  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:13:09 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 1019  total_loss: 0.9721  loss_cls: 0.2312  loss_box_reg: 0.4258  loss_mask: 0.2717  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.04977  time: 0.8646  data_time: 0.2023  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:13:26 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 1039  total_loss: 0.8556  loss_cls: 0.2233  loss_box_reg: 0.3699  loss_mask: 0.2431  loss_rpn_cls: 0.007842  loss_rpn_loc: 0.0388  time: 0.8647  data_time: 0.1842  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:13:45 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 1059  total_loss: 0.9011  loss_cls: 0.2303  loss_box_reg: 0.3311  loss_mask: 0.2507  loss_rpn_cls: 0.006087  loss_rpn_loc: 0.03645  time: 0.8656  data_time: 0.2096  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:14:02 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 1079  total_loss: 0.8443  loss_cls: 0.199  loss_box_reg: 0.3439  loss_mask: 0.2394  loss_rpn_cls: 0.006137  loss_rpn_loc: 0.03751  time: 0.8659  data_time: 0.1953  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:14:20 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1099  total_loss: 0.8901  loss_cls: 0.2115  loss_box_reg: 0.38  loss_mask: 0.24  loss_rpn_cls: 0.00658  loss_rpn_loc: 0.04566  time: 0.8659  data_time: 0.1721  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:14:36 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1119  total_loss: 0.9152  loss_cls: 0.2197  loss_box_reg: 0.375  loss_mask: 0.2352  loss_rpn_cls: 0.008821  loss_rpn_loc: 0.05342  time: 0.8653  data_time: 0.1672  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:14:53 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 1139  total_loss: 0.9346  loss_cls: 0.2341  loss_box_reg: 0.3961  loss_mask: 0.2319  loss_rpn_cls: 0.006109  loss_rpn_loc: 0.03549  time: 0.8649  data_time: 0.1587  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:15:10 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 1159  total_loss: 0.8627  loss_cls: 0.2282  loss_box_reg: 0.3801  loss_mask: 0.2444  loss_rpn_cls: 0.00762  loss_rpn_loc: 0.04809  time: 0.8649  data_time: 0.1824  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:15:28 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 1179  total_loss: 0.831  loss_cls: 0.1981  loss_box_reg: 0.3535  loss_mask: 0.2478  loss_rpn_cls: 0.006317  loss_rpn_loc: 0.03499  time: 0.8648  data_time: 0.1616  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:15:45 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 1199  total_loss: 0.876  loss_cls: 0.1939  loss_box_reg: 0.3556  loss_mask: 0.254  loss_rpn_cls: 0.007412  loss_rpn_loc: 0.04059  time: 0.8648  data_time: 0.1713  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:16:02 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 1219  total_loss: 0.8527  loss_cls: 0.1998  loss_box_reg: 0.3719  loss_mask: 0.2466  loss_rpn_cls: 0.00615  loss_rpn_loc: 0.0377  time: 0.8647  data_time: 0.1870  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:16:19 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 1239  total_loss: 0.8395  loss_cls: 0.1881  loss_box_reg: 0.3369  loss_mask: 0.2317  loss_rpn_cls: 0.005417  loss_rpn_loc: 0.05022  time: 0.8648  data_time: 0.1815  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:16:36 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 1259  total_loss: 0.8735  loss_cls: 0.2225  loss_box_reg: 0.3162  loss_mask: 0.2296  loss_rpn_cls: 0.006996  loss_rpn_loc: 0.04604  time: 0.8644  data_time: 0.1723  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:16:53 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 1279  total_loss: 0.8563  loss_cls: 0.1969  loss_box_reg: 0.3337  loss_mask: 0.2522  loss_rpn_cls: 0.004619  loss_rpn_loc: 0.03862  time: 0.8636  data_time: 0.1477  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:17:10 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 1299  total_loss: 0.8478  loss_cls: 0.2042  loss_box_reg: 0.3342  loss_mask: 0.2591  loss_rpn_cls: 0.008641  loss_rpn_loc: 0.04521  time: 0.8638  data_time: 0.1847  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:17:27 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 1319  total_loss: 0.7653  loss_cls: 0.1803  loss_box_reg: 0.3051  loss_mask: 0.2273  loss_rpn_cls: 0.008258  loss_rpn_loc: 0.04205  time: 0.8635  data_time: 0.1689  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 00:17:44 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 1339  total_loss: 0.8787  loss_cls: 0.2055  loss_box_reg: 0.349  loss_mask: 0.2395  loss_rpn_cls: 0.008166  loss_rpn_loc: 0.04598  time: 0.8635  data_time: 0.1753  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:18:01 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 1359  total_loss: 0.7384  loss_cls: 0.1832  loss_box_reg: 0.3033  loss_mask: 0.2161  loss_rpn_cls: 0.007242  loss_rpn_loc: 0.03834  time: 0.8633  data_time: 0.1773  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:18:19 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 1379  total_loss: 0.9033  loss_cls: 0.2154  loss_box_reg: 0.3534  loss_mask: 0.2396  loss_rpn_cls: 0.005835  loss_rpn_loc: 0.04902  time: 0.8638  data_time: 0.1858  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:18:37 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 1399  total_loss: 0.7969  loss_cls: 0.1969  loss_box_reg: 0.2955  loss_mask: 0.2064  loss_rpn_cls: 0.007087  loss_rpn_loc: 0.03621  time: 0.8638  data_time: 0.1821  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:18:54 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 1419  total_loss: 0.9049  loss_cls: 0.2174  loss_box_reg: 0.3869  loss_mask: 0.2684  loss_rpn_cls: 0.009348  loss_rpn_loc: 0.04583  time: 0.8640  data_time: 0.1709  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:19:12 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 1439  total_loss: 0.8626  loss_cls: 0.2026  loss_box_reg: 0.3488  loss_mask: 0.2435  loss_rpn_cls: 0.00605  loss_rpn_loc: 0.0357  time: 0.8641  data_time: 0.1972  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:19:29 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 1459  total_loss: 0.8218  loss_cls: 0.1865  loss_box_reg: 0.3571  loss_mask: 0.2448  loss_rpn_cls: 0.005433  loss_rpn_loc: 0.04607  time: 0.8639  data_time: 0.1707  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:19:46 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.863  loss_cls: 0.1852  loss_box_reg: 0.3415  loss_mask: 0.2323  loss_rpn_cls: 0.006609  loss_rpn_loc: 0.04115  time: 0.8641  data_time: 0.1858  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:20:04 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.8441  loss_cls: 0.2181  loss_box_reg: 0.3233  loss_mask: 0.2491  loss_rpn_cls: 0.007228  loss_rpn_loc: 0.0385  time: 0.8638  data_time: 0.1674  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:20:05 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:33 (0.8638 s / it)\n",
      "\u001b[32m[03/05 00:20:05 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:36 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 00:20:05 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 00:20:05 d2.data.datasets.coco]: \u001b[0mLoaded 209 images in COCO format from /host/mic21-framework/server/uploads/military_helicopter_gt.json\n",
      "military_helicopter\n",
      "\u001b[32m[03/05 00:20:06 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=32, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 00:20:06 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 00:20:06 d2.data.datasets.coco]: \u001b[0mLoaded 209 images in COCO format from /host/mic21-framework/server/uploads/military_helicopter_gt.json\n",
      "\u001b[32m[03/05 00:20:06 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 209 images left.\n",
      "\u001b[32m[03/05 00:20:06 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|   category   | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|     man      | 74           |    person     | 291          |     pilot     | 107          |\n",
      "| landing gear | 65           |     vane      | 262          | military he.. | 243          |\n",
      "| rotor system | 414          | helicopter .. | 538          |               |              |\n",
      "|    total     | 1994         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 00:20:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 00:20:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 00:20:06 d2.data.common]: \u001b[0mSerializing 209 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 00:20:06 d2.data.common]: \u001b[0mSerialized dataset takes 2.53 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (9, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (9,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (32, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (32,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (8, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 00:20:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 00:20:25 d2.utils.events]: \u001b[0m eta: 0:22:01  iter: 19  total_loss: 2.77  loss_cls: 0.9924  loss_box_reg: 0.8379  loss_mask: 0.5965  loss_rpn_cls: 0.116  loss_rpn_loc: 0.1972  time: 0.8972  data_time: 0.2433  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:20:44 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 39  total_loss: 2.363  loss_cls: 0.7309  loss_box_reg: 0.8741  loss_mask: 0.4505  loss_rpn_cls: 0.07608  loss_rpn_loc: 0.1729  time: 0.9197  data_time: 0.2520  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:21:02 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 59  total_loss: 2.111  loss_cls: 0.6055  loss_box_reg: 0.8665  loss_mask: 0.3698  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.1951  time: 0.9169  data_time: 0.2238  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:21:20 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 79  total_loss: 1.909  loss_cls: 0.5447  loss_box_reg: 0.7968  loss_mask: 0.3189  loss_rpn_cls: 0.06201  loss_rpn_loc: 0.1504  time: 0.9137  data_time: 0.2434  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:21:38 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 99  total_loss: 1.707  loss_cls: 0.4803  loss_box_reg: 0.7426  loss_mask: 0.2893  loss_rpn_cls: 0.06164  loss_rpn_loc: 0.1693  time: 0.9109  data_time: 0.2405  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:21:56 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 119  total_loss: 1.743  loss_cls: 0.4908  loss_box_reg: 0.7114  loss_mask: 0.3086  loss_rpn_cls: 0.05091  loss_rpn_loc: 0.1596  time: 0.9108  data_time: 0.2386  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:22:15 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 139  total_loss: 1.631  loss_cls: 0.4732  loss_box_reg: 0.6219  loss_mask: 0.2772  loss_rpn_cls: 0.04714  loss_rpn_loc: 0.1584  time: 0.9120  data_time: 0.2469  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:22:33 d2.utils.events]: \u001b[0m eta: 0:20:14  iter: 159  total_loss: 1.573  loss_cls: 0.3791  loss_box_reg: 0.6656  loss_mask: 0.2673  loss_rpn_cls: 0.0555  loss_rpn_loc: 0.19  time: 0.9104  data_time: 0.2139  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:22:51 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 179  total_loss: 1.521  loss_cls: 0.4305  loss_box_reg: 0.6314  loss_mask: 0.2796  loss_rpn_cls: 0.04595  loss_rpn_loc: 0.172  time: 0.9117  data_time: 0.2427  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:23:09 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 199  total_loss: 1.473  loss_cls: 0.3745  loss_box_reg: 0.6156  loss_mask: 0.2497  loss_rpn_cls: 0.04134  loss_rpn_loc: 0.1599  time: 0.9109  data_time: 0.2445  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:23:27 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 219  total_loss: 1.47  loss_cls: 0.4512  loss_box_reg: 0.5454  loss_mask: 0.2689  loss_rpn_cls: 0.04347  loss_rpn_loc: 0.1788  time: 0.9100  data_time: 0.2323  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:23:45 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 239  total_loss: 1.413  loss_cls: 0.3669  loss_box_reg: 0.5798  loss_mask: 0.2917  loss_rpn_cls: 0.0387  loss_rpn_loc: 0.1454  time: 0.9077  data_time: 0.2166  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:24:03 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 259  total_loss: 1.536  loss_cls: 0.3919  loss_box_reg: 0.6463  loss_mask: 0.2796  loss_rpn_cls: 0.04254  loss_rpn_loc: 0.1533  time: 0.9071  data_time: 0.2345  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:24:20 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 279  total_loss: 1.361  loss_cls: 0.342  loss_box_reg: 0.5685  loss_mask: 0.2454  loss_rpn_cls: 0.03384  loss_rpn_loc: 0.1463  time: 0.9033  data_time: 0.1989  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:24:39 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 299  total_loss: 1.37  loss_cls: 0.3441  loss_box_reg: 0.5955  loss_mask: 0.2689  loss_rpn_cls: 0.03612  loss_rpn_loc: 0.1307  time: 0.9046  data_time: 0.2446  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:24:56 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 319  total_loss: 1.461  loss_cls: 0.3823  loss_box_reg: 0.5841  loss_mask: 0.2393  loss_rpn_cls: 0.04132  loss_rpn_loc: 0.1628  time: 0.9032  data_time: 0.2085  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:25:13 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 339  total_loss: 1.344  loss_cls: 0.367  loss_box_reg: 0.5469  loss_mask: 0.2269  loss_rpn_cls: 0.03651  loss_rpn_loc: 0.1396  time: 0.9007  data_time: 0.1999  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:25:32 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 359  total_loss: 1.243  loss_cls: 0.3209  loss_box_reg: 0.5446  loss_mask: 0.2576  loss_rpn_cls: 0.02946  loss_rpn_loc: 0.1302  time: 0.9025  data_time: 0.2648  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:25:49 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 379  total_loss: 1.448  loss_cls: 0.3449  loss_box_reg: 0.5466  loss_mask: 0.2449  loss_rpn_cls: 0.03068  loss_rpn_loc: 0.1622  time: 0.9004  data_time: 0.2125  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:26:07 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 399  total_loss: 1.301  loss_cls: 0.3229  loss_box_reg: 0.5146  loss_mask: 0.2452  loss_rpn_cls: 0.03004  loss_rpn_loc: 0.1396  time: 0.8989  data_time: 0.2312  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:26:25 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 419  total_loss: 1.35  loss_cls: 0.3396  loss_box_reg: 0.5304  loss_mask: 0.2676  loss_rpn_cls: 0.0317  loss_rpn_loc: 0.1751  time: 0.9002  data_time: 0.2449  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:26:44 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 439  total_loss: 1.266  loss_cls: 0.3405  loss_box_reg: 0.5064  loss_mask: 0.2396  loss_rpn_cls: 0.03146  loss_rpn_loc: 0.1368  time: 0.9009  data_time: 0.2358  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:27:01 d2.utils.events]: \u001b[0m eta: 0:15:39  iter: 459  total_loss: 1.199  loss_cls: 0.2949  loss_box_reg: 0.5247  loss_mask: 0.2441  loss_rpn_cls: 0.03164  loss_rpn_loc: 0.1346  time: 0.8995  data_time: 0.2067  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:27:20 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 479  total_loss: 1.33  loss_cls: 0.3227  loss_box_reg: 0.523  loss_mask: 0.2356  loss_rpn_cls: 0.03536  loss_rpn_loc: 0.1901  time: 0.9005  data_time: 0.2376  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:27:38 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 499  total_loss: 1.248  loss_cls: 0.3387  loss_box_reg: 0.4773  loss_mask: 0.2383  loss_rpn_cls: 0.03105  loss_rpn_loc: 0.1237  time: 0.9010  data_time: 0.2266  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:27:55 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 519  total_loss: 1.249  loss_cls: 0.3034  loss_box_reg: 0.4888  loss_mask: 0.2498  loss_rpn_cls: 0.03378  loss_rpn_loc: 0.1471  time: 0.9000  data_time: 0.2292  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:28:12 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 539  total_loss: 1.209  loss_cls: 0.3087  loss_box_reg: 0.4873  loss_mask: 0.2498  loss_rpn_cls: 0.02674  loss_rpn_loc: 0.1574  time: 0.8984  data_time: 0.1976  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:28:30 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 559  total_loss: 1.264  loss_cls: 0.3349  loss_box_reg: 0.4735  loss_mask: 0.261  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.1286  time: 0.8978  data_time: 0.2069  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:28:48 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 579  total_loss: 1.23  loss_cls: 0.3081  loss_box_reg: 0.4828  loss_mask: 0.2301  loss_rpn_cls: 0.02977  loss_rpn_loc: 0.1626  time: 0.8977  data_time: 0.2257  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:29:06 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 599  total_loss: 1.258  loss_cls: 0.2964  loss_box_reg: 0.5263  loss_mask: 0.2446  loss_rpn_cls: 0.02864  loss_rpn_loc: 0.1522  time: 0.8985  data_time: 0.2382  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:29:24 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 619  total_loss: 1.209  loss_cls: 0.3375  loss_box_reg: 0.4635  loss_mask: 0.2262  loss_rpn_cls: 0.02511  loss_rpn_loc: 0.1498  time: 0.8985  data_time: 0.2215  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:29:42 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 639  total_loss: 1.098  loss_cls: 0.257  loss_box_reg: 0.4613  loss_mask: 0.2224  loss_rpn_cls: 0.02342  loss_rpn_loc: 0.1317  time: 0.8981  data_time: 0.2445  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:30:00 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 659  total_loss: 1.144  loss_cls: 0.2447  loss_box_reg: 0.4438  loss_mask: 0.2391  loss_rpn_cls: 0.02657  loss_rpn_loc: 0.152  time: 0.8985  data_time: 0.2486  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 00:30:18 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 679  total_loss: 1.175  loss_cls: 0.2864  loss_box_reg: 0.4756  loss_mask: 0.2368  loss_rpn_cls: 0.02495  loss_rpn_loc: 0.1382  time: 0.8986  data_time: 0.2244  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:30:37 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 699  total_loss: 1.23  loss_cls: 0.2687  loss_box_reg: 0.5073  loss_mask: 0.2412  loss_rpn_cls: 0.02147  loss_rpn_loc: 0.1404  time: 0.8990  data_time: 0.2297  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:30:55 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 719  total_loss: 1.19  loss_cls: 0.2969  loss_box_reg: 0.4722  loss_mask: 0.234  loss_rpn_cls: 0.02276  loss_rpn_loc: 0.1234  time: 0.8993  data_time: 0.2463  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:31:13 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 739  total_loss: 1.188  loss_cls: 0.3019  loss_box_reg: 0.4585  loss_mask: 0.2455  loss_rpn_cls: 0.026  loss_rpn_loc: 0.1378  time: 0.8997  data_time: 0.2426  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:31:31 d2.utils.events]: \u001b[0m eta: 0:11:09  iter: 759  total_loss: 1.137  loss_cls: 0.2976  loss_box_reg: 0.4524  loss_mask: 0.2161  loss_rpn_cls: 0.0229  loss_rpn_loc: 0.1338  time: 0.8998  data_time: 0.2257  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:31:49 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 779  total_loss: 1.258  loss_cls: 0.3283  loss_box_reg: 0.5179  loss_mask: 0.2311  loss_rpn_cls: 0.02198  loss_rpn_loc: 0.1317  time: 0.8990  data_time: 0.1887  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:32:06 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 799  total_loss: 1.189  loss_cls: 0.2869  loss_box_reg: 0.4892  loss_mask: 0.2368  loss_rpn_cls: 0.02441  loss_rpn_loc: 0.1365  time: 0.8983  data_time: 0.2430  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:32:24 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 819  total_loss: 1.156  loss_cls: 0.2601  loss_box_reg: 0.4798  loss_mask: 0.2282  loss_rpn_cls: 0.02317  loss_rpn_loc: 0.1399  time: 0.8983  data_time: 0.2257  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:32:43 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 839  total_loss: 1.116  loss_cls: 0.2578  loss_box_reg: 0.4105  loss_mask: 0.23  loss_rpn_cls: 0.02441  loss_rpn_loc: 0.1345  time: 0.8996  data_time: 0.2494  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:33:02 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 859  total_loss: 1.113  loss_cls: 0.2545  loss_box_reg: 0.4483  loss_mask: 0.2342  loss_rpn_cls: 0.0219  loss_rpn_loc: 0.1377  time: 0.9006  data_time: 0.2449  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:33:20 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 879  total_loss: 1.165  loss_cls: 0.2912  loss_box_reg: 0.4681  loss_mask: 0.22  loss_rpn_cls: 0.02718  loss_rpn_loc: 0.1126  time: 0.9002  data_time: 0.2169  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:33:38 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 899  total_loss: 1.132  loss_cls: 0.2581  loss_box_reg: 0.4477  loss_mask: 0.2171  loss_rpn_cls: 0.02366  loss_rpn_loc: 0.1439  time: 0.9005  data_time: 0.2448  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:33:56 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 919  total_loss: 1.117  loss_cls: 0.2687  loss_box_reg: 0.4245  loss_mask: 0.2235  loss_rpn_cls: 0.02182  loss_rpn_loc: 0.1255  time: 0.9005  data_time: 0.2197  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:34:14 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 939  total_loss: 1.247  loss_cls: 0.3025  loss_box_reg: 0.4704  loss_mask: 0.2427  loss_rpn_cls: 0.0218  loss_rpn_loc: 0.1506  time: 0.9002  data_time: 0.2283  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:34:32 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 959  total_loss: 1.049  loss_cls: 0.2648  loss_box_reg: 0.4536  loss_mask: 0.2385  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.1436  time: 0.9001  data_time: 0.2331  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:34:50 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 979  total_loss: 1.086  loss_cls: 0.2798  loss_box_reg: 0.4292  loss_mask: 0.2087  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.1136  time: 0.9002  data_time: 0.2108  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:35:09 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 999  total_loss: 1.168  loss_cls: 0.263  loss_box_reg: 0.4636  loss_mask: 0.238  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.1266  time: 0.9015  data_time: 0.2541  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:35:27 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 1019  total_loss: 1.108  loss_cls: 0.2691  loss_box_reg: 0.4443  loss_mask: 0.238  loss_rpn_cls: 0.0276  loss_rpn_loc: 0.1356  time: 0.9012  data_time: 0.2299  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:35:45 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1039  total_loss: 1.012  loss_cls: 0.2216  loss_box_reg: 0.4272  loss_mask: 0.222  loss_rpn_cls: 0.01921  loss_rpn_loc: 0.09747  time: 0.9009  data_time: 0.2259  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:36:03 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 1059  total_loss: 1.119  loss_cls: 0.282  loss_box_reg: 0.4303  loss_mask: 0.2265  loss_rpn_cls: 0.02044  loss_rpn_loc: 0.1534  time: 0.9015  data_time: 0.2406  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:36:21 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 1079  total_loss: 1.037  loss_cls: 0.2349  loss_box_reg: 0.4112  loss_mask: 0.2313  loss_rpn_cls: 0.01812  loss_rpn_loc: 0.1135  time: 0.9016  data_time: 0.2254  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:36:39 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 1099  total_loss: 1.109  loss_cls: 0.2328  loss_box_reg: 0.4315  loss_mask: 0.2242  loss_rpn_cls: 0.01781  loss_rpn_loc: 0.1285  time: 0.9015  data_time: 0.2325  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:36:58 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 1119  total_loss: 1.069  loss_cls: 0.2355  loss_box_reg: 0.4142  loss_mask: 0.2187  loss_rpn_cls: 0.01941  loss_rpn_loc: 0.1361  time: 0.9020  data_time: 0.2333  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:37:16 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 1139  total_loss: 1.025  loss_cls: 0.2206  loss_box_reg: 0.4201  loss_mask: 0.244  loss_rpn_cls: 0.01791  loss_rpn_loc: 0.1115  time: 0.9022  data_time: 0.2484  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:37:33 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 1159  total_loss: 0.9431  loss_cls: 0.2707  loss_box_reg: 0.3717  loss_mask: 0.2001  loss_rpn_cls: 0.01971  loss_rpn_loc: 0.1096  time: 0.9010  data_time: 0.1900  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:37:51 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 1179  total_loss: 1.094  loss_cls: 0.2439  loss_box_reg: 0.4233  loss_mask: 0.2473  loss_rpn_cls: 0.0194  loss_rpn_loc: 0.1195  time: 0.9009  data_time: 0.2274  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:38:09 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 1199  total_loss: 0.9693  loss_cls: 0.2235  loss_box_reg: 0.3827  loss_mask: 0.219  loss_rpn_cls: 0.01926  loss_rpn_loc: 0.1301  time: 0.9007  data_time: 0.2226  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:38:27 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 1219  total_loss: 1.058  loss_cls: 0.2439  loss_box_reg: 0.3868  loss_mask: 0.2246  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.1214  time: 0.9007  data_time: 0.2297  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:38:45 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 1239  total_loss: 0.9874  loss_cls: 0.253  loss_box_reg: 0.3974  loss_mask: 0.2489  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.1153  time: 0.9006  data_time: 0.2143  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:39:03 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 1259  total_loss: 1.038  loss_cls: 0.2245  loss_box_reg: 0.4022  loss_mask: 0.2362  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.1503  time: 0.9009  data_time: 0.2399  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:39:20 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 1279  total_loss: 1.042  loss_cls: 0.2358  loss_box_reg: 0.3997  loss_mask: 0.2266  loss_rpn_cls: 0.02092  loss_rpn_loc: 0.13  time: 0.9002  data_time: 0.1949  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:39:39 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 1299  total_loss: 0.9752  loss_cls: 0.2059  loss_box_reg: 0.3847  loss_mask: 0.2242  loss_rpn_cls: 0.01767  loss_rpn_loc: 0.1202  time: 0.9006  data_time: 0.2468  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:39:57 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 1319  total_loss: 1.114  loss_cls: 0.2745  loss_box_reg: 0.3796  loss_mask: 0.2484  loss_rpn_cls: 0.02203  loss_rpn_loc: 0.1241  time: 0.9007  data_time: 0.2295  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:40:16 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 1339  total_loss: 1.008  loss_cls: 0.233  loss_box_reg: 0.4178  loss_mask: 0.2131  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.1107  time: 0.9013  data_time: 0.2222  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 00:40:33 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 1359  total_loss: 0.9963  loss_cls: 0.227  loss_box_reg: 0.3526  loss_mask: 0.2268  loss_rpn_cls: 0.01872  loss_rpn_loc: 0.1251  time: 0.9012  data_time: 0.2291  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:40:52 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 1379  total_loss: 1.034  loss_cls: 0.2623  loss_box_reg: 0.3953  loss_mask: 0.2387  loss_rpn_cls: 0.01956  loss_rpn_loc: 0.1228  time: 0.9013  data_time: 0.2428  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:41:10 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 1399  total_loss: 0.991  loss_cls: 0.216  loss_box_reg: 0.4011  loss_mask: 0.2282  loss_rpn_cls: 0.01576  loss_rpn_loc: 0.1286  time: 0.9013  data_time: 0.2196  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:41:29 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 1419  total_loss: 1.002  loss_cls: 0.2087  loss_box_reg: 0.3849  loss_mask: 0.2087  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.1244  time: 0.9019  data_time: 0.2593  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:41:47 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 1439  total_loss: 1.039  loss_cls: 0.2335  loss_box_reg: 0.3979  loss_mask: 0.2255  loss_rpn_cls: 0.02153  loss_rpn_loc: 0.1329  time: 0.9019  data_time: 0.2447  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:42:05 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 1459  total_loss: 0.9138  loss_cls: 0.2023  loss_box_reg: 0.3495  loss_mask: 0.203  loss_rpn_cls: 0.01813  loss_rpn_loc: 0.1054  time: 0.9023  data_time: 0.2301  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:42:23 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1479  total_loss: 1.023  loss_cls: 0.2362  loss_box_reg: 0.4123  loss_mask: 0.2227  loss_rpn_cls: 0.01698  loss_rpn_loc: 0.1307  time: 0.9019  data_time: 0.2039  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:42:42 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 1.029  loss_cls: 0.2562  loss_box_reg: 0.3938  loss_mask: 0.2275  loss_rpn_cls: 0.01868  loss_rpn_loc: 0.1222  time: 0.9016  data_time: 0.2159  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 00:42:42 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:22:30 (0.9016 s / it)\n",
      "\u001b[32m[03/05 00:42:42 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:33 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 00:42:43 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 00:42:43 d2.data.datasets.coco]: \u001b[0mLoaded 152 images in COCO format from /host/mic21-framework/server/uploads/police_boat_gt.json\n",
      "police_boat\n",
      "\u001b[32m[03/05 00:42:43 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 5, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 00:42:43 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 00:42:43 d2.data.datasets.coco]: \u001b[0mLoaded 152 images in COCO format from /host/mic21-framework/server/uploads/police_boat_gt.json\n",
      "\u001b[32m[03/05 00:42:43 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 150 images left.\n",
      "\u001b[32m[03/05 00:42:43 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| emergency s.. | 115          | police boat.. | 183          | body of water | 152          |\n",
      "|  police boat  | 159          |   policeman   | 73           |               |              |\n",
      "|     total     | 682          |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 00:42:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 00:42:43 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 00:42:43 d2.data.common]: \u001b[0mSerializing 150 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 00:42:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.43 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (5, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 00:42:44 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 00:43:00 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 19  total_loss: 2.368  loss_cls: 0.7194  loss_box_reg: 0.8204  loss_mask: 0.5477  loss_rpn_cls: 0.1434  loss_rpn_loc: 0.106  time: 0.8311  data_time: 0.1634  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:43:17 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 39  total_loss: 1.89  loss_cls: 0.4953  loss_box_reg: 0.7827  loss_mask: 0.3716  loss_rpn_cls: 0.08214  loss_rpn_loc: 0.1275  time: 0.8365  data_time: 0.1752  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:43:34 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 59  total_loss: 1.634  loss_cls: 0.393  loss_box_reg: 0.7178  loss_mask: 0.3224  loss_rpn_cls: 0.06077  loss_rpn_loc: 0.09698  time: 0.8394  data_time: 0.1630  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:43:51 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 79  total_loss: 1.389  loss_cls: 0.2863  loss_box_reg: 0.6669  loss_mask: 0.2852  loss_rpn_cls: 0.04493  loss_rpn_loc: 0.1048  time: 0.8330  data_time: 0.1542  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:44:08 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 99  total_loss: 1.271  loss_cls: 0.1998  loss_box_reg: 0.6057  loss_mask: 0.2679  loss_rpn_cls: 0.04178  loss_rpn_loc: 0.1142  time: 0.8418  data_time: 0.1839  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:44:25 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 119  total_loss: 1.22  loss_cls: 0.2567  loss_box_reg: 0.6002  loss_mask: 0.2481  loss_rpn_cls: 0.03713  loss_rpn_loc: 0.08485  time: 0.8408  data_time: 0.1573  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:44:41 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 139  total_loss: 1.19  loss_cls: 0.2142  loss_box_reg: 0.5772  loss_mask: 0.208  loss_rpn_cls: 0.03776  loss_rpn_loc: 0.104  time: 0.8363  data_time: 0.1531  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:44:58 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 159  total_loss: 1.1  loss_cls: 0.1996  loss_box_reg: 0.5113  loss_mask: 0.2253  loss_rpn_cls: 0.03866  loss_rpn_loc: 0.09332  time: 0.8363  data_time: 0.1539  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:45:14 d2.utils.events]: \u001b[0m eta: 0:18:20  iter: 179  total_loss: 1.04  loss_cls: 0.1965  loss_box_reg: 0.498  loss_mask: 0.1888  loss_rpn_cls: 0.03359  loss_rpn_loc: 0.08303  time: 0.8342  data_time: 0.1399  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:45:31 d2.utils.events]: \u001b[0m eta: 0:18:01  iter: 199  total_loss: 0.995  loss_cls: 0.2147  loss_box_reg: 0.4554  loss_mask: 0.2002  loss_rpn_cls: 0.0283  loss_rpn_loc: 0.08441  time: 0.8333  data_time: 0.1449  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:45:47 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 219  total_loss: 1.064  loss_cls: 0.2028  loss_box_reg: 0.5019  loss_mask: 0.223  loss_rpn_cls: 0.02641  loss_rpn_loc: 0.1064  time: 0.8333  data_time: 0.1487  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:46:04 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 239  total_loss: 0.9439  loss_cls: 0.1816  loss_box_reg: 0.4761  loss_mask: 0.1837  loss_rpn_cls: 0.02644  loss_rpn_loc: 0.1052  time: 0.8327  data_time: 0.1520  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:46:21 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 259  total_loss: 0.8976  loss_cls: 0.1871  loss_box_reg: 0.4213  loss_mask: 0.1802  loss_rpn_cls: 0.02447  loss_rpn_loc: 0.08272  time: 0.8349  data_time: 0.1751  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:46:39 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 279  total_loss: 1.006  loss_cls: 0.181  loss_box_reg: 0.5004  loss_mask: 0.2035  loss_rpn_cls: 0.02284  loss_rpn_loc: 0.08942  time: 0.8383  data_time: 0.2038  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:46:55 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 299  total_loss: 0.9683  loss_cls: 0.2124  loss_box_reg: 0.4363  loss_mask: 0.2033  loss_rpn_cls: 0.02131  loss_rpn_loc: 0.0776  time: 0.8366  data_time: 0.1392  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:47:12 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 319  total_loss: 0.8581  loss_cls: 0.1736  loss_box_reg: 0.4029  loss_mask: 0.1857  loss_rpn_cls: 0.0179  loss_rpn_loc: 0.07742  time: 0.8383  data_time: 0.1644  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:47:29 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 339  total_loss: 0.9416  loss_cls: 0.1931  loss_box_reg: 0.4276  loss_mask: 0.204  loss_rpn_cls: 0.02337  loss_rpn_loc: 0.09556  time: 0.8384  data_time: 0.1429  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:47:45 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 359  total_loss: 0.8777  loss_cls: 0.1631  loss_box_reg: 0.4044  loss_mask: 0.173  loss_rpn_cls: 0.02387  loss_rpn_loc: 0.08158  time: 0.8369  data_time: 0.1351  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:48:02 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 379  total_loss: 0.8337  loss_cls: 0.1541  loss_box_reg: 0.3814  loss_mask: 0.1611  loss_rpn_cls: 0.01886  loss_rpn_loc: 0.07922  time: 0.8364  data_time: 0.1452  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:48:19 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 399  total_loss: 0.8138  loss_cls: 0.1579  loss_box_reg: 0.3893  loss_mask: 0.163  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.07212  time: 0.8366  data_time: 0.1735  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:48:35 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 419  total_loss: 0.8487  loss_cls: 0.1684  loss_box_reg: 0.3918  loss_mask: 0.1935  loss_rpn_cls: 0.0149  loss_rpn_loc: 0.07089  time: 0.8353  data_time: 0.1508  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:48:51 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 439  total_loss: 0.8546  loss_cls: 0.1842  loss_box_reg: 0.3989  loss_mask: 0.1854  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.06565  time: 0.8340  data_time: 0.1430  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:49:08 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 459  total_loss: 0.8064  loss_cls: 0.1598  loss_box_reg: 0.3749  loss_mask: 0.1685  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.06943  time: 0.8338  data_time: 0.1471  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:49:24 d2.utils.events]: \u001b[0m eta: 0:14:09  iter: 479  total_loss: 0.7788  loss_cls: 0.1617  loss_box_reg: 0.3583  loss_mask: 0.1635  loss_rpn_cls: 0.01675  loss_rpn_loc: 0.08285  time: 0.8322  data_time: 0.1482  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:49:40 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 499  total_loss: 0.8513  loss_cls: 0.1558  loss_box_reg: 0.3692  loss_mask: 0.1871  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.07647  time: 0.8318  data_time: 0.1375  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:49:57 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 519  total_loss: 0.8148  loss_cls: 0.1794  loss_box_reg: 0.3554  loss_mask: 0.1738  loss_rpn_cls: 0.01565  loss_rpn_loc: 0.07121  time: 0.8317  data_time: 0.1470  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:50:14 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 539  total_loss: 0.8033  loss_cls: 0.1476  loss_box_reg: 0.3535  loss_mask: 0.1777  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.08001  time: 0.8329  data_time: 0.1618  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:50:30 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 559  total_loss: 0.746  loss_cls: 0.1334  loss_box_reg: 0.346  loss_mask: 0.1544  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.0671  time: 0.8320  data_time: 0.1558  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:50:47 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 579  total_loss: 0.6947  loss_cls: 0.1611  loss_box_reg: 0.3377  loss_mask: 0.1438  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.07896  time: 0.8320  data_time: 0.1520  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:51:03 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 599  total_loss: 0.791  loss_cls: 0.1533  loss_box_reg: 0.3858  loss_mask: 0.1856  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.07183  time: 0.8317  data_time: 0.1487  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:51:20 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 619  total_loss: 0.793  loss_cls: 0.1516  loss_box_reg: 0.3636  loss_mask: 0.1458  loss_rpn_cls: 0.01515  loss_rpn_loc: 0.06907  time: 0.8320  data_time: 0.1741  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:51:37 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 639  total_loss: 0.6466  loss_cls: 0.1273  loss_box_reg: 0.3047  loss_mask: 0.149  loss_rpn_cls: 0.009313  loss_rpn_loc: 0.06232  time: 0.8319  data_time: 0.1579  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:51:54 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 659  total_loss: 0.7549  loss_cls: 0.1464  loss_box_reg: 0.3607  loss_mask: 0.159  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.07078  time: 0.8326  data_time: 0.1610  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 00:52:10 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 679  total_loss: 0.7459  loss_cls: 0.1399  loss_box_reg: 0.3233  loss_mask: 0.1635  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.0709  time: 0.8323  data_time: 0.1386  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:52:27 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 699  total_loss: 0.7615  loss_cls: 0.1379  loss_box_reg: 0.3679  loss_mask: 0.171  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.06983  time: 0.8327  data_time: 0.1644  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:52:44 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 719  total_loss: 0.7022  loss_cls: 0.1263  loss_box_reg: 0.351  loss_mask: 0.1513  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.06619  time: 0.8325  data_time: 0.1405  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:53:00 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 739  total_loss: 0.7563  loss_cls: 0.1413  loss_box_reg: 0.3138  loss_mask: 0.1665  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.0695  time: 0.8316  data_time: 0.1197  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:53:16 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 759  total_loss: 0.6928  loss_cls: 0.1248  loss_box_reg: 0.3402  loss_mask: 0.1649  loss_rpn_cls: 0.01062  loss_rpn_loc: 0.07042  time: 0.8316  data_time: 0.1291  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:53:33 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 779  total_loss: 0.7117  loss_cls: 0.1369  loss_box_reg: 0.3215  loss_mask: 0.1514  loss_rpn_cls: 0.008552  loss_rpn_loc: 0.07383  time: 0.8313  data_time: 0.1650  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:53:49 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 799  total_loss: 0.6632  loss_cls: 0.1233  loss_box_reg: 0.2959  loss_mask: 0.1667  loss_rpn_cls: 0.011  loss_rpn_loc: 0.07333  time: 0.8306  data_time: 0.1329  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:54:05 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 819  total_loss: 0.6399  loss_cls: 0.09218  loss_box_reg: 0.2907  loss_mask: 0.1458  loss_rpn_cls: 0.008794  loss_rpn_loc: 0.06084  time: 0.8298  data_time: 0.1157  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:54:21 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 839  total_loss: 0.7114  loss_cls: 0.1249  loss_box_reg: 0.3557  loss_mask: 0.1559  loss_rpn_cls: 0.008092  loss_rpn_loc: 0.07699  time: 0.8295  data_time: 0.1434  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:54:38 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 859  total_loss: 0.6598  loss_cls: 0.1026  loss_box_reg: 0.3027  loss_mask: 0.1474  loss_rpn_cls: 0.008202  loss_rpn_loc: 0.07024  time: 0.8292  data_time: 0.1347  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:54:54 d2.utils.events]: \u001b[0m eta: 0:08:36  iter: 879  total_loss: 0.6703  loss_cls: 0.1203  loss_box_reg: 0.3085  loss_mask: 0.1598  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.06239  time: 0.8294  data_time: 0.1527  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:55:10 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 899  total_loss: 0.6782  loss_cls: 0.125  loss_box_reg: 0.3073  loss_mask: 0.1541  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.06289  time: 0.8287  data_time: 0.1315  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:55:27 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 919  total_loss: 0.6453  loss_cls: 0.1263  loss_box_reg: 0.3104  loss_mask: 0.1401  loss_rpn_cls: 0.008611  loss_rpn_loc: 0.06995  time: 0.8285  data_time: 0.1313  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:55:43 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 939  total_loss: 0.6753  loss_cls: 0.1226  loss_box_reg: 0.3147  loss_mask: 0.1558  loss_rpn_cls: 0.009181  loss_rpn_loc: 0.07784  time: 0.8279  data_time: 0.1502  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:56:00 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 959  total_loss: 0.6538  loss_cls: 0.1059  loss_box_reg: 0.3238  loss_mask: 0.1519  loss_rpn_cls: 0.009513  loss_rpn_loc: 0.06805  time: 0.8283  data_time: 0.1350  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:56:16 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 979  total_loss: 0.6532  loss_cls: 0.1136  loss_box_reg: 0.3011  loss_mask: 0.1372  loss_rpn_cls: 0.008126  loss_rpn_loc: 0.06612  time: 0.8277  data_time: 0.1270  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:56:32 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 999  total_loss: 0.6885  loss_cls: 0.1246  loss_box_reg: 0.3027  loss_mask: 0.1313  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.08087  time: 0.8276  data_time: 0.1290  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 00:56:48 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 1019  total_loss: 0.6552  loss_cls: 0.1069  loss_box_reg: 0.3189  loss_mask: 0.1585  loss_rpn_cls: 0.008678  loss_rpn_loc: 0.06503  time: 0.8272  data_time: 0.1223  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:57:05 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 1039  total_loss: 0.6716  loss_cls: 0.1033  loss_box_reg: 0.3125  loss_mask: 0.1574  loss_rpn_cls: 0.008743  loss_rpn_loc: 0.06202  time: 0.8273  data_time: 0.1262  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:57:22 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1059  total_loss: 0.6246  loss_cls: 0.1106  loss_box_reg: 0.2724  loss_mask: 0.1516  loss_rpn_cls: 0.01112  loss_rpn_loc: 0.05947  time: 0.8275  data_time: 0.1338  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:57:38 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1079  total_loss: 0.6487  loss_cls: 0.1101  loss_box_reg: 0.276  loss_mask: 0.1413  loss_rpn_cls: 0.008465  loss_rpn_loc: 0.06146  time: 0.8271  data_time: 0.1456  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:57:54 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1099  total_loss: 0.5947  loss_cls: 0.09945  loss_box_reg: 0.2735  loss_mask: 0.1386  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.08046  time: 0.8269  data_time: 0.1363  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:58:11 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 1119  total_loss: 0.5587  loss_cls: 0.07829  loss_box_reg: 0.2609  loss_mask: 0.1474  loss_rpn_cls: 0.00787  loss_rpn_loc: 0.0515  time: 0.8268  data_time: 0.1265  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:58:27 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 1139  total_loss: 0.5632  loss_cls: 0.1022  loss_box_reg: 0.2578  loss_mask: 0.1406  loss_rpn_cls: 0.009225  loss_rpn_loc: 0.05855  time: 0.8265  data_time: 0.1313  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:58:43 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 1159  total_loss: 0.6058  loss_cls: 0.08293  loss_box_reg: 0.2695  loss_mask: 0.1614  loss_rpn_cls: 0.008744  loss_rpn_loc: 0.06783  time: 0.8262  data_time: 0.1220  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:58:59 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 1179  total_loss: 0.6268  loss_cls: 0.1231  loss_box_reg: 0.259  loss_mask: 0.1477  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.06703  time: 0.8259  data_time: 0.1352  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:59:16 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 1199  total_loss: 0.5693  loss_cls: 0.1012  loss_box_reg: 0.2385  loss_mask: 0.1326  loss_rpn_cls: 0.007647  loss_rpn_loc: 0.05915  time: 0.8259  data_time: 0.1229  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:59:32 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 1219  total_loss: 0.5916  loss_cls: 0.1072  loss_box_reg: 0.2672  loss_mask: 0.1381  loss_rpn_cls: 0.008655  loss_rpn_loc: 0.05471  time: 0.8254  data_time: 0.1238  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 00:59:48 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 1239  total_loss: 0.5933  loss_cls: 0.1061  loss_box_reg: 0.2687  loss_mask: 0.1447  loss_rpn_cls: 0.008301  loss_rpn_loc: 0.06783  time: 0.8253  data_time: 0.1331  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:00:04 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 1259  total_loss: 0.5335  loss_cls: 0.09119  loss_box_reg: 0.2515  loss_mask: 0.1318  loss_rpn_cls: 0.01032  loss_rpn_loc: 0.06299  time: 0.8253  data_time: 0.1523  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:00:20 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 1279  total_loss: 0.6178  loss_cls: 0.09228  loss_box_reg: 0.2758  loss_mask: 0.1623  loss_rpn_cls: 0.008964  loss_rpn_loc: 0.0615  time: 0.8247  data_time: 0.1247  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:00:37 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 1299  total_loss: 0.5882  loss_cls: 0.1047  loss_box_reg: 0.2642  loss_mask: 0.1405  loss_rpn_cls: 0.008127  loss_rpn_loc: 0.07012  time: 0.8250  data_time: 0.1460  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:00:54 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 1319  total_loss: 0.5559  loss_cls: 0.09189  loss_box_reg: 0.2412  loss_mask: 0.1316  loss_rpn_cls: 0.008674  loss_rpn_loc: 0.06285  time: 0.8253  data_time: 0.1506  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 01:01:10 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 1339  total_loss: 0.5635  loss_cls: 0.09412  loss_box_reg: 0.2602  loss_mask: 0.1425  loss_rpn_cls: 0.009529  loss_rpn_loc: 0.06375  time: 0.8252  data_time: 0.1479  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:01:27 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 1359  total_loss: 0.63  loss_cls: 0.1015  loss_box_reg: 0.2754  loss_mask: 0.1414  loss_rpn_cls: 0.008784  loss_rpn_loc: 0.05601  time: 0.8256  data_time: 0.1455  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:01:44 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 1379  total_loss: 0.5572  loss_cls: 0.08908  loss_box_reg: 0.2347  loss_mask: 0.1421  loss_rpn_cls: 0.006229  loss_rpn_loc: 0.06922  time: 0.8253  data_time: 0.1447  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:02:00 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 1399  total_loss: 0.5973  loss_cls: 0.117  loss_box_reg: 0.2497  loss_mask: 0.1398  loss_rpn_cls: 0.00803  loss_rpn_loc: 0.06924  time: 0.8254  data_time: 0.1483  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:02:17 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 1419  total_loss: 0.5407  loss_cls: 0.1021  loss_box_reg: 0.2357  loss_mask: 0.1399  loss_rpn_cls: 0.006827  loss_rpn_loc: 0.0546  time: 0.8255  data_time: 0.1392  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:02:33 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 1439  total_loss: 0.6089  loss_cls: 0.08883  loss_box_reg: 0.2674  loss_mask: 0.1541  loss_rpn_cls: 0.0077  loss_rpn_loc: 0.05758  time: 0.8253  data_time: 0.1316  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:02:50 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 1459  total_loss: 0.5276  loss_cls: 0.09383  loss_box_reg: 0.246  loss_mask: 0.1307  loss_rpn_cls: 0.008829  loss_rpn_loc: 0.05853  time: 0.8253  data_time: 0.1538  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:03:07 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 1479  total_loss: 0.5929  loss_cls: 0.1031  loss_box_reg: 0.2392  loss_mask: 0.1537  loss_rpn_cls: 0.00908  loss_rpn_loc: 0.06239  time: 0.8255  data_time: 0.1562  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:03:24 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.5553  loss_cls: 0.08356  loss_box_reg: 0.2411  loss_mask: 0.1304  loss_rpn_cls: 0.008071  loss_rpn_loc: 0.0576  time: 0.8250  data_time: 0.1348  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:03:24 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:20:35 (0.8250 s / it)\n",
      "\u001b[32m[03/05 01:03:24 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:38 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 01:03:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 01:03:25 d2.data.datasets.coco]: \u001b[0mLoaded 170 images in COCO format from /host/mic21-framework/server/uploads/motorcycle_police_gt.json\n",
      "motorcycle_police\n",
      "\u001b[32m[03/05 01:03:25 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=12, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 01:03:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 01:03:25 d2.data.datasets.coco]: \u001b[0mLoaded 170 images in COCO format from /host/mic21-framework/server/uploads/motorcycle_police_gt.json\n",
      "\u001b[32m[03/05 01:03:25 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 169 images left.\n",
      "\u001b[32m[03/05 01:03:25 d2.data.build]: \u001b[0mDistribution of instances among all 11 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      man      | 141          |     woman     | 69           |      car      | 158          |\n",
      "|   duty boot   | 165          | reflective .. | 71           | uniform shirt | 99           |\n",
      "| uniform pants | 137          | police helmet | 222          | police moto.. | 189          |\n",
      "| police moto.. | 237          | motorcycle .. | 225          |               |              |\n",
      "|     total     | 1713         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 01:03:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 01:03:25 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 01:03:25 d2.data.common]: \u001b[0mSerializing 169 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 01:03:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.38 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (44, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (44,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (11, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 01:03:26 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 01:03:42 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 19  total_loss: 2.853  loss_cls: 1.11  loss_box_reg: 0.8234  loss_mask: 0.6493  loss_rpn_cls: 0.1432  loss_rpn_loc: 0.08314  time: 0.8009  data_time: 0.1666  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:03:59 d2.utils.events]: \u001b[0m eta: 0:20:21  iter: 39  total_loss: 2.363  loss_cls: 0.8191  loss_box_reg: 0.8554  loss_mask: 0.562  loss_rpn_cls: 0.08014  loss_rpn_loc: 0.06677  time: 0.8232  data_time: 0.1688  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:04:15 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 59  total_loss: 2.308  loss_cls: 0.794  loss_box_reg: 0.8432  loss_mask: 0.4885  loss_rpn_cls: 0.05475  loss_rpn_loc: 0.08368  time: 0.8258  data_time: 0.1680  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:04:33 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 79  total_loss: 1.957  loss_cls: 0.6215  loss_box_reg: 0.7944  loss_mask: 0.4068  loss_rpn_cls: 0.05179  loss_rpn_loc: 0.06793  time: 0.8333  data_time: 0.1742  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:04:50 d2.utils.events]: \u001b[0m eta: 0:19:40  iter: 99  total_loss: 1.672  loss_cls: 0.4805  loss_box_reg: 0.7016  loss_mask: 0.3208  loss_rpn_cls: 0.04188  loss_rpn_loc: 0.06664  time: 0.8389  data_time: 0.1739  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:05:06 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 119  total_loss: 1.684  loss_cls: 0.4998  loss_box_reg: 0.7296  loss_mask: 0.3312  loss_rpn_cls: 0.04066  loss_rpn_loc: 0.06933  time: 0.8381  data_time: 0.1616  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:05:24 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 139  total_loss: 1.545  loss_cls: 0.4507  loss_box_reg: 0.6548  loss_mask: 0.2926  loss_rpn_cls: 0.03587  loss_rpn_loc: 0.05426  time: 0.8425  data_time: 0.1860  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:05:40 d2.utils.events]: \u001b[0m eta: 0:18:47  iter: 159  total_loss: 1.492  loss_cls: 0.3956  loss_box_reg: 0.6532  loss_mask: 0.2816  loss_rpn_cls: 0.05154  loss_rpn_loc: 0.07172  time: 0.8376  data_time: 0.1566  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:05:57 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 179  total_loss: 1.417  loss_cls: 0.406  loss_box_reg: 0.667  loss_mask: 0.2505  loss_rpn_cls: 0.03303  loss_rpn_loc: 0.0517  time: 0.8372  data_time: 0.1758  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:06:13 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 199  total_loss: 1.339  loss_cls: 0.3802  loss_box_reg: 0.6092  loss_mask: 0.2548  loss_rpn_cls: 0.03889  loss_rpn_loc: 0.05738  time: 0.8349  data_time: 0.1702  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:06:29 d2.utils.events]: \u001b[0m eta: 0:17:51  iter: 219  total_loss: 1.264  loss_cls: 0.3819  loss_box_reg: 0.5363  loss_mask: 0.2538  loss_rpn_cls: 0.02953  loss_rpn_loc: 0.06504  time: 0.8330  data_time: 0.1696  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:06:47 d2.utils.events]: \u001b[0m eta: 0:17:32  iter: 239  total_loss: 1.256  loss_cls: 0.3897  loss_box_reg: 0.5578  loss_mask: 0.2543  loss_rpn_cls: 0.02769  loss_rpn_loc: 0.05679  time: 0.8359  data_time: 0.1686  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:07:03 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 259  total_loss: 1.301  loss_cls: 0.3248  loss_box_reg: 0.5776  loss_mask: 0.28  loss_rpn_cls: 0.0324  loss_rpn_loc: 0.0611  time: 0.8346  data_time: 0.1550  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:07:19 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 279  total_loss: 1.183  loss_cls: 0.3447  loss_box_reg: 0.5206  loss_mask: 0.232  loss_rpn_cls: 0.03085  loss_rpn_loc: 0.05338  time: 0.8323  data_time: 0.1662  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:07:36 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 299  total_loss: 1.192  loss_cls: 0.3436  loss_box_reg: 0.5269  loss_mask: 0.2266  loss_rpn_cls: 0.02515  loss_rpn_loc: 0.05931  time: 0.8339  data_time: 0.1558  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:07:53 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 319  total_loss: 1.269  loss_cls: 0.3733  loss_box_reg: 0.534  loss_mask: 0.259  loss_rpn_cls: 0.02799  loss_rpn_loc: 0.05861  time: 0.8345  data_time: 0.1542  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:08:09 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 339  total_loss: 1.15  loss_cls: 0.3275  loss_box_reg: 0.5262  loss_mask: 0.2391  loss_rpn_cls: 0.02964  loss_rpn_loc: 0.05522  time: 0.8334  data_time: 0.1606  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:08:26 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 359  total_loss: 1.173  loss_cls: 0.3487  loss_box_reg: 0.5074  loss_mask: 0.2377  loss_rpn_cls: 0.03079  loss_rpn_loc: 0.06653  time: 0.8340  data_time: 0.1807  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:08:43 d2.utils.events]: \u001b[0m eta: 0:15:31  iter: 379  total_loss: 1.132  loss_cls: 0.3293  loss_box_reg: 0.4698  loss_mask: 0.2273  loss_rpn_cls: 0.02271  loss_rpn_loc: 0.0521  time: 0.8334  data_time: 0.1583  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:09:00 d2.utils.events]: \u001b[0m eta: 0:15:16  iter: 399  total_loss: 1.104  loss_cls: 0.3044  loss_box_reg: 0.4824  loss_mask: 0.2211  loss_rpn_cls: 0.02258  loss_rpn_loc: 0.05081  time: 0.8345  data_time: 0.1681  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:09:17 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 419  total_loss: 1.126  loss_cls: 0.2768  loss_box_reg: 0.4952  loss_mask: 0.2371  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.06279  time: 0.8349  data_time: 0.1812  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:09:33 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 439  total_loss: 1.086  loss_cls: 0.3047  loss_box_reg: 0.4563  loss_mask: 0.229  loss_rpn_cls: 0.01735  loss_rpn_loc: 0.04606  time: 0.8344  data_time: 0.1596  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:09:50 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 459  total_loss: 1.071  loss_cls: 0.3069  loss_box_reg: 0.4464  loss_mask: 0.2194  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.05209  time: 0.8341  data_time: 0.1746  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:10:07 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 479  total_loss: 1.163  loss_cls: 0.3072  loss_box_reg: 0.4831  loss_mask: 0.2254  loss_rpn_cls: 0.02727  loss_rpn_loc: 0.07013  time: 0.8355  data_time: 0.2194  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:10:24 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 499  total_loss: 0.9746  loss_cls: 0.2827  loss_box_reg: 0.4265  loss_mask: 0.2248  loss_rpn_cls: 0.02373  loss_rpn_loc: 0.05363  time: 0.8347  data_time: 0.1581  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:10:40 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 519  total_loss: 1.104  loss_cls: 0.306  loss_box_reg: 0.4998  loss_mask: 0.2451  loss_rpn_cls: 0.02233  loss_rpn_loc: 0.05524  time: 0.8348  data_time: 0.1749  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:10:57 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 539  total_loss: 1.038  loss_cls: 0.301  loss_box_reg: 0.4572  loss_mask: 0.2184  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.05511  time: 0.8340  data_time: 0.1702  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:11:13 d2.utils.events]: \u001b[0m eta: 0:13:05  iter: 559  total_loss: 1.145  loss_cls: 0.3113  loss_box_reg: 0.4781  loss_mask: 0.2032  loss_rpn_cls: 0.02136  loss_rpn_loc: 0.0504  time: 0.8340  data_time: 0.1684  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:11:30 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 579  total_loss: 1.008  loss_cls: 0.3061  loss_box_reg: 0.4149  loss_mask: 0.2259  loss_rpn_cls: 0.01696  loss_rpn_loc: 0.05038  time: 0.8334  data_time: 0.1509  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:11:46 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 599  total_loss: 0.9866  loss_cls: 0.2543  loss_box_reg: 0.4015  loss_mask: 0.2037  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.04577  time: 0.8329  data_time: 0.1719  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:12:03 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 619  total_loss: 0.9728  loss_cls: 0.2572  loss_box_reg: 0.4102  loss_mask: 0.2107  loss_rpn_cls: 0.01756  loss_rpn_loc: 0.04556  time: 0.8339  data_time: 0.1839  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:12:20 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 639  total_loss: 1.053  loss_cls: 0.2996  loss_box_reg: 0.4403  loss_mask: 0.2284  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.05921  time: 0.8342  data_time: 0.1654  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:12:37 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 659  total_loss: 1.014  loss_cls: 0.2742  loss_box_reg: 0.4399  loss_mask: 0.2063  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.04309  time: 0.8338  data_time: 0.1611  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 01:12:53 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 679  total_loss: 0.9128  loss_cls: 0.2274  loss_box_reg: 0.4086  loss_mask: 0.1971  loss_rpn_cls: 0.01806  loss_rpn_loc: 0.05273  time: 0.8338  data_time: 0.1732  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:13:10 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 699  total_loss: 0.9911  loss_cls: 0.2874  loss_box_reg: 0.4454  loss_mask: 0.2295  loss_rpn_cls: 0.01838  loss_rpn_loc: 0.04998  time: 0.8337  data_time: 0.1611  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:13:26 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 719  total_loss: 1.013  loss_cls: 0.2994  loss_box_reg: 0.4267  loss_mask: 0.2118  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.05454  time: 0.8335  data_time: 0.1652  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:13:43 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 739  total_loss: 0.974  loss_cls: 0.2476  loss_box_reg: 0.4301  loss_mask: 0.1981  loss_rpn_cls: 0.01799  loss_rpn_loc: 0.04621  time: 0.8337  data_time: 0.1641  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:14:00 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 759  total_loss: 1.016  loss_cls: 0.2589  loss_box_reg: 0.4038  loss_mask: 0.2191  loss_rpn_cls: 0.01834  loss_rpn_loc: 0.04822  time: 0.8333  data_time: 0.1652  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:14:17 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 779  total_loss: 0.9397  loss_cls: 0.2599  loss_box_reg: 0.4022  loss_mask: 0.2092  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.04888  time: 0.8340  data_time: 0.1794  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:14:33 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 799  total_loss: 0.9302  loss_cls: 0.2486  loss_box_reg: 0.4221  loss_mask: 0.2112  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.05459  time: 0.8338  data_time: 0.1522  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:14:50 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 819  total_loss: 0.9883  loss_cls: 0.2777  loss_box_reg: 0.4058  loss_mask: 0.2082  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.05204  time: 0.8336  data_time: 0.1461  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:15:07 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 839  total_loss: 0.9449  loss_cls: 0.2407  loss_box_reg: 0.3992  loss_mask: 0.2021  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.04491  time: 0.8344  data_time: 0.1758  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:15:24 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 859  total_loss: 0.9213  loss_cls: 0.229  loss_box_reg: 0.416  loss_mask: 0.1963  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.05383  time: 0.8346  data_time: 0.1606  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:15:40 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 879  total_loss: 0.9631  loss_cls: 0.2623  loss_box_reg: 0.4215  loss_mask: 0.2217  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.04105  time: 0.8339  data_time: 0.1417  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:15:57 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 899  total_loss: 0.8583  loss_cls: 0.2359  loss_box_reg: 0.3696  loss_mask: 0.1808  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.04628  time: 0.8335  data_time: 0.1411  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:16:13 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 919  total_loss: 0.9812  loss_cls: 0.2633  loss_box_reg: 0.4267  loss_mask: 0.2024  loss_rpn_cls: 0.01943  loss_rpn_loc: 0.05298  time: 0.8336  data_time: 0.1539  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:16:30 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 939  total_loss: 0.9796  loss_cls: 0.2479  loss_box_reg: 0.4079  loss_mask: 0.1977  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.05045  time: 0.8332  data_time: 0.1517  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:16:47 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 959  total_loss: 0.8795  loss_cls: 0.2361  loss_box_reg: 0.3737  loss_mask: 0.1999  loss_rpn_cls: 0.01422  loss_rpn_loc: 0.05034  time: 0.8336  data_time: 0.1693  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:17:02 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 979  total_loss: 0.8117  loss_cls: 0.177  loss_box_reg: 0.3796  loss_mask: 0.1868  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.0434  time: 0.8323  data_time: 0.1372  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:17:18 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 999  total_loss: 0.8591  loss_cls: 0.2484  loss_box_reg: 0.361  loss_mask: 0.1973  loss_rpn_cls: 0.01029  loss_rpn_loc: 0.04255  time: 0.8319  data_time: 0.1673  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:17:34 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1019  total_loss: 0.9266  loss_cls: 0.2528  loss_box_reg: 0.3843  loss_mask: 0.1934  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.04868  time: 0.8312  data_time: 0.1509  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:17:51 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 1039  total_loss: 0.7969  loss_cls: 0.221  loss_box_reg: 0.3513  loss_mask: 0.1923  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.04082  time: 0.8308  data_time: 0.1530  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:18:06 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 1059  total_loss: 0.8183  loss_cls: 0.2422  loss_box_reg: 0.3628  loss_mask: 0.1846  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.04121  time: 0.8301  data_time: 0.1489  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:18:23 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1079  total_loss: 0.855  loss_cls: 0.2528  loss_box_reg: 0.3487  loss_mask: 0.1873  loss_rpn_cls: 0.009126  loss_rpn_loc: 0.04829  time: 0.8298  data_time: 0.1577  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:18:39 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1099  total_loss: 0.7719  loss_cls: 0.1863  loss_box_reg: 0.3417  loss_mask: 0.1865  loss_rpn_cls: 0.01349  loss_rpn_loc: 0.03982  time: 0.8299  data_time: 0.1515  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:18:57 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 1119  total_loss: 0.7951  loss_cls: 0.2023  loss_box_reg: 0.3158  loss_mask: 0.1793  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.05506  time: 0.8305  data_time: 0.1816  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:19:13 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 1139  total_loss: 0.7025  loss_cls: 0.1687  loss_box_reg: 0.3125  loss_mask: 0.161  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.04006  time: 0.8303  data_time: 0.1437  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:19:30 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 1159  total_loss: 0.7761  loss_cls: 0.1926  loss_box_reg: 0.346  loss_mask: 0.1941  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.04413  time: 0.8303  data_time: 0.1606  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:19:46 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 1179  total_loss: 0.8023  loss_cls: 0.2225  loss_box_reg: 0.3504  loss_mask: 0.1859  loss_rpn_cls: 0.009392  loss_rpn_loc: 0.03992  time: 0.8301  data_time: 0.1542  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:20:02 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 1199  total_loss: 0.8147  loss_cls: 0.2232  loss_box_reg: 0.3364  loss_mask: 0.1858  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.06104  time: 0.8298  data_time: 0.1640  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:20:19 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 1219  total_loss: 0.7154  loss_cls: 0.1999  loss_box_reg: 0.3082  loss_mask: 0.1837  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.03822  time: 0.8295  data_time: 0.1545  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:20:35 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 1239  total_loss: 0.7727  loss_cls: 0.1807  loss_box_reg: 0.3357  loss_mask: 0.1876  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.04951  time: 0.8294  data_time: 0.1628  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:20:51 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 1259  total_loss: 0.8  loss_cls: 0.2413  loss_box_reg: 0.3095  loss_mask: 0.1793  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.04765  time: 0.8291  data_time: 0.1454  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:21:08 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 1279  total_loss: 0.7563  loss_cls: 0.2094  loss_box_reg: 0.3272  loss_mask: 0.1898  loss_rpn_cls: 0.008473  loss_rpn_loc: 0.03935  time: 0.8293  data_time: 0.1565  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:21:24 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 1299  total_loss: 0.7981  loss_cls: 0.2196  loss_box_reg: 0.3126  loss_mask: 0.1715  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.04724  time: 0.8290  data_time: 0.1527  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:21:41 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 1319  total_loss: 0.8465  loss_cls: 0.2016  loss_box_reg: 0.3188  loss_mask: 0.1817  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.04465  time: 0.8291  data_time: 0.1414  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 01:21:57 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 1339  total_loss: 0.8106  loss_cls: 0.2355  loss_box_reg: 0.346  loss_mask: 0.1992  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.04512  time: 0.8288  data_time: 0.1466  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:22:14 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 1359  total_loss: 0.7959  loss_cls: 0.2359  loss_box_reg: 0.3326  loss_mask: 0.19  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.05075  time: 0.8291  data_time: 0.1783  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:22:31 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 1379  total_loss: 0.782  loss_cls: 0.1931  loss_box_reg: 0.3239  loss_mask: 0.1824  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.04826  time: 0.8289  data_time: 0.1409  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:22:47 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 1399  total_loss: 0.7442  loss_cls: 0.1825  loss_box_reg: 0.3178  loss_mask: 0.1859  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.04459  time: 0.8289  data_time: 0.1459  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:23:03 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 1419  total_loss: 0.8112  loss_cls: 0.2264  loss_box_reg: 0.327  loss_mask: 0.1679  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.05236  time: 0.8286  data_time: 0.1443  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:23:19 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 1439  total_loss: 0.7895  loss_cls: 0.2079  loss_box_reg: 0.3121  loss_mask: 0.192  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.04578  time: 0.8280  data_time: 0.1492  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:23:36 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 1459  total_loss: 0.779  loss_cls: 0.2466  loss_box_reg: 0.292  loss_mask: 0.1779  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.04191  time: 0.8280  data_time: 0.1532  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:23:53 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 1479  total_loss: 0.7162  loss_cls: 0.1775  loss_box_reg: 0.3151  loss_mask: 0.1718  loss_rpn_cls: 0.007822  loss_rpn_loc: 0.03187  time: 0.8285  data_time: 0.1726  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:24:11 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7518  loss_cls: 0.1957  loss_box_reg: 0.3113  loss_mask: 0.1913  loss_rpn_cls: 0.008107  loss_rpn_loc: 0.04819  time: 0.8286  data_time: 0.1752  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:24:11 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:20:41 (0.8286 s / it)\n",
      "\u001b[32m[03/05 01:24:11 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:43 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 01:24:12 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 01:24:12 d2.data.datasets.coco]: \u001b[0mLoaded 224 images in COCO format from /host/mic21-framework/server/uploads/soldier_gt.json\n",
      "soldier\n",
      "\u001b[32m[03/05 01:24:13 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 01:24:13 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 01:24:13 d2.data.datasets.coco]: \u001b[0mLoaded 224 images in COCO format from /host/mic21-framework/server/uploads/soldier_gt.json\n",
      "\u001b[32m[03/05 01:24:13 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 221 images left.\n",
      "\u001b[32m[03/05 01:24:13 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|  category  | #instances   |   category    | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
      "|  hard hat  | 234          |    soldier    | 453          | duty boot  | 294          |\n",
      "|   rifle    | 101          | camouflage .. | 378          |  carbine   | 58           |\n",
      "|            |              |               |              |            |              |\n",
      "|   total    | 1518         |               |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/05 01:24:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 01:24:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 01:24:13 d2.data.common]: \u001b[0mSerializing 221 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 01:24:13 d2.data.common]: \u001b[0mSerialized dataset takes 2.41 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 01:24:13 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 01:24:30 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 19  total_loss: 2.658  loss_cls: 0.926  loss_box_reg: 0.9435  loss_mask: 0.6516  loss_rpn_cls: 0.07081  loss_rpn_loc: 0.05122  time: 0.8301  data_time: 0.1961  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:24:47 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 39  total_loss: 2.132  loss_cls: 0.6612  loss_box_reg: 0.8327  loss_mask: 0.526  loss_rpn_cls: 0.04143  loss_rpn_loc: 0.04279  time: 0.8328  data_time: 0.2013  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:25:04 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 59  total_loss: 1.849  loss_cls: 0.5494  loss_box_reg: 0.7768  loss_mask: 0.3878  loss_rpn_cls: 0.03041  loss_rpn_loc: 0.05151  time: 0.8426  data_time: 0.1835  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:25:21 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 79  total_loss: 1.6  loss_cls: 0.4498  loss_box_reg: 0.7021  loss_mask: 0.3855  loss_rpn_cls: 0.03125  loss_rpn_loc: 0.04363  time: 0.8456  data_time: 0.1936  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:25:38 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 99  total_loss: 1.463  loss_cls: 0.4016  loss_box_reg: 0.6072  loss_mask: 0.3512  loss_rpn_cls: 0.02991  loss_rpn_loc: 0.05283  time: 0.8495  data_time: 0.2155  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:25:55 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 119  total_loss: 1.482  loss_cls: 0.3888  loss_box_reg: 0.5812  loss_mask: 0.3406  loss_rpn_cls: 0.03562  loss_rpn_loc: 0.06007  time: 0.8488  data_time: 0.1849  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:26:12 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 139  total_loss: 1.397  loss_cls: 0.3789  loss_box_reg: 0.583  loss_mask: 0.3207  loss_rpn_cls: 0.02184  loss_rpn_loc: 0.05152  time: 0.8430  data_time: 0.1696  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:26:28 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 159  total_loss: 1.401  loss_cls: 0.3555  loss_box_reg: 0.5863  loss_mask: 0.3397  loss_rpn_cls: 0.02702  loss_rpn_loc: 0.04237  time: 0.8403  data_time: 0.1702  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:26:45 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 179  total_loss: 1.361  loss_cls: 0.3615  loss_box_reg: 0.5618  loss_mask: 0.2843  loss_rpn_cls: 0.02305  loss_rpn_loc: 0.04218  time: 0.8391  data_time: 0.1815  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:27:02 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 199  total_loss: 1.225  loss_cls: 0.3232  loss_box_reg: 0.5255  loss_mask: 0.2913  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.04916  time: 0.8429  data_time: 0.2222  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:27:19 d2.utils.events]: \u001b[0m eta: 0:18:04  iter: 219  total_loss: 1.244  loss_cls: 0.3401  loss_box_reg: 0.5392  loss_mask: 0.2984  loss_rpn_cls: 0.02538  loss_rpn_loc: 0.04604  time: 0.8441  data_time: 0.1998  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:27:36 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 239  total_loss: 1.144  loss_cls: 0.2957  loss_box_reg: 0.492  loss_mask: 0.3002  loss_rpn_cls: 0.01806  loss_rpn_loc: 0.0386  time: 0.8452  data_time: 0.2238  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:27:53 d2.utils.events]: \u001b[0m eta: 0:17:32  iter: 259  total_loss: 1.116  loss_cls: 0.2814  loss_box_reg: 0.4891  loss_mask: 0.2471  loss_rpn_cls: 0.02482  loss_rpn_loc: 0.04097  time: 0.8437  data_time: 0.1750  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:28:10 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 279  total_loss: 1.051  loss_cls: 0.2805  loss_box_reg: 0.4637  loss_mask: 0.2579  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.04694  time: 0.8441  data_time: 0.1967  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:28:28 d2.utils.events]: \u001b[0m eta: 0:17:03  iter: 299  total_loss: 1.036  loss_cls: 0.2663  loss_box_reg: 0.4537  loss_mask: 0.2568  loss_rpn_cls: 0.01527  loss_rpn_loc: 0.03932  time: 0.8477  data_time: 0.2432  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:28:45 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 319  total_loss: 1.08  loss_cls: 0.2928  loss_box_reg: 0.4338  loss_mask: 0.2666  loss_rpn_cls: 0.0195  loss_rpn_loc: 0.05273  time: 0.8481  data_time: 0.1987  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:29:02 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 339  total_loss: 1.078  loss_cls: 0.2556  loss_box_reg: 0.4446  loss_mask: 0.2781  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.04266  time: 0.8472  data_time: 0.1754  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:29:19 d2.utils.events]: \u001b[0m eta: 0:16:06  iter: 359  total_loss: 1.007  loss_cls: 0.2438  loss_box_reg: 0.4429  loss_mask: 0.2503  loss_rpn_cls: 0.01689  loss_rpn_loc: 0.05201  time: 0.8473  data_time: 0.1878  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:29:36 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 379  total_loss: 1.125  loss_cls: 0.3322  loss_box_reg: 0.4523  loss_mask: 0.2781  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.04218  time: 0.8489  data_time: 0.2247  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:29:53 d2.utils.events]: \u001b[0m eta: 0:15:34  iter: 399  total_loss: 0.9832  loss_cls: 0.2513  loss_box_reg: 0.4471  loss_mask: 0.251  loss_rpn_cls: 0.01498  loss_rpn_loc: 0.03637  time: 0.8484  data_time: 0.2141  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:30:10 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 419  total_loss: 1.03  loss_cls: 0.2413  loss_box_reg: 0.4409  loss_mask: 0.2766  loss_rpn_cls: 0.01692  loss_rpn_loc: 0.05283  time: 0.8489  data_time: 0.1993  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:30:27 d2.utils.events]: \u001b[0m eta: 0:14:58  iter: 439  total_loss: 1.052  loss_cls: 0.2886  loss_box_reg: 0.4463  loss_mask: 0.2482  loss_rpn_cls: 0.0203  loss_rpn_loc: 0.04025  time: 0.8486  data_time: 0.1981  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:30:44 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 459  total_loss: 0.9878  loss_cls: 0.2643  loss_box_reg: 0.4419  loss_mask: 0.2495  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.03904  time: 0.8485  data_time: 0.1893  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:31:01 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 479  total_loss: 0.9955  loss_cls: 0.2645  loss_box_reg: 0.4401  loss_mask: 0.2433  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.03325  time: 0.8480  data_time: 0.1829  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:31:18 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 499  total_loss: 0.9774  loss_cls: 0.2668  loss_box_reg: 0.3988  loss_mask: 0.2173  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.04326  time: 0.8494  data_time: 0.2103  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:31:35 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 519  total_loss: 1.031  loss_cls: 0.2499  loss_box_reg: 0.4229  loss_mask: 0.2512  loss_rpn_cls: 0.01666  loss_rpn_loc: 0.03958  time: 0.8487  data_time: 0.1725  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:31:53 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 539  total_loss: 0.9677  loss_cls: 0.2385  loss_box_reg: 0.4189  loss_mask: 0.2527  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.04212  time: 0.8497  data_time: 0.2196  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:32:10 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 559  total_loss: 0.9321  loss_cls: 0.2238  loss_box_reg: 0.3894  loss_mask: 0.2419  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.04885  time: 0.8507  data_time: 0.2254  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:32:27 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 579  total_loss: 0.9544  loss_cls: 0.2017  loss_box_reg: 0.4104  loss_mask: 0.2233  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.04273  time: 0.8502  data_time: 0.2014  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:32:44 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 599  total_loss: 0.964  loss_cls: 0.233  loss_box_reg: 0.4094  loss_mask: 0.249  loss_rpn_cls: 0.01612  loss_rpn_loc: 0.04529  time: 0.8498  data_time: 0.2084  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:33:01 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 619  total_loss: 0.8784  loss_cls: 0.2431  loss_box_reg: 0.3523  loss_mask: 0.235  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.03535  time: 0.8500  data_time: 0.2148  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:33:18 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 639  total_loss: 0.9125  loss_cls: 0.2537  loss_box_reg: 0.3836  loss_mask: 0.2415  loss_rpn_cls: 0.01003  loss_rpn_loc: 0.03579  time: 0.8506  data_time: 0.2118  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:33:35 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 659  total_loss: 1.015  loss_cls: 0.2543  loss_box_reg: 0.4029  loss_mask: 0.2572  loss_rpn_cls: 0.0143  loss_rpn_loc: 0.04899  time: 0.8501  data_time: 0.1914  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 01:33:53 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 679  total_loss: 0.9338  loss_cls: 0.2525  loss_box_reg: 0.3731  loss_mask: 0.2362  loss_rpn_cls: 0.00784  loss_rpn_loc: 0.03794  time: 0.8510  data_time: 0.2197  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:34:10 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 699  total_loss: 0.8827  loss_cls: 0.2071  loss_box_reg: 0.3694  loss_mask: 0.2277  loss_rpn_cls: 0.008211  loss_rpn_loc: 0.04814  time: 0.8517  data_time: 0.2020  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:34:27 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 719  total_loss: 0.8505  loss_cls: 0.227  loss_box_reg: 0.3667  loss_mask: 0.2231  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.03807  time: 0.8511  data_time: 0.2027  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:34:44 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 739  total_loss: 0.918  loss_cls: 0.1977  loss_box_reg: 0.3915  loss_mask: 0.2406  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.04501  time: 0.8510  data_time: 0.1870  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:35:00 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 759  total_loss: 0.9351  loss_cls: 0.2545  loss_box_reg: 0.369  loss_mask: 0.223  loss_rpn_cls: 0.009408  loss_rpn_loc: 0.04372  time: 0.8502  data_time: 0.1659  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:35:18 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 779  total_loss: 0.8947  loss_cls: 0.2123  loss_box_reg: 0.3804  loss_mask: 0.2122  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.0413  time: 0.8508  data_time: 0.2005  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:35:35 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 799  total_loss: 0.8305  loss_cls: 0.2298  loss_box_reg: 0.3517  loss_mask: 0.2198  loss_rpn_cls: 0.01062  loss_rpn_loc: 0.04352  time: 0.8512  data_time: 0.2066  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:35:52 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 819  total_loss: 0.8847  loss_cls: 0.2099  loss_box_reg: 0.3653  loss_mask: 0.2288  loss_rpn_cls: 0.008634  loss_rpn_loc: 0.04378  time: 0.8509  data_time: 0.1868  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:36:08 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 839  total_loss: 0.941  loss_cls: 0.2187  loss_box_reg: 0.3564  loss_mask: 0.2424  loss_rpn_cls: 0.0099  loss_rpn_loc: 0.03485  time: 0.8506  data_time: 0.1789  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:36:25 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 859  total_loss: 0.8829  loss_cls: 0.2207  loss_box_reg: 0.3847  loss_mask: 0.2341  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.05112  time: 0.8502  data_time: 0.1870  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:36:42 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 879  total_loss: 0.8899  loss_cls: 0.1964  loss_box_reg: 0.3847  loss_mask: 0.2215  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.03973  time: 0.8504  data_time: 0.1914  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:37:00 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 899  total_loss: 0.7673  loss_cls: 0.1994  loss_box_reg: 0.3568  loss_mask: 0.2004  loss_rpn_cls: 0.007375  loss_rpn_loc: 0.03342  time: 0.8506  data_time: 0.2117  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:37:17 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 919  total_loss: 0.8164  loss_cls: 0.2025  loss_box_reg: 0.3551  loss_mask: 0.2138  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.03764  time: 0.8512  data_time: 0.2271  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:37:34 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 939  total_loss: 0.881  loss_cls: 0.2191  loss_box_reg: 0.3469  loss_mask: 0.2681  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.04979  time: 0.8508  data_time: 0.1999  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:37:51 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 959  total_loss: 0.7861  loss_cls: 0.1484  loss_box_reg: 0.3375  loss_mask: 0.214  loss_rpn_cls: 0.008277  loss_rpn_loc: 0.04449  time: 0.8512  data_time: 0.2132  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:38:08 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 979  total_loss: 0.8358  loss_cls: 0.2278  loss_box_reg: 0.3359  loss_mask: 0.2083  loss_rpn_cls: 0.009483  loss_rpn_loc: 0.03718  time: 0.8506  data_time: 0.1747  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:38:25 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 999  total_loss: 0.8044  loss_cls: 0.216  loss_box_reg: 0.3293  loss_mask: 0.2268  loss_rpn_cls: 0.008864  loss_rpn_loc: 0.03167  time: 0.8514  data_time: 0.2419  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:38:42 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 1019  total_loss: 0.9207  loss_cls: 0.2242  loss_box_reg: 0.3882  loss_mask: 0.2106  loss_rpn_cls: 0.009404  loss_rpn_loc: 0.03088  time: 0.8512  data_time: 0.1715  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:39:00 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 1039  total_loss: 0.8356  loss_cls: 0.2146  loss_box_reg: 0.3402  loss_mask: 0.222  loss_rpn_cls: 0.008655  loss_rpn_loc: 0.04374  time: 0.8517  data_time: 0.2321  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:39:17 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 1059  total_loss: 0.7804  loss_cls: 0.1973  loss_box_reg: 0.325  loss_mask: 0.1969  loss_rpn_cls: 0.007152  loss_rpn_loc: 0.03402  time: 0.8515  data_time: 0.1812  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:39:34 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 1079  total_loss: 0.7442  loss_cls: 0.1823  loss_box_reg: 0.2905  loss_mask: 0.2038  loss_rpn_cls: 0.006426  loss_rpn_loc: 0.03836  time: 0.8514  data_time: 0.1989  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:39:50 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 1099  total_loss: 0.7723  loss_cls: 0.2189  loss_box_reg: 0.3404  loss_mask: 0.2141  loss_rpn_cls: 0.007806  loss_rpn_loc: 0.03937  time: 0.8512  data_time: 0.1903  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:40:08 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 1119  total_loss: 0.7476  loss_cls: 0.1908  loss_box_reg: 0.3026  loss_mask: 0.1988  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.04242  time: 0.8513  data_time: 0.1969  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:40:24 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 1139  total_loss: 0.8243  loss_cls: 0.2034  loss_box_reg: 0.3297  loss_mask: 0.2102  loss_rpn_cls: 0.009692  loss_rpn_loc: 0.04764  time: 0.8507  data_time: 0.1756  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:40:41 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 1159  total_loss: 0.7679  loss_cls: 0.1885  loss_box_reg: 0.298  loss_mask: 0.2061  loss_rpn_cls: 0.007985  loss_rpn_loc: 0.03898  time: 0.8507  data_time: 0.1947  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:40:59 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1179  total_loss: 0.8116  loss_cls: 0.1985  loss_box_reg: 0.3122  loss_mask: 0.2261  loss_rpn_cls: 0.008623  loss_rpn_loc: 0.04354  time: 0.8511  data_time: 0.2187  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:41:16 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 1199  total_loss: 0.7058  loss_cls: 0.1778  loss_box_reg: 0.2892  loss_mask: 0.2053  loss_rpn_cls: 0.00681  loss_rpn_loc: 0.04008  time: 0.8511  data_time: 0.1942  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:41:32 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 1219  total_loss: 0.7904  loss_cls: 0.223  loss_box_reg: 0.3044  loss_mask: 0.2089  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.03789  time: 0.8508  data_time: 0.1999  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:41:48 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 1239  total_loss: 0.7293  loss_cls: 0.1533  loss_box_reg: 0.2769  loss_mask: 0.2192  loss_rpn_cls: 0.008898  loss_rpn_loc: 0.04068  time: 0.8501  data_time: 0.1616  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:42:05 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 1259  total_loss: 0.7265  loss_cls: 0.1707  loss_box_reg: 0.278  loss_mask: 0.2036  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.03632  time: 0.8499  data_time: 0.1955  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:42:21 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 1279  total_loss: 0.7111  loss_cls: 0.1686  loss_box_reg: 0.3  loss_mask: 0.2015  loss_rpn_cls: 0.007182  loss_rpn_loc: 0.03163  time: 0.8494  data_time: 0.2000  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:42:38 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 1299  total_loss: 0.7982  loss_cls: 0.1829  loss_box_reg: 0.2973  loss_mask: 0.2166  loss_rpn_cls: 0.007039  loss_rpn_loc: 0.04403  time: 0.8489  data_time: 0.1777  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:42:55 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 1319  total_loss: 0.6845  loss_cls: 0.1576  loss_box_reg: 0.2841  loss_mask: 0.183  loss_rpn_cls: 0.007526  loss_rpn_loc: 0.0398  time: 0.8491  data_time: 0.1935  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 01:43:12 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 1339  total_loss: 0.7641  loss_cls: 0.19  loss_box_reg: 0.3081  loss_mask: 0.1894  loss_rpn_cls: 0.008289  loss_rpn_loc: 0.0292  time: 0.8491  data_time: 0.1860  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:43:28 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 1359  total_loss: 0.7505  loss_cls: 0.1868  loss_box_reg: 0.2979  loss_mask: 0.2013  loss_rpn_cls: 0.007003  loss_rpn_loc: 0.03921  time: 0.8486  data_time: 0.1828  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:43:46 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 1379  total_loss: 0.7912  loss_cls: 0.1794  loss_box_reg: 0.3254  loss_mask: 0.2252  loss_rpn_cls: 0.006799  loss_rpn_loc: 0.0383  time: 0.8487  data_time: 0.2055  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:44:02 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 1399  total_loss: 0.7056  loss_cls: 0.1908  loss_box_reg: 0.3083  loss_mask: 0.1865  loss_rpn_cls: 0.005747  loss_rpn_loc: 0.03559  time: 0.8483  data_time: 0.1849  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 01:44:18 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 1419  total_loss: 0.7266  loss_cls: 0.1763  loss_box_reg: 0.2958  loss_mask: 0.2014  loss_rpn_cls: 0.005963  loss_rpn_loc: 0.03414  time: 0.8478  data_time: 0.1730  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:44:35 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 1439  total_loss: 0.8442  loss_cls: 0.231  loss_box_reg: 0.3569  loss_mask: 0.2142  loss_rpn_cls: 0.009054  loss_rpn_loc: 0.03706  time: 0.8479  data_time: 0.1939  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:44:52 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 1459  total_loss: 0.7324  loss_cls: 0.2018  loss_box_reg: 0.3004  loss_mask: 0.1812  loss_rpn_cls: 0.006943  loss_rpn_loc: 0.02279  time: 0.8480  data_time: 0.1983  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:45:10 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 1479  total_loss: 0.7439  loss_cls: 0.1734  loss_box_reg: 0.3278  loss_mask: 0.2056  loss_rpn_cls: 0.00889  loss_rpn_loc: 0.04393  time: 0.8485  data_time: 0.1876  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:45:29 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7853  loss_cls: 0.1845  loss_box_reg: 0.3034  loss_mask: 0.2012  loss_rpn_cls: 0.01221  loss_rpn_loc: 0.04958  time: 0.8485  data_time: 0.2060  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 01:45:29 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:21:11 (0.8485 s / it)\n",
      "\u001b[32m[03/05 01:45:29 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:13 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 01:45:30 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 01:45:30 d2.data.datasets.coco]: \u001b[0mLoaded 150 images in COCO format from /host/mic21-framework/server/uploads/double-decker_gt.json\n",
      "double-decker\n",
      "\u001b[32m[03/05 01:45:30 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=12, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 01:45:30 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 01:45:30 d2.data.datasets.coco]: \u001b[0mLoaded 150 images in COCO format from /host/mic21-framework/server/uploads/double-decker_gt.json\n",
      "\u001b[32m[03/05 01:45:30 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 150 images left.\n",
      "\u001b[32m[03/05 01:45:30 d2.data.build]: \u001b[0mDistribution of instances among all 11 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      man      | 98           |      car      | 111          |    person     | 64           |\n",
      "|  bus window   | 76           | double-decker | 196          | double-deck.. | 1397         |\n",
      "| double-deck.. | 122          | double-deck.. | 312          | double-deck.. | 293          |\n",
      "| double-deck.. | 371          |     road      | 87           |               |              |\n",
      "|     total     | 3127         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 01:45:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 01:45:30 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 01:45:30 d2.data.common]: \u001b[0mSerializing 150 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 01:45:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.09 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (44, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (44,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (11, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 01:45:31 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 01:45:49 d2.utils.events]: \u001b[0m eta: 0:22:54  iter: 19  total_loss: 3.012  loss_cls: 1.148  loss_box_reg: 0.8749  loss_mask: 0.6391  loss_rpn_cls: 0.1616  loss_rpn_loc: 0.1831  time: 0.8841  data_time: 0.2424  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:46:07 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 39  total_loss: 2.405  loss_cls: 0.881  loss_box_reg: 0.7748  loss_mask: 0.4702  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.1873  time: 0.8912  data_time: 0.2499  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:46:24 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 59  total_loss: 2.128  loss_cls: 0.7837  loss_box_reg: 0.7051  loss_mask: 0.3564  loss_rpn_cls: 0.08967  loss_rpn_loc: 0.1602  time: 0.8859  data_time: 0.2175  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:46:42 d2.utils.events]: \u001b[0m eta: 0:21:03  iter: 79  total_loss: 1.915  loss_cls: 0.6881  loss_box_reg: 0.6778  loss_mask: 0.3022  loss_rpn_cls: 0.0759  loss_rpn_loc: 0.143  time: 0.8848  data_time: 0.2252  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:46:59 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 99  total_loss: 1.765  loss_cls: 0.6266  loss_box_reg: 0.5988  loss_mask: 0.2887  loss_rpn_cls: 0.06406  loss_rpn_loc: 0.152  time: 0.8788  data_time: 0.1942  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:47:17 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 119  total_loss: 1.508  loss_cls: 0.534  loss_box_reg: 0.571  loss_mask: 0.2471  loss_rpn_cls: 0.05939  loss_rpn_loc: 0.1373  time: 0.8832  data_time: 0.2270  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:47:35 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 139  total_loss: 1.499  loss_cls: 0.4894  loss_box_reg: 0.5638  loss_mask: 0.2271  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.1683  time: 0.8847  data_time: 0.2172  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:47:53 d2.utils.events]: \u001b[0m eta: 0:19:54  iter: 159  total_loss: 1.381  loss_cls: 0.4419  loss_box_reg: 0.5013  loss_mask: 0.2155  loss_rpn_cls: 0.0523  loss_rpn_loc: 0.1353  time: 0.8859  data_time: 0.2433  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:48:10 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 179  total_loss: 1.385  loss_cls: 0.4518  loss_box_reg: 0.5167  loss_mask: 0.2568  loss_rpn_cls: 0.04554  loss_rpn_loc: 0.1216  time: 0.8833  data_time: 0.1827  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:48:29 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 199  total_loss: 1.411  loss_cls: 0.4287  loss_box_reg: 0.5374  loss_mask: 0.2265  loss_rpn_cls: 0.05166  loss_rpn_loc: 0.1496  time: 0.8872  data_time: 0.2419  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:48:47 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 219  total_loss: 1.289  loss_cls: 0.3828  loss_box_reg: 0.5145  loss_mask: 0.2  loss_rpn_cls: 0.0468  loss_rpn_loc: 0.1291  time: 0.8880  data_time: 0.2442  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:49:05 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 239  total_loss: 1.381  loss_cls: 0.4338  loss_box_reg: 0.5345  loss_mask: 0.2327  loss_rpn_cls: 0.04707  loss_rpn_loc: 0.1377  time: 0.8903  data_time: 0.2439  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:49:23 d2.utils.events]: \u001b[0m eta: 0:18:31  iter: 259  total_loss: 1.259  loss_cls: 0.4147  loss_box_reg: 0.4804  loss_mask: 0.2017  loss_rpn_cls: 0.04262  loss_rpn_loc: 0.1402  time: 0.8894  data_time: 0.2212  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:49:40 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 279  total_loss: 1.271  loss_cls: 0.3847  loss_box_reg: 0.486  loss_mask: 0.1963  loss_rpn_cls: 0.04131  loss_rpn_loc: 0.1284  time: 0.8894  data_time: 0.2195  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:49:58 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 299  total_loss: 1.228  loss_cls: 0.4072  loss_box_reg: 0.4561  loss_mask: 0.2118  loss_rpn_cls: 0.04564  loss_rpn_loc: 0.1237  time: 0.8901  data_time: 0.2139  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:50:17 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 319  total_loss: 1.226  loss_cls: 0.3593  loss_box_reg: 0.4398  loss_mask: 0.1946  loss_rpn_cls: 0.04426  loss_rpn_loc: 0.1364  time: 0.8917  data_time: 0.2523  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:50:35 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 339  total_loss: 1.24  loss_cls: 0.3468  loss_box_reg: 0.4778  loss_mask: 0.2038  loss_rpn_cls: 0.03753  loss_rpn_loc: 0.119  time: 0.8917  data_time: 0.2308  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:50:53 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 359  total_loss: 1.138  loss_cls: 0.3439  loss_box_reg: 0.4479  loss_mask: 0.1795  loss_rpn_cls: 0.03317  loss_rpn_loc: 0.116  time: 0.8940  data_time: 0.2508  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:51:11 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 379  total_loss: 1.214  loss_cls: 0.3261  loss_box_reg: 0.463  loss_mask: 0.2111  loss_rpn_cls: 0.04047  loss_rpn_loc: 0.1376  time: 0.8946  data_time: 0.2437  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:51:29 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 399  total_loss: 1.162  loss_cls: 0.3697  loss_box_reg: 0.4199  loss_mask: 0.1958  loss_rpn_cls: 0.03413  loss_rpn_loc: 0.1082  time: 0.8948  data_time: 0.2141  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:51:47 d2.utils.events]: \u001b[0m eta: 0:16:06  iter: 419  total_loss: 1.17  loss_cls: 0.3673  loss_box_reg: 0.4548  loss_mask: 0.2129  loss_rpn_cls: 0.03283  loss_rpn_loc: 0.1232  time: 0.8938  data_time: 0.2174  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:52:05 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 439  total_loss: 1.159  loss_cls: 0.3508  loss_box_reg: 0.4343  loss_mask: 0.197  loss_rpn_cls: 0.03253  loss_rpn_loc: 0.1344  time: 0.8942  data_time: 0.2308  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:52:22 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 459  total_loss: 1.133  loss_cls: 0.3559  loss_box_reg: 0.4392  loss_mask: 0.1911  loss_rpn_cls: 0.03484  loss_rpn_loc: 0.1257  time: 0.8932  data_time: 0.2115  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:52:40 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 479  total_loss: 1.117  loss_cls: 0.325  loss_box_reg: 0.4566  loss_mask: 0.1989  loss_rpn_cls: 0.03393  loss_rpn_loc: 0.1211  time: 0.8928  data_time: 0.2197  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:52:59 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 499  total_loss: 1.177  loss_cls: 0.3671  loss_box_reg: 0.4268  loss_mask: 0.1939  loss_rpn_cls: 0.02854  loss_rpn_loc: 0.132  time: 0.8945  data_time: 0.2523  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:53:17 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 519  total_loss: 1.043  loss_cls: 0.2864  loss_box_reg: 0.3823  loss_mask: 0.1717  loss_rpn_cls: 0.02752  loss_rpn_loc: 0.1211  time: 0.8946  data_time: 0.2381  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:53:35 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 539  total_loss: 1.068  loss_cls: 0.3038  loss_box_reg: 0.3932  loss_mask: 0.1817  loss_rpn_cls: 0.03577  loss_rpn_loc: 0.1383  time: 0.8957  data_time: 0.2544  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:53:54 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 559  total_loss: 1.152  loss_cls: 0.3135  loss_box_reg: 0.4384  loss_mask: 0.2063  loss_rpn_cls: 0.02897  loss_rpn_loc: 0.1235  time: 0.8968  data_time: 0.2421  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:54:12 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 579  total_loss: 1.085  loss_cls: 0.3125  loss_box_reg: 0.3842  loss_mask: 0.1885  loss_rpn_cls: 0.02922  loss_rpn_loc: 0.1336  time: 0.8976  data_time: 0.2406  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:54:30 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 599  total_loss: 0.9973  loss_cls: 0.3034  loss_box_reg: 0.3858  loss_mask: 0.1807  loss_rpn_cls: 0.02678  loss_rpn_loc: 0.1089  time: 0.8975  data_time: 0.2391  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:54:49 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 619  total_loss: 1.002  loss_cls: 0.3031  loss_box_reg: 0.3805  loss_mask: 0.1633  loss_rpn_cls: 0.02208  loss_rpn_loc: 0.1285  time: 0.8984  data_time: 0.2583  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:55:07 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 639  total_loss: 0.9896  loss_cls: 0.3096  loss_box_reg: 0.3722  loss_mask: 0.1785  loss_rpn_cls: 0.02853  loss_rpn_loc: 0.1126  time: 0.8995  data_time: 0.2340  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:55:25 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 659  total_loss: 0.9729  loss_cls: 0.2917  loss_box_reg: 0.3634  loss_mask: 0.1518  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.1147  time: 0.8994  data_time: 0.2515  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 01:55:43 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 679  total_loss: 0.9649  loss_cls: 0.2958  loss_box_reg: 0.3867  loss_mask: 0.1698  loss_rpn_cls: 0.02456  loss_rpn_loc: 0.1128  time: 0.8994  data_time: 0.2281  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:56:02 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 699  total_loss: 1.045  loss_cls: 0.3092  loss_box_reg: 0.3921  loss_mask: 0.1738  loss_rpn_cls: 0.0246  loss_rpn_loc: 0.1137  time: 0.9007  data_time: 0.2642  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:56:19 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 719  total_loss: 1.02  loss_cls: 0.3033  loss_box_reg: 0.3911  loss_mask: 0.1822  loss_rpn_cls: 0.0241  loss_rpn_loc: 0.1268  time: 0.8997  data_time: 0.2238  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:56:38 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 739  total_loss: 1.034  loss_cls: 0.313  loss_box_reg: 0.4068  loss_mask: 0.1846  loss_rpn_cls: 0.02441  loss_rpn_loc: 0.1171  time: 0.9005  data_time: 0.2584  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:56:57 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 759  total_loss: 1.01  loss_cls: 0.2622  loss_box_reg: 0.3846  loss_mask: 0.1748  loss_rpn_cls: 0.0262  loss_rpn_loc: 0.1154  time: 0.9012  data_time: 0.2717  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:57:15 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 779  total_loss: 0.9541  loss_cls: 0.2641  loss_box_reg: 0.3584  loss_mask: 0.1738  loss_rpn_cls: 0.02401  loss_rpn_loc: 0.1078  time: 0.9018  data_time: 0.2569  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:57:34 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 799  total_loss: 0.9705  loss_cls: 0.2606  loss_box_reg: 0.3781  loss_mask: 0.1793  loss_rpn_cls: 0.02178  loss_rpn_loc: 0.1109  time: 0.9023  data_time: 0.2339  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:57:52 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 819  total_loss: 1.023  loss_cls: 0.2759  loss_box_reg: 0.3849  loss_mask: 0.1728  loss_rpn_cls: 0.02478  loss_rpn_loc: 0.1238  time: 0.9029  data_time: 0.2552  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:58:11 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 839  total_loss: 0.9132  loss_cls: 0.2663  loss_box_reg: 0.3681  loss_mask: 0.1714  loss_rpn_cls: 0.0209  loss_rpn_loc: 0.1191  time: 0.9034  data_time: 0.2595  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:58:29 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 859  total_loss: 1.067  loss_cls: 0.2836  loss_box_reg: 0.3969  loss_mask: 0.1971  loss_rpn_cls: 0.02218  loss_rpn_loc: 0.1093  time: 0.9040  data_time: 0.2543  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:58:48 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 879  total_loss: 0.96  loss_cls: 0.2685  loss_box_reg: 0.3654  loss_mask: 0.1822  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.1153  time: 0.9048  data_time: 0.2569  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:59:06 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 899  total_loss: 0.9706  loss_cls: 0.3018  loss_box_reg: 0.3974  loss_mask: 0.1616  loss_rpn_cls: 0.02191  loss_rpn_loc: 0.1112  time: 0.9043  data_time: 0.2358  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:59:24 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 919  total_loss: 0.978  loss_cls: 0.2688  loss_box_reg: 0.3582  loss_mask: 0.2041  loss_rpn_cls: 0.02221  loss_rpn_loc: 0.1191  time: 0.9044  data_time: 0.2316  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 01:59:42 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 939  total_loss: 0.9469  loss_cls: 0.2868  loss_box_reg: 0.3417  loss_mask: 0.1967  loss_rpn_cls: 0.0227  loss_rpn_loc: 0.1078  time: 0.9041  data_time: 0.2284  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:00:00 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 959  total_loss: 0.891  loss_cls: 0.2503  loss_box_reg: 0.3598  loss_mask: 0.1665  loss_rpn_cls: 0.01833  loss_rpn_loc: 0.09792  time: 0.9047  data_time: 0.2617  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:00:19 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 979  total_loss: 0.9423  loss_cls: 0.2529  loss_box_reg: 0.3728  loss_mask: 0.1683  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.1262  time: 0.9050  data_time: 0.2291  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:00:37 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 999  total_loss: 0.9257  loss_cls: 0.2419  loss_box_reg: 0.3556  loss_mask: 0.1674  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.09838  time: 0.9055  data_time: 0.2697  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:00:56 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 1019  total_loss: 0.9783  loss_cls: 0.2842  loss_box_reg: 0.3607  loss_mask: 0.211  loss_rpn_cls: 0.01811  loss_rpn_loc: 0.1054  time: 0.9055  data_time: 0.2165  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:01:13 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 1039  total_loss: 0.9134  loss_cls: 0.2861  loss_box_reg: 0.3258  loss_mask: 0.1711  loss_rpn_cls: 0.01902  loss_rpn_loc: 0.108  time: 0.9051  data_time: 0.2469  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:01:31 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1059  total_loss: 0.9058  loss_cls: 0.2531  loss_box_reg: 0.3038  loss_mask: 0.1614  loss_rpn_cls: 0.02382  loss_rpn_loc: 0.1084  time: 0.9050  data_time: 0.2521  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:01:50 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 1079  total_loss: 0.8021  loss_cls: 0.2276  loss_box_reg: 0.2815  loss_mask: 0.1611  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.1059  time: 0.9056  data_time: 0.2512  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:02:09 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 1099  total_loss: 0.8712  loss_cls: 0.2472  loss_box_reg: 0.3117  loss_mask: 0.1517  loss_rpn_cls: 0.01944  loss_rpn_loc: 0.09737  time: 0.9061  data_time: 0.2484  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:02:27 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 1119  total_loss: 0.9203  loss_cls: 0.2538  loss_box_reg: 0.3323  loss_mask: 0.1491  loss_rpn_cls: 0.01979  loss_rpn_loc: 0.107  time: 0.9059  data_time: 0.2316  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:02:45 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 1139  total_loss: 0.8023  loss_cls: 0.2298  loss_box_reg: 0.2974  loss_mask: 0.1657  loss_rpn_cls: 0.01887  loss_rpn_loc: 0.09661  time: 0.9065  data_time: 0.2531  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:03:04 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 1159  total_loss: 0.8331  loss_cls: 0.2296  loss_box_reg: 0.3098  loss_mask: 0.1553  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.1003  time: 0.9066  data_time: 0.2495  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:03:22 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 1179  total_loss: 0.9081  loss_cls: 0.2729  loss_box_reg: 0.3426  loss_mask: 0.1749  loss_rpn_cls: 0.01783  loss_rpn_loc: 0.1049  time: 0.9065  data_time: 0.2410  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:03:39 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1199  total_loss: 0.8683  loss_cls: 0.2655  loss_box_reg: 0.31  loss_mask: 0.168  loss_rpn_cls: 0.01773  loss_rpn_loc: 0.1007  time: 0.9058  data_time: 0.2269  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:03:57 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 1219  total_loss: 0.8075  loss_cls: 0.2186  loss_box_reg: 0.2948  loss_mask: 0.1674  loss_rpn_cls: 0.01734  loss_rpn_loc: 0.09937  time: 0.9059  data_time: 0.2361  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:04:15 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 1239  total_loss: 0.9442  loss_cls: 0.272  loss_box_reg: 0.3527  loss_mask: 0.1796  loss_rpn_cls: 0.01973  loss_rpn_loc: 0.09823  time: 0.9060  data_time: 0.2409  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:04:34 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 1259  total_loss: 0.7975  loss_cls: 0.2374  loss_box_reg: 0.3029  loss_mask: 0.1517  loss_rpn_cls: 0.01961  loss_rpn_loc: 0.1033  time: 0.9061  data_time: 0.2520  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:04:52 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 1279  total_loss: 0.9043  loss_cls: 0.2522  loss_box_reg: 0.3335  loss_mask: 0.1803  loss_rpn_cls: 0.01943  loss_rpn_loc: 0.1063  time: 0.9066  data_time: 0.2605  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:05:10 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 1299  total_loss: 0.8098  loss_cls: 0.2444  loss_box_reg: 0.2914  loss_mask: 0.1534  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.1039  time: 0.9059  data_time: 0.2000  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:05:28 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 1319  total_loss: 0.7898  loss_cls: 0.2442  loss_box_reg: 0.2753  loss_mask: 0.1687  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.1023  time: 0.9056  data_time: 0.2363  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 02:05:45 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 1339  total_loss: 0.8449  loss_cls: 0.2591  loss_box_reg: 0.2908  loss_mask: 0.1613  loss_rpn_cls: 0.02393  loss_rpn_loc: 0.1127  time: 0.9052  data_time: 0.2310  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:06:04 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 1359  total_loss: 0.8927  loss_cls: 0.2413  loss_box_reg: 0.3078  loss_mask: 0.154  loss_rpn_cls: 0.02022  loss_rpn_loc: 0.1027  time: 0.9057  data_time: 0.2471  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:06:22 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 1379  total_loss: 0.8464  loss_cls: 0.2283  loss_box_reg: 0.2895  loss_mask: 0.1636  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.09139  time: 0.9058  data_time: 0.2473  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:06:40 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 1399  total_loss: 0.7991  loss_cls: 0.2425  loss_box_reg: 0.2943  loss_mask: 0.1578  loss_rpn_cls: 0.01583  loss_rpn_loc: 0.0993  time: 0.9055  data_time: 0.2432  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:06:58 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 1419  total_loss: 0.7456  loss_cls: 0.2068  loss_box_reg: 0.2881  loss_mask: 0.1495  loss_rpn_cls: 0.01873  loss_rpn_loc: 0.09972  time: 0.9055  data_time: 0.2389  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:07:16 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 1439  total_loss: 0.9487  loss_cls: 0.276  loss_box_reg: 0.3624  loss_mask: 0.168  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.1025  time: 0.9058  data_time: 0.2450  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:07:35 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 1459  total_loss: 0.8386  loss_cls: 0.2145  loss_box_reg: 0.2824  loss_mask: 0.1468  loss_rpn_cls: 0.01662  loss_rpn_loc: 0.09574  time: 0.9060  data_time: 0.2369  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:07:53 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1479  total_loss: 0.8771  loss_cls: 0.2186  loss_box_reg: 0.3371  loss_mask: 0.1833  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.1077  time: 0.9061  data_time: 0.2286  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:08:12 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7895  loss_cls: 0.2227  loss_box_reg: 0.2888  loss_mask: 0.1474  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.09825  time: 0.9058  data_time: 0.2273  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:08:12 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:22:36 (0.9058 s / it)\n",
      "\u001b[32m[03/05 02:08:13 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:39 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 02:08:13 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 02:08:13 d2.data.datasets.coco]: \u001b[0mLoaded 133 images in COCO format from /host/mic21-framework/server/uploads/bicycle_racing_gt.json\n",
      "bicycle_racing\n",
      "\u001b[32m[03/05 02:08:14 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=10, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=36, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 02:08:14 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 02:08:14 d2.data.datasets.coco]: \u001b[0mLoaded 133 images in COCO format from /host/mic21-framework/server/uploads/bicycle_racing_gt.json\n",
      "\u001b[32m[03/05 02:08:14 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 133 images left.\n",
      "\u001b[32m[03/05 02:08:14 d2.data.build]: \u001b[0mDistribution of instances among all 9 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      man      | 65           |    bicycle    | 234          |    cyclist    | 208          |\n",
      "| bicycle seat  | 73           | bicycle wheel | 323          | bicycle chain | 92           |\n",
      "| bicycle pedal | 188          | cycling jer.. | 97           | cycling tig.. | 87           |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 1367         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 02:08:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 02:08:14 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 02:08:14 d2.data.common]: \u001b[0mSerializing 133 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 02:08:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.53 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (10, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (10,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (36, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (36,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (9, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (9,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 02:08:14 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 02:08:35 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 19  total_loss: 2.656  loss_cls: 1.023  loss_box_reg: 0.8942  loss_mask: 0.635  loss_rpn_cls: 0.118  loss_rpn_loc: 0.08905  time: 1.0014  data_time: 0.3407  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:08:54 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 39  total_loss: 2.175  loss_cls: 0.7078  loss_box_reg: 0.8225  loss_mask: 0.4863  loss_rpn_cls: 0.06679  loss_rpn_loc: 0.07014  time: 0.9792  data_time: 0.3127  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:09:13 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 59  total_loss: 1.881  loss_cls: 0.5733  loss_box_reg: 0.7878  loss_mask: 0.3983  loss_rpn_cls: 0.0539  loss_rpn_loc: 0.06059  time: 0.9715  data_time: 0.3082  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:09:32 d2.utils.events]: \u001b[0m eta: 0:22:41  iter: 79  total_loss: 1.579  loss_cls: 0.4709  loss_box_reg: 0.6188  loss_mask: 0.3576  loss_rpn_cls: 0.04947  loss_rpn_loc: 0.05754  time: 0.9717  data_time: 0.3228  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:09:51 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 99  total_loss: 1.55  loss_cls: 0.463  loss_box_reg: 0.6414  loss_mask: 0.3432  loss_rpn_cls: 0.05288  loss_rpn_loc: 0.07244  time: 0.9673  data_time: 0.3277  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:10:10 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 119  total_loss: 1.37  loss_cls: 0.4381  loss_box_reg: 0.5533  loss_mask: 0.2987  loss_rpn_cls: 0.03548  loss_rpn_loc: 0.05443  time: 0.9650  data_time: 0.3271  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:10:30 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 139  total_loss: 1.327  loss_cls: 0.397  loss_box_reg: 0.5212  loss_mask: 0.2969  loss_rpn_cls: 0.04219  loss_rpn_loc: 0.07337  time: 0.9684  data_time: 0.3208  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:10:49 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 159  total_loss: 1.34  loss_cls: 0.3474  loss_box_reg: 0.5591  loss_mask: 0.2914  loss_rpn_cls: 0.0381  loss_rpn_loc: 0.05897  time: 0.9621  data_time: 0.2993  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:11:08 d2.utils.events]: \u001b[0m eta: 0:20:55  iter: 179  total_loss: 1.303  loss_cls: 0.3629  loss_box_reg: 0.5072  loss_mask: 0.2979  loss_rpn_cls: 0.03948  loss_rpn_loc: 0.0581  time: 0.9600  data_time: 0.3128  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:11:27 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 199  total_loss: 1.29  loss_cls: 0.3992  loss_box_reg: 0.5229  loss_mask: 0.3042  loss_rpn_cls: 0.03729  loss_rpn_loc: 0.062  time: 0.9612  data_time: 0.3051  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:11:47 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 219  total_loss: 1.283  loss_cls: 0.3494  loss_box_reg: 0.5303  loss_mask: 0.2715  loss_rpn_cls: 0.03059  loss_rpn_loc: 0.06259  time: 0.9659  data_time: 0.3409  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:12:06 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 239  total_loss: 1.216  loss_cls: 0.3119  loss_box_reg: 0.5149  loss_mask: 0.2873  loss_rpn_cls: 0.03147  loss_rpn_loc: 0.04997  time: 0.9653  data_time: 0.3065  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:12:25 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 259  total_loss: 1.225  loss_cls: 0.3108  loss_box_reg: 0.5347  loss_mask: 0.2905  loss_rpn_cls: 0.03088  loss_rpn_loc: 0.05938  time: 0.9636  data_time: 0.3234  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:12:45 d2.utils.events]: \u001b[0m eta: 0:19:32  iter: 279  total_loss: 1.255  loss_cls: 0.3387  loss_box_reg: 0.5191  loss_mask: 0.2941  loss_rpn_cls: 0.02581  loss_rpn_loc: 0.05405  time: 0.9634  data_time: 0.3402  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:13:05 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 299  total_loss: 1.212  loss_cls: 0.3314  loss_box_reg: 0.5255  loss_mask: 0.2685  loss_rpn_cls: 0.0293  loss_rpn_loc: 0.05347  time: 0.9657  data_time: 0.3323  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:13:23 d2.utils.events]: \u001b[0m eta: 0:18:57  iter: 319  total_loss: 1.18  loss_cls: 0.3244  loss_box_reg: 0.4937  loss_mask: 0.283  loss_rpn_cls: 0.03043  loss_rpn_loc: 0.05307  time: 0.9638  data_time: 0.3055  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:13:43 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 339  total_loss: 1.149  loss_cls: 0.3086  loss_box_reg: 0.4786  loss_mask: 0.2601  loss_rpn_cls: 0.0222  loss_rpn_loc: 0.04226  time: 0.9648  data_time: 0.3276  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:14:03 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 359  total_loss: 1.167  loss_cls: 0.3089  loss_box_reg: 0.4884  loss_mask: 0.2759  loss_rpn_cls: 0.02156  loss_rpn_loc: 0.05394  time: 0.9661  data_time: 0.3011  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:14:22 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 379  total_loss: 1.165  loss_cls: 0.2734  loss_box_reg: 0.532  loss_mask: 0.2765  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.05861  time: 0.9666  data_time: 0.3296  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:14:42 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 399  total_loss: 1.134  loss_cls: 0.2943  loss_box_reg: 0.501  loss_mask: 0.2567  loss_rpn_cls: 0.02099  loss_rpn_loc: 0.05253  time: 0.9669  data_time: 0.3342  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:15:01 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 419  total_loss: 1.143  loss_cls: 0.2734  loss_box_reg: 0.4935  loss_mask: 0.2744  loss_rpn_cls: 0.02801  loss_rpn_loc: 0.05689  time: 0.9666  data_time: 0.3189  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:15:21 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 439  total_loss: 1.099  loss_cls: 0.2832  loss_box_reg: 0.451  loss_mask: 0.2477  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.04825  time: 0.9682  data_time: 0.3616  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:15:41 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 459  total_loss: 1.155  loss_cls: 0.319  loss_box_reg: 0.468  loss_mask: 0.2577  loss_rpn_cls: 0.02093  loss_rpn_loc: 0.05395  time: 0.9696  data_time: 0.3439  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:16:00 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 479  total_loss: 1.063  loss_cls: 0.2659  loss_box_reg: 0.451  loss_mask: 0.2514  loss_rpn_cls: 0.02183  loss_rpn_loc: 0.04443  time: 0.9695  data_time: 0.3056  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:16:20 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 499  total_loss: 1.09  loss_cls: 0.2677  loss_box_reg: 0.4839  loss_mask: 0.2592  loss_rpn_cls: 0.02318  loss_rpn_loc: 0.06212  time: 0.9696  data_time: 0.3331  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:16:40 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 519  total_loss: 1.092  loss_cls: 0.3037  loss_box_reg: 0.4618  loss_mask: 0.2453  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.04857  time: 0.9714  data_time: 0.3292  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:17:00 d2.utils.events]: \u001b[0m eta: 0:15:39  iter: 539  total_loss: 1.038  loss_cls: 0.2515  loss_box_reg: 0.4361  loss_mask: 0.2275  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.0431  time: 0.9716  data_time: 0.3438  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:17:18 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 559  total_loss: 1.157  loss_cls: 0.2897  loss_box_reg: 0.4406  loss_mask: 0.2639  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.04746  time: 0.9702  data_time: 0.3028  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:17:38 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 579  total_loss: 1.118  loss_cls: 0.2783  loss_box_reg: 0.4747  loss_mask: 0.2576  loss_rpn_cls: 0.01871  loss_rpn_loc: 0.05263  time: 0.9710  data_time: 0.3294  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:17:57 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 599  total_loss: 1.022  loss_cls: 0.2968  loss_box_reg: 0.428  loss_mask: 0.2485  loss_rpn_cls: 0.018  loss_rpn_loc: 0.04509  time: 0.9705  data_time: 0.3175  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:18:17 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 619  total_loss: 1.034  loss_cls: 0.2789  loss_box_reg: 0.3928  loss_mask: 0.2468  loss_rpn_cls: 0.01784  loss_rpn_loc: 0.0468  time: 0.9705  data_time: 0.3194  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:18:37 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 639  total_loss: 1.015  loss_cls: 0.2692  loss_box_reg: 0.4491  loss_mask: 0.231  loss_rpn_cls: 0.01702  loss_rpn_loc: 0.05239  time: 0.9722  data_time: 0.3582  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:18:57 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 659  total_loss: 0.9912  loss_cls: 0.2645  loss_box_reg: 0.4145  loss_mask: 0.2277  loss_rpn_cls: 0.01761  loss_rpn_loc: 0.04729  time: 0.9722  data_time: 0.3063  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 02:19:16 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 679  total_loss: 1.011  loss_cls: 0.2699  loss_box_reg: 0.4428  loss_mask: 0.2364  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.04386  time: 0.9723  data_time: 0.3272  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:19:36 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 699  total_loss: 0.9366  loss_cls: 0.2324  loss_box_reg: 0.4318  loss_mask: 0.2259  loss_rpn_cls: 0.01655  loss_rpn_loc: 0.04207  time: 0.9728  data_time: 0.3155  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:19:55 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 719  total_loss: 0.9855  loss_cls: 0.2598  loss_box_reg: 0.4239  loss_mask: 0.2355  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.04743  time: 0.9719  data_time: 0.3102  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:20:14 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 739  total_loss: 0.9852  loss_cls: 0.2552  loss_box_reg: 0.4145  loss_mask: 0.2194  loss_rpn_cls: 0.01489  loss_rpn_loc: 0.04216  time: 0.9717  data_time: 0.3070  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:20:34 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 759  total_loss: 1.035  loss_cls: 0.2392  loss_box_reg: 0.4507  loss_mask: 0.2378  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.04985  time: 0.9721  data_time: 0.3256  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:20:53 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 779  total_loss: 0.969  loss_cls: 0.2525  loss_box_reg: 0.4318  loss_mask: 0.2388  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.0496  time: 0.9722  data_time: 0.3179  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:21:13 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 799  total_loss: 1.001  loss_cls: 0.2794  loss_box_reg: 0.4397  loss_mask: 0.2356  loss_rpn_cls: 0.013  loss_rpn_loc: 0.04394  time: 0.9719  data_time: 0.3085  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:21:33 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 819  total_loss: 1.016  loss_cls: 0.2492  loss_box_reg: 0.4582  loss_mask: 0.2346  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.04206  time: 0.9725  data_time: 0.3357  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:21:52 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 839  total_loss: 0.9257  loss_cls: 0.2387  loss_box_reg: 0.41  loss_mask: 0.2267  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.04068  time: 0.9719  data_time: 0.3018  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:22:12 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 859  total_loss: 0.9866  loss_cls: 0.2476  loss_box_reg: 0.4143  loss_mask: 0.2238  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.04517  time: 0.9727  data_time: 0.3455  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:22:31 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 879  total_loss: 0.9687  loss_cls: 0.2527  loss_box_reg: 0.4144  loss_mask: 0.2186  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.04562  time: 0.9729  data_time: 0.3089  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:22:50 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 899  total_loss: 0.9216  loss_cls: 0.2314  loss_box_reg: 0.3827  loss_mask: 0.2243  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.0471  time: 0.9724  data_time: 0.2944  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:23:10 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 919  total_loss: 0.9778  loss_cls: 0.2509  loss_box_reg: 0.412  loss_mask: 0.2272  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.04701  time: 0.9729  data_time: 0.3385  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:23:30 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 939  total_loss: 0.9186  loss_cls: 0.202  loss_box_reg: 0.4309  loss_mask: 0.2255  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.04478  time: 0.9732  data_time: 0.3369  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:23:50 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 959  total_loss: 0.8889  loss_cls: 0.2225  loss_box_reg: 0.4205  loss_mask: 0.1998  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.04586  time: 0.9732  data_time: 0.3250  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:24:09 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 979  total_loss: 0.8834  loss_cls: 0.2001  loss_box_reg: 0.3956  loss_mask: 0.213  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.04301  time: 0.9737  data_time: 0.3264  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:24:29 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 999  total_loss: 0.8658  loss_cls: 0.2226  loss_box_reg: 0.3634  loss_mask: 0.2162  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.05389  time: 0.9736  data_time: 0.2961  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:24:48 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 1019  total_loss: 0.9378  loss_cls: 0.2402  loss_box_reg: 0.4148  loss_mask: 0.2096  loss_rpn_cls: 0.009786  loss_rpn_loc: 0.04631  time: 0.9732  data_time: 0.3264  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:25:07 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 1039  total_loss: 0.8008  loss_cls: 0.2195  loss_box_reg: 0.3386  loss_mask: 0.2001  loss_rpn_cls: 0.01024  loss_rpn_loc: 0.03856  time: 0.9732  data_time: 0.3304  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:25:27 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 1059  total_loss: 0.879  loss_cls: 0.2334  loss_box_reg: 0.3781  loss_mask: 0.2046  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.03835  time: 0.9729  data_time: 0.3301  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:25:47 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 1079  total_loss: 0.8357  loss_cls: 0.1981  loss_box_reg: 0.347  loss_mask: 0.209  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.04544  time: 0.9736  data_time: 0.3271  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:26:06 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 1099  total_loss: 0.7826  loss_cls: 0.2115  loss_box_reg: 0.3357  loss_mask: 0.2136  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.04138  time: 0.9733  data_time: 0.3147  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:26:25 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 1119  total_loss: 0.8108  loss_cls: 0.2302  loss_box_reg: 0.3476  loss_mask: 0.2066  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.0438  time: 0.9731  data_time: 0.3170  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:26:44 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 1139  total_loss: 0.8422  loss_cls: 0.1831  loss_box_reg: 0.3693  loss_mask: 0.2316  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.04382  time: 0.9728  data_time: 0.2992  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:27:04 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1159  total_loss: 0.8505  loss_cls: 0.2118  loss_box_reg: 0.3549  loss_mask: 0.2141  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.04056  time: 0.9730  data_time: 0.3038  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:27:24 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 1179  total_loss: 0.8124  loss_cls: 0.2025  loss_box_reg: 0.3473  loss_mask: 0.2008  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.04789  time: 0.9731  data_time: 0.3105  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:27:43 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 1199  total_loss: 0.808  loss_cls: 0.2122  loss_box_reg: 0.3158  loss_mask: 0.2134  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.04052  time: 0.9726  data_time: 0.2929  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:28:03 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 1219  total_loss: 0.8228  loss_cls: 0.2304  loss_box_reg: 0.326  loss_mask: 0.2064  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.04411  time: 0.9732  data_time: 0.3252  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:28:22 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 1239  total_loss: 0.8111  loss_cls: 0.2137  loss_box_reg: 0.3636  loss_mask: 0.2194  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.04314  time: 0.9734  data_time: 0.3187  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:28:42 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 1259  total_loss: 0.8397  loss_cls: 0.2089  loss_box_reg: 0.3549  loss_mask: 0.2153  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.04472  time: 0.9738  data_time: 0.3475  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:29:02 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 1279  total_loss: 0.7987  loss_cls: 0.1923  loss_box_reg: 0.3105  loss_mask: 0.2235  loss_rpn_cls: 0.009477  loss_rpn_loc: 0.04106  time: 0.9737  data_time: 0.2982  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:29:21 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 1299  total_loss: 0.8469  loss_cls: 0.1948  loss_box_reg: 0.3491  loss_mask: 0.1915  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.03888  time: 0.9737  data_time: 0.3302  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:29:40 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 1319  total_loss: 0.7835  loss_cls: 0.1959  loss_box_reg: 0.3317  loss_mask: 0.2151  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.04035  time: 0.9733  data_time: 0.2923  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 02:29:59 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 1339  total_loss: 0.8383  loss_cls: 0.1959  loss_box_reg: 0.3441  loss_mask: 0.2028  loss_rpn_cls: 0.012  loss_rpn_loc: 0.04646  time: 0.9724  data_time: 0.3414  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:30:19 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 1359  total_loss: 0.8417  loss_cls: 0.2424  loss_box_reg: 0.3368  loss_mask: 0.2147  loss_rpn_cls: 0.009566  loss_rpn_loc: 0.0356  time: 0.9729  data_time: 0.3447  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:30:37 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1379  total_loss: 0.8865  loss_cls: 0.2379  loss_box_reg: 0.3672  loss_mask: 0.2166  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.03954  time: 0.9723  data_time: 0.2914  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:30:57 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 1399  total_loss: 0.7861  loss_cls: 0.1933  loss_box_reg: 0.3174  loss_mask: 0.2041  loss_rpn_cls: 0.01178  loss_rpn_loc: 0.03935  time: 0.9722  data_time: 0.3266  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:31:16 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.8155  loss_cls: 0.2333  loss_box_reg: 0.355  loss_mask: 0.2041  loss_rpn_cls: 0.008432  loss_rpn_loc: 0.04775  time: 0.9723  data_time: 0.3300  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:31:36 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.821  loss_cls: 0.2075  loss_box_reg: 0.3377  loss_mask: 0.2038  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.042  time: 0.9728  data_time: 0.3482  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:31:57 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.8491  loss_cls: 0.199  loss_box_reg: 0.3661  loss_mask: 0.2169  loss_rpn_cls: 0.008766  loss_rpn_loc: 0.04346  time: 0.9734  data_time: 0.3546  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:32:16 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.8045  loss_cls: 0.2086  loss_box_reg: 0.3302  loss_mask: 0.2111  loss_rpn_cls: 0.009015  loss_rpn_loc: 0.03807  time: 0.9730  data_time: 0.2981  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:32:37 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.8622  loss_cls: 0.2225  loss_box_reg: 0.3456  loss_mask: 0.2056  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.04625  time: 0.9735  data_time: 0.3423  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:32:37 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:18 (0.9735 s / it)\n",
      "\u001b[32m[03/05 02:32:37 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:20 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 02:32:38 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 02:32:38 d2.data.datasets.coco]: \u001b[0mLoaded 167 images in COCO format from /host/mic21-framework/server/uploads/handball_gt.json\n",
      "handball\n",
      "\u001b[32m[03/05 02:32:39 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=12, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 02:32:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 02:32:39 d2.data.datasets.coco]: \u001b[0mLoaded 167 images in COCO format from /host/mic21-framework/server/uploads/handball_gt.json\n",
      "\u001b[32m[03/05 02:32:39 d2.data.build]: \u001b[0mRemoved 10 images with no usable annotations. 157 images left.\n",
      "\u001b[32m[03/05 02:32:39 d2.data.build]: \u001b[0mDistribution of instances among all 11 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|  race number  | 298          |   knee pad    | 78           | handball shoe | 663          |\n",
      "| handball je.. | 436          | handball goal | 63           | handball sh.. | 351          |\n",
      "| handball co.. | 124          | handball pa.. | 66           |   handball    | 134          |\n",
      "| handball pl.. | 511          | handball sock | 484          |               |              |\n",
      "|     total     | 3208         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 02:32:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 02:32:39 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 02:32:39 d2.data.common]: \u001b[0mSerializing 157 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 02:32:39 d2.data.common]: \u001b[0mSerialized dataset takes 2.24 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (44, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (44,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (11, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 02:32:39 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 02:32:56 d2.utils.events]: \u001b[0m eta: 0:20:36  iter: 19  total_loss: 2.919  loss_cls: 1.106  loss_box_reg: 0.8163  loss_mask: 0.6552  loss_rpn_cls: 0.1311  loss_rpn_loc: 0.1511  time: 0.8337  data_time: 0.2077  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:33:14 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 39  total_loss: 2.492  loss_cls: 0.8994  loss_box_reg: 0.8042  loss_mask: 0.5286  loss_rpn_cls: 0.07403  loss_rpn_loc: 0.1399  time: 0.8516  data_time: 0.1985  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:33:30 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 59  total_loss: 2.16  loss_cls: 0.7436  loss_box_reg: 0.8045  loss_mask: 0.3957  loss_rpn_cls: 0.05668  loss_rpn_loc: 0.1372  time: 0.8456  data_time: 0.1755  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:33:47 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 79  total_loss: 1.876  loss_cls: 0.5879  loss_box_reg: 0.7935  loss_mask: 0.2963  loss_rpn_cls: 0.05133  loss_rpn_loc: 0.1309  time: 0.8413  data_time: 0.1513  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:34:04 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 99  total_loss: 1.744  loss_cls: 0.5389  loss_box_reg: 0.7213  loss_mask: 0.3307  loss_rpn_cls: 0.05019  loss_rpn_loc: 0.1419  time: 0.8385  data_time: 0.1516  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:34:21 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 119  total_loss: 1.606  loss_cls: 0.4641  loss_box_reg: 0.6302  loss_mask: 0.2873  loss_rpn_cls: 0.04407  loss_rpn_loc: 0.1208  time: 0.8409  data_time: 0.1800  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:34:38 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 139  total_loss: 1.469  loss_cls: 0.4198  loss_box_reg: 0.6021  loss_mask: 0.2486  loss_rpn_cls: 0.03778  loss_rpn_loc: 0.1395  time: 0.8440  data_time: 0.1809  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:34:55 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 159  total_loss: 1.346  loss_cls: 0.38  loss_box_reg: 0.5867  loss_mask: 0.2559  loss_rpn_cls: 0.03976  loss_rpn_loc: 0.1362  time: 0.8444  data_time: 0.1808  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:35:12 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 179  total_loss: 1.354  loss_cls: 0.3957  loss_box_reg: 0.542  loss_mask: 0.2411  loss_rpn_cls: 0.03757  loss_rpn_loc: 0.1504  time: 0.8443  data_time: 0.1871  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:35:28 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 199  total_loss: 1.353  loss_cls: 0.4006  loss_box_reg: 0.5756  loss_mask: 0.2428  loss_rpn_cls: 0.03326  loss_rpn_loc: 0.1148  time: 0.8428  data_time: 0.1515  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:35:45 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 219  total_loss: 1.311  loss_cls: 0.3709  loss_box_reg: 0.5374  loss_mask: 0.2431  loss_rpn_cls: 0.03672  loss_rpn_loc: 0.1181  time: 0.8438  data_time: 0.1508  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:36:02 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 239  total_loss: 1.358  loss_cls: 0.366  loss_box_reg: 0.5269  loss_mask: 0.2582  loss_rpn_cls: 0.03665  loss_rpn_loc: 0.1257  time: 0.8435  data_time: 0.1525  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:36:19 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 259  total_loss: 1.188  loss_cls: 0.3264  loss_box_reg: 0.4852  loss_mask: 0.22  loss_rpn_cls: 0.02689  loss_rpn_loc: 0.1326  time: 0.8436  data_time: 0.1687  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:36:36 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 279  total_loss: 1.333  loss_cls: 0.3709  loss_box_reg: 0.5566  loss_mask: 0.2258  loss_rpn_cls: 0.0323  loss_rpn_loc: 0.1138  time: 0.8436  data_time: 0.1532  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:36:54 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 299  total_loss: 1.307  loss_cls: 0.3447  loss_box_reg: 0.563  loss_mask: 0.2371  loss_rpn_cls: 0.02763  loss_rpn_loc: 0.136  time: 0.8486  data_time: 0.2123  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:37:10 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 319  total_loss: 1.156  loss_cls: 0.3244  loss_box_reg: 0.464  loss_mask: 0.215  loss_rpn_cls: 0.02921  loss_rpn_loc: 0.09802  time: 0.8450  data_time: 0.1459  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:37:28 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 339  total_loss: 1.076  loss_cls: 0.3053  loss_box_reg: 0.4676  loss_mask: 0.1889  loss_rpn_cls: 0.02679  loss_rpn_loc: 0.1201  time: 0.8477  data_time: 0.1779  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:37:45 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 359  total_loss: 1.129  loss_cls: 0.3098  loss_box_reg: 0.4382  loss_mask: 0.2027  loss_rpn_cls: 0.02412  loss_rpn_loc: 0.1201  time: 0.8481  data_time: 0.1832  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:38:02 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 379  total_loss: 1.189  loss_cls: 0.3002  loss_box_reg: 0.4844  loss_mask: 0.2156  loss_rpn_cls: 0.02872  loss_rpn_loc: 0.1217  time: 0.8473  data_time: 0.1433  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:38:19 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 399  total_loss: 1.202  loss_cls: 0.3294  loss_box_reg: 0.4727  loss_mask: 0.2241  loss_rpn_cls: 0.0234  loss_rpn_loc: 0.1098  time: 0.8482  data_time: 0.1785  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:38:36 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 419  total_loss: 1.158  loss_cls: 0.3147  loss_box_reg: 0.4561  loss_mask: 0.1917  loss_rpn_cls: 0.02173  loss_rpn_loc: 0.1113  time: 0.8474  data_time: 0.1490  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:38:52 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 439  total_loss: 1.149  loss_cls: 0.311  loss_box_reg: 0.4481  loss_mask: 0.2127  loss_rpn_cls: 0.02204  loss_rpn_loc: 0.1012  time: 0.8461  data_time: 0.1681  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:39:09 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 459  total_loss: 1.092  loss_cls: 0.3193  loss_box_reg: 0.4398  loss_mask: 0.1784  loss_rpn_cls: 0.01625  loss_rpn_loc: 0.09846  time: 0.8453  data_time: 0.1522  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:39:27 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 479  total_loss: 1.201  loss_cls: 0.3414  loss_box_reg: 0.4554  loss_mask: 0.1966  loss_rpn_cls: 0.02381  loss_rpn_loc: 0.1034  time: 0.8473  data_time: 0.2046  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:39:44 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 499  total_loss: 1.104  loss_cls: 0.3111  loss_box_reg: 0.47  loss_mask: 0.2006  loss_rpn_cls: 0.01933  loss_rpn_loc: 0.1036  time: 0.8477  data_time: 0.1701  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:40:01 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 519  total_loss: 1.081  loss_cls: 0.2867  loss_box_reg: 0.4619  loss_mask: 0.1891  loss_rpn_cls: 0.02635  loss_rpn_loc: 0.1196  time: 0.8482  data_time: 0.1757  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:40:18 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 539  total_loss: 0.9994  loss_cls: 0.261  loss_box_reg: 0.4218  loss_mask: 0.1906  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.09617  time: 0.8477  data_time: 0.1659  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:40:35 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 559  total_loss: 1.053  loss_cls: 0.2873  loss_box_reg: 0.4022  loss_mask: 0.1853  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.129  time: 0.8475  data_time: 0.1620  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:40:52 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 579  total_loss: 1.047  loss_cls: 0.2499  loss_box_reg: 0.423  loss_mask: 0.2058  loss_rpn_cls: 0.02037  loss_rpn_loc: 0.1  time: 0.8479  data_time: 0.2130  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:41:08 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 599  total_loss: 1.004  loss_cls: 0.2683  loss_box_reg: 0.4228  loss_mask: 0.1858  loss_rpn_cls: 0.01969  loss_rpn_loc: 0.1184  time: 0.8468  data_time: 0.1476  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:41:25 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 619  total_loss: 1.014  loss_cls: 0.3121  loss_box_reg: 0.3935  loss_mask: 0.1913  loss_rpn_cls: 0.01777  loss_rpn_loc: 0.1022  time: 0.8470  data_time: 0.1807  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:41:41 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 639  total_loss: 0.9953  loss_cls: 0.2944  loss_box_reg: 0.3958  loss_mask: 0.1863  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.1135  time: 0.8457  data_time: 0.1394  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:41:58 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 659  total_loss: 0.9952  loss_cls: 0.2904  loss_box_reg: 0.396  loss_mask: 0.1845  loss_rpn_cls: 0.01784  loss_rpn_loc: 0.1027  time: 0.8455  data_time: 0.1639  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 02:42:15 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 679  total_loss: 0.9635  loss_cls: 0.2699  loss_box_reg: 0.4033  loss_mask: 0.1815  loss_rpn_cls: 0.01766  loss_rpn_loc: 0.09472  time: 0.8452  data_time: 0.1585  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:42:31 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 699  total_loss: 0.9836  loss_cls: 0.2697  loss_box_reg: 0.3846  loss_mask: 0.1821  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.112  time: 0.8444  data_time: 0.1589  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:42:47 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 719  total_loss: 0.9713  loss_cls: 0.2697  loss_box_reg: 0.383  loss_mask: 0.1781  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.09253  time: 0.8433  data_time: 0.1567  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:43:04 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 739  total_loss: 0.9282  loss_cls: 0.2302  loss_box_reg: 0.4133  loss_mask: 0.189  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.08892  time: 0.8425  data_time: 0.1414  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:43:20 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 759  total_loss: 1.039  loss_cls: 0.3054  loss_box_reg: 0.4281  loss_mask: 0.1921  loss_rpn_cls: 0.01827  loss_rpn_loc: 0.1252  time: 0.8416  data_time: 0.1381  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:43:37 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 779  total_loss: 0.9151  loss_cls: 0.2422  loss_box_reg: 0.394  loss_mask: 0.1818  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.0781  time: 0.8417  data_time: 0.1783  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:43:54 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 799  total_loss: 0.9562  loss_cls: 0.2497  loss_box_reg: 0.386  loss_mask: 0.181  loss_rpn_cls: 0.01896  loss_rpn_loc: 0.1088  time: 0.8423  data_time: 0.1708  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:44:11 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 819  total_loss: 0.8968  loss_cls: 0.2608  loss_box_reg: 0.3629  loss_mask: 0.1796  loss_rpn_cls: 0.01544  loss_rpn_loc: 0.1008  time: 0.8420  data_time: 0.1784  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:44:27 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 839  total_loss: 0.9917  loss_cls: 0.2736  loss_box_reg: 0.3826  loss_mask: 0.1905  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.1126  time: 0.8413  data_time: 0.1655  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:44:44 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 859  total_loss: 0.9729  loss_cls: 0.2582  loss_box_reg: 0.3711  loss_mask: 0.1792  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.09862  time: 0.8414  data_time: 0.1837  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:45:01 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 879  total_loss: 0.9507  loss_cls: 0.2405  loss_box_reg: 0.3852  loss_mask: 0.1826  loss_rpn_cls: 0.0137  loss_rpn_loc: 0.1011  time: 0.8421  data_time: 0.1731  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:45:18 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 899  total_loss: 0.9238  loss_cls: 0.2426  loss_box_reg: 0.3856  loss_mask: 0.1812  loss_rpn_cls: 0.01345  loss_rpn_loc: 0.09864  time: 0.8414  data_time: 0.1543  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:45:33 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 919  total_loss: 0.9815  loss_cls: 0.2465  loss_box_reg: 0.3847  loss_mask: 0.1868  loss_rpn_cls: 0.01686  loss_rpn_loc: 0.115  time: 0.8404  data_time: 0.1578  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:45:50 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 939  total_loss: 0.8902  loss_cls: 0.2492  loss_box_reg: 0.3625  loss_mask: 0.1816  loss_rpn_cls: 0.02312  loss_rpn_loc: 0.09124  time: 0.8400  data_time: 0.1563  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:46:07 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 959  total_loss: 0.9383  loss_cls: 0.2311  loss_box_reg: 0.3958  loss_mask: 0.1692  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.1021  time: 0.8404  data_time: 0.1876  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:46:24 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 979  total_loss: 0.9104  loss_cls: 0.2403  loss_box_reg: 0.3705  loss_mask: 0.1812  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.09811  time: 0.8400  data_time: 0.1474  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:46:40 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 999  total_loss: 0.8372  loss_cls: 0.2196  loss_box_reg: 0.3269  loss_mask: 0.1524  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.1194  time: 0.8396  data_time: 0.1793  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:46:57 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 1019  total_loss: 0.9606  loss_cls: 0.2595  loss_box_reg: 0.3957  loss_mask: 0.1926  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.1084  time: 0.8398  data_time: 0.1654  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:47:14 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 1039  total_loss: 0.8526  loss_cls: 0.1925  loss_box_reg: 0.3432  loss_mask: 0.1708  loss_rpn_cls: 0.009414  loss_rpn_loc: 0.109  time: 0.8400  data_time: 0.1797  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:47:30 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1059  total_loss: 0.861  loss_cls: 0.2082  loss_box_reg: 0.3445  loss_mask: 0.1857  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.09534  time: 0.8392  data_time: 0.1633  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:47:46 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1079  total_loss: 0.9377  loss_cls: 0.261  loss_box_reg: 0.3417  loss_mask: 0.1754  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.09574  time: 0.8390  data_time: 0.1477  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:48:03 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1099  total_loss: 0.8555  loss_cls: 0.2338  loss_box_reg: 0.3337  loss_mask: 0.1755  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.09158  time: 0.8384  data_time: 0.1484  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:48:19 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 1119  total_loss: 0.8467  loss_cls: 0.2277  loss_box_reg: 0.3169  loss_mask: 0.1717  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.08913  time: 0.8384  data_time: 0.1592  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:48:35 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 1139  total_loss: 0.9068  loss_cls: 0.2355  loss_box_reg: 0.3607  loss_mask: 0.1996  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.09679  time: 0.8377  data_time: 0.1354  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:48:52 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 1159  total_loss: 0.8741  loss_cls: 0.2405  loss_box_reg: 0.3267  loss_mask: 0.1759  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.08988  time: 0.8375  data_time: 0.1551  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:49:09 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 1179  total_loss: 0.8467  loss_cls: 0.2091  loss_box_reg: 0.3237  loss_mask: 0.1755  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.09528  time: 0.8376  data_time: 0.1654  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:49:25 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 1199  total_loss: 0.8952  loss_cls: 0.2496  loss_box_reg: 0.322  loss_mask: 0.1711  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.1049  time: 0.8374  data_time: 0.1696  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:49:42 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 1219  total_loss: 0.8101  loss_cls: 0.2141  loss_box_reg: 0.3088  loss_mask: 0.1591  loss_rpn_cls: 0.008375  loss_rpn_loc: 0.07149  time: 0.8370  data_time: 0.1319  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:49:58 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 1239  total_loss: 0.8287  loss_cls: 0.2274  loss_box_reg: 0.3264  loss_mask: 0.1861  loss_rpn_cls: 0.01345  loss_rpn_loc: 0.0976  time: 0.8370  data_time: 0.1630  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:50:15 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 1259  total_loss: 0.8355  loss_cls: 0.2548  loss_box_reg: 0.3164  loss_mask: 0.166  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.09203  time: 0.8370  data_time: 0.1648  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:50:32 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 1279  total_loss: 0.8021  loss_cls: 0.1987  loss_box_reg: 0.3001  loss_mask: 0.1695  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.09418  time: 0.8370  data_time: 0.1809  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:50:49 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 1299  total_loss: 0.7102  loss_cls: 0.1974  loss_box_reg: 0.2801  loss_mask: 0.1453  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.09572  time: 0.8370  data_time: 0.1723  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:51:05 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 1319  total_loss: 0.8318  loss_cls: 0.2164  loss_box_reg: 0.3083  loss_mask: 0.1652  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.08584  time: 0.8367  data_time: 0.1428  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 02:51:21 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 1339  total_loss: 0.8248  loss_cls: 0.2145  loss_box_reg: 0.3191  loss_mask: 0.1685  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.08416  time: 0.8363  data_time: 0.1561  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:51:38 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 1359  total_loss: 0.8036  loss_cls: 0.2075  loss_box_reg: 0.3106  loss_mask: 0.1549  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.08295  time: 0.8362  data_time: 0.1644  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:51:55 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 1379  total_loss: 0.8424  loss_cls: 0.2218  loss_box_reg: 0.3338  loss_mask: 0.172  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.1022  time: 0.8366  data_time: 0.1814  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:52:11 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 1399  total_loss: 0.888  loss_cls: 0.2291  loss_box_reg: 0.3488  loss_mask: 0.1959  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.08745  time: 0.8357  data_time: 0.1511  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 02:52:28 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 1419  total_loss: 0.7608  loss_cls: 0.2029  loss_box_reg: 0.3189  loss_mask: 0.1633  loss_rpn_cls: 0.01085  loss_rpn_loc: 0.09034  time: 0.8360  data_time: 0.1677  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:52:44 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 1439  total_loss: 0.8505  loss_cls: 0.2215  loss_box_reg: 0.3253  loss_mask: 0.1615  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.09725  time: 0.8359  data_time: 0.1875  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:53:01 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 1459  total_loss: 0.8154  loss_cls: 0.2013  loss_box_reg: 0.3165  loss_mask: 0.1709  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.08683  time: 0.8357  data_time: 0.1497  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:53:17 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 1479  total_loss: 0.7643  loss_cls: 0.1756  loss_box_reg: 0.3039  loss_mask: 0.1543  loss_rpn_cls: 0.01342  loss_rpn_loc: 0.08983  time: 0.8354  data_time: 0.1414  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:53:35 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7726  loss_cls: 0.2136  loss_box_reg: 0.2973  loss_mask: 0.1523  loss_rpn_cls: 0.01839  loss_rpn_loc: 0.1053  time: 0.8353  data_time: 0.1743  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 02:53:35 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:20:51 (0.8353 s / it)\n",
      "\u001b[32m[03/05 02:53:35 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:53 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 02:53:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 02:53:36 d2.data.datasets.coco]: \u001b[0mLoaded 108 images in COCO format from /host/mic21-framework/server/uploads/armoured_personnel_carrier_gt.json\n",
      "armoured_personnel_carrier\n",
      "\u001b[32m[03/05 02:53:36 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 02:53:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 02:53:36 d2.data.datasets.coco]: \u001b[0mLoaded 108 images in COCO format from /host/mic21-framework/server/uploads/armoured_personnel_carrier_gt.json\n",
      "\u001b[32m[03/05 02:53:36 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 106 images left.\n",
      "\u001b[32m[03/05 02:53:36 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
      "|    soldier    | 136          | armoured pe.. | 145          | apc wheel  | 489          |\n",
      "| apc headlight | 149          |               |              |            |              |\n",
      "|     total     | 919          |               |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/05 02:53:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 02:53:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 02:53:36 d2.data.common]: \u001b[0mSerializing 106 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 02:53:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.75 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 02:53:37 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 02:53:53 d2.utils.events]: \u001b[0m eta: 0:19:36  iter: 19  total_loss: 2.522  loss_cls: 0.7916  loss_box_reg: 0.8694  loss_mask: 0.6117  loss_rpn_cls: 0.07807  loss_rpn_loc: 0.07187  time: 0.8097  data_time: 0.1473  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:54:09 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 39  total_loss: 1.808  loss_cls: 0.4915  loss_box_reg: 0.852  loss_mask: 0.3375  loss_rpn_cls: 0.05636  loss_rpn_loc: 0.06965  time: 0.8150  data_time: 0.1368  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:54:25 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 59  total_loss: 1.42  loss_cls: 0.3476  loss_box_reg: 0.6224  loss_mask: 0.2654  loss_rpn_cls: 0.05576  loss_rpn_loc: 0.08491  time: 0.8024  data_time: 0.1279  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:54:41 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 79  total_loss: 1.187  loss_cls: 0.2776  loss_box_reg: 0.5029  loss_mask: 0.2204  loss_rpn_cls: 0.04209  loss_rpn_loc: 0.04936  time: 0.8030  data_time: 0.1379  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:54:57 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 99  total_loss: 0.9578  loss_cls: 0.2045  loss_box_reg: 0.4717  loss_mask: 0.2049  loss_rpn_cls: 0.03538  loss_rpn_loc: 0.04633  time: 0.8020  data_time: 0.1268  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:55:13 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 119  total_loss: 0.9754  loss_cls: 0.2162  loss_box_reg: 0.4882  loss_mask: 0.1872  loss_rpn_cls: 0.03573  loss_rpn_loc: 0.05649  time: 0.8016  data_time: 0.1302  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:55:28 d2.utils.events]: \u001b[0m eta: 0:18:03  iter: 139  total_loss: 0.9723  loss_cls: 0.2267  loss_box_reg: 0.4535  loss_mask: 0.2051  loss_rpn_cls: 0.03471  loss_rpn_loc: 0.05342  time: 0.7968  data_time: 0.1239  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:55:44 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 159  total_loss: 0.9367  loss_cls: 0.2019  loss_box_reg: 0.4467  loss_mask: 0.2073  loss_rpn_cls: 0.03006  loss_rpn_loc: 0.04962  time: 0.7956  data_time: 0.1204  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:56:00 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 179  total_loss: 0.849  loss_cls: 0.1733  loss_box_reg: 0.422  loss_mask: 0.1734  loss_rpn_cls: 0.02817  loss_rpn_loc: 0.05106  time: 0.7945  data_time: 0.1338  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:56:16 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 199  total_loss: 0.8811  loss_cls: 0.1738  loss_box_reg: 0.4351  loss_mask: 0.1959  loss_rpn_cls: 0.02414  loss_rpn_loc: 0.04635  time: 0.7933  data_time: 0.1154  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:56:31 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 219  total_loss: 0.9024  loss_cls: 0.1864  loss_box_reg: 0.3895  loss_mask: 0.1829  loss_rpn_cls: 0.02836  loss_rpn_loc: 0.0576  time: 0.7931  data_time: 0.1240  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:56:47 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 239  total_loss: 0.8114  loss_cls: 0.1483  loss_box_reg: 0.3858  loss_mask: 0.1827  loss_rpn_cls: 0.02623  loss_rpn_loc: 0.05428  time: 0.7936  data_time: 0.1258  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:57:04 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 259  total_loss: 0.8271  loss_cls: 0.1742  loss_box_reg: 0.391  loss_mask: 0.1744  loss_rpn_cls: 0.01987  loss_rpn_loc: 0.05645  time: 0.7949  data_time: 0.1340  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:57:19 d2.utils.events]: \u001b[0m eta: 0:16:06  iter: 279  total_loss: 0.8052  loss_cls: 0.1766  loss_box_reg: 0.3723  loss_mask: 0.2  loss_rpn_cls: 0.02198  loss_rpn_loc: 0.04764  time: 0.7934  data_time: 0.1195  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:57:35 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 299  total_loss: 0.7438  loss_cls: 0.1538  loss_box_reg: 0.3396  loss_mask: 0.166  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.03643  time: 0.7935  data_time: 0.1233  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:57:51 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 319  total_loss: 0.7966  loss_cls: 0.167  loss_box_reg: 0.3642  loss_mask: 0.1644  loss_rpn_cls: 0.02452  loss_rpn_loc: 0.05509  time: 0.7923  data_time: 0.1201  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:58:07 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 339  total_loss: 0.7453  loss_cls: 0.137  loss_box_reg: 0.3442  loss_mask: 0.1648  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.04015  time: 0.7927  data_time: 0.1268  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:58:22 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 359  total_loss: 0.7187  loss_cls: 0.1527  loss_box_reg: 0.3325  loss_mask: 0.1632  loss_rpn_cls: 0.02208  loss_rpn_loc: 0.0501  time: 0.7920  data_time: 0.1305  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:58:37 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 379  total_loss: 0.7229  loss_cls: 0.1281  loss_box_reg: 0.3548  loss_mask: 0.1614  loss_rpn_cls: 0.01539  loss_rpn_loc: 0.03931  time: 0.7898  data_time: 0.1226  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:58:53 d2.utils.events]: \u001b[0m eta: 0:14:27  iter: 399  total_loss: 0.7226  loss_cls: 0.1625  loss_box_reg: 0.3243  loss_mask: 0.15  loss_rpn_cls: 0.01648  loss_rpn_loc: 0.04852  time: 0.7898  data_time: 0.1206  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:59:09 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 419  total_loss: 0.7466  loss_cls: 0.1332  loss_box_reg: 0.3204  loss_mask: 0.1622  loss_rpn_cls: 0.0152  loss_rpn_loc: 0.04251  time: 0.7893  data_time: 0.1308  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:59:25 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 439  total_loss: 0.7333  loss_cls: 0.1461  loss_box_reg: 0.3348  loss_mask: 0.1569  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.04433  time: 0.7910  data_time: 0.1379  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:59:41 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 459  total_loss: 0.7008  loss_cls: 0.17  loss_box_reg: 0.3089  loss_mask: 0.1579  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.04447  time: 0.7907  data_time: 0.1211  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 02:59:56 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 479  total_loss: 0.7627  loss_cls: 0.1521  loss_box_reg: 0.3526  loss_mask: 0.1747  loss_rpn_cls: 0.01563  loss_rpn_loc: 0.04782  time: 0.7903  data_time: 0.1180  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:00:12 d2.utils.events]: \u001b[0m eta: 0:13:08  iter: 499  total_loss: 0.6746  loss_cls: 0.117  loss_box_reg: 0.3113  loss_mask: 0.1592  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.03904  time: 0.7905  data_time: 0.1350  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:00:28 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 519  total_loss: 0.6986  loss_cls: 0.16  loss_box_reg: 0.34  loss_mask: 0.178  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.0425  time: 0.7910  data_time: 0.1412  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:00:44 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 539  total_loss: 0.6791  loss_cls: 0.1576  loss_box_reg: 0.2831  loss_mask: 0.1492  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.04026  time: 0.7912  data_time: 0.1253  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:01:00 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 559  total_loss: 0.7021  loss_cls: 0.1682  loss_box_reg: 0.3019  loss_mask: 0.144  loss_rpn_cls: 0.009286  loss_rpn_loc: 0.04025  time: 0.7912  data_time: 0.1285  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:01:16 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 579  total_loss: 0.6568  loss_cls: 0.1309  loss_box_reg: 0.3011  loss_mask: 0.159  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.04122  time: 0.7906  data_time: 0.1264  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:01:31 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 599  total_loss: 0.6241  loss_cls: 0.1366  loss_box_reg: 0.2793  loss_mask: 0.1466  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.0367  time: 0.7902  data_time: 0.1208  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:01:48 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 619  total_loss: 0.6756  loss_cls: 0.1226  loss_box_reg: 0.2862  loss_mask: 0.1578  loss_rpn_cls: 0.01049  loss_rpn_loc: 0.03894  time: 0.7909  data_time: 0.1460  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:02:03 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 639  total_loss: 0.6594  loss_cls: 0.1094  loss_box_reg: 0.3059  loss_mask: 0.1599  loss_rpn_cls: 0.01012  loss_rpn_loc: 0.04378  time: 0.7909  data_time: 0.1145  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:02:20 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 659  total_loss: 0.626  loss_cls: 0.1116  loss_box_reg: 0.2816  loss_mask: 0.1459  loss_rpn_cls: 0.01018  loss_rpn_loc: 0.04178  time: 0.7924  data_time: 0.1333  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 03:02:36 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 679  total_loss: 0.6  loss_cls: 0.1172  loss_box_reg: 0.2444  loss_mask: 0.134  loss_rpn_cls: 0.00938  loss_rpn_loc: 0.0398  time: 0.7925  data_time: 0.1282  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:02:52 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 699  total_loss: 0.618  loss_cls: 0.1111  loss_box_reg: 0.3037  loss_mask: 0.1576  loss_rpn_cls: 0.009476  loss_rpn_loc: 0.03941  time: 0.7921  data_time: 0.1208  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:03:07 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 719  total_loss: 0.664  loss_cls: 0.1422  loss_box_reg: 0.2886  loss_mask: 0.1505  loss_rpn_cls: 0.008266  loss_rpn_loc: 0.04031  time: 0.7916  data_time: 0.1331  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:03:23 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 739  total_loss: 0.6479  loss_cls: 0.126  loss_box_reg: 0.3057  loss_mask: 0.1584  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.04189  time: 0.7918  data_time: 0.1148  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:03:39 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 759  total_loss: 0.6348  loss_cls: 0.1267  loss_box_reg: 0.2641  loss_mask: 0.1522  loss_rpn_cls: 0.007601  loss_rpn_loc: 0.03753  time: 0.7920  data_time: 0.1299  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:03:55 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 779  total_loss: 0.568  loss_cls: 0.1013  loss_box_reg: 0.2713  loss_mask: 0.1349  loss_rpn_cls: 0.007908  loss_rpn_loc: 0.03283  time: 0.7920  data_time: 0.1239  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:04:11 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 799  total_loss: 0.5915  loss_cls: 0.1108  loss_box_reg: 0.2693  loss_mask: 0.1513  loss_rpn_cls: 0.009477  loss_rpn_loc: 0.04423  time: 0.7922  data_time: 0.1225  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:04:27 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 819  total_loss: 0.5903  loss_cls: 0.1117  loss_box_reg: 0.2667  loss_mask: 0.1438  loss_rpn_cls: 0.007047  loss_rpn_loc: 0.04051  time: 0.7928  data_time: 0.1362  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:04:43 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 839  total_loss: 0.5837  loss_cls: 0.1098  loss_box_reg: 0.2735  loss_mask: 0.1446  loss_rpn_cls: 0.008114  loss_rpn_loc: 0.03677  time: 0.7925  data_time: 0.1336  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:04:58 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 859  total_loss: 0.5701  loss_cls: 0.1133  loss_box_reg: 0.2642  loss_mask: 0.1435  loss_rpn_cls: 0.008361  loss_rpn_loc: 0.04418  time: 0.7917  data_time: 0.1147  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:05:14 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 879  total_loss: 0.5555  loss_cls: 0.1201  loss_box_reg: 0.2902  loss_mask: 0.1466  loss_rpn_cls: 0.007542  loss_rpn_loc: 0.04158  time: 0.7915  data_time: 0.1356  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:05:29 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 899  total_loss: 0.5209  loss_cls: 0.09649  loss_box_reg: 0.2507  loss_mask: 0.124  loss_rpn_cls: 0.006987  loss_rpn_loc: 0.04199  time: 0.7910  data_time: 0.1323  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:05:45 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 919  total_loss: 0.5836  loss_cls: 0.09153  loss_box_reg: 0.2778  loss_mask: 0.1407  loss_rpn_cls: 0.005852  loss_rpn_loc: 0.04013  time: 0.7911  data_time: 0.1303  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:06:01 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 939  total_loss: 0.6076  loss_cls: 0.1212  loss_box_reg: 0.2679  loss_mask: 0.1391  loss_rpn_cls: 0.007079  loss_rpn_loc: 0.03594  time: 0.7911  data_time: 0.1251  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:06:17 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 959  total_loss: 0.5837  loss_cls: 0.1171  loss_box_reg: 0.2613  loss_mask: 0.1536  loss_rpn_cls: 0.009049  loss_rpn_loc: 0.03927  time: 0.7911  data_time: 0.1231  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:06:32 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 979  total_loss: 0.5579  loss_cls: 0.1119  loss_box_reg: 0.256  loss_mask: 0.1527  loss_rpn_cls: 0.006195  loss_rpn_loc: 0.03174  time: 0.7902  data_time: 0.1247  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:06:47 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 999  total_loss: 0.5365  loss_cls: 0.08956  loss_box_reg: 0.2489  loss_mask: 0.1396  loss_rpn_cls: 0.007126  loss_rpn_loc: 0.03676  time: 0.7897  data_time: 0.1202  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:07:03 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 1019  total_loss: 0.5385  loss_cls: 0.1201  loss_box_reg: 0.2582  loss_mask: 0.1229  loss_rpn_cls: 0.004015  loss_rpn_loc: 0.03067  time: 0.7899  data_time: 0.1251  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:07:19 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 1039  total_loss: 0.5552  loss_cls: 0.09376  loss_box_reg: 0.2536  loss_mask: 0.1477  loss_rpn_cls: 0.006069  loss_rpn_loc: 0.03089  time: 0.7901  data_time: 0.1374  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:07:34 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 1059  total_loss: 0.5222  loss_cls: 0.09752  loss_box_reg: 0.243  loss_mask: 0.1547  loss_rpn_cls: 0.005404  loss_rpn_loc: 0.03505  time: 0.7895  data_time: 0.1237  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:07:50 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 1079  total_loss: 0.5143  loss_cls: 0.0956  loss_box_reg: 0.2342  loss_mask: 0.1288  loss_rpn_cls: 0.004623  loss_rpn_loc: 0.0386  time: 0.7896  data_time: 0.1279  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:08:06 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 1099  total_loss: 0.5384  loss_cls: 0.1049  loss_box_reg: 0.2265  loss_mask: 0.1406  loss_rpn_cls: 0.006113  loss_rpn_loc: 0.03941  time: 0.7899  data_time: 0.1292  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:08:22 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 1119  total_loss: 0.4879  loss_cls: 0.0891  loss_box_reg: 0.2098  loss_mask: 0.1335  loss_rpn_cls: 0.008041  loss_rpn_loc: 0.04141  time: 0.7897  data_time: 0.1266  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:08:38 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 1139  total_loss: 0.509  loss_cls: 0.1047  loss_box_reg: 0.2222  loss_mask: 0.1327  loss_rpn_cls: 0.006382  loss_rpn_loc: 0.03263  time: 0.7896  data_time: 0.1278  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:08:54 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 1159  total_loss: 0.5133  loss_cls: 0.1066  loss_box_reg: 0.2238  loss_mask: 0.1259  loss_rpn_cls: 0.005181  loss_rpn_loc: 0.03252  time: 0.7898  data_time: 0.1236  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:09:09 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 1179  total_loss: 0.4973  loss_cls: 0.08753  loss_box_reg: 0.2089  loss_mask: 0.1242  loss_rpn_cls: 0.006312  loss_rpn_loc: 0.0358  time: 0.7892  data_time: 0.1307  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:09:25 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 1199  total_loss: 0.4381  loss_cls: 0.07253  loss_box_reg: 0.1999  loss_mask: 0.1211  loss_rpn_cls: 0.006178  loss_rpn_loc: 0.02966  time: 0.7893  data_time: 0.1258  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:09:41 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 1219  total_loss: 0.5136  loss_cls: 0.1013  loss_box_reg: 0.2213  loss_mask: 0.1303  loss_rpn_cls: 0.004829  loss_rpn_loc: 0.03517  time: 0.7895  data_time: 0.1183  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:09:56 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 1239  total_loss: 0.4726  loss_cls: 0.1001  loss_box_reg: 0.2049  loss_mask: 0.1212  loss_rpn_cls: 0.003784  loss_rpn_loc: 0.02863  time: 0.7892  data_time: 0.1314  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:10:12 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 1259  total_loss: 0.5595  loss_cls: 0.09379  loss_box_reg: 0.2211  loss_mask: 0.1451  loss_rpn_cls: 0.006448  loss_rpn_loc: 0.04976  time: 0.7893  data_time: 0.1285  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:10:28 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 1279  total_loss: 0.5096  loss_cls: 0.09086  loss_box_reg: 0.2287  loss_mask: 0.1268  loss_rpn_cls: 0.005825  loss_rpn_loc: 0.03398  time: 0.7895  data_time: 0.1251  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:10:44 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 1299  total_loss: 0.4604  loss_cls: 0.08665  loss_box_reg: 0.2098  loss_mask: 0.1271  loss_rpn_cls: 0.005318  loss_rpn_loc: 0.03328  time: 0.7894  data_time: 0.1305  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:11:00 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 1319  total_loss: 0.5089  loss_cls: 0.08377  loss_box_reg: 0.2109  loss_mask: 0.1262  loss_rpn_cls: 0.005566  loss_rpn_loc: 0.0407  time: 0.7898  data_time: 0.1343  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 03:11:16 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 1339  total_loss: 0.4832  loss_cls: 0.09584  loss_box_reg: 0.2029  loss_mask: 0.1263  loss_rpn_cls: 0.004818  loss_rpn_loc: 0.03477  time: 0.7899  data_time: 0.1298  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:11:32 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 1359  total_loss: 0.4849  loss_cls: 0.07635  loss_box_reg: 0.2227  loss_mask: 0.1347  loss_rpn_cls: 0.006981  loss_rpn_loc: 0.0376  time: 0.7896  data_time: 0.1241  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:11:48 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 1379  total_loss: 0.4977  loss_cls: 0.09344  loss_box_reg: 0.2083  loss_mask: 0.1459  loss_rpn_cls: 0.006217  loss_rpn_loc: 0.03288  time: 0.7898  data_time: 0.1242  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:12:03 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1399  total_loss: 0.4889  loss_cls: 0.1108  loss_box_reg: 0.1969  loss_mask: 0.1255  loss_rpn_cls: 0.004495  loss_rpn_loc: 0.03155  time: 0.7897  data_time: 0.1315  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:12:19 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 1419  total_loss: 0.4751  loss_cls: 0.06802  loss_box_reg: 0.219  loss_mask: 0.1337  loss_rpn_cls: 0.004772  loss_rpn_loc: 0.03063  time: 0.7895  data_time: 0.1381  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:12:35 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 1439  total_loss: 0.5356  loss_cls: 0.08284  loss_box_reg: 0.2167  loss_mask: 0.14  loss_rpn_cls: 0.006292  loss_rpn_loc: 0.03852  time: 0.7896  data_time: 0.1295  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:12:51 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 1459  total_loss: 0.4932  loss_cls: 0.1047  loss_box_reg: 0.2104  loss_mask: 0.1193  loss_rpn_cls: 0.005452  loss_rpn_loc: 0.03098  time: 0.7897  data_time: 0.1320  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:13:06 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 1479  total_loss: 0.5173  loss_cls: 0.09629  loss_box_reg: 0.2316  loss_mask: 0.145  loss_rpn_cls: 0.005826  loss_rpn_loc: 0.03445  time: 0.7896  data_time: 0.1189  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:13:23 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.4865  loss_cls: 0.0999  loss_box_reg: 0.1992  loss_mask: 0.1371  loss_rpn_cls: 0.006048  loss_rpn_loc: 0.04094  time: 0.7897  data_time: 0.1292  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:13:24 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:19:42 (0.7897 s / it)\n",
      "\u001b[32m[03/05 03:13:24 d2.engine.hooks]: \u001b[0mTotal training time: 0:19:45 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 03:13:24 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 03:13:24 d2.data.datasets.coco]: \u001b[0mLoaded 172 images in COCO format from /host/mic21-framework/server/uploads/military_truck_gt.json\n",
      "military_truck\n",
      "\u001b[32m[03/05 03:13:25 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=32, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 03:13:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 03:13:25 d2.data.datasets.coco]: \u001b[0mLoaded 172 images in COCO format from /host/mic21-framework/server/uploads/military_truck_gt.json\n",
      "\u001b[32m[03/05 03:13:25 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 169 images left.\n",
      "\u001b[32m[03/05 03:13:25 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|      man      | 56           |    soldier    | 128          | military tr.. | 199          |\n",
      "| military tr.. | 640          | military tr.. | 171          | military tr.. | 282          |\n",
      "| military tr.. | 160          | military tr.. | 195          |               |              |\n",
      "|     total     | 1831         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 03:13:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 03:13:25 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 03:13:25 d2.data.common]: \u001b[0mSerializing 169 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 03:13:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.32 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (9, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (9,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (32, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (32,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (8, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 03:13:25 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 03:13:44 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 19  total_loss: 2.814  loss_cls: 1.005  loss_box_reg: 0.8604  loss_mask: 0.6373  loss_rpn_cls: 0.1419  loss_rpn_loc: 0.1013  time: 0.9228  data_time: 0.2596  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:14:03 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 39  total_loss: 2.209  loss_cls: 0.7327  loss_box_reg: 0.8309  loss_mask: 0.4903  loss_rpn_cls: 0.08919  loss_rpn_loc: 0.07938  time: 0.9218  data_time: 0.2474  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:14:20 d2.utils.events]: \u001b[0m eta: 0:21:44  iter: 59  total_loss: 1.973  loss_cls: 0.6376  loss_box_reg: 0.7767  loss_mask: 0.3927  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.09513  time: 0.9052  data_time: 0.2134  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:14:38 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 79  total_loss: 1.608  loss_cls: 0.5286  loss_box_reg: 0.6496  loss_mask: 0.3011  loss_rpn_cls: 0.05199  loss_rpn_loc: 0.07474  time: 0.8974  data_time: 0.2232  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:14:55 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 99  total_loss: 1.666  loss_cls: 0.5307  loss_box_reg: 0.6932  loss_mask: 0.3101  loss_rpn_cls: 0.05091  loss_rpn_loc: 0.09251  time: 0.8930  data_time: 0.2206  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:15:12 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 119  total_loss: 1.477  loss_cls: 0.4184  loss_box_reg: 0.6125  loss_mask: 0.2739  loss_rpn_cls: 0.04682  loss_rpn_loc: 0.07139  time: 0.8862  data_time: 0.1738  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:15:30 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 139  total_loss: 1.394  loss_cls: 0.3824  loss_box_reg: 0.5889  loss_mask: 0.2608  loss_rpn_cls: 0.03647  loss_rpn_loc: 0.06765  time: 0.8856  data_time: 0.2104  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:15:48 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 159  total_loss: 1.288  loss_cls: 0.3671  loss_box_reg: 0.5569  loss_mask: 0.2391  loss_rpn_cls: 0.03638  loss_rpn_loc: 0.07857  time: 0.8848  data_time: 0.2028  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:16:06 d2.utils.events]: \u001b[0m eta: 0:19:36  iter: 179  total_loss: 1.253  loss_cls: 0.3435  loss_box_reg: 0.5218  loss_mask: 0.2437  loss_rpn_cls: 0.03382  loss_rpn_loc: 0.0609  time: 0.8878  data_time: 0.2387  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:16:23 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 199  total_loss: 1.179  loss_cls: 0.3206  loss_box_reg: 0.5018  loss_mask: 0.231  loss_rpn_cls: 0.03149  loss_rpn_loc: 0.06018  time: 0.8848  data_time: 0.2022  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:16:40 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 219  total_loss: 1.136  loss_cls: 0.3072  loss_box_reg: 0.4688  loss_mask: 0.2531  loss_rpn_cls: 0.03942  loss_rpn_loc: 0.072  time: 0.8835  data_time: 0.2166  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:16:59 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 239  total_loss: 1.083  loss_cls: 0.2945  loss_box_reg: 0.4692  loss_mask: 0.2041  loss_rpn_cls: 0.03369  loss_rpn_loc: 0.06577  time: 0.8873  data_time: 0.2415  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:17:16 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 259  total_loss: 1.162  loss_cls: 0.3124  loss_box_reg: 0.4655  loss_mask: 0.2062  loss_rpn_cls: 0.02887  loss_rpn_loc: 0.07442  time: 0.8839  data_time: 0.2152  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:17:34 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 279  total_loss: 1.069  loss_cls: 0.283  loss_box_reg: 0.4385  loss_mask: 0.2196  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.071  time: 0.8850  data_time: 0.2211  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:17:51 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 299  total_loss: 0.9948  loss_cls: 0.2704  loss_box_reg: 0.4276  loss_mask: 0.192  loss_rpn_cls: 0.02846  loss_rpn_loc: 0.06244  time: 0.8844  data_time: 0.2159  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:18:09 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 319  total_loss: 1.071  loss_cls: 0.2714  loss_box_reg: 0.4596  loss_mask: 0.2216  loss_rpn_cls: 0.02515  loss_rpn_loc: 0.067  time: 0.8845  data_time: 0.2137  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:18:26 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 339  total_loss: 0.9496  loss_cls: 0.2633  loss_box_reg: 0.4348  loss_mask: 0.1988  loss_rpn_cls: 0.02481  loss_rpn_loc: 0.06417  time: 0.8818  data_time: 0.1787  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:18:44 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 359  total_loss: 0.9642  loss_cls: 0.2787  loss_box_reg: 0.4092  loss_mask: 0.2107  loss_rpn_cls: 0.02973  loss_rpn_loc: 0.07582  time: 0.8831  data_time: 0.2326  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:19:01 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 379  total_loss: 0.9374  loss_cls: 0.2361  loss_box_reg: 0.414  loss_mask: 0.1956  loss_rpn_cls: 0.02367  loss_rpn_loc: 0.05924  time: 0.8822  data_time: 0.2022  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:19:19 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 399  total_loss: 0.9394  loss_cls: 0.2099  loss_box_reg: 0.3878  loss_mask: 0.202  loss_rpn_cls: 0.02217  loss_rpn_loc: 0.07209  time: 0.8825  data_time: 0.2235  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:19:37 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 419  total_loss: 0.9886  loss_cls: 0.2633  loss_box_reg: 0.4182  loss_mask: 0.1911  loss_rpn_cls: 0.02449  loss_rpn_loc: 0.06086  time: 0.8829  data_time: 0.2292  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:19:55 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 439  total_loss: 1.018  loss_cls: 0.2737  loss_box_reg: 0.4214  loss_mask: 0.1954  loss_rpn_cls: 0.02337  loss_rpn_loc: 0.06542  time: 0.8840  data_time: 0.2134  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:20:13 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 459  total_loss: 0.9393  loss_cls: 0.2207  loss_box_reg: 0.3957  loss_mask: 0.1906  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.06326  time: 0.8850  data_time: 0.2115  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:20:31 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 479  total_loss: 0.8876  loss_cls: 0.2364  loss_box_reg: 0.3766  loss_mask: 0.1932  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.05297  time: 0.8853  data_time: 0.2095  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:20:49 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 499  total_loss: 0.8738  loss_cls: 0.2397  loss_box_reg: 0.3682  loss_mask: 0.1841  loss_rpn_cls: 0.02519  loss_rpn_loc: 0.06689  time: 0.8847  data_time: 0.2238  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:21:07 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 519  total_loss: 0.8403  loss_cls: 0.1948  loss_box_reg: 0.3645  loss_mask: 0.1703  loss_rpn_cls: 0.02201  loss_rpn_loc: 0.06105  time: 0.8851  data_time: 0.2106  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:21:24 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 539  total_loss: 0.9778  loss_cls: 0.2341  loss_box_reg: 0.3957  loss_mask: 0.1863  loss_rpn_cls: 0.01736  loss_rpn_loc: 0.06625  time: 0.8855  data_time: 0.2053  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:21:42 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 559  total_loss: 0.8471  loss_cls: 0.2296  loss_box_reg: 0.3858  loss_mask: 0.1818  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.06785  time: 0.8844  data_time: 0.1913  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:21:59 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 579  total_loss: 0.882  loss_cls: 0.2548  loss_box_reg: 0.3676  loss_mask: 0.1776  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.05499  time: 0.8836  data_time: 0.1930  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:22:17 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 599  total_loss: 0.9595  loss_cls: 0.2568  loss_box_reg: 0.4015  loss_mask: 0.2048  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.06345  time: 0.8842  data_time: 0.2120  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:22:33 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 619  total_loss: 0.8512  loss_cls: 0.2346  loss_box_reg: 0.3651  loss_mask: 0.1919  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.05244  time: 0.8824  data_time: 0.1890  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:22:51 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 639  total_loss: 0.8793  loss_cls: 0.1929  loss_box_reg: 0.3973  loss_mask: 0.1912  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.06198  time: 0.8828  data_time: 0.2137  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:23:09 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 659  total_loss: 0.8729  loss_cls: 0.1998  loss_box_reg: 0.397  loss_mask: 0.1826  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.04919  time: 0.8833  data_time: 0.2143  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 03:23:28 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 679  total_loss: 0.7948  loss_cls: 0.1929  loss_box_reg: 0.3081  loss_mask: 0.1739  loss_rpn_cls: 0.01953  loss_rpn_loc: 0.06886  time: 0.8843  data_time: 0.2474  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:23:45 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 699  total_loss: 0.804  loss_cls: 0.211  loss_box_reg: 0.3571  loss_mask: 0.1681  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.05727  time: 0.8840  data_time: 0.2186  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:24:03 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 719  total_loss: 0.8194  loss_cls: 0.2041  loss_box_reg: 0.357  loss_mask: 0.1738  loss_rpn_cls: 0.01839  loss_rpn_loc: 0.05998  time: 0.8840  data_time: 0.2052  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:24:20 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 739  total_loss: 0.853  loss_cls: 0.2388  loss_box_reg: 0.3445  loss_mask: 0.1846  loss_rpn_cls: 0.01789  loss_rpn_loc: 0.05406  time: 0.8838  data_time: 0.2109  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:24:38 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 759  total_loss: 0.7545  loss_cls: 0.1913  loss_box_reg: 0.32  loss_mask: 0.159  loss_rpn_cls: 0.01662  loss_rpn_loc: 0.05925  time: 0.8834  data_time: 0.1983  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:24:55 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 779  total_loss: 0.8867  loss_cls: 0.2487  loss_box_reg: 0.3399  loss_mask: 0.2087  loss_rpn_cls: 0.01945  loss_rpn_loc: 0.06288  time: 0.8832  data_time: 0.2054  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:25:14 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 799  total_loss: 0.8225  loss_cls: 0.1982  loss_box_reg: 0.3443  loss_mask: 0.1795  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.05905  time: 0.8839  data_time: 0.2196  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:25:31 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 819  total_loss: 0.8177  loss_cls: 0.2133  loss_box_reg: 0.3321  loss_mask: 0.1774  loss_rpn_cls: 0.0147  loss_rpn_loc: 0.06453  time: 0.8833  data_time: 0.2052  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:25:48 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 839  total_loss: 0.7931  loss_cls: 0.1631  loss_box_reg: 0.3388  loss_mask: 0.1628  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.05875  time: 0.8825  data_time: 0.1884  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:26:06 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 859  total_loss: 0.7952  loss_cls: 0.1979  loss_box_reg: 0.3374  loss_mask: 0.1724  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.05316  time: 0.8826  data_time: 0.2310  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:26:24 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 879  total_loss: 0.7529  loss_cls: 0.1623  loss_box_reg: 0.3212  loss_mask: 0.1662  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.05309  time: 0.8831  data_time: 0.2108  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:26:42 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 899  total_loss: 0.8102  loss_cls: 0.181  loss_box_reg: 0.3332  loss_mask: 0.1819  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.0539  time: 0.8839  data_time: 0.2316  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:27:00 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 919  total_loss: 0.9352  loss_cls: 0.2432  loss_box_reg: 0.3836  loss_mask: 0.1775  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.05636  time: 0.8839  data_time: 0.2065  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:27:17 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 939  total_loss: 0.7884  loss_cls: 0.1634  loss_box_reg: 0.3221  loss_mask: 0.1806  loss_rpn_cls: 0.00834  loss_rpn_loc: 0.04838  time: 0.8838  data_time: 0.2205  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:27:35 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 959  total_loss: 0.8168  loss_cls: 0.2094  loss_box_reg: 0.3085  loss_mask: 0.168  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.06151  time: 0.8833  data_time: 0.1904  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:27:53 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 979  total_loss: 0.7824  loss_cls: 0.1715  loss_box_reg: 0.3258  loss_mask: 0.1688  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.04629  time: 0.8840  data_time: 0.2422  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:28:11 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 999  total_loss: 0.7115  loss_cls: 0.1734  loss_box_reg: 0.3288  loss_mask: 0.1533  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.05938  time: 0.8841  data_time: 0.1918  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:28:28 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1019  total_loss: 0.7346  loss_cls: 0.1603  loss_box_reg: 0.3193  loss_mask: 0.1568  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.05413  time: 0.8836  data_time: 0.2019  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:28:46 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 1039  total_loss: 0.752  loss_cls: 0.202  loss_box_reg: 0.3203  loss_mask: 0.1553  loss_rpn_cls: 0.01349  loss_rpn_loc: 0.05657  time: 0.8844  data_time: 0.2358  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:29:04 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 1059  total_loss: 0.7045  loss_cls: 0.1935  loss_box_reg: 0.2816  loss_mask: 0.1578  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.04622  time: 0.8843  data_time: 0.2058  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:29:23 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 1079  total_loss: 0.7098  loss_cls: 0.172  loss_box_reg: 0.2841  loss_mask: 0.1676  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.06246  time: 0.8851  data_time: 0.2455  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:29:40 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 1099  total_loss: 0.6673  loss_cls: 0.144  loss_box_reg: 0.2754  loss_mask: 0.1532  loss_rpn_cls: 0.009039  loss_rpn_loc: 0.05276  time: 0.8850  data_time: 0.2029  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:29:58 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1119  total_loss: 0.6942  loss_cls: 0.1825  loss_box_reg: 0.3044  loss_mask: 0.1625  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.04798  time: 0.8847  data_time: 0.2164  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:30:17 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 1139  total_loss: 0.6834  loss_cls: 0.1606  loss_box_reg: 0.2751  loss_mask: 0.1487  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.04945  time: 0.8858  data_time: 0.2561  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:30:34 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 1159  total_loss: 0.7476  loss_cls: 0.1911  loss_box_reg: 0.2777  loss_mask: 0.1639  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.05625  time: 0.8857  data_time: 0.2172  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:30:52 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 1179  total_loss: 0.6509  loss_cls: 0.1698  loss_box_reg: 0.2493  loss_mask: 0.1559  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.04947  time: 0.8857  data_time: 0.2064  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:31:09 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 1199  total_loss: 0.737  loss_cls: 0.1906  loss_box_reg: 0.2974  loss_mask: 0.1661  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.0575  time: 0.8855  data_time: 0.2291  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:31:27 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 1219  total_loss: 0.661  loss_cls: 0.1655  loss_box_reg: 0.266  loss_mask: 0.157  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.04986  time: 0.8851  data_time: 0.2061  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:31:44 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 1239  total_loss: 0.6906  loss_cls: 0.1595  loss_box_reg: 0.2593  loss_mask: 0.1711  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.04933  time: 0.8846  data_time: 0.2372  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:32:01 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 1259  total_loss: 0.6451  loss_cls: 0.1524  loss_box_reg: 0.2435  loss_mask: 0.1479  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.05483  time: 0.8842  data_time: 0.2003  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:32:19 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 1279  total_loss: 0.6231  loss_cls: 0.1431  loss_box_reg: 0.2795  loss_mask: 0.1425  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.04725  time: 0.8844  data_time: 0.2238  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:32:36 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 1299  total_loss: 0.7221  loss_cls: 0.1763  loss_box_reg: 0.2875  loss_mask: 0.1611  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.05443  time: 0.8842  data_time: 0.2042  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:32:55 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 1319  total_loss: 0.761  loss_cls: 0.1745  loss_box_reg: 0.296  loss_mask: 0.1705  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.05602  time: 0.8848  data_time: 0.2341  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 03:33:12 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 1339  total_loss: 0.7361  loss_cls: 0.1886  loss_box_reg: 0.2794  loss_mask: 0.1619  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.05475  time: 0.8844  data_time: 0.2105  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:33:29 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 1359  total_loss: 0.7015  loss_cls: 0.1696  loss_box_reg: 0.2807  loss_mask: 0.1504  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.04769  time: 0.8841  data_time: 0.2183  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:33:47 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 1379  total_loss: 0.6375  loss_cls: 0.1695  loss_box_reg: 0.2638  loss_mask: 0.1538  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.0473  time: 0.8839  data_time: 0.1943  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:34:05 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 1399  total_loss: 0.671  loss_cls: 0.1771  loss_box_reg: 0.2773  loss_mask: 0.1542  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.05043  time: 0.8843  data_time: 0.2360  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:34:23 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 1419  total_loss: 0.6653  loss_cls: 0.1794  loss_box_reg: 0.2689  loss_mask: 0.1552  loss_rpn_cls: 0.009357  loss_rpn_loc: 0.04568  time: 0.8842  data_time: 0.2056  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:34:40 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 1439  total_loss: 0.6386  loss_cls: 0.1515  loss_box_reg: 0.2634  loss_mask: 0.1469  loss_rpn_cls: 0.009622  loss_rpn_loc: 0.05356  time: 0.8842  data_time: 0.2142  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:34:57 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 1459  total_loss: 0.5898  loss_cls: 0.1585  loss_box_reg: 0.2291  loss_mask: 0.1446  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.04757  time: 0.8838  data_time: 0.2141  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:35:15 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 1479  total_loss: 0.7047  loss_cls: 0.1688  loss_box_reg: 0.2817  loss_mask: 0.1611  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.0569  time: 0.8836  data_time: 0.2029  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:35:34 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7103  loss_cls: 0.1582  loss_box_reg: 0.3037  loss_mask: 0.1756  loss_rpn_cls: 0.01302  loss_rpn_loc: 0.05172  time: 0.8839  data_time: 0.2330  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:35:34 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:22:04 (0.8839 s / it)\n",
      "\u001b[32m[03/05 03:35:34 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:06 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 03:35:35 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 03:35:35 d2.data.datasets.coco]: \u001b[0mLoaded 124 images in COCO format from /host/mic21-framework/server/uploads/rickshaw_gt.json\n",
      "rickshaw\n",
      "\u001b[32m[03/05 03:35:36 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 03:35:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 03:35:36 d2.data.datasets.coco]: \u001b[0mLoaded 124 images in COCO format from /host/mic21-framework/server/uploads/rickshaw_gt.json\n",
      "\u001b[32m[03/05 03:35:36 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 124 images left.\n",
      "\u001b[32m[03/05 03:35:36 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|  category  | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|    man     | 222          |     woman     | 160          | rickshaw pu.. | 124          |\n",
      "|  rickshaw  | 155          | rickshaw wh.. | 343          | rickshaw cab  | 143          |\n",
      "|            |              |               |              |               |              |\n",
      "|   total    | 1147         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 03:35:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 03:35:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 03:35:36 d2.data.common]: \u001b[0mSerializing 124 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 03:35:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.06 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 03:35:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 03:35:56 d2.utils.events]: \u001b[0m eta: 0:24:24  iter: 19  total_loss: 2.632  loss_cls: 0.9134  loss_box_reg: 0.8979  loss_mask: 0.6402  loss_rpn_cls: 0.0529  loss_rpn_loc: 0.06497  time: 0.9811  data_time: 0.3421  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:36:15 d2.utils.events]: \u001b[0m eta: 0:24:06  iter: 39  total_loss: 2.161  loss_cls: 0.6424  loss_box_reg: 0.8943  loss_mask: 0.4791  loss_rpn_cls: 0.03131  loss_rpn_loc: 0.05459  time: 0.9698  data_time: 0.3005  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:36:34 d2.utils.events]: \u001b[0m eta: 0:23:17  iter: 59  total_loss: 1.867  loss_cls: 0.5644  loss_box_reg: 0.7757  loss_mask: 0.4121  loss_rpn_cls: 0.03106  loss_rpn_loc: 0.05662  time: 0.9495  data_time: 0.2770  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:36:53 d2.utils.events]: \u001b[0m eta: 0:22:37  iter: 79  total_loss: 1.68  loss_cls: 0.5172  loss_box_reg: 0.7392  loss_mask: 0.3428  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.06034  time: 0.9494  data_time: 0.3058  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:37:10 d2.utils.events]: \u001b[0m eta: 0:21:49  iter: 99  total_loss: 1.516  loss_cls: 0.4517  loss_box_reg: 0.6945  loss_mask: 0.285  loss_rpn_cls: 0.02676  loss_rpn_loc: 0.07489  time: 0.9357  data_time: 0.2672  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:37:30 d2.utils.events]: \u001b[0m eta: 0:21:40  iter: 119  total_loss: 1.393  loss_cls: 0.4393  loss_box_reg: 0.6064  loss_mask: 0.2869  loss_rpn_cls: 0.02686  loss_rpn_loc: 0.06418  time: 0.9409  data_time: 0.2904  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:37:49 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 139  total_loss: 1.268  loss_cls: 0.4045  loss_box_reg: 0.5446  loss_mask: 0.2645  loss_rpn_cls: 0.02283  loss_rpn_loc: 0.05681  time: 0.9427  data_time: 0.3160  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:38:06 d2.utils.events]: \u001b[0m eta: 0:20:59  iter: 159  total_loss: 1.297  loss_cls: 0.3983  loss_box_reg: 0.5422  loss_mask: 0.2595  loss_rpn_cls: 0.02485  loss_rpn_loc: 0.05265  time: 0.9356  data_time: 0.2505  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:38:25 d2.utils.events]: \u001b[0m eta: 0:20:21  iter: 179  total_loss: 1.322  loss_cls: 0.4088  loss_box_reg: 0.5688  loss_mask: 0.2737  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.05641  time: 0.9333  data_time: 0.2601  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:38:44 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 199  total_loss: 1.201  loss_cls: 0.3485  loss_box_reg: 0.5147  loss_mask: 0.2765  loss_rpn_cls: 0.01764  loss_rpn_loc: 0.04801  time: 0.9344  data_time: 0.2954  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:39:02 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 219  total_loss: 1.213  loss_cls: 0.3754  loss_box_reg: 0.4771  loss_mask: 0.2487  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.05855  time: 0.9338  data_time: 0.2810  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:39:21 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 239  total_loss: 1.117  loss_cls: 0.353  loss_box_reg: 0.4596  loss_mask: 0.2425  loss_rpn_cls: 0.01921  loss_rpn_loc: 0.05564  time: 0.9346  data_time: 0.2926  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:39:39 d2.utils.events]: \u001b[0m eta: 0:19:04  iter: 259  total_loss: 1.132  loss_cls: 0.3375  loss_box_reg: 0.4574  loss_mask: 0.2527  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.04712  time: 0.9304  data_time: 0.2840  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:39:58 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 279  total_loss: 1.096  loss_cls: 0.3515  loss_box_reg: 0.4645  loss_mask: 0.2335  loss_rpn_cls: 0.01565  loss_rpn_loc: 0.05407  time: 0.9311  data_time: 0.3093  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:40:17 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 299  total_loss: 1.134  loss_cls: 0.3332  loss_box_reg: 0.4908  loss_mask: 0.2495  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.04931  time: 0.9325  data_time: 0.3185  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:40:35 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 319  total_loss: 1.038  loss_cls: 0.3245  loss_box_reg: 0.4189  loss_mask: 0.2456  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.04743  time: 0.9313  data_time: 0.2979  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:40:53 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 339  total_loss: 1.009  loss_cls: 0.2865  loss_box_reg: 0.4167  loss_mask: 0.218  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.05384  time: 0.9305  data_time: 0.2610  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:41:13 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 359  total_loss: 1.105  loss_cls: 0.3115  loss_box_reg: 0.475  loss_mask: 0.2389  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.06224  time: 0.9324  data_time: 0.3201  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:41:32 d2.utils.events]: \u001b[0m eta: 0:17:23  iter: 379  total_loss: 1.097  loss_cls: 0.3197  loss_box_reg: 0.4358  loss_mask: 0.2245  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.05168  time: 0.9334  data_time: 0.3154  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:41:51 d2.utils.events]: \u001b[0m eta: 0:17:02  iter: 399  total_loss: 1.044  loss_cls: 0.3184  loss_box_reg: 0.416  loss_mask: 0.2114  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.05001  time: 0.9340  data_time: 0.3110  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:42:09 d2.utils.events]: \u001b[0m eta: 0:16:46  iter: 419  total_loss: 1.023  loss_cls: 0.2984  loss_box_reg: 0.4025  loss_mask: 0.2408  loss_rpn_cls: 0.009467  loss_rpn_loc: 0.04607  time: 0.9336  data_time: 0.2632  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:42:28 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 439  total_loss: 1.008  loss_cls: 0.2867  loss_box_reg: 0.4116  loss_mask: 0.2468  loss_rpn_cls: 0.009847  loss_rpn_loc: 0.05155  time: 0.9346  data_time: 0.3107  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:42:46 d2.utils.events]: \u001b[0m eta: 0:16:06  iter: 459  total_loss: 1.027  loss_cls: 0.3082  loss_box_reg: 0.4237  loss_mask: 0.2242  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.05143  time: 0.9330  data_time: 0.2439  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:43:04 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 479  total_loss: 1.046  loss_cls: 0.3455  loss_box_reg: 0.3905  loss_mask: 0.2469  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.04608  time: 0.9319  data_time: 0.2756  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:43:22 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 499  total_loss: 0.9635  loss_cls: 0.3151  loss_box_reg: 0.3734  loss_mask: 0.2122  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.0523  time: 0.9307  data_time: 0.2613  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:43:41 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 519  total_loss: 0.9727  loss_cls: 0.2528  loss_box_reg: 0.384  loss_mask: 0.224  loss_rpn_cls: 0.009073  loss_rpn_loc: 0.04645  time: 0.9298  data_time: 0.2688  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:43:59 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 539  total_loss: 0.9983  loss_cls: 0.2765  loss_box_reg: 0.4021  loss_mask: 0.2388  loss_rpn_cls: 0.00854  loss_rpn_loc: 0.04426  time: 0.9291  data_time: 0.2560  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:44:17 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 559  total_loss: 0.9772  loss_cls: 0.2762  loss_box_reg: 0.3942  loss_mask: 0.221  loss_rpn_cls: 0.01032  loss_rpn_loc: 0.05336  time: 0.9291  data_time: 0.2840  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:44:37 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 579  total_loss: 0.8695  loss_cls: 0.2924  loss_box_reg: 0.3353  loss_mask: 0.194  loss_rpn_cls: 0.008608  loss_rpn_loc: 0.04602  time: 0.9303  data_time: 0.2941  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:44:55 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 599  total_loss: 1.024  loss_cls: 0.2888  loss_box_reg: 0.4149  loss_mask: 0.2381  loss_rpn_cls: 0.008503  loss_rpn_loc: 0.04956  time: 0.9302  data_time: 0.2772  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:45:14 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 619  total_loss: 0.9169  loss_cls: 0.246  loss_box_reg: 0.3638  loss_mask: 0.2044  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.04465  time: 0.9302  data_time: 0.2807  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:45:33 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 639  total_loss: 0.9617  loss_cls: 0.2659  loss_box_reg: 0.3699  loss_mask: 0.2087  loss_rpn_cls: 0.007774  loss_rpn_loc: 0.04681  time: 0.9307  data_time: 0.2989  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:45:52 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 659  total_loss: 0.9656  loss_cls: 0.2884  loss_box_reg: 0.3812  loss_mask: 0.2204  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.0521  time: 0.9319  data_time: 0.3125  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 03:46:10 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 679  total_loss: 0.9187  loss_cls: 0.2629  loss_box_reg: 0.3537  loss_mask: 0.209  loss_rpn_cls: 0.008837  loss_rpn_loc: 0.04725  time: 0.9309  data_time: 0.2938  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:46:29 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 699  total_loss: 0.9867  loss_cls: 0.2962  loss_box_reg: 0.3831  loss_mask: 0.1976  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.05106  time: 0.9317  data_time: 0.3127  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:46:48 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 719  total_loss: 0.9002  loss_cls: 0.2832  loss_box_reg: 0.3803  loss_mask: 0.2064  loss_rpn_cls: 0.00735  loss_rpn_loc: 0.04067  time: 0.9318  data_time: 0.3023  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:47:06 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 739  total_loss: 0.8888  loss_cls: 0.2623  loss_box_reg: 0.395  loss_mask: 0.1923  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.04701  time: 0.9307  data_time: 0.2609  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:47:25 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 759  total_loss: 0.8992  loss_cls: 0.2456  loss_box_reg: 0.3596  loss_mask: 0.2117  loss_rpn_cls: 0.007601  loss_rpn_loc: 0.04581  time: 0.9306  data_time: 0.2995  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:47:42 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 779  total_loss: 0.8905  loss_cls: 0.2621  loss_box_reg: 0.3767  loss_mask: 0.2299  loss_rpn_cls: 0.006289  loss_rpn_loc: 0.04236  time: 0.9293  data_time: 0.2485  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:48:01 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 799  total_loss: 0.8698  loss_cls: 0.2224  loss_box_reg: 0.3474  loss_mask: 0.2085  loss_rpn_cls: 0.007691  loss_rpn_loc: 0.04058  time: 0.9295  data_time: 0.3125  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:48:20 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 819  total_loss: 0.791  loss_cls: 0.2355  loss_box_reg: 0.3317  loss_mask: 0.2011  loss_rpn_cls: 0.01009  loss_rpn_loc: 0.04889  time: 0.9298  data_time: 0.3157  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:48:38 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 839  total_loss: 0.9361  loss_cls: 0.2704  loss_box_reg: 0.4095  loss_mask: 0.2017  loss_rpn_cls: 0.007378  loss_rpn_loc: 0.04614  time: 0.9296  data_time: 0.2865  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:48:56 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 859  total_loss: 0.8702  loss_cls: 0.2417  loss_box_reg: 0.3604  loss_mask: 0.1917  loss_rpn_cls: 0.008051  loss_rpn_loc: 0.04464  time: 0.9290  data_time: 0.2606  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:49:15 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 879  total_loss: 0.8804  loss_cls: 0.2681  loss_box_reg: 0.3486  loss_mask: 0.205  loss_rpn_cls: 0.007136  loss_rpn_loc: 0.0544  time: 0.9287  data_time: 0.2675  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:49:33 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 899  total_loss: 0.8119  loss_cls: 0.2462  loss_box_reg: 0.3361  loss_mask: 0.2067  loss_rpn_cls: 0.008665  loss_rpn_loc: 0.04491  time: 0.9289  data_time: 0.3105  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:49:50 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 919  total_loss: 0.8274  loss_cls: 0.2154  loss_box_reg: 0.3617  loss_mask: 0.195  loss_rpn_cls: 0.009554  loss_rpn_loc: 0.04261  time: 0.9270  data_time: 0.2334  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:50:09 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 939  total_loss: 0.8371  loss_cls: 0.2408  loss_box_reg: 0.3272  loss_mask: 0.2101  loss_rpn_cls: 0.005479  loss_rpn_loc: 0.05015  time: 0.9274  data_time: 0.2914  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:50:27 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 959  total_loss: 0.8112  loss_cls: 0.2446  loss_box_reg: 0.3292  loss_mask: 0.1987  loss_rpn_cls: 0.008633  loss_rpn_loc: 0.05  time: 0.9271  data_time: 0.2642  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:50:46 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 979  total_loss: 0.8419  loss_cls: 0.2407  loss_box_reg: 0.3205  loss_mask: 0.2051  loss_rpn_cls: 0.006947  loss_rpn_loc: 0.04049  time: 0.9274  data_time: 0.3063  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:51:05 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 999  total_loss: 0.825  loss_cls: 0.2078  loss_box_reg: 0.3513  loss_mask: 0.1891  loss_rpn_cls: 0.006769  loss_rpn_loc: 0.03773  time: 0.9272  data_time: 0.2900  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:51:23 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 1019  total_loss: 0.8058  loss_cls: 0.2119  loss_box_reg: 0.334  loss_mask: 0.1952  loss_rpn_cls: 0.007821  loss_rpn_loc: 0.04602  time: 0.9268  data_time: 0.2641  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:51:41 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1039  total_loss: 0.7629  loss_cls: 0.2015  loss_box_reg: 0.3233  loss_mask: 0.1971  loss_rpn_cls: 0.007315  loss_rpn_loc: 0.04371  time: 0.9262  data_time: 0.2698  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:52:00 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1059  total_loss: 0.7989  loss_cls: 0.2565  loss_box_reg: 0.3013  loss_mask: 0.1938  loss_rpn_cls: 0.006325  loss_rpn_loc: 0.05132  time: 0.9266  data_time: 0.2939  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:52:17 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 1079  total_loss: 0.7619  loss_cls: 0.2128  loss_box_reg: 0.3081  loss_mask: 0.1885  loss_rpn_cls: 0.00461  loss_rpn_loc: 0.0446  time: 0.9257  data_time: 0.2459  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:52:35 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 1099  total_loss: 0.7005  loss_cls: 0.2042  loss_box_reg: 0.2618  loss_mask: 0.1847  loss_rpn_cls: 0.006531  loss_rpn_loc: 0.03941  time: 0.9253  data_time: 0.2703  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:52:54 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 1119  total_loss: 0.7767  loss_cls: 0.207  loss_box_reg: 0.2981  loss_mask: 0.1867  loss_rpn_cls: 0.005129  loss_rpn_loc: 0.03599  time: 0.9252  data_time: 0.2566  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:53:12 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1139  total_loss: 0.7663  loss_cls: 0.2496  loss_box_reg: 0.2863  loss_mask: 0.1851  loss_rpn_cls: 0.005816  loss_rpn_loc: 0.05294  time: 0.9246  data_time: 0.2598  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:53:30 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1159  total_loss: 0.7244  loss_cls: 0.2384  loss_box_reg: 0.2633  loss_mask: 0.1809  loss_rpn_cls: 0.005757  loss_rpn_loc: 0.0377  time: 0.9244  data_time: 0.2665  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:53:48 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 1179  total_loss: 0.7132  loss_cls: 0.1867  loss_box_reg: 0.2697  loss_mask: 0.1808  loss_rpn_cls: 0.006248  loss_rpn_loc: 0.04158  time: 0.9239  data_time: 0.2588  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:54:04 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 1199  total_loss: 0.7584  loss_cls: 0.2269  loss_box_reg: 0.2802  loss_mask: 0.1986  loss_rpn_cls: 0.008584  loss_rpn_loc: 0.04154  time: 0.9224  data_time: 0.2227  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:54:24 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 1219  total_loss: 0.725  loss_cls: 0.2006  loss_box_reg: 0.2577  loss_mask: 0.1903  loss_rpn_cls: 0.005854  loss_rpn_loc: 0.0437  time: 0.9232  data_time: 0.3210  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:54:42 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 1239  total_loss: 0.7198  loss_cls: 0.1975  loss_box_reg: 0.2846  loss_mask: 0.2041  loss_rpn_cls: 0.00761  loss_rpn_loc: 0.04263  time: 0.9227  data_time: 0.2709  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:55:01 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 1259  total_loss: 0.7493  loss_cls: 0.2187  loss_box_reg: 0.3029  loss_mask: 0.193  loss_rpn_cls: 0.005548  loss_rpn_loc: 0.03872  time: 0.9229  data_time: 0.2768  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:55:19 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 1279  total_loss: 0.8039  loss_cls: 0.2358  loss_box_reg: 0.2774  loss_mask: 0.2081  loss_rpn_cls: 0.005346  loss_rpn_loc: 0.05335  time: 0.9232  data_time: 0.3188  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:55:37 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 1299  total_loss: 0.7891  loss_cls: 0.2188  loss_box_reg: 0.3254  loss_mask: 0.1828  loss_rpn_cls: 0.006177  loss_rpn_loc: 0.04338  time: 0.9226  data_time: 0.2355  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:55:56 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 1319  total_loss: 0.7449  loss_cls: 0.2401  loss_box_reg: 0.2846  loss_mask: 0.1993  loss_rpn_cls: 0.007458  loss_rpn_loc: 0.04492  time: 0.9226  data_time: 0.2707  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 03:56:14 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 1339  total_loss: 0.7897  loss_cls: 0.2224  loss_box_reg: 0.3248  loss_mask: 0.2054  loss_rpn_cls: 0.004589  loss_rpn_loc: 0.03792  time: 0.9226  data_time: 0.2789  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:56:32 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 1359  total_loss: 0.6977  loss_cls: 0.1969  loss_box_reg: 0.2747  loss_mask: 0.1953  loss_rpn_cls: 0.005881  loss_rpn_loc: 0.04475  time: 0.9220  data_time: 0.2449  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:56:50 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 1379  total_loss: 0.6878  loss_cls: 0.2079  loss_box_reg: 0.2903  loss_mask: 0.181  loss_rpn_cls: 0.00561  loss_rpn_loc: 0.03682  time: 0.9216  data_time: 0.2571  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:57:07 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 1399  total_loss: 0.7821  loss_cls: 0.2438  loss_box_reg: 0.2949  loss_mask: 0.2007  loss_rpn_cls: 0.005545  loss_rpn_loc: 0.03815  time: 0.9210  data_time: 0.2609  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 03:57:26 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 1419  total_loss: 0.8116  loss_cls: 0.2299  loss_box_reg: 0.3072  loss_mask: 0.2118  loss_rpn_cls: 0.009658  loss_rpn_loc: 0.05418  time: 0.9212  data_time: 0.2717  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:57:44 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 1439  total_loss: 0.7335  loss_cls: 0.2102  loss_box_reg: 0.307  loss_mask: 0.1904  loss_rpn_cls: 0.004897  loss_rpn_loc: 0.03937  time: 0.9210  data_time: 0.2591  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:58:02 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 1459  total_loss: 0.811  loss_cls: 0.2286  loss_box_reg: 0.3029  loss_mask: 0.2014  loss_rpn_cls: 0.006547  loss_rpn_loc: 0.04684  time: 0.9204  data_time: 0.2582  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:58:20 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1479  total_loss: 0.7127  loss_cls: 0.1907  loss_box_reg: 0.271  loss_mask: 0.1778  loss_rpn_cls: 0.005558  loss_rpn_loc: 0.04133  time: 0.9201  data_time: 0.2654  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:58:39 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7157  loss_cls: 0.2017  loss_box_reg: 0.2668  loss_mask: 0.1841  loss_rpn_cls: 0.005224  loss_rpn_loc: 0.03633  time: 0.9199  data_time: 0.2735  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 03:58:39 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:22:57 (0.9199 s / it)\n",
      "\u001b[32m[03/05 03:58:39 d2.engine.hooks]: \u001b[0mTotal training time: 0:23:00 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 03:58:40 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 03:58:40 d2.data.datasets.coco]: \u001b[0mLoaded 137 images in COCO format from /host/mic21-framework/server/uploads/scooter_gt.json\n",
      "scooter\n",
      "\u001b[32m[03/05 03:58:40 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 03:58:40 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 03:58:40 d2.data.datasets.coco]: \u001b[0mLoaded 137 images in COCO format from /host/mic21-framework/server/uploads/scooter_gt.json\n",
      "\u001b[32m[03/05 03:58:40 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 136 images left.\n",
      "\u001b[32m[03/05 03:58:40 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:-------------:|:-------------|\n",
      "|  scooter   | 171          | scooter rider | 132          |\n",
      "|            |              |               |              |\n",
      "|   total    | 303          |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 03:58:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 03:58:40 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 03:58:40 d2.data.common]: \u001b[0mSerializing 136 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 03:58:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.55 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 03:58:41 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 03:59:01 d2.utils.events]: \u001b[0m eta: 0:22:59  iter: 19  total_loss: 2.033  loss_cls: 0.5441  loss_box_reg: 0.9318  loss_mask: 0.4785  loss_rpn_cls: 0.02801  loss_rpn_loc: 0.01239  time: 1.0001  data_time: 0.3494  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:59:21 d2.utils.events]: \u001b[0m eta: 0:22:42  iter: 39  total_loss: 1.237  loss_cls: 0.2366  loss_box_reg: 0.749  loss_mask: 0.2376  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.01083  time: 0.9939  data_time: 0.3203  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:59:40 d2.utils.events]: \u001b[0m eta: 0:22:23  iter: 59  total_loss: 0.9379  loss_cls: 0.1823  loss_box_reg: 0.5322  loss_mask: 0.1712  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.01278  time: 0.9731  data_time: 0.2995  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 03:59:59 d2.utils.events]: \u001b[0m eta: 0:22:21  iter: 79  total_loss: 0.8045  loss_cls: 0.1484  loss_box_reg: 0.4531  loss_mask: 0.1434  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.01293  time: 0.9726  data_time: 0.3176  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:00:18 d2.utils.events]: \u001b[0m eta: 0:22:19  iter: 99  total_loss: 0.711  loss_cls: 0.1543  loss_box_reg: 0.392  loss_mask: 0.1367  loss_rpn_cls: 0.005042  loss_rpn_loc: 0.009522  time: 0.9674  data_time: 0.2926  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:00:39 d2.utils.events]: \u001b[0m eta: 0:22:23  iter: 119  total_loss: 0.7278  loss_cls: 0.141  loss_box_reg: 0.3989  loss_mask: 0.1435  loss_rpn_cls: 0.005817  loss_rpn_loc: 0.01008  time: 0.9772  data_time: 0.3329  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:00:58 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 139  total_loss: 0.6093  loss_cls: 0.1019  loss_box_reg: 0.3732  loss_mask: 0.1355  loss_rpn_cls: 0.006409  loss_rpn_loc: 0.008942  time: 0.9729  data_time: 0.2890  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:01:17 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 159  total_loss: 0.5925  loss_cls: 0.1125  loss_box_reg: 0.3376  loss_mask: 0.1312  loss_rpn_cls: 0.005308  loss_rpn_loc: 0.009548  time: 0.9728  data_time: 0.2886  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:01:36 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 179  total_loss: 0.5915  loss_cls: 0.1121  loss_box_reg: 0.3223  loss_mask: 0.141  loss_rpn_cls: 0.00276  loss_rpn_loc: 0.008599  time: 0.9727  data_time: 0.3256  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:01:56 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 199  total_loss: 0.5324  loss_cls: 0.1158  loss_box_reg: 0.3161  loss_mask: 0.126  loss_rpn_cls: 0.005271  loss_rpn_loc: 0.008973  time: 0.9741  data_time: 0.3156  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:02:15 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 219  total_loss: 0.5608  loss_cls: 0.1026  loss_box_reg: 0.3152  loss_mask: 0.131  loss_rpn_cls: 0.004046  loss_rpn_loc: 0.009274  time: 0.9722  data_time: 0.2797  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:02:35 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 239  total_loss: 0.5815  loss_cls: 0.103  loss_box_reg: 0.2957  loss_mask: 0.1274  loss_rpn_cls: 0.004195  loss_rpn_loc: 0.007483  time: 0.9747  data_time: 0.3365  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:02:55 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 259  total_loss: 0.5292  loss_cls: 0.08654  loss_box_reg: 0.2908  loss_mask: 0.1169  loss_rpn_cls: 0.003867  loss_rpn_loc: 0.008403  time: 0.9752  data_time: 0.2994  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:03:14 d2.utils.events]: \u001b[0m eta: 0:19:24  iter: 279  total_loss: 0.5212  loss_cls: 0.09765  loss_box_reg: 0.2808  loss_mask: 0.115  loss_rpn_cls: 0.005571  loss_rpn_loc: 0.007918  time: 0.9734  data_time: 0.3046  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:03:33 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 299  total_loss: 0.4917  loss_cls: 0.08439  loss_box_reg: 0.2977  loss_mask: 0.1254  loss_rpn_cls: 0.002665  loss_rpn_loc: 0.00713  time: 0.9734  data_time: 0.3069  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:03:53 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 319  total_loss: 0.4613  loss_cls: 0.08526  loss_box_reg: 0.2616  loss_mask: 0.1147  loss_rpn_cls: 0.003722  loss_rpn_loc: 0.008557  time: 0.9742  data_time: 0.3202  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:04:12 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 339  total_loss: 0.5033  loss_cls: 0.09703  loss_box_reg: 0.2698  loss_mask: 0.1143  loss_rpn_cls: 0.003641  loss_rpn_loc: 0.008292  time: 0.9722  data_time: 0.2968  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:04:31 d2.utils.events]: \u001b[0m eta: 0:18:03  iter: 359  total_loss: 0.4639  loss_cls: 0.09049  loss_box_reg: 0.2604  loss_mask: 0.1111  loss_rpn_cls: 0.002673  loss_rpn_loc: 0.007835  time: 0.9721  data_time: 0.3402  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:04:51 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 379  total_loss: 0.4689  loss_cls: 0.09318  loss_box_reg: 0.2594  loss_mask: 0.1247  loss_rpn_cls: 0.002038  loss_rpn_loc: 0.007617  time: 0.9726  data_time: 0.3222  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:05:10 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 399  total_loss: 0.4949  loss_cls: 0.1032  loss_box_reg: 0.2473  loss_mask: 0.1174  loss_rpn_cls: 0.002663  loss_rpn_loc: 0.008578  time: 0.9721  data_time: 0.3004  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:05:30 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 419  total_loss: 0.4849  loss_cls: 0.09761  loss_box_reg: 0.2543  loss_mask: 0.1162  loss_rpn_cls: 0.004196  loss_rpn_loc: 0.007577  time: 0.9719  data_time: 0.3156  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:05:51 d2.utils.events]: \u001b[0m eta: 0:17:02  iter: 439  total_loss: 0.4402  loss_cls: 0.07543  loss_box_reg: 0.2489  loss_mask: 0.1064  loss_rpn_cls: 0.001335  loss_rpn_loc: 0.006794  time: 0.9752  data_time: 0.3514  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:06:10 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 459  total_loss: 0.468  loss_cls: 0.06262  loss_box_reg: 0.2539  loss_mask: 0.1082  loss_rpn_cls: 0.002567  loss_rpn_loc: 0.007047  time: 0.9754  data_time: 0.3144  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:06:30 d2.utils.events]: \u001b[0m eta: 0:16:28  iter: 479  total_loss: 0.4565  loss_cls: 0.06838  loss_box_reg: 0.2511  loss_mask: 0.1156  loss_rpn_cls: 0.002898  loss_rpn_loc: 0.009623  time: 0.9758  data_time: 0.3223  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:06:50 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 499  total_loss: 0.4557  loss_cls: 0.07041  loss_box_reg: 0.2451  loss_mask: 0.1102  loss_rpn_cls: 0.002383  loss_rpn_loc: 0.008074  time: 0.9767  data_time: 0.3166  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:07:09 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 519  total_loss: 0.4421  loss_cls: 0.09036  loss_box_reg: 0.2321  loss_mask: 0.1047  loss_rpn_cls: 0.0019  loss_rpn_loc: 0.006284  time: 0.9759  data_time: 0.3207  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:07:28 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 539  total_loss: 0.4318  loss_cls: 0.07381  loss_box_reg: 0.2558  loss_mask: 0.109  loss_rpn_cls: 0.001878  loss_rpn_loc: 0.00768  time: 0.9756  data_time: 0.2967  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:07:47 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 559  total_loss: 0.4342  loss_cls: 0.05812  loss_box_reg: 0.242  loss_mask: 0.1072  loss_rpn_cls: 0.002586  loss_rpn_loc: 0.006988  time: 0.9744  data_time: 0.2950  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:08:07 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 579  total_loss: 0.4582  loss_cls: 0.07529  loss_box_reg: 0.2444  loss_mask: 0.109  loss_rpn_cls: 0.003826  loss_rpn_loc: 0.007  time: 0.9749  data_time: 0.3286  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:08:26 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 599  total_loss: 0.4245  loss_cls: 0.06454  loss_box_reg: 0.2364  loss_mask: 0.1102  loss_rpn_cls: 0.002171  loss_rpn_loc: 0.006758  time: 0.9743  data_time: 0.3052  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:08:46 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 619  total_loss: 0.4435  loss_cls: 0.0755  loss_box_reg: 0.2309  loss_mask: 0.1075  loss_rpn_cls: 0.001966  loss_rpn_loc: 0.008321  time: 0.9750  data_time: 0.3207  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:09:06 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 639  total_loss: 0.4402  loss_cls: 0.09568  loss_box_reg: 0.2211  loss_mask: 0.1094  loss_rpn_cls: 0.001752  loss_rpn_loc: 0.006744  time: 0.9752  data_time: 0.3335  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:09:25 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 659  total_loss: 0.4203  loss_cls: 0.07103  loss_box_reg: 0.2203  loss_mask: 0.1065  loss_rpn_cls: 0.003629  loss_rpn_loc: 0.008527  time: 0.9751  data_time: 0.3091  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 04:09:45 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 679  total_loss: 0.443  loss_cls: 0.07224  loss_box_reg: 0.2327  loss_mask: 0.09835  loss_rpn_cls: 0.001233  loss_rpn_loc: 0.007235  time: 0.9749  data_time: 0.3065  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:10:04 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 699  total_loss: 0.4039  loss_cls: 0.08006  loss_box_reg: 0.2172  loss_mask: 0.1046  loss_rpn_cls: 0.003103  loss_rpn_loc: 0.007074  time: 0.9749  data_time: 0.3154  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:10:24 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 719  total_loss: 0.3975  loss_cls: 0.06235  loss_box_reg: 0.2182  loss_mask: 0.1036  loss_rpn_cls: 0.001695  loss_rpn_loc: 0.007166  time: 0.9754  data_time: 0.3310  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:10:44 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 739  total_loss: 0.3751  loss_cls: 0.06275  loss_box_reg: 0.2001  loss_mask: 0.1186  loss_rpn_cls: 0.001721  loss_rpn_loc: 0.007073  time: 0.9761  data_time: 0.3164  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:11:03 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 759  total_loss: 0.3773  loss_cls: 0.05863  loss_box_reg: 0.2008  loss_mask: 0.1031  loss_rpn_cls: 0.001621  loss_rpn_loc: 0.006695  time: 0.9753  data_time: 0.3154  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:11:22 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 779  total_loss: 0.3929  loss_cls: 0.06169  loss_box_reg: 0.2045  loss_mask: 0.1046  loss_rpn_cls: 0.002358  loss_rpn_loc: 0.006286  time: 0.9751  data_time: 0.3065  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:11:42 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 799  total_loss: 0.3798  loss_cls: 0.06577  loss_box_reg: 0.2092  loss_mask: 0.09543  loss_rpn_cls: 0.0008107  loss_rpn_loc: 0.006408  time: 0.9754  data_time: 0.3400  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:12:02 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 819  total_loss: 0.391  loss_cls: 0.06309  loss_box_reg: 0.2092  loss_mask: 0.1071  loss_rpn_cls: 0.001999  loss_rpn_loc: 0.00722  time: 0.9753  data_time: 0.2925  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:12:21 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 839  total_loss: 0.3672  loss_cls: 0.05987  loss_box_reg: 0.199  loss_mask: 0.09291  loss_rpn_cls: 0.002002  loss_rpn_loc: 0.005781  time: 0.9752  data_time: 0.3193  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:12:41 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 859  total_loss: 0.408  loss_cls: 0.07758  loss_box_reg: 0.2181  loss_mask: 0.1008  loss_rpn_cls: 0.001895  loss_rpn_loc: 0.00856  time: 0.9761  data_time: 0.3355  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:13:01 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 879  total_loss: 0.4063  loss_cls: 0.07909  loss_box_reg: 0.2188  loss_mask: 0.1002  loss_rpn_cls: 0.003156  loss_rpn_loc: 0.008416  time: 0.9763  data_time: 0.3227  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:13:21 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 899  total_loss: 0.3433  loss_cls: 0.04998  loss_box_reg: 0.1955  loss_mask: 0.09626  loss_rpn_cls: 0.0008785  loss_rpn_loc: 0.007071  time: 0.9766  data_time: 0.3297  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:13:40 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 919  total_loss: 0.3843  loss_cls: 0.06305  loss_box_reg: 0.1978  loss_mask: 0.1025  loss_rpn_cls: 0.001639  loss_rpn_loc: 0.006858  time: 0.9767  data_time: 0.3283  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:14:00 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 939  total_loss: 0.3779  loss_cls: 0.05768  loss_box_reg: 0.2053  loss_mask: 0.1008  loss_rpn_cls: 0.002283  loss_rpn_loc: 0.00673  time: 0.9769  data_time: 0.3295  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:14:20 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 959  total_loss: 0.3755  loss_cls: 0.08156  loss_box_reg: 0.1913  loss_mask: 0.09308  loss_rpn_cls: 0.000899  loss_rpn_loc: 0.005737  time: 0.9772  data_time: 0.3005  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:14:39 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 979  total_loss: 0.3574  loss_cls: 0.05322  loss_box_reg: 0.1844  loss_mask: 0.1009  loss_rpn_cls: 0.001299  loss_rpn_loc: 0.007062  time: 0.9768  data_time: 0.2964  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:14:58 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 999  total_loss: 0.373  loss_cls: 0.05149  loss_box_reg: 0.1954  loss_mask: 0.09506  loss_rpn_cls: 0.001456  loss_rpn_loc: 0.007626  time: 0.9760  data_time: 0.2950  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:15:18 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 1019  total_loss: 0.3504  loss_cls: 0.04792  loss_box_reg: 0.1883  loss_mask: 0.09621  loss_rpn_cls: 0.0009258  loss_rpn_loc: 0.006113  time: 0.9761  data_time: 0.3206  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:15:37 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 1039  total_loss: 0.3409  loss_cls: 0.057  loss_box_reg: 0.1722  loss_mask: 0.09924  loss_rpn_cls: 0.001285  loss_rpn_loc: 0.006578  time: 0.9762  data_time: 0.3382  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:15:56 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 1059  total_loss: 0.3334  loss_cls: 0.05263  loss_box_reg: 0.1651  loss_mask: 0.09491  loss_rpn_cls: 0.001595  loss_rpn_loc: 0.006111  time: 0.9759  data_time: 0.3074  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:16:16 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 1079  total_loss: 0.322  loss_cls: 0.04891  loss_box_reg: 0.1642  loss_mask: 0.09549  loss_rpn_cls: 0.001426  loss_rpn_loc: 0.00672  time: 0.9756  data_time: 0.2963  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:16:36 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 1099  total_loss: 0.3302  loss_cls: 0.05683  loss_box_reg: 0.161  loss_mask: 0.09907  loss_rpn_cls: 0.001009  loss_rpn_loc: 0.005323  time: 0.9760  data_time: 0.3469  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:16:55 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 1119  total_loss: 0.3095  loss_cls: 0.04886  loss_box_reg: 0.1558  loss_mask: 0.09239  loss_rpn_cls: 0.002296  loss_rpn_loc: 0.006962  time: 0.9760  data_time: 0.3056  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:17:14 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 1139  total_loss: 0.2955  loss_cls: 0.05279  loss_box_reg: 0.155  loss_mask: 0.09192  loss_rpn_cls: 0.001176  loss_rpn_loc: 0.005665  time: 0.9755  data_time: 0.2894  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:17:34 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 1159  total_loss: 0.3469  loss_cls: 0.07101  loss_box_reg: 0.167  loss_mask: 0.1035  loss_rpn_cls: 0.001666  loss_rpn_loc: 0.006884  time: 0.9759  data_time: 0.3230  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:17:54 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 1179  total_loss: 0.3374  loss_cls: 0.04276  loss_box_reg: 0.1577  loss_mask: 0.1028  loss_rpn_cls: 0.001764  loss_rpn_loc: 0.006074  time: 0.9759  data_time: 0.3025  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:18:13 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 1199  total_loss: 0.3151  loss_cls: 0.06981  loss_box_reg: 0.1435  loss_mask: 0.08769  loss_rpn_cls: 0.00246  loss_rpn_loc: 0.006268  time: 0.9760  data_time: 0.3297  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:18:33 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 1219  total_loss: 0.3327  loss_cls: 0.08162  loss_box_reg: 0.1492  loss_mask: 0.09587  loss_rpn_cls: 0.001665  loss_rpn_loc: 0.00633  time: 0.9762  data_time: 0.3187  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:18:52 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 1239  total_loss: 0.3235  loss_cls: 0.05796  loss_box_reg: 0.155  loss_mask: 0.103  loss_rpn_cls: 0.001633  loss_rpn_loc: 0.006596  time: 0.9760  data_time: 0.3073  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:19:12 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 1259  total_loss: 0.298  loss_cls: 0.04598  loss_box_reg: 0.1415  loss_mask: 0.09465  loss_rpn_cls: 0.002345  loss_rpn_loc: 0.007327  time: 0.9759  data_time: 0.3302  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:19:32 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 1279  total_loss: 0.3252  loss_cls: 0.05433  loss_box_reg: 0.1563  loss_mask: 0.0968  loss_rpn_cls: 0.001954  loss_rpn_loc: 0.006394  time: 0.9762  data_time: 0.3296  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:19:50 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 1299  total_loss: 0.3075  loss_cls: 0.05521  loss_box_reg: 0.1419  loss_mask: 0.09517  loss_rpn_cls: 0.001585  loss_rpn_loc: 0.007092  time: 0.9754  data_time: 0.2947  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:20:10 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 1319  total_loss: 0.3253  loss_cls: 0.06011  loss_box_reg: 0.1555  loss_mask: 0.09122  loss_rpn_cls: 0.00163  loss_rpn_loc: 0.006298  time: 0.9757  data_time: 0.3299  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 04:20:30 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 1339  total_loss: 0.331  loss_cls: 0.06192  loss_box_reg: 0.1552  loss_mask: 0.1013  loss_rpn_cls: 0.001358  loss_rpn_loc: 0.007096  time: 0.9762  data_time: 0.3618  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:20:50 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 1359  total_loss: 0.2998  loss_cls: 0.0515  loss_box_reg: 0.1368  loss_mask: 0.09478  loss_rpn_cls: 0.001907  loss_rpn_loc: 0.00716  time: 0.9759  data_time: 0.2850  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:21:10 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 1379  total_loss: 0.2863  loss_cls: 0.04575  loss_box_reg: 0.1402  loss_mask: 0.09285  loss_rpn_cls: 0.001792  loss_rpn_loc: 0.006625  time: 0.9764  data_time: 0.3169  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:21:29 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 1399  total_loss: 0.3163  loss_cls: 0.05504  loss_box_reg: 0.1516  loss_mask: 0.098  loss_rpn_cls: 0.002027  loss_rpn_loc: 0.007227  time: 0.9762  data_time: 0.3278  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:21:48 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1419  total_loss: 0.3199  loss_cls: 0.06237  loss_box_reg: 0.1509  loss_mask: 0.09606  loss_rpn_cls: 0.001385  loss_rpn_loc: 0.005876  time: 0.9758  data_time: 0.3103  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:22:08 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1439  total_loss: 0.3139  loss_cls: 0.06551  loss_box_reg: 0.1393  loss_mask: 0.1026  loss_rpn_cls: 0.002529  loss_rpn_loc: 0.00672  time: 0.9759  data_time: 0.3288  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:22:28 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 1459  total_loss: 0.3196  loss_cls: 0.0483  loss_box_reg: 0.1479  loss_mask: 0.09369  loss_rpn_cls: 0.002014  loss_rpn_loc: 0.006806  time: 0.9762  data_time: 0.3310  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:22:47 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.2939  loss_cls: 0.06704  loss_box_reg: 0.1377  loss_mask: 0.09441  loss_rpn_cls: 0.001151  loss_rpn_loc: 0.005712  time: 0.9761  data_time: 0.3058  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:23:07 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.3172  loss_cls: 0.05167  loss_box_reg: 0.149  loss_mask: 0.1018  loss_rpn_cls: 0.001169  loss_rpn_loc: 0.00667  time: 0.9757  data_time: 0.2904  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:23:07 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:24:21 (0.9757 s / it)\n",
      "\u001b[32m[03/05 04:23:07 d2.engine.hooks]: \u001b[0mTotal training time: 0:24:24 (0:00:02 on hooks)\n",
      "New dataset\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 04:23:08 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 04:23:08 d2.data.datasets.coco]: \u001b[0mLoaded 139 images in COCO format from /host/mic21-framework/server/uploads/pole_vaulting_gt.json\n",
      "pole_vaulting\n",
      "\u001b[32m[03/05 04:23:09 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=10, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=36, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/05 04:23:09 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[03/05 04:23:09 d2.data.datasets.coco]: \u001b[0mLoaded 139 images in COCO format from /host/mic21-framework/server/uploads/pole_vaulting_gt.json\n",
      "\u001b[32m[03/05 04:23:09 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 139 images left.\n",
      "\u001b[32m[03/05 04:23:09 d2.data.build]: \u001b[0mDistribution of instances among all 9 categories:\n",
      "\u001b[36m|   category   | #instances   |   category   | #instances   |   category    | #instances   |\n",
      "|:------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
      "|    briefs    | 60           |    shorts    | 74           | athletic sock | 107          |\n",
      "| pole vaulter | 141          | jumping pole | 137          |   standard    | 66           |\n",
      "|   crossbar   | 95           |   tank top   | 125          |  jumper shoe  | 248          |\n",
      "|              |              |              |              |               |              |\n",
      "|    total     | 1053         |              |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/05 04:23:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/05 04:23:09 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/05 04:23:09 d2.data.common]: \u001b[0mSerializing 139 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/05 04:23:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.03 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (10, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (10,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (36, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (36,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (9, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (9,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 04:23:09 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[03/05 04:23:29 d2.utils.events]: \u001b[0m eta: 0:24:05  iter: 19  total_loss: 3.044  loss_cls: 1.094  loss_box_reg: 0.9486  loss_mask: 0.6168  loss_rpn_cls: 0.09174  loss_rpn_loc: 0.2865  time: 0.9850  data_time: 0.3459  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:23:49 d2.utils.events]: \u001b[0m eta: 0:24:14  iter: 39  total_loss: 2.519  loss_cls: 0.8204  loss_box_reg: 0.8441  loss_mask: 0.4553  loss_rpn_cls: 0.07566  loss_rpn_loc: 0.2682  time: 0.9817  data_time: 0.3251  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:24:08 d2.utils.events]: \u001b[0m eta: 0:24:34  iter: 59  total_loss: 2.208  loss_cls: 0.6931  loss_box_reg: 0.8788  loss_mask: 0.3564  loss_rpn_cls: 0.04825  loss_rpn_loc: 0.2632  time: 0.9789  data_time: 0.3266  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:24:27 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 79  total_loss: 2.027  loss_cls: 0.651  loss_box_reg: 0.7658  loss_mask: 0.3183  loss_rpn_cls: 0.04875  loss_rpn_loc: 0.2449  time: 0.9708  data_time: 0.3053  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:24:46 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 99  total_loss: 1.791  loss_cls: 0.5481  loss_box_reg: 0.7228  loss_mask: 0.2752  loss_rpn_cls: 0.03359  loss_rpn_loc: 0.2229  time: 0.9667  data_time: 0.3078  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:25:06 d2.utils.events]: \u001b[0m eta: 0:22:17  iter: 119  total_loss: 1.711  loss_cls: 0.5216  loss_box_reg: 0.6895  loss_mask: 0.246  loss_rpn_cls: 0.04005  loss_rpn_loc: 0.2461  time: 0.9660  data_time: 0.3010  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:25:25 d2.utils.events]: \u001b[0m eta: 0:21:57  iter: 139  total_loss: 1.518  loss_cls: 0.4409  loss_box_reg: 0.6333  loss_mask: 0.2138  loss_rpn_cls: 0.02887  loss_rpn_loc: 0.1983  time: 0.9656  data_time: 0.3265  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:25:44 d2.utils.events]: \u001b[0m eta: 0:21:38  iter: 159  total_loss: 1.528  loss_cls: 0.4389  loss_box_reg: 0.6068  loss_mask: 0.23  loss_rpn_cls: 0.02684  loss_rpn_loc: 0.2  time: 0.9628  data_time: 0.3144  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:26:02 d2.utils.events]: \u001b[0m eta: 0:21:17  iter: 179  total_loss: 1.632  loss_cls: 0.444  loss_box_reg: 0.6153  loss_mask: 0.216  loss_rpn_cls: 0.03207  loss_rpn_loc: 0.2911  time: 0.9572  data_time: 0.2846  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:26:21 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 199  total_loss: 1.439  loss_cls: 0.4261  loss_box_reg: 0.5598  loss_mask: 0.2108  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.1735  time: 0.9553  data_time: 0.2918  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:26:41 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 219  total_loss: 1.311  loss_cls: 0.3917  loss_box_reg: 0.569  loss_mask: 0.2016  loss_rpn_cls: 0.0304  loss_rpn_loc: 0.1616  time: 0.9588  data_time: 0.3249  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:27:00 d2.utils.events]: \u001b[0m eta: 0:20:20  iter: 239  total_loss: 1.389  loss_cls: 0.418  loss_box_reg: 0.5857  loss_mask: 0.1732  loss_rpn_cls: 0.02523  loss_rpn_loc: 0.2155  time: 0.9584  data_time: 0.3193  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:27:18 d2.utils.events]: \u001b[0m eta: 0:19:59  iter: 259  total_loss: 1.332  loss_cls: 0.3512  loss_box_reg: 0.5237  loss_mask: 0.1995  loss_rpn_cls: 0.02157  loss_rpn_loc: 0.252  time: 0.9549  data_time: 0.2921  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:27:37 d2.utils.events]: \u001b[0m eta: 0:19:36  iter: 279  total_loss: 1.293  loss_cls: 0.3611  loss_box_reg: 0.4966  loss_mask: 0.1857  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.1856  time: 0.9552  data_time: 0.3230  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:27:56 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 299  total_loss: 1.256  loss_cls: 0.3258  loss_box_reg: 0.5015  loss_mask: 0.1968  loss_rpn_cls: 0.01976  loss_rpn_loc: 0.2361  time: 0.9557  data_time: 0.3315  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:28:16 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 319  total_loss: 1.184  loss_cls: 0.308  loss_box_reg: 0.459  loss_mask: 0.1743  loss_rpn_cls: 0.02131  loss_rpn_loc: 0.2036  time: 0.9581  data_time: 0.3250  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:28:36 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 339  total_loss: 1.141  loss_cls: 0.3147  loss_box_reg: 0.4633  loss_mask: 0.1674  loss_rpn_cls: 0.01882  loss_rpn_loc: 0.2018  time: 0.9584  data_time: 0.3040  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:28:55 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 359  total_loss: 1.176  loss_cls: 0.309  loss_box_reg: 0.4957  loss_mask: 0.1862  loss_rpn_cls: 0.01956  loss_rpn_loc: 0.1836  time: 0.9589  data_time: 0.3419  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:29:13 d2.utils.events]: \u001b[0m eta: 0:18:03  iter: 379  total_loss: 1.141  loss_cls: 0.2789  loss_box_reg: 0.4711  loss_mask: 0.1664  loss_rpn_cls: 0.01939  loss_rpn_loc: 0.1869  time: 0.9563  data_time: 0.2936  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:29:32 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 399  total_loss: 1.174  loss_cls: 0.265  loss_box_reg: 0.4771  loss_mask: 0.1873  loss_rpn_cls: 0.019  loss_rpn_loc: 0.1587  time: 0.9565  data_time: 0.3155  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:29:51 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 419  total_loss: 1.134  loss_cls: 0.3081  loss_box_reg: 0.4436  loss_mask: 0.1811  loss_rpn_cls: 0.01851  loss_rpn_loc: 0.1936  time: 0.9551  data_time: 0.2853  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:30:10 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 439  total_loss: 1.131  loss_cls: 0.2767  loss_box_reg: 0.4662  loss_mask: 0.1621  loss_rpn_cls: 0.01823  loss_rpn_loc: 0.2124  time: 0.9557  data_time: 0.3200  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:30:29 d2.utils.events]: \u001b[0m eta: 0:16:46  iter: 459  total_loss: 1.085  loss_cls: 0.2428  loss_box_reg: 0.4559  loss_mask: 0.1583  loss_rpn_cls: 0.01662  loss_rpn_loc: 0.2052  time: 0.9548  data_time: 0.3016  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:30:48 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 479  total_loss: 1.045  loss_cls: 0.2409  loss_box_reg: 0.434  loss_mask: 0.1624  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.1871  time: 0.9550  data_time: 0.3182  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:31:08 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 499  total_loss: 1.079  loss_cls: 0.2747  loss_box_reg: 0.4518  loss_mask: 0.1755  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.1732  time: 0.9562  data_time: 0.3347  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:31:27 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 519  total_loss: 1.038  loss_cls: 0.2804  loss_box_reg: 0.4087  loss_mask: 0.151  loss_rpn_cls: 0.0183  loss_rpn_loc: 0.1965  time: 0.9563  data_time: 0.2928  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:31:47 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 539  total_loss: 0.9877  loss_cls: 0.2439  loss_box_reg: 0.4009  loss_mask: 0.1597  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.1403  time: 0.9570  data_time: 0.3346  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:32:06 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 559  total_loss: 1.017  loss_cls: 0.2384  loss_box_reg: 0.3867  loss_mask: 0.1542  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.1793  time: 0.9569  data_time: 0.3030  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:32:26 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 579  total_loss: 1.119  loss_cls: 0.2556  loss_box_reg: 0.4298  loss_mask: 0.1592  loss_rpn_cls: 0.01626  loss_rpn_loc: 0.1808  time: 0.9581  data_time: 0.3349  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:32:45 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 599  total_loss: 0.977  loss_cls: 0.2383  loss_box_reg: 0.4052  loss_mask: 0.1719  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.1866  time: 0.9586  data_time: 0.3264  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:33:04 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 619  total_loss: 1.024  loss_cls: 0.2165  loss_box_reg: 0.4039  loss_mask: 0.1512  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.1982  time: 0.9587  data_time: 0.3111  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:33:24 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 639  total_loss: 1.03  loss_cls: 0.2567  loss_box_reg: 0.4074  loss_mask: 0.1535  loss_rpn_cls: 0.01416  loss_rpn_loc: 0.1839  time: 0.9588  data_time: 0.3161  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:33:43 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 659  total_loss: 1.076  loss_cls: 0.2565  loss_box_reg: 0.4061  loss_mask: 0.1617  loss_rpn_cls: 0.014  loss_rpn_loc: 0.1902  time: 0.9586  data_time: 0.3202  lr: 0.001  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 04:34:01 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 679  total_loss: 0.9421  loss_cls: 0.2058  loss_box_reg: 0.3888  loss_mask: 0.1573  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.171  time: 0.9573  data_time: 0.2881  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:34:20 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 699  total_loss: 0.9458  loss_cls: 0.2363  loss_box_reg: 0.3763  loss_mask: 0.1544  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.1792  time: 0.9566  data_time: 0.2975  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:34:39 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 719  total_loss: 1.013  loss_cls: 0.2363  loss_box_reg: 0.3954  loss_mask: 0.1494  loss_rpn_cls: 0.013  loss_rpn_loc: 0.1473  time: 0.9575  data_time: 0.3217  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:34:58 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 739  total_loss: 0.9285  loss_cls: 0.1907  loss_box_reg: 0.3635  loss_mask: 0.1442  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.1864  time: 0.9571  data_time: 0.3046  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:35:17 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 759  total_loss: 0.9347  loss_cls: 0.2099  loss_box_reg: 0.388  loss_mask: 0.1676  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.1769  time: 0.9563  data_time: 0.2870  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:35:35 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 779  total_loss: 0.9493  loss_cls: 0.2124  loss_box_reg: 0.3633  loss_mask: 0.163  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.1479  time: 0.9556  data_time: 0.2981  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:35:54 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 799  total_loss: 0.9484  loss_cls: 0.2163  loss_box_reg: 0.3783  loss_mask: 0.1451  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.1675  time: 0.9553  data_time: 0.2962  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:36:14 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 819  total_loss: 0.9181  loss_cls: 0.2134  loss_box_reg: 0.3629  loss_mask: 0.1544  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.1719  time: 0.9559  data_time: 0.3214  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:36:33 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 839  total_loss: 0.8997  loss_cls: 0.1959  loss_box_reg: 0.3781  loss_mask: 0.1449  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.1255  time: 0.9558  data_time: 0.3011  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:36:52 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 859  total_loss: 0.8901  loss_cls: 0.1877  loss_box_reg: 0.3665  loss_mask: 0.1439  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.1618  time: 0.9560  data_time: 0.3133  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:37:11 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 879  total_loss: 0.8725  loss_cls: 0.1733  loss_box_reg: 0.378  loss_mask: 0.1428  loss_rpn_cls: 0.01262  loss_rpn_loc: 0.1545  time: 0.9559  data_time: 0.3035  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:37:31 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 899  total_loss: 0.8501  loss_cls: 0.2043  loss_box_reg: 0.368  loss_mask: 0.1315  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.1508  time: 0.9567  data_time: 0.3483  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:37:50 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 919  total_loss: 0.918  loss_cls: 0.2208  loss_box_reg: 0.3813  loss_mask: 0.1408  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.1406  time: 0.9561  data_time: 0.3058  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:38:08 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 939  total_loss: 0.8633  loss_cls: 0.1708  loss_box_reg: 0.3487  loss_mask: 0.1401  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.175  time: 0.9551  data_time: 0.3025  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:38:28 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 959  total_loss: 0.8483  loss_cls: 0.1977  loss_box_reg: 0.3594  loss_mask: 0.1544  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.1515  time: 0.9560  data_time: 0.3418  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:38:47 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 979  total_loss: 0.9228  loss_cls: 0.1784  loss_box_reg: 0.384  loss_mask: 0.1496  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.1497  time: 0.9561  data_time: 0.3102  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:39:06 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 999  total_loss: 0.8682  loss_cls: 0.1679  loss_box_reg: 0.3665  loss_mask: 0.1421  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.1362  time: 0.9558  data_time: 0.3087  lr: 0.001  max_mem: 0M\n",
      "\u001b[32m[03/05 04:39:25 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 1019  total_loss: 0.9423  loss_cls: 0.1954  loss_box_reg: 0.3495  loss_mask: 0.1404  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.1416  time: 0.9558  data_time: 0.3115  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:39:44 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 1039  total_loss: 0.8586  loss_cls: 0.1681  loss_box_reg: 0.3453  loss_mask: 0.1406  loss_rpn_cls: 0.009868  loss_rpn_loc: 0.1621  time: 0.9558  data_time: 0.3122  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:40:04 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 1059  total_loss: 0.81  loss_cls: 0.1682  loss_box_reg: 0.3247  loss_mask: 0.1424  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.1252  time: 0.9559  data_time: 0.3191  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:40:23 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 1079  total_loss: 0.82  loss_cls: 0.1547  loss_box_reg: 0.3448  loss_mask: 0.1467  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.1464  time: 0.9561  data_time: 0.3186  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:40:41 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 1099  total_loss: 0.7906  loss_cls: 0.1682  loss_box_reg: 0.305  loss_mask: 0.1407  loss_rpn_cls: 0.01212  loss_rpn_loc: 0.1443  time: 0.9553  data_time: 0.2992  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:41:01 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 1119  total_loss: 0.7798  loss_cls: 0.1647  loss_box_reg: 0.3081  loss_mask: 0.1272  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.1375  time: 0.9555  data_time: 0.3192  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:41:20 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1139  total_loss: 0.791  loss_cls: 0.1746  loss_box_reg: 0.3047  loss_mask: 0.143  loss_rpn_cls: 0.01235  loss_rpn_loc: 0.1492  time: 0.9560  data_time: 0.3314  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:41:40 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 1159  total_loss: 0.8084  loss_cls: 0.1617  loss_box_reg: 0.3108  loss_mask: 0.1402  loss_rpn_cls: 0.009452  loss_rpn_loc: 0.1167  time: 0.9563  data_time: 0.3257  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:41:59 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 1179  total_loss: 0.7566  loss_cls: 0.1715  loss_box_reg: 0.3108  loss_mask: 0.1565  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.1333  time: 0.9564  data_time: 0.3216  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:42:18 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 1199  total_loss: 0.7424  loss_cls: 0.1513  loss_box_reg: 0.2702  loss_mask: 0.1476  loss_rpn_cls: 0.008795  loss_rpn_loc: 0.1234  time: 0.9561  data_time: 0.3091  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:42:37 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 1219  total_loss: 0.7266  loss_cls: 0.1512  loss_box_reg: 0.2856  loss_mask: 0.1291  loss_rpn_cls: 0.009528  loss_rpn_loc: 0.1528  time: 0.9558  data_time: 0.3191  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:42:55 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 1239  total_loss: 0.7897  loss_cls: 0.1745  loss_box_reg: 0.3082  loss_mask: 0.1585  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.1277  time: 0.9556  data_time: 0.2917  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:43:15 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 1259  total_loss: 0.7536  loss_cls: 0.164  loss_box_reg: 0.2846  loss_mask: 0.1364  loss_rpn_cls: 0.009891  loss_rpn_loc: 0.1621  time: 0.9559  data_time: 0.3184  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:43:33 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 1279  total_loss: 0.7509  loss_cls: 0.169  loss_box_reg: 0.3142  loss_mask: 0.1438  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.134  time: 0.9554  data_time: 0.3162  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:43:53 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 1299  total_loss: 0.7957  loss_cls: 0.161  loss_box_reg: 0.2929  loss_mask: 0.1387  loss_rpn_cls: 0.008443  loss_rpn_loc: 0.1242  time: 0.9557  data_time: 0.3282  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:44:11 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 1319  total_loss: 0.831  loss_cls: 0.1772  loss_box_reg: 0.3184  loss_mask: 0.1428  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.1306  time: 0.9550  data_time: 0.2970  lr: 5e-05  max_mem: 0M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/05 04:44:30 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 1339  total_loss: 0.825  loss_cls: 0.1642  loss_box_reg: 0.3099  loss_mask: 0.1406  loss_rpn_cls: 0.009872  loss_rpn_loc: 0.1563  time: 0.9552  data_time: 0.3141  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:44:50 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 1359  total_loss: 0.7072  loss_cls: 0.1434  loss_box_reg: 0.2843  loss_mask: 0.1291  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.1482  time: 0.9556  data_time: 0.3376  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:45:10 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 1379  total_loss: 0.7944  loss_cls: 0.1543  loss_box_reg: 0.3008  loss_mask: 0.1451  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.1485  time: 0.9559  data_time: 0.3313  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:45:29 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 1399  total_loss: 0.7129  loss_cls: 0.1349  loss_box_reg: 0.2912  loss_mask: 0.1398  loss_rpn_cls: 0.009904  loss_rpn_loc: 0.1365  time: 0.9557  data_time: 0.3115  lr: 5e-05  max_mem: 0M\n",
      "\u001b[32m[03/05 04:45:48 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 1419  total_loss: 0.7296  loss_cls: 0.1516  loss_box_reg: 0.2762  loss_mask: 0.1373  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.1328  time: 0.9562  data_time: 0.3223  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:46:07 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 1439  total_loss: 0.7776  loss_cls: 0.1609  loss_box_reg: 0.2914  loss_mask: 0.1393  loss_rpn_cls: 0.01  loss_rpn_loc: 0.1475  time: 0.9556  data_time: 0.2881  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:46:26 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 1459  total_loss: 0.7589  loss_cls: 0.1773  loss_box_reg: 0.2752  loss_mask: 0.141  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.1501  time: 0.9555  data_time: 0.3211  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:46:45 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 1479  total_loss: 0.8056  loss_cls: 0.1653  loss_box_reg: 0.322  loss_mask: 0.1271  loss_rpn_cls: 0.008082  loss_rpn_loc: 0.1544  time: 0.9555  data_time: 0.2882  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:47:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.7724  loss_cls: 0.1555  loss_box_reg: 0.2914  loss_mask: 0.1383  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.1489  time: 0.9555  data_time: 0.3162  lr: 2.5e-06  max_mem: 0M\n",
      "\u001b[32m[03/05 04:47:05 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:23:51 (0.9555 s / it)\n",
      "\u001b[32m[03/05 04:47:05 d2.engine.hooks]: \u001b[0mTotal training time: 0:23:53 (0:00:02 on hooks)\n"
     ]
    }
   ],
   "source": [
    "training_categ = ['chess', 'skiing', 'weightlifting', 'climbing', 'cricket', 'flying', 'hockey', 'soccer', 'volleyball', 'tennis', 'skateboarding', 'swimming', 'rowing', 'roller skating', 'horse racing', 'steeplechase', 'jogging', 'gymnastics', 'golf', 'diving', 'car racing', 'boxing', 'bowling', 'billiard', 'beach volleyball', 'basketball', 'baseball', 'jumping', 'running', 'acrobatics', 'airplane', 'glider', 'helicopter', 'hot-air_balloon', 'bicycle', 'camper', 'convertible', 'jeep', 'limousine', 'sedan', 'taxi', 'wagon', 'carriage', 'motorcycle', 'bus', 'minibus', 'tram', 'trolleybus', 'road sign', 'traffic police', 'zebra crossing', 'boat', 'ferry', 'gondola', 'motorboat', 'sailing vessel', 'ship', 'yacht', 'sleigh', 'rocket', 'spaceship', 'train', 'car transporter', 'dumper', 'garbage truck', 'lorry', 'pickup', 'tow truck', 'truck', 'van', 'bulldozer', 'digger', 'forklift', 'tractor', 'artist', 'sculptor', 'accordionist', 'piper', 'cellist', 'clarinetist', 'conductor', 'flute player', 'guitar player', 'opera singer', 'percussionist', 'piano player', 'rapper', 'saxophonist', 'singer', 'trombonist', 'trumpeter', 'violinist', 'ballet dancer', 'cameraman', 'clown', 'dancer', 'makeup artist', 'photographer', 'writer', 'figure skating', 'off road motorcycling', 'motorcycle racing', 'baby carriage', 'fire engine', 'fireman', 'police car', 'police helicopter', 'mounted police', 'policeman', 'wheelchair', 'fishing', 'hunting', 'tank', 'hang gliding', 'rhythmic gymnastics', 'horse sleigh', 'ambulance', 'dog sleigh', 'military helicopter', 'police boat', 'motorcycle police', 'soldier', 'double-decker', 'bicycle racing', 'handball', 'armoured personnel carrier', 'military truck', 'rickshaw', 'scooter', 'pole vaulting']\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml')\n",
    "cfg.MODEL.WEIGHTS = 'detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x/137260431/model_final_a54504.pkl'\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.WARMUP_ITERS = 0\n",
    "cfg.SOLVER.MAX_ITER = 1500 #adjust up if val mAP is still rising, adjust down if overfit\n",
    "cfg.SOLVER.STEPS = (1000, 1400)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 16\n",
    "cfg.TEST.EVAL_PERIOD = 2000\n",
    "cfg.MODEL.DEVICE='cuda:1'\n",
    "\n",
    "for folder_name in training_categ:\n",
    "    folder_name = folder_name.replace(' ','_')\n",
    "    try:\n",
    "        DatasetCatalog.remove(folder_name)\n",
    "        MetadataCatalog.remove(folder_name)\n",
    "        print('Update dataset')\n",
    "    except:\n",
    "        print('New dataset')\n",
    "    #register_coco_instances(folder_name,{},'/host/comparison/'+folder_name+'/'+folder_name+'_train.json','/host/comparison/'+folder_name+'/data/')\n",
    "    register_coco_instances(folder_name,{},'/host/mic21-framework/server/uploads/'+folder_name+'_gt.json','/host/mic21-framework/server/uploads/'+folder_name+'/')\n",
    "    \n",
    "    try:\n",
    "        del trainer\n",
    "    except:\n",
    "        print(\"Starting...\")\n",
    "    \n",
    "    ind = 0\n",
    "    img = DatasetCatalog.get(folder_name)[ind]['file_name']\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #v = Visualizer(img,MetadataCatalog.get(folder_name))\n",
    "    #v.draw_dataset_dict(DatasetCatalog.get(folder_name)[ind])\n",
    "    print(folder_name)\n",
    "\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #plt.imshow(v.get_output().get_image())\n",
    "    #plt.show()\n",
    "    \n",
    "    cfg.DATASETS.TRAIN = (folder_name,)\n",
    "    cfg.DATASETS.TEST = ()\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(folder_name).thing_classes)\n",
    "    \n",
    "    torch.cuda.init()\n",
    "        \n",
    "    trainer = NonCocoTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    try:\n",
    "        trainer.train()\n",
    "    except:\n",
    "        continue\n",
    "    trainer.checkpointer.save(folder_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
